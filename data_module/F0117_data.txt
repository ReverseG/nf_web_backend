压缩域视频水印及其在P2P流媒体中的应用研究	压缩域;视频转码;P2P流媒体;H.264;视频水印	视频水印是数字水印技术的重要分支。目前，视频水印研究侧重于空间域的水印算法及其应用研究。由于视频数据量大，通常压缩后进行存储和传输，故需要发展直接在压缩域嵌入和提取的视频水印算法。本申请通过分析编码后视频流的特点，研究压缩域视频水印理论及其在P2P流媒体应用中的若干关键技术。主要包括：(1)针对最新的视频编码国际标准H.264/AVC，分别提出适合于版权保护和视频认证的H.264视频流水印算法，并将其拓展到我国自行制定的AVS国家标准；(2)将视频转换编码与视频水印联合考虑，研究视频转码条件下水印的检测条件和率失真保证机制，并提出可抵抗压缩域视频转码的视频水印算法；(3)分析P2P流媒体的特点，研究适合于P2P流媒体的视频水印技术。预计研究成果可应用到数字视频产品的版权保护、内容认证和安全隐蔽通信等领域。在掌握自主知识产权的同时，使我国在这一领域处于国际前沿地位。
基于视差调整的3D视频重绘方法研究	视频后处理;3DTV;视频重绘;立体匹配	随着当前图像采集、编码、显示技术的持续发展，立体电视技术不断取得新的突破，已成为未来产业的重要增长点。但目前对3DTV的研究，大多集中于3D场景信息的获取、3D场景的表达、编解码、虚拟视点合成以及立体显示等方面，对于在立体视频在回放过程中所产生的一些视觉问题尚未引起重视。本项目通过对立体视频从拍摄到人眼感知整个过程的研究分析，首先指出了回放过程中各种因素所导致的视差变化，及其对人眼深度感知的影响。在此基础上，提出了一种基于视差调整的3D视频重绘方法，并在视差调整中考虑了人的视觉认知因素的影响。预期研究成果在给观众带来更好的观看体验的同时，可加强我国在3DTV这一未来重要增长点的自主创新能力、研究水平和主动地位。
安全稳健的图像感知哈希关键技术的研究	多媒体安全;混沌;感知哈希;图像认证;图像检索	感知哈希是多媒体内容的一种单向紧凑表示，在多媒体认证、检索、识别等领域有广泛的应用。本项目从视觉处理机制入手，借鉴信息、神经科学、混沌密码学的最新研究成果，研究感知稳健的、抗各种复杂攻击的、高安全性的感知图像哈希关键技术。具体的研究内容有：研究视觉基本机理，根据主视皮层的层次结构及其动力学模型，建立图像感知表示的计算模型和模型的实现方法，组合提取的特征与颜色等信息构建视皮层的全局感知特征，形成符合感知内容的稳健图像哈希方法；研究去除几何变换影响的方法，形成基于局部线性嵌入的抗几何变换的感知哈希方法；面向在复杂环境下的应用，研究基于SIFT的抗各种复杂攻击的感知哈希方法；研究利用混沌密码学建立感知哈希的安全机制，采用二维混沌映射，分段混沌映射来加强感知哈希的随机性与抗共谋的能力。研究的内容和方法发展和丰富了感知哈希的理论，并为其他多媒体信息服务提供技术支撑。
中文新闻广播故事自动分割技术研究	主题分割;语音识别;新闻检索;多媒体信息检索;新闻故事自动分割	故事自动化分割是实现新闻广播检索技术的先决条件。本项目旨在突破现有研究照搬英文方法的局限，探索更加适合中文新闻广播故事自动分割的新思想和新途径。首先，考虑汉字声调现象对基频等韵律特征的影响，提出声调归一化的中文韵律特征。利用中文组词灵活、分词多样和同音异形字众多的特点，提出在子词单元（汉字、音节）上进行词汇黏合关系度量的方法。其次，为缓解语音识别错误对故事分割正确性的影响，提出在语音识别网格上进行黏合关系测量的方法，从多个识别结果候选中修补由于识别错误而破损的词汇黏合关系。最后，针对固定信赖度不能反映各信息源对融合贡献不断变化的问题，提出采用分类器后验概率熵倒数作为信息源动态信赖度指标，对各信息源（声学信息、词汇信息）进行动态融合的新闻分割方法，既避免了固定信赖度对数据的过度依赖，又反映了各信息源的信赖程度随时间不断变化的事实。通过本项目的研究，提高中文新闻广播故事分割的自动化水平和性能。
基于故事的新闻视频语义分析模型与方法研究	新闻视频;故事分割;语义模型;故事跟踪;关联分析	视频语义分析和处理是视频内容分析技术中的热点和难点，在视频检索、媒体资产管理、情报分析、战略决策等领域有着广泛的应用。新闻视频作为视频数据中有代表性的一类媒体，对其进行语义分析方面的探索性研究具有重要意义。本项目以视频信息服务的应用需求为牵引，研究基于故事的新闻视频语义分析模型与方法。旨在建立合理的以新闻故事为基本语义单元的语义分析模型，并在此模型的指导下展开一系列关键技术的研究。具体包括新闻故事的分割技术、新闻故事的跟踪技术、新闻视频面向语义实体和语义事件的关联分析技术，以及基于故事的新闻主题探测与跟踪技术，从而改善视频信息的组织与检索方式，为视频分析、处理与挖掘提供理论基础和技术支持。该项目的研究在理论与实践上都具有非常重要的意义。它不仅可以提高新闻视频处理和情报分析的智能化程度，而且可以为更高级的事件趋势挖掘奠定技术基础，推动视频挖掘技术的进一步发展。
移动便携终端小屏幕视觉体验增强方法研究	主成份分析;高斯混合模型;手机视频;感兴趣区域;镜头分割与归类	随着第三代移动无线通信协议的发展与成熟，使得无线通信网络带宽日益增大，能够满足用户的多媒体业务需求。越来越多的移动终端用户喜欢通过手机观看各类视频。由于不同多媒体显示设备之间存在物理条件的差异，适合大屏幕的普通视频片源转换到小尺寸的手机屏幕上观看时，在视觉理解和感受上很容易导致人眼的不舒适感，很大程度上降低了用户对手机视频的视觉体验。因此，面对日益流行的移动多媒体业务，迫切需要从多个层面，研究一些能够专门针对手机小屏幕视频显示的相应方法，从而提高人们在小屏幕上观看视频的体验度。为此，本课题组从视频片源格式转换技术角度出发，针对小屏幕显示的智能视觉体验增强问题，提出一种合理的理论解决方案，同时，挖掘出关键技术模块，提出通过视觉感知窗口模型解决窗口大小自适应计算问题；感兴趣区域自动识别与时域更新算法；抑制快速大物体运动及摄像机运动干扰的鲁棒镜头联合分割算法；基于多模式归类的镜头归类算法。
基于多尺度几何分析和SVM的Web图像检索技术研究	自动标注模型;多尺度几何分析;Web图像检索;SVM	本项目研究基于多尺度几何分析和支撑矢量机(SVM)的Web图像检索问题,其中多尺度几何分析主要用于基于视觉内容的图像分割和特征提取,并辅助构造SVM的核函数；SVM用于完成图像分类,并辅助建立相应的自动标注模型.边缘和围线等信息是图像表示及其应用的关键,对人类视觉和计算机视觉至关重要,属于感兴趣区域,不同类型的图像体现为不同的特征;本项目对现有的具有多方向性和各项异性特点的图像的多尺度几何分析工具进行改进,并基于应用需求构建新的多尺度几何分析工具;在变换域对系数统计,结合改进的隐马尔柯夫模型并用于图像的分割,然后对分割后的主要对象作特征提取.通过对支撑矢量机的研究,结合所建立的多尺度几何分析基函数,确定多尺度几何分析核函数,并用于图像分类,辅助构成图像自动标注模型.本研究方案的成功实施将对多尺度几何分析、SVM和Web图像检索领域，及其融合交叉都具有重要的理论和应用价值。
基于激活力的音频场景表征及其在公共场合音频场景识别中的应用研究	音频场景识别;音频事件分类;音频分类	音频场景识别技术对实现智能化社会具有重要的研究价值。本申请拟基于激活力技术研究公共场合音频场景的识别。激活力技术是一种新的复杂网络分析技术。激活力可以很好地描述网络节点的网络结构，而基于激活力的相似性度量能很好地挖掘复杂网络中潜在的功能网络。激活力技术在文本分析领域得到了成功应用，可以准确得到表达同一语义的不同的词。音频场景识别技术和文本分析技术具有许多相似之处:音频场景相当于一段文本，音频场景中的音频事件相当于文本中的词，因此，可以借鉴文本分析技术来识别音频场景。基于此，本申请将激活力引入音频场景识别，用音频场景和音频事件之间的激活力来表征音频场景，进而实现识别。本申请引入激活力实质上是在激活力框架下将音频场景直接识别技术和基于音频事件的音频场景识别技术进行了有效结合。这种结合能更准确地表达音频场景和音频事件之间的激活力，进而能充分发挥激活力技术的优势，实现精确的音频场景识别。
面向非平行文本的说话人个性特征转换的关键技术及应用研究	个性特征转换;语音合成;语音转换	语音转换是实现高自然度个性化语音交互的核心技术，平行训练文本的瓶颈严重限制了该技术的广泛应用，本课题针对非平行文本条件下的说话人个性特征转换的关键问题和应用进行研究。在语音信号的韵律特性方面，注重多时间尺度韵律特征的提取与参数化表示，发展层次结构式概率统计模型对其进行融合与转换，自下而上地衔接底层信号特征提取和上层语音清晰度与自然度之间的断层。在频谱特性方面，自上而下地将语音学理论和语言学信息引入到频谱特征转换模型的分析和构建中，采用拓扑方法实现转换模型从欧氏空间向拓扑空间的转变；对于无法预先采集源说话人训练文本的实际情形提出"润色"修正的思想，实现任意源说话人直接向特定目标说话人的转换。本课题首次将自上而下和自下而上的方法论相结合，指导语音信号不同特性的分析与处理，以实现非平行文本条件下的高质量的说话人个性特征转换，为语音转换技术走向实际应用提供新的理论依据和技术支撑。
基于压缩感知理论的视频编解码技术研究	多媒体信息处理;视频重建;视频信息采集	随着压缩感知理论的逐步成熟，为突破以奈奎斯特采样定理为基础的信号处理框架提供了新的理论支撑，给视频图像信号的采集、编码、存储和处理等带来了前所未有的突破。本项目将研究基于压缩感知理论的视频编解码技术，将视频采集和视频编码进行深度融合，构建一套完整的压缩感知视频编解码技术框架体系，为压缩感知理论在视频编解码方面的应用提供理论支持和算法保证。主要研究内容包括：在视频感知测量方面，采用近似确定性感知测量矩阵，基于自适应感知测量模型对视频信号进行感知测量，利用感知域中的相关性对测量值进行预测、量化和熵编码；在视频图像重建方面，利用感知域中的时空相关性，研究一种基于预测残差的压缩感知视频重建算法；为了提高视频编码的率失真性能，还将对感知测量矩阵和稀疏字典进行联合优化，并使用序列化压缩感知技术来实现自适应压缩感知视频编码。通过本项目的研究将为压缩感知理论在视频编解码方面的应用提供技术参考和理论指导。
基于空间听觉感知的双耳语音分离和识别关键问题研究	深度神经网络;浮值掩蔽;双耳语音分离;空间线索;隐马尔科夫模型	混合声信号的分离和重构是人耳听觉系统感知和理解的基础，也是鲁棒语音信号处理的关键。针对基于听觉场景分析的单通路语音分离过分依赖基音周期估计准确性、无法分离清音等不足，本项目基于人耳听觉的空间感知机制，研究基于空间线索的双耳语音分离和识别中分离线索模型、分离机制等关键问题，具体内容包括：1)研究基于迭代结构的感知单元同时组织过程；2)将深度神经网络DNN作为分离线索的生成概率模型，研究基于隐马尔科夫模型HMM-DNN框架下的感知单元序列组织过程；3)针对语音识别，研究基于浮值掩蔽重构和丢失感知单元的分离目标语音声学模型优化问题。本项目将给出基于空间线索的双耳语音分离框架和识别算法，研究成果为鲁棒语音处理提供了新的研究思路和方向。
视频时空兴趣点检测与描述的几何代数方法	几何代数;视频时空兴趣点检测描述;视频信息处理;视频时空兴趣点检测;视频特征	随着视频数据的急剧增加，如何对海量视频进行智能分析已成为视频信息处理领域重要的研究课题。视频时空兴趣点是一类可以用于智能视频处理的重要特征，是智能视频搜索、事件检测、行为识别等智能视频分析的基础。由于它能从视频中直接提取，不需进行视频目标提取、跟踪等存在技术难点的中间环节，具有其他特征不可比拟的优越性，已引起国内外大量研究者的关注。但是，已有时空兴趣点检测与描述算法过多注重算法及其实现的研究，缺乏对视频时空域相关性进行有效、系统分析的模型与方法支持，缺乏将视频时空域上的相关性融入到算法中，影响了视频时空兴趣点的性能。本项目在我们原来的工作上，以几何代数为工具，建立新的视频处理与分析模型，分析和挖掘时空域相关性，研究一套新的融入了时空相关性的视频时空兴趣点的检测与描述算法，同时为视频处理提供新的方法和手段。
基于H无穷滤波的视频压缩运动估计算法研究	块匹配;Krein空间;运动估计;视频压缩;H无穷理论	运动估计性能的优劣直接影响到编码器的运行效率和整个视频序列的重构质量。当前研究多考虑改进各种快速搜索算法，减小运算复杂度。本项目结合快速搜索算法，充分利用图像帧的空间相关性构造带有不确定噪声干扰项的模型，引入H无穷控制理论，通过牺牲较少的计算负担获得运动向量的更精确的估计和更平滑的运动向量域，实现高补偿品质和视觉质量。本项目的创新之处首先在于估计框架的通用性，针对具体问题选择合适的快速搜索算法，便于物理实现；几何投影方法在Krein空间中的使用可以大大减小H无穷滤波方法的计算量；所构造模型的干扰项的不确定性更符合真实的场景，估计结果关于噪声扰动具有强鲁棒性等。研究的课题理论基础可靠，运动估计结果精确，所给方法对于运动估计的研究有重大突破。可以预见基于H无滤波的运动估计策略将拥有广阔的应用前景和适用范围，可以解决一系列对运动估计结果精度要求较高的问题（如数字电视、超高分辩率图像）。
三维声场中声源水平定位线索感知特性测量与分析	临界可感知差异;感知阈值;声源定位;空间音频编码;双耳线索	3D影视的兴起使三维音视频技术成为信息与通信行业的技术前沿和研究热点。三维音频系统声道数多、数据量大。通过简化系统和压缩数据来降低三维音频系统的声道数和数据量，是三维音频系统亟待解决的重要问题。双耳线索是三维声场中人耳对声源水平方位定位的重要依据，但是人耳对不同方位声源的双耳线索的感知敏感度具有较大的差异性。本项目针对双耳线索的感知敏感度特性，在水平面多个方位测量双耳线索的感知阈值；通过数学插值建立基于空间分布和频率特性的双耳线索感知阈值曲面，将传统的双耳线索感知阈值研究由定性描述拓展到定量分析；将该曲面模型应用于水平多声道信号的高效编码，提出基于感知阈值的多声道信号空间参数感知无失真量化方法。在传统单声道编码码率条件下，增加8kbps空间参数信息可获得优质的立体声重建信号。与现有参数立体声编码器相比，重建音质提升10个MUSHRA得分。研究成果对于三维音频信号的高效表达具有指导意义。
听音者声场扰动特性研究及三维声场重建优化技术	感知特性;空间参数;3D音频声场重建;恰可感知差异;声场扰动	传统音频系统无法重建三维空间声场，不能提供与三维影视对等的听觉体验。三维音频能为听音者带来全方位三维声场体验。与传统多声道三维声场重建方法主要针对不考虑听音者对声场扰动情况下的理想物理声场重建思想不同，本项申请研究面向听音者感知特性的多声道三维声场重建，针对听音者对多声道重建声场扰动带来的双耳信号变化规律，分析影响空间声像定位的关键频谱特征因素，构建多声道三维声场重建优化模型。其次，研究高效的多声道信号空间参数感知压缩编码方法。引入人耳空间方位感知特性建立空间参数恰可感知差异模型，实现空间参数空间感知无失真量化编解码重建方法。本研究预期与MPEG标准方法相比，空间参数同等编码码率下，空间声像水平方位角和高度角重建准确率分别提高30%和20%，可望推动三维音频空间感知特性基础研究、提升三维音频实际应用中的用户听觉感知体验。
多视角混合分辨率视频关键技术研究	视频处理;混合分辨率;视觉显著性;图像处理;超分辨	视觉融合与抑制原理表明，在满足一定图像峰值信噪比阈值条件下，非对称质量及分辨率的混合分辨率立体视频能获得与原始全分辨率视频的同等视觉感知质量，为多视角视频编码提供了新的研究方向。本项目以超分辨率重构高分辨率图像技术为基础，探索将多视角视频分解为混合分辨率视频的描述方法。本项目具体研究内容包括：（1）研究应用视内、视间的运动显著性及其静态显著性多维线索，构建多视角图像的视觉显著性线索空间，实现对多视角视频关键帧图像最优化提取算法。（2）研究将全分辨率图像信息分解为细节（高频）信息与结构（低频）信息，滤除非关键帧图像的细节信息，仅保留其结构信息的下抽样模型。（3）研究由于多视角图像配准与投影误差而导致的复杂局部运动条件下，关键帧的细节信息提取，以及将其融合到非关键帧的信息融合方法。
最大化泊松盘采样方法及其在媒体处理中的应用	动态网格生成;三维建模;最大化泊松圆盘;图像处理;采样	采样方法是多媒体和三维内容处理的基础技术之一，其中生成具有蓝噪声点集的最大化泊松圆盘采样方法是国际研究热点。本项目研究的内容为高质量的最大化泊松圆盘采样方法，以及在网格生成和多媒体信息处理的技术问题，有四个方面：①欧式空间中最大化泊松圆盘采样的理论及技术框架；②网格曲面上的采样及重新网格化，三维体内部采样及四面体网格生成；③动态区域的采样技术以及在多媒体处理中的应用（视频的点绘，流场可视化，三维动态形变网格生成等）， ④采样算法的评估方法。技术创新在于采样方法的理论分析和最大化泊松采样方法的技术关键、定位和提取已有采样点集的空隙区域、将该理论推广到三维网格曲面和三维形体内部、网格生成及优化算法。主要技术难点在于欧式空间以及曲面上空隙区域的定位以及提取，最大化泊松圆盘采样点集与网格生成之间的关系，以及针对不同动态区域的采样方法。
基于统一结构场模型的警务视频分析研究	结构场模型;警务视频;能量函数;参数学习推理	视频侦查技术是对警务视频进行分析和研判、获得有价值的线索或证据辅助侦查破案的公安技术。然而，当前公安工作中仍主要是通过人工处理完成，如能利用智能信息方法实现对于警务视频自动分析处理，则可大大提升公安部门的工作效率。本课题拟研究警务视频自动分析的统一结构场模型，以期通过构建统一结构场模型，利用共性的模型表述、状态推理和参数学习方法，尝试解决语义鸿沟问题，在警务视频发生较大变化时，仍可满足准确性、鲁棒性和效率性的组合检测需求。具体研究内容包括：1）警务视频目标提取的连续时空场模型；2）感兴趣的单语义目标检测的离散标记场模型；3）具有时序关系的目标组合检测的离散状态场模型。本项目的研究将会对于警务视频分析的理论和应用起到推进作用。
基于编码感知的高帧率高光谱视频获取及重建	稀疏表示;高分辨率;光谱视频;压缩感知;计算摄像	高光谱信息在诸多军用和民用领域具有重要的应用需求。对于动态目标和场景，需要快速地获取其高光谱信息，形成高光谱视频。然而，传统成像技术普遍采用"时分复用"的思想进行光谱信息获取，因此无法完成光谱视频获取的任务，高分辨率光谱视频获取技术遭遇原理瓶颈。.本项目基于计算成像理论，探索光谱信息获取的新机理、新途径和新技术，提出新型的光谱视频获取系统。特别地，本项目拟设计编码感知光谱成像新模式，实现光谱信息的高维度高分辨率获取，挖掘高维信号的内在属性，设计鲁棒和快速的优化重建算法，实现高质量的光谱视频重建。研究内容包括：1）基于编码感知的时-空-谱联合高分辨率光谱信息获取；2）基于高维信息相关性的高质量光谱视频重建算法。本项目预期在高光谱视频获取技术上有突破，有助于提升我国卫星高分辨对地观测的应用水平，为新一代成像光谱仪的研制奠定理论和技术基础。
图像尖锐性的测度及其在计算成像中的应用	自适应成像;尖锐性;图像;测度;最锐图像法	在计算成像中，由于各种因素的影响，观测数据可能出现偏差，进而导致图像质量下降。采用自适应成像算法可有效解决该问题。在各种自适应成像算法中，最锐图像法以其出色的成像质量和抗噪性能而获得了巨大的成功。然而，随着研究的深入，该算法的应用越来越受制于一个基本的数学问题，即图像尖锐性的测度。该问题的解决，不仅对各类计算成像而且对信号处理的其它领域都将产生重大的影响。本项目旨在建立图像尖锐性的测度理论。首先是解决图像尖锐性测度的统一问题，即抛开各种图像尖锐性测度的具体特点，发现其本质上的共性，从而找到图像尖锐性测度的一般形式。然后是解决图像尖锐性测度的设计问题，即找到图像尖锐性测度的一般设计方法，以便在其指导下，针对具体应用中图像的特点设计适用的尖锐性测度函数。此外，项目还将以合成孔径雷达成像为例，探讨图像尖锐性的测度理论在计算成像中的应用，以展示该理论的实际价值。
基于声学场景先验的远讲语音识别前端研究	语音增强和分离;远讲数据库;声学场景先验;远讲语音识别前端;深度学习	复杂的声学场景是导致"远讲"语音识别性能相比于"近讲"下降的重要原因之一，广义上的声学场景涵盖了语音自身特性以及其在"远讲"传输过程声学环境中噪声、混响等引入的非线性变化，远讲语音识别前端处理被用来克服这种变化。本项目针对现有的前端处理方法先验声学场景信息不足，鲁棒性受到制约的研究现状，希望通过设计和收集多维标注的远讲语音数据，引入深度学习方法分析和获取真实、有效、可靠的先验声学场景的声学参数和语音参数，并将其应用于基于物理模型方法与数据驱动方法的目标语音信号检测、估计和分离的前端，提升远讲语音识别前端的复杂声学场景鲁棒性。本项目对于最终实现远讲语音向近讲语音的映射，提升远讲语音识别率具有潜在应用价值和指导意义。
大规模视频数据的拷贝检测关键技术研究	互联网监管;指纹索引技术;拷贝检测;视频指纹	随着网络技术和多媒体技术的发展，网络视频的非法传播越来越多，这给大规模视频数据的监管带来了新的挑战。基于内容的视频拷贝检测技术是一种有效的视频监管方法，此技术利用视频内容本身的特征，提取出其特有的内容指纹信息，利用此信息来检测视频库中的视频是否为同一视频的拷贝版本，进而判断该视频的合法性。视频拷贝检测技术是一个新兴的研究领域，包括众多基础理论和实用技术，其研究具有重要的理论意义和广泛的应用价值。现有的视频拷贝检测技术尚不能满足大规模视频数据的检测需求，本课题将对大规模视频数据的拷贝检测技术展开研究，主要研究内容包括：视频指纹特征提取算法、指纹数据库索引策略和拷贝视频关联图分析挖掘算法等，并在以上关键技术与核心算法研究的基础上，探索基于拷贝检测技术的互联网视频监管方案。本课题力争在视频指纹处理的理论上有所突破，在视频拷贝检测的技术方法上有所创新，为该项技术的理论研究和实际应用奠定基础。
说话人识别中时变鲁棒的声纹特征研究	说话人识别;特征提取	说话人识别应用广泛，对于公共安全和国防安全等都有重要的战略意义。随着时间的推移，人的声纹会发生变化，从而严重影响说话人识别的精度，这就是声纹的时变现象。本项目针对这一现象，从声纹特征入手，研究说话人识别的时变鲁棒性问题。项目拟建设一个支持深入研究声纹时变性的语音数据库。在此数据库基础上采用数据驱动的方法，参照F比率的思想，探索人类语音基于频带能量的参数和基于声道模型短管截面积比的参数在说话人个体的区分度和概率分布稳定性上的规律，研究用于说话人识别的时变鲁棒性准则的计算公式；结合发声机理和听觉机理，通过短管合并、频率弯折、幅度加权等方式修改语音特征的计算方法，得到时变鲁棒的声纹特征提取算法；研究不同声纹特征时变鲁棒性优劣的判别准则，以指导声纹特征的选取与融合；构建原型系统，对所研究的声纹特征提取算法的正确性和有效性进行验证。
真实场景全视觉信息重建与生成	重光照;运动生成;三维重建;体素;外观采集	全视觉信息定义为真实场景中与人类视觉相关的信息，包括几何、运动和外观。对这些信息的重建与生成，已成为多媒体信息处理的前沿热点方向，逐渐应用于军事，教育，医学，工业设计，文化传媒等领域。然而，当前技术只能对部分视觉信息进行处理，大大局限了人类对现实场景的感知能力和对虚拟场景的生成能力。.本项目拟将全视觉信息作为整体进行研究，旨在实现全视觉信息的高效统一表达，高精度重建和高真实感渲染生成。首先，研究全视觉信息各要素的内在关联机制，建立基于多尺度体素的全视觉信息高效、统一表达框架；其次，搭建多源多视数据采集平台，研究数据、物理联合驱动的高精度全视觉信息解耦重建；最后，基于真实场景重建结果和各视觉信息的相互作用机理，实现几何、运动、外观自由可控的高真实感渲染生成。.本项目将围绕全视觉信息的基本原理，实现方法和实际应用三个方面展开工作，为全视觉信息处理技术的发展提供理论基础、技术支撑和应用拓展。
基于噪声分组和对抗训练的语音增强方法研究	深度神经网络;语音增强;深度卷积神经网络;语音估计;特征表示	智能语音技术在移动设备上的广泛应用给语音增强带来了新的挑战，深度学习技术的发展为解决该类问题提供了新的思路。针对制约基于深度学习的语音增强方法的实际应用的主要因素，本项目从三个方面展开研究：首先，为了提高语音增强性能，基于语音和噪声信号在时域和频域的相关性，采用深度卷积神经网络建立模型来估计和表示含噪语音中的语音成分，构建针对语音增强任务优化的网络结构；其次，针对模型泛化能力不足的问题，依据影响模型泛化能力的关键因素，建立基于对抗训练的语音增强模型来最小化环境因素对语音表示的影响；最后，针对单一模型下由训练集噪声特性的多样性带来的模型复杂度问题，提出针对噪声类型的噪声分组方法，并将其融入到对抗模型的训练过程中，建立基于噪声分组的语音增强系统。通过提升语音增强性能、提高模型泛化能力并降低模型复杂度，本项目的研究将促进基于深度学习的语音增强方法在实时语音处理系统中的应用。
基于视觉认知的立体视频舒适感重绘方法研究	视觉认知;视差调节;辐辏深度	观看立体视频时的视疲劳现象是目前平面立体显示技术中存着的普遍问题，其原因与视觉认知过程中的深度线索冲突有关，其中辐辏和聚焦调节之间的矛盾被认为是主要原因。本项目从人的视觉认知出发，提出了通过调整立体视频的视差信息进而改变辐辏深度的途径，来解决视疲劳问题的立体视频舒适感重绘方法研究。主要研究内容包括：1）舒适感立体视觉的认知学基础及立体视频疲劳度评价；2) 基于视觉注意机制的参考视差平面提取；3）基于Condition-Aware 的舒适感视差调整；4）基于视差调整的立体视频重绘方法。项目完成后，可望在心理层面揭示立体视频的视差信息在辐辏调节中的传导机制及其对视疲劳现象的影响，建立一种舒适感立体视频重绘的基本理论和方法。在给观众带来更好的观看体验的同时，加强我国在三维立体显示这一未来重要增长点的自主创新能力、研究水平和主动地位。
基于深度学习的压缩感知成像技术研究	测量矩阵;深度学习;图像重建;压缩感知成像	压缩感知成像在采集的同时对数据进行压缩，利用少量的测量值重建出原始图像。目前压缩感知图像重建过程都基于迭代算法求解约束问题，并行度难以提高，从而导致重建速度慢，成为阻碍压缩感知成像应用的瓶颈。近年来，有研究工作开始尝试将深度学习应用到压缩感知成像中，一方面将原有的图像重建问题，从最优化问题求解所必须的迭代计算，转变为不需迭代的深度网络重建问题；另一方面，深度学习可以训练得到更为有效的测量矩阵；这两方面的突破，使得快速高质量的压缩感知成像成为可能。在本项目中我们将面向快速高质量的压缩感知成像，利用深度学习技术开展压缩感知图像测量与重建工作。构建特定测量矩阵压缩感知重建网络，实现快速非迭代的压缩感知图像重建；构建端对端压缩感知图像测量-重建深度网络，学习更为高效的测量矩阵；进一步在网络设计过程中引入图像内部的局部相似性和图像的非相似性，提高网络的重建质量，最终实现压缩感知图像的快速高质量重建。
面向立体视觉的图上信号处理方法研究	稀疏表示;多视点彩色深度图像;图上信号处理;立体视觉	现有深度感知技术在分辨率、完整性、准确性等方面的不足难以支撑高质量三维场景呈现的需求，严重制约立体视觉领域的发展。本项目以新兴的图上信号处理理论为根基，突破平凡拓扑结构对探求多维度相关特性的束缚，发展立体视觉信息的图上稀疏表示理论，研究基于图上稀疏表示理论的立体视觉信息重建与处理方法。主要内容包括：1）探求立体视觉信息结构相关性，构建多视角彩色深度图像中基本信号单元在降质观测下近似不变的拓扑连接结构以及反映视点、空间、模态等多维度相关特性的自适应节点边权；2）探索图上立体视觉信号稀疏表示的分析与综合先验，并给出相应综合字典与分析字典的训练方法；3）针对普通单一先验难以紧致描述复杂立体视觉信号的问题，建立多重先验的图上视觉重建模型，并设计稳定快速的信号重建算法。利用所构建图上视觉信号稀疏重建模型，研究深度采样与编码，以及虚拟视点合成方法，形成一套基于图上稀疏重建的立体视觉处理原型系统。
开放场景下基于深度学习的时空信息融合行人再识别方法研究	深度学习;行人再识别;时空信息融合;视频检测;视频监控	行人目标识别是智能视频分析中最为重要的信息。在智能视频分析系统中多摄像头间的行人再识别具有重要的研究意义。针对当前开放场景下非重叠视域行人再识别所面临的瓶颈问题和关键技术，本项目致力于研究开放场景下基于深度学习的非重叠视域行人再识别理论、方法和关键技术，以实现对行人目标在跨越非重叠视域、消失后再现等情况下的再识别。本项目重点是基于深度学习的行人表观和步态鉴别特征提取、非重叠视域行人匹配和时空信息融合方法的研究。主要研究内容是，研究基于卷积神经网络和精细行人关键点及属性信息的行人表观鉴别性特征提取和描述，同时提高识别准确率；研究基于循环神经网络的行人时空信息提取方法和多视角步态特征匹配算法，实现对行人运动信息的提取与匹配；研究开放场景下非重叠视域行人表观特征和步态特征时空信息融合和匹配的方法，提高行人再识别性能。本项目将通过上述内容，研究和掌握开放场景下非重叠视域行人再识别关键技术。
复杂公共环境下群体行为尺度自适应建模与特定异常行为识别算法研究	复杂公共环境;尺度自适应;群体行为建模;异常行为识别;多特征联合分析	群体异常行为的准确检测是智能视频分析系统功能发挥的一个重要基础，但复杂公共环境会影响群体行为建模的准确性，从而降低异常行为的检测率。同时，传统异常行为检测算法不能识别特定群体异常行为，导致无法对严重异常行为优先响应。针对这些问题，本项目首先提取群体行为的多种特征进行联合分析，根据特征分析结果估计当前场景的人群拥挤程度，并基于拥挤程度设计尺度自适应的群体行为模型，有效提高了复杂公共环境下群体行为建模的准确性；然后，设计分层分类器识别特定群体异常行为，第一层分类器用于检测广义群体异常行为，第二层分类器用于识别特定群体异常行为；最后，在真实监控环境下搭建群体异常行为检测平台，验证并改进所提算法的性能。本项目的创新之处在于从新的角度考虑了影响群体行为模型准确性与异常行为检测实用性的关键因素，将有效解决复杂公共环境中难以识别特定群体异常行为的难题，具有重要的理论与应用价值。
基于小样本学习和多模态融合的人群行为识别研究	组群行为识别;视频分析;人行为识别;样本有限模型训练	视频内容分析和视频监控在日常生活及军事等各领域正发挥着越来越重要的作用。而人行为识别技术是视频内容分析和视频监控的关键技术。本项目拟结合申请人在行为识别和事件检测方面的前期研究工作以及模式识别和机器学习理论的发展趋势，分别从识别模型的构建和训练等方面对行为识别领域中的几个重要问题提出解决方法，主要体现为：（1）提出基于有限训练样本的模型训练方法，突破在训练样本不足的情况下难以构建良好识别模型的限制（2）提出新模型架构和算法来解决在多层次及成员人数可变情况下组群行为的识别问题（3）提出基于多模态融合的方法来进一步提高识别的准确率。目前，人行为识别的研究工作在国内外仍处于理论探索阶段，能用于实际应用的仍然很少，对于作为本项目研究重点之一的多人组群行为的识别问题，现阶段国内外的研究更是只处于起步阶段。因此本项目的研究成果将提高我国行为识别的基础研究水平，同时为实际应用提供新的理论依据和可行算法。
基于演化学习的名人识别技术与名人库构建研究	稀疏表示;条件随机场;人脸识别;视频上下文;关键人物标识	目前，多媒体数据随着信息传播速度加快而急剧增加。在这些数据中，体现人们共同关注焦点的名人（影视明星、政治人物等）数据具有很重要的价值。本研究正是针对名人图片视频识别和分析挖掘，旨在提出一种新的基于稀疏表示和条件随机场的人物识别算法以及模拟婴儿学习过程的半监督演化学习模型。同时，针对训练样本有限问题，利用视频上下文信息来解决，并构建海量名人数据库。简而言之，通过模仿婴儿成长的学习过程，在婴儿成长初期，首先给定有限静态图片，建立初始弱分类模型。然后，基于该模型将数据集中获得较确定判别的数据加入到知识库（训练库）中。最后，结合新加入样本，重新演化获得新模型至收敛。具体而言，本研究首先研究如何利用有限样本和多模态稀疏表示方法及随机场理论来构建高效人脸识别算法。其次，利用上下文信息，提出一种新的学习模型（演化学习模型）。最后，利用上述模型，自动采集大量图片视频构建基于HBase的海量名人数据库。
基于机器听觉及稀疏表示分类的音乐音频与语义符号比对研究	机器听觉;音乐乐谱比对;序列比对;稀疏表示分类器;音频内容分析	当前，迫切需要基于内容对海量、丰富的数字音乐资源进行有效定位、分析和检索，但相关系统性能的提升遭遇了音乐音频物理特征与语义内容脱节的瓶颈。因此,音乐音频与语义符号的比对研究是音乐内容分析、检索领域的关键研究问题之一。为此，本课题创新研究思路，拟将音乐音频信号的表示由声源端移至与认知直接相关的听觉端，尝试构建普遍适用于音乐音频各种声源的机器听觉系统,并结合欠定方程最小一范数凸优化的最新研究成果，为音乐音频语义符号比对提供新方法，以解决传统方法难以适应各种复杂多变音乐声源、音频事件，算法不稳定，过拟合等问题，从而达到有效提高音乐音频语义符号比对的准确度和精度的目的。本项目中机器听觉系统由听觉预处理、特征提取和分类判决构成开放式结构，还适用于其他基于内容的音频处理应用。相关研究成果将推动音乐音频内容定位、检索、交互式计算机虚拟乐器陪练、计算机伴奏系统、音乐评价系统等方面的研究。
基于人-物互信息模型的HOI行为异常侦测机制研究	APO距离;人-物互信息;人物交互行为;视频感知;异常行为侦测	心理学研究证明人-物交互作用在人体行为识别中具有非常重要的作用，但鲜有研究者在该方向做深入研究。本课题以人体异常行为识别问题为研究对象，提出了一种新的基于人-物互信息的异常行为侦测方法。主要工作包括：1）深入分析人-物共生关系，综合考虑人、物外观特征、几何特征，共生特征，引入刚体约束及人体动力学约束，融合多元信息，基于分层随机场思想构建人-物交互行为自适应表达模型；2）基于主动学习机制，引入原子动作字典，研究人体关节空间位置先验边缘分布特性及空间、动力学等多元约束，基于信息质心强化模型，反馈调整模型参数，完成样本池优化模型构建及新样本的分类策略智能调整；3）模拟人的自然思维模式，研究不同样本间行为、动作、目标物体之间的"距离"以表征行为的异常度，构建一种全新的APO距离异常行为度量机制。本项目研究有助于丰富和发展人体行为识别与理解的理论研究体系，并为异常行为侦测研究提供了全新的研究方向。
基于视觉关键词层次模型的遥感图像检索研究	视觉显著特征;视觉关键词;遥感图像检索;语义建模	本项目试图从研究符合人类视觉感知特性的遥感图像检索理论、模型和方法出发，为解决目前遥感图像数据应用领域"数据又多又少"的矛盾提供全新的解决途径。本项目以从遥感图像复杂的视觉特征中提取符合视觉特性的语义场景信息为目标，研究遥感图像视觉关键词层次模型、遥感图像语义建模、基于视觉关键词的检索算法等内容。首先提出将遥感图像视觉特征抽象为包含低层视觉词汇、中层关键模式及高层语义信息的视觉关键词层次模型，分别表示视觉特征元素的集合表达、低层视觉词汇的代表性实例表达及图像场景信息的语义表达，并通过自动聚类和机器学习理论建立层次间的关联和映射；进一步研究不同尺度遥感图像视觉显著特征提取模型、关键模式搜索和视觉关键词语义描述方法；最后研究基于遥感图像显著点、主色调和纹理构建多类别关键词模型的方法及视觉相似性度量模型等。本项目的研究对于解决从海量遥感图像库中快速定位和查找感兴趣目标问题具有理论意义及实用价值。
面向智能监控的高效视频分析和编码方法及芯片可实现性研究	智能视频分析;高效视频编码;芯片流水线;视频监控	集智能分析和高效编码于一身的高清晰度智能监控摄像头已成为敏感场所安全防范和重大事件应急管理的迫切需求，而研制新一代智能视频监控摄像头所面临的关键技术挑战则主要来自于对高清监控视频的高效编码表示和智能内容分析。本项目针对视频监控中的智能分析、高效编码方法及其计算复杂度和可实现性问题，从分析模型与方法、编码框架与算法、可实现性验证三个层次开展研究工作，重点突破监控视频自适应背景建模、基于视觉显著性的感兴趣对象提取、预定义安防事件的快速检测与索引、基于背景的高效监控视频编码算法、面向智能视频监控的三层编码框架、芯片多目标优化模型及方法、以及两层芯片高效流水线结构等方法和关键技术，建立一套集监控视频智能分析、高效视频编码和智能监控摄像头芯片流水线结构为一体的方法与技术体系，从而为新一代高清智能监控系统提供核心技术。
高时空分辨率的动态对象几何与运动信息获取方法	视频;多目;点云场景;双目立体匹配;形状理解	动态对象的几何信息和运动信息获取技术是计算机视觉和图形学中的热点研究问题，在动漫制作、虚拟现实等领域具有重要的应用价值。现有方法技术受到硬件条件和算法不足等多方面因素制约，无法达到高空间分辨率和高时间分辨率的双重获取要求。本项目针对这一问题，研究在现有硬件条件下动态对象高时空分辨率数字化信息的视觉获取方法和技术。主要研究内容包括快速高精度几何重建，拓扑变换下的运动信息计算以及基于运动信息引导的高精度动态序列重建。关键科学问题包括重建算法精度效率的平衡问题，多视角点云后处理问题，拓扑变化检测问题以及动态序列时空一致性重建问题等。主要技术创新包括保持细节的多尺度立体匹配算法，表面细节生成方法，基于拓扑变化的动态序列分割方法，基准模型选取方法和基于混合插值的动态序列重建方法等。本项目的研究成果可直接服务于国家产业需求。
情感语音音色分析及补偿方法研究	文语转换;个性特征转换;情感语音合成;语音合成;语音转换	语音交互是人类最基本的交互方式之一，语音中不仅包含着话语的内容信息，同时还包含了说话人的情感状态等信息。目前维度情感语音建模和生成的研究更多的关注于对韵律特征的建模，针对语音音色的分析和建模以及语音音色与情感状态的关系研究尚不成熟，从而制约了情感语音生成和自然人机交互的发展。针对该问题，本项目将对语音中的音色特征进行分析和处理，通过有效的音色补偿方法提高情感语音生成的表现力。本项目将在维度情感空间中分析语音音色与情感状态的关联关系，通过对语音音色特征的建模和补偿来控制语音的情感状态，并融合韵律特征补偿和音色特征补偿生成任意维度情感状态下的语音。本项目的研究可以同时促进情感语音合成、发音机理感知以及言语理解的推进，有助于促进人机语音交互技术的发展，具有很大的实际应用价值和重要的科学意义。
超复数小波变换理论及其在图像处理与分析中的应用研究	多尺度几何分析;超复数代数;彩色小波变换;调和分析	自然图像中存在大量线奇异的纹理特征结构，通常的实/复小波变换不能有效刻画此类信号的几何正则性与瞬时行为特征。此外，彩色图像的颜色通常表示为三维向量，现有标量形式的小波分析方式不能充分反映彩色像素颜色的矢量表征。本项目拟结合申请人在超复数小波方面的前期研究工作以及信号调和分析理论的发展趋势，分别从矢量域和解析域的角度提出"彩色小波"变换与超解析多尺度几何分析方法，主要体现为：（1）提出可逆的"彩色小波"变换理论，实现彩色矢量图像的多尺度小波描述机制，突破传统标量形式的小波变换方式。（2）基于多尺度空间理论和希尔伯特变换理论，在超解析域为线奇异的纹理图像结构建立多尺度几何分析工具。目前，超复数小波理论的研究工作在国内外还处于起步阶段，而以彩色矢量图像和超解析图像为处理对象的小波变换理论更有待建立，因此本项目的研究成果将提高我国小波理论的基础研究水平，为图像分析与处理提供新的理论依据和关健技术。
图像和视频空/时域相关性建模及其应用	视频处理;参数估计;噪声估计;相关性建模	图像及图像序列的空/时域相关性是实现视频信号预测和噪声分离的重要条件，它决定了视频压缩及处理算法所能达到的性能。目前，多数算法在做视频处理时仅部分利用信号的空域或时域相关性，从未将空/时域相关性作为一个系统问题加以考虑。本项目拟以多通道信号处理理论为基础，研究图像/视频的空/时域相关模型，对视频信号做2D+T的3D相关性建模，再依据所建模型深化图像/视频去噪声、视频超分辨率重建、视频帧率上变换和可分级视频编码等算法的研究，从而设计出性能更优的图像/视频处理算法。实现上述目标需研究解决的问题包括：图像/视频的相关性模型选择；相关性模型的参数估计；图像噪声估计及去噪；图像增强中的正则化算子设计；基于对象的分割和映射等问题。本项研究融合图像处理、统计信号处理和盲信号估计等前沿技术理论，在研究基础理论的同时关注研究的实用性，预期研究成果在国防军事、医学诊断和安防监控等领域有着广泛的应用。
基于深度强化学习的大尺度人群监控场景理解研究	多代理的强化学习;行为-评判模型;人群行为预测;群体运动结构;人群场景理解	针对当前监控视频分析中群体活动和突发事态管理的现实问题，本课题结合本领域的研究动态、发展趋势和申请者相关的工作基础，充分考虑大尺度群体行为的本质特征，综合运用群体动力学、计算机视觉、机器学习和流体动力学等多个领域的科学方法，对面临的关键问题和瓶颈进行研究和探索。本课题研究复杂监控人群场景状态表达和深度感知，包括空间变换的人群密度分布和一致性约束的语义分组；利用流体力学模型和社会力模型构建行为主体与环境交互的人群场景领域知识约束；研究联合深度学习和强化学习的Actor-Critic系统框架；通过基于领域知识约束的多Agents的组合强化学习模型获得价值最大的行为策略实现人群状态分析和行为的预测。本课题拟构建人群常态化监控和突发事件演进预测的研究方案，以期获得该交叉领域研究理论与技术的突破，为复杂的集群行为和场景的深度理解提供有效的算法和理论基础。
海量星球表面数据的多尺度合成方法研究	实时;纹理合成;地形合成;多尺度;图形处理单元	本项目针对轨道探测器获取的全星表数据分辨率不足、不能满足某些可视化应用的需求这一问题，将多尺度纹理合成方法应用于全星表探测数据超分辨合成。主要研究内容为海量星球表面数据(以DEM和DOM为主)的样本多尺度合成方法，以及GPU上的并行多尺度合成算法和加速方法。相比于传统的可视化方法，本项目研究的多尺度合成结合多尺度绘制的可视化方法具有层次细节丰富、硬盘存储少、加载数据少等特点，适合应用于全星表高分辨实时可视化系统。
多旋翼无人机机载智能安全监控关键技术研究	智能飞行机器人;图像配准;目标检测与跟踪;多旋翼无人机;智能监控	随着无人机的迅速发展，无人机机载智能安全监控的理念和构建方法已经越来越成为国际上前沿研究的热点，然而由于无人机平台的诸多限制，普遍存在稳定性差、复杂程度高、监控效率低等问题。且目前国内外研究大都着眼于固定翼无人机大范围监控，其飞行特性适合发现目标，因灵活性不足而不适合瞬时跟踪监控目标等任务。针对上述问题，本申请课题拟探索从固定翼向多旋翼无人机的机载智能安全监控发展的理念，研究各种机载传感器参数与智能安全监控的融合，构建准确、快速的图像配准方法来提升智能安全系统的精度和运行速度；并进一步以自适应背景模型为基础，针对性的探索适合多旋翼无人机智能监控任务的目标检测与追踪方法，提高监控效率和稳定性；通过智能安全监控系统和无人机导航与飞行控制系统的互联，提升无人机监控水平和灵活性。本申请项目有望在多旋翼无人机智能监控领域取得理论和技术上的突破，为进一步发展智能飞行机器人建立基础。
基于人数与局部运动的人群属性推演及安全状态预评估	异常事件检测;视频理解;群体事件预报;视频监控	人群分析是视频监控领域的热门问题，人群行为的复杂性和突发性使当前的视频监控系统仅能对已发生的异常进行报警，然而，在未发生异常前就对人群安全状态进行预评估将更有价值。人群异常事件的发生常伴随着人数及运动形态的变化，故此，本项目拟探究人群属性与安全状态间的关系，提出利用人数与局部运动进行人群属性推演和安全状态预评估的方法，主要内容包括：(1)人群分割与计数：探索基于图像流场可视化方法的人群运动纹理表达，通过纹理分割算法检测运动行人，进而抽取可描述人群人数的图像与流体粘滞性特征，利用神经网络估计场景中的人数；(2)局部运动结构抽取：探究基于物理特性的流场典型与非典型拓扑结构的抽取方式，构建描述粒子间关联的复杂网络模型，利用网络参数表征不同人群运动形态；(3)安全状态模糊决策：探索人群特征与安全状态间的相互关系，构建人群属性与安全状态间的推演方式，最终实现异常事件未发生前的人群安全状态等级评估。
基于感知模型和软计算的视频事件检测及关键技术研究	软计算;感知模型;视频检索	基于内容的视频检索是国际上在信息检索领域最前沿的研究方向之一。视频事件检测是对视频进行语义标注和分析最有效的手段。由于视频数据的复杂性以及不确定性，我们拟采用适用于不确定数据分析的软计算方法以及基于人类大脑神经科学的感知模型作为研究基础，开展视频事件检测算法研究。1.研究适合于视频、音频数据分析的软计算方法，并将其应用于视频镜头边界检测、音频分类当中。2.研究基于视觉、听觉感知模型以及生物感知原理的关键帧提取、特殊音效检测以及人脸目标检测方法。3. 根据提取到的音视频关键线索，将软计算方法与人脑感知认知理论相结合，构建适合于多种类型视频的事件检测模型。该项目的研究成果将为在视频中寻找感兴趣的事件提供有效工具，为多媒体检索技术的发展提供新的技术途径。另一方面，对于该项目的研究，促进了软计算方法以及人类大脑感知理论的发展。同时，也为计算机视觉、神经科学以及视频检索等领域搭建了一个桥梁。
基于音节模型的音频点播关键技术研究	音节模型;语音识别;环境补偿;混响语音处理;音频点播	针对汉语同音字多，音节较少, 多个汉字对应一个音节的特点，为每个汉语音节建立音频索引库，将用户发出的口语识别为音节序列。在匹配解码阶段，首先根据输入语音的音节序列信息，从音频索引库的相应音节条目中选取候选音频，再将输入语音的音节序列与候选音频的音节序列进行匹配解码。用音节序列匹配取代传统的文本匹配，提高了解码精度，降低了系统复杂度。在前端语音识别中，用非线性环境补偿技术对加性噪声、信道失真和室内混响进行补偿，提高语音识别的鲁棒性；并采用N-best算法选取前N个最有可能的语音单元作为输出结果，得到待识别语音的多个可能的音节序列，从而减小前端语音识别错误对后端音节序列匹配解码的影响。
大规模网络视频在线定位与地理信息挖掘技术研究	社区发现;网络视频内容监管;社会特征;网络视频在线定位;地理一致性	本项目面向网络视频监管的实际需求，开展基于社会信息的网络视频在线定位技术研究，以及基于社区结构的大规模网络视频地理信息挖掘和展示，最终建立一个基于地理空间的多层次的网络视频内容监管平台。.由于大量视频本身不包含可用地理信息，本项目提出地理一致性度量方法，从信息丰富的视频网络环境中提取具有地理属性的社会特征并形式化；.基于这些社会特征构成的稀疏的弱关联网络，进一步提出异构网络中的弱标签传播算法，在连通子图中快速传播地理标签，实现视频在线定位；同时通过对给定区域训练视觉和文本的地理背景模型，实现特定区域的视频地理位置确认；.最后，从这些已定位的大规模网络视频数据中挖掘地理社区结构，实现区域性网络视频事件检测，并以地图的形式进行预警和可视化展示，为决策者提供重要参考信息。本项目的研究成果将在广电总局互联网视听节目监管系统中进行验证，为国家视频监管提供关键技术。
基于电子全息的裸眼三维图像实时显示研究	立体重构;压缩编码;全息采集;实时显示;裸视三维	电子全息三维显示是全息技术和电子显示技术相结合的产物，是以电子形式来表示物体的3D信息。课题目的是研究电子全息3D图像实时裸眼显示机理，包括数字全息记录与再现、3D图像编码高速传输和裸视3D图像实时显示。.课题建立在一种将电子学和傅里叶光学紧密结合的基础上，来克服全光学系统或全电子学系统的缺陷，研究涉及多学科。采用高精度光敏电子元件作记录介质，不需要多个摄像头和光全息的繁琐后续处理，适合记录运动物体。采用液晶显示－空间光调制器（LCD-SLM）灵活控制信号，将信号所载荷的信息恰当的写进入射光波中，对数子全息光波二维分布的相位、振幅、频率、偏振态等特性进行空间和时间的调制，提高了传输速度和显示质量。采用GPU并列传输和复函数的编码合成计算，改善3D图像实时显示的解像度和对比度。.该研究对于电子全息高分辨率显微、裸视立体电视、三维人机交互通信以及国防等科学领域有着重要意义和应用价值。
高角度分辨率光场数据获取与图像生成方法研究	全局优化;深度图;计算摄影术;编码孔径;光场	光场成像技术是对传统成像模式的突破性创新。但现有采集设备获得数据的角度分辨率较低，导致光场图像质量下降，限制了光场成像技术的广泛应用。本项目将构建编码孔径与微镜头阵列结合的光场采集装置，在估计场景深度信息基础上实现角度超分辨重建，实现高质量光场图像的生成。具体的研究内容包括：1）研究编码孔径结构和装置内参数的优化设计方案，实现高角度分辨率光场数据的获取。2）研究场景深度与光场角度分辨率之间的耦合关系，建立基于深度先验的角度超分辨重建模型。3）研究角度分辨率与光场图像混叠现象之间的量化关系模型，寻求利用超分辨角度信息检测和去除图像混叠的方法。创新之处在于突破现有光场采集的折衷瓶颈，揭示深度信息与光场角度信息之间的本质联系，达到生成高质量光场图像的目的。本项目属于计算机视觉领域的基本理论与方法研究。研究成果对丰富光场成像理论体系、创新光场采集方法、推动光场成像技术的广泛应用具有重要作用。
基于单目视觉的实时人脸动画生成方法研究	稀疏表示;轮廓建模;轮廓提取;人脸动画;回归分析	以动画形式实时表现人脸的表情和动作变化，是颇具理论和实际意义的科研课题，在影片和游戏制作、虚拟会议场景构建等方面有广泛的应用价值。针对当前技术存在依赖专业视频采集设备、用户友好性差等弱点的问题，本项目拟研究设计一种基于普通单目视频采集设备的实时人脸动画生成方法。具体包括两部分研究内容：实时提取跟踪人脸轮廓，捕获视频中人脸的表情和动作；建立人脸轮廓关键点坐标向面部动画模型参数的映射，使所获取的面部表情和动作可以以动画形式实时表现出来。轮廓提取时，本项目将依据子空间约束和邻域内高斯分布构建人脸轮廓描述模型，并引入三维轮廓模型辅助处理人脸多姿态问题；在建立映射关系时，本项目将首先以稀疏表示系数投票的方式，提取动画模型中的关键参数，降低参数间的依赖性，再基于回归分析建立映射。本研究有助于人脸动画制作成本的降低和用户友好性的提升，同时可以有效促进人脸轮廓提取一般性方法和稀疏表示应用理论的发展。
多模态言语运动评估用于帕金森症构音障碍机制研究	病理语音信息;多模检测;无创检测;实时提取;定量评价	帕金森症构音障碍是帕金森症的核心症状之一，严重影响病人的情感、交流和日常生活。药物、手术治疗对帕金森症患者的言语困难改善的效果不佳。无法改善干预治疗方案的原因是当前对基底神经节功能以及其对言语运动系统的病理影响机制尚不能完全解释。本研究将致力于设计一系列创新性、多模态的言语运动功能评估体系，运用三维电磁发音运动跟踪、面部运动捕捉以及呼吸声学参数分析技术追踪发音器官运动特征，全面、客观地评估帕金森症对言语运动功能的影响以及多巴胺替代疗法对其改善作用。以此为基础，重构基底神经节功能模型及帕金森症构音障碍损伤模型，并明确非多巴胺能运动环路对言语运动功能的影响。最后，根据帕金森症构音障碍损伤模型及其临床表现，设计融合口面部运动和声学参数的新型帕金森症构音障碍评估系统。本研究的成果可用来指导未来的包括使用左旋多巴及言语康复治疗的干预性治疗手段的改进。
基于张量分析的空间音频信号压缩与重建技术研究	多声道音频恢复;空间音频对象编码;多声道音频编码;张量分析;空间音频信号	空间音频信号压缩与重建是未来临场感通信、交互娱乐、三维音视频等多媒体应用领域的重要研究方向，其往往受到声道、对象、时间、频率等多种因素的共同影响，大规模和高维度的空间音频数据对压缩和重建技术提出了挑战，而张量分析在处理多因素信号问题上具有天然的优势，能够充分挖掘空间音频的稀疏和低秩特点。本研究将致力于多声道和多对象空间音频的合理建模、高效压缩与有效重建关键问题，提出基于张量分析理论构建空间音频信号的高阶张量模型，通过引入张量分解技术对多声道音频及空间音频对象进行压缩编码，利用张量数据挖掘原理实现丢失声道情况下的空间音频重建，进一步结合空间音频特点和张量约束条件来提高压缩效率和重建效果，从而为空间音频信号处理研究领域提供新的建模方法和分析思路，具有重要的理论和应用意义。
面向用户的视频自动标注关键技术研究	视频标注;视频内容分析;知识迁移;稀疏编码	飞速增长的信息会导致人们注意力的稀缺性。个性化信息自动检索的目标是降低人们的信息负载量和缓解注意力稀缺的重要研究方向。本课题针对提高个性化视频内容的管理和分发效率，为用户有效的搜索和利用富媒体信息提供视频自动标注关键技术保障。面向用户的视频标注技术涉及的研究内容包括：视频内容的语义分析和表示、基于稀疏编码的中层语义表示、基于知识迁移的自动标注、个性化用户行为分析及个性化标注问题。课题将通过研究视频的语义分析和镜头场景等概念的抽取，结合用户的个性化分析和机器学习的方法，来对视频进行语义标注。面向交互式数字电视服务，建立一个真实的个性化视频标注及推介系统,将图像视频自动标注、视频结构化及语义分析、用户模型学习三个关键技术环节有机地结合，定位当前视频自动标注、个性化定制技术面向实际应用时存在的瓶颈，从而更进一步促进面向用户的视频自动标注理论与方法研究。
面向光栅式裸视3D显示的多视点视频重建与立体合成技术研究	视频;三维;重建;多视点合成;自由视点	本项目结合3D显示从助视走向裸视的发展趋势，面向基于光栅和2D平板显示器耦合而成的裸视3D显示技术，研究多视点视频的3D重建和立体合成技术。主要研究内容包括：面向提高平板式3D显示的立体视觉效果，研究多视点视差优化理论和方法，以取得健康、舒适、逼真的多视点环视效果；面向提高虚拟视点图像质量，探索在时间方向上对参考视点的3D场景信息进行积累和更新的方法，构造出基于多层"纹理＋深度"的3D全景，研究时空域信息联合的空洞修复算法，发展多视点视频的高质量重建技术；面向改善光栅式3D显示质量，研究多视点视频立体合成的优化方法，通过视频信号处理的途径减少光学失真；面向3D终端实时应用，研究基于通用GPU和专用VLSI结构的高效并行处理技术，促进成果的产业化应用。本项目旨在探索解决光栅式裸视3D技术应用中的难点问题，发展视频3D重建和3D显示的理论与方法，为3D文化产业的持续健康发展提供关键技术支撑。
基于本体的视频语义内容分析方法研究	感知概念;本体;视频语义内容分析;基于本体的视频概念探测;语义鸿沟	视频语义内容分析的目标是跨越语义鸿沟获取视频高层语义。本项目试图从分析框架和分析方法两个方面系统全面地探讨视频语义内容分析。分析框架对视频语义进行抽象，对相关领域知识和上下文信息进行建模，明确视频语义内容分析要解决的根本问题；而分析方法研究视频语义分析的技术实现途径。视频语义可归纳为概念语义和关系语义（对应于本项目定义的视频感知概念、视频概念及其关系），视频感知概念与视频概念及其关系的抽象与本体论是吻合的。因此，项目研究视频概念模型和基于本体的视频语义内容分析知识基础，明确视频语义内容分析的着重点在于感知概念与视频概念的探测。在此基础上，立足于视频语义内容的层次特性以及模糊性和不确定性，提出基于上下文信息与概率统计关联模型的视频语义内容分析方法论；具体研究基于机器学习理论的感知概念探测方法和基于本体的视频概念探测方法，为跨越语义鸿沟提供解决之道。
视频异常事件检测中的群体特征感知研究	群体特征抽取;空时序列建模;事件监控;异常行为监控;群体特征解集	伴随着城市化进程及人口流动性的增加，热点公共场所的群体安全问题日益严重。避免群体灾害的发生，消弱群体灾害的蔓延和扩大，及时准确的群体异常事件检测至关重要。本项目拟以群体特征感知作为群体异常事件检测的切入点，具体研究群体特征抽取、群体特征解集和群体特征空时建模三个问题。拟利用复合型先验协调群体中个体的社会性与随机性，基于深度结构框架下的稀疏编码，研究多层逐级局部聚类的群体特征抽取方法；基于信息熵分析建立群体特征时空关联网络流图，拟通过网络优化和鉴别稀疏编码解决群体异常事件的多空间覆盖和多时间延续问题，实现群体特征的解集处理；针对群体异常事件空时耦合关系的多样性，在群体特征空间模型和时间模型之间引入谐振，拟研究谐振式群体特征空时模型，避免对某类空时耦合关系形成检测盲区。本项目的研究成果整体有望在群体特征感知方面实现核心理论的突破，形成群体异常事件检测的关键技术支撑。
基于调频广播及非相干扩频水印的隐蔽通信系统关键技术研究	调频广播;扩频;信息隐藏;音频水印	信息隐藏和数字水印技术可在公开的媒介中嵌入不被察觉的微弱信息，进而实现隐蔽通信，这对保障信息安全、提高通信的抗截获能力具有重要意义。模拟制式的调频广播是隐蔽通信的优良载体，也是检验信息隐藏性能的试金石。现有方案多采用相干扩频水印技术，但调频广播信道的频率选择性衰落将导致扩频序列相关峰的扩散和极性翻转，从而使依赖相关峰极性的相干解调产生高误码。本项目提出以非相干扩频代替相干扩频的策略，解决了现有方案对频率选择性干扰敏感的问题；同时，针对载体对水印的干扰问题，提出利用边信息的非相干扩频水印理论，在嵌入端抑制载体干扰并利用载体改善扩频水印的相关特性，使其更易被检测和提取。基于上述技术构建适合调频广播的隐蔽通信系统。本项目所提出的抗频率选择性干扰的水印技术对信息隐藏的其它应用具有借鉴意义，所倡导的利用载体改善水印鲁棒性的策略具有先进性，模拟广播这一恶劣信道的攻克也有利于推动信息隐藏技术的进步。
基于贝叶斯理论的音乐信号模式空间研究	智能感知;贝叶斯;音乐信号;模式空间	音乐信号的智能分析是音乐检索、识别、音乐创作与音乐信号压缩的基础理论，我们的智能分析理论基于脑神经科学家Daniel J.Levitin对音乐在人脑中感知过程的研究成果。基于此研究成果，我们将提出并建立新型音乐信号的模式空间，研究模式空间的组成和表示方法，把音乐信号分成音色、节拍、旋律、和声等多维模式，然后分析音乐的底层特性，主要通过贝叶斯理论建立各类特征模型，最后提取各模型参数，进一步用模式参数来表示音乐信号。.我们的初步研究结果表明，基于贝叶斯理论的谐波模型能高效地捕捉多声部音乐的音高模式参数，基于贝叶斯理论的节奏模型适用于提取单声部音乐的节拍模式参数，这为我们研究音乐信号的模式空间打下良好基础。.本项目研究内容属于智能信号处理的基础前沿，基础理论的研究对于音乐文化产业，核心软件产品和制作工具具有重要意义。
基于流形学习的视频人脸识别方法研究	视频;人脸识别;流形学习;计算机视觉	在几十年的国际计算机视觉及智能计算研究中，人脸识别始终是最重要的难题 之一并吸引了大量研究工作人员的兴趣。随着视频监控、视频分享等应用的普及，视频人脸 识别技术的需求也日益迫切。基于视频的人脸识别可以利用视频中的时间及空间信息增加识 别的准确度，近年来成为了人脸识别领域的研究热点。本项目认识到了流形学习方法在人脸 识别领域的独特优势，而视频人脸具有比静止人脸更丰富的认知特征，而作为非线性数据的 维数也更高，很自然的一个想法是基于流形学习的算法应该可以在视频人脸识别上表现优 异。本项目准备在前期对流形学习方法的优化研究基础上，致力于解决困扰流形学习方法应 用于视频人脸识别时遇到的一些具体问题，找到使流形学习方法成功应用于视频人脸识别的 有效途径，从而推动视频人脸识别技术的发展。
基于非线性压缩感知和自适应字典学习的相位恢复与图像重建方法研究	稀疏表示;图像重建;相位恢复;字典学习;压缩感知	相位恢复的目标是仅根据图像二维傅立叶变换或菲涅耳变换的幅值或部分幅值精确地复原丢失的相位信息，而图像先验是决定相位恢复质量的关键因素。最近发展的稀疏相位恢复和可压缩相位恢复方法利用图像空域的稀疏性或某种固定变换的稀疏性来代替传统的图像支撑先验，图像表示的稀疏程度对相位恢复和图像重建质量具有至关重要的影响。本项目以非线性压缩感知理论为基础，根据综合稀疏和解析稀疏两种模型，利用测量的高度不完备非线性幅值信息，结合字典约束条件和图像固有的非局部相似性及边缘稀疏性等多种先验信息学习能对重建图像本身进行最优表示的个性化字典，并根据这种自适应表示的稀疏性及结构稀疏性进行单像面和多像面相位恢复和图像重建。该方法有望突破现有相位恢复方法的诸多限制，在低采样率下实现高精度、抗噪性能强的相位恢复与图像重建。本项目将促进非线性压缩感知、自适应稀疏表示理论和相位恢复技术的发展，具有重要的理论意义和应用价值。
多源异质数据的复杂事件分析	事件到类别距离;多源数据;图矩阵;复杂事件;异质数据	复杂事件（Complex Event）是由多个在时间上相继或并发出现的简单事件所组成的，具有一定语义的多媒体信息分析单元。有效的复杂事件分析的理论和技术是进行多媒体检索与监控等研究的重要基础。对复杂事件的分析面临着如下的挑战：音频与视频等异质数据的统一表示问题、不同用户的同质多源数据的类内大差异问题、复杂事件内简单事件的时序关系解析和建模问题。本项目将针对上述挑战展开研究，其内容如下：1）基于本征空间学习的异质化数据的统一表征，包括多核函数的距离子空间超向量表示和局部保持的判别稀疏编码超向量表示；2）基于空间映射解决类内大差异去除问题，包括有监督子空间映射和多源数据典型相关性分析映射；3）基于上下文关系分析的事件时空建模，包括状态持续时间的HMM建模和时间-空间的信息图矩阵建模。本项目的研究和突破将为新形势下多媒体信息检索、管理和监控等领域的研究奠定重要的理论和实践基础。
面向混合标记样本的连续行为识别技术研究	连续行为识别;卷积神经网络;深度学习;概率图模型	实际视频场景中的连续行为识别较传统的单个行为识别更加具有挑战，本项目研究大数据背景下面向混合标记样本的连续行为识别技术。研究基于深度网络的行为时空特征自动学习方法，以数据驱动的方式学习更适应特定应用的特征。研究基于概率图模型的连续行为时序建模方法，以建立描述行为内动态过程以及行为间相互转移关系的数学模型。研究混合标记样本下集成模型的构建和学习方法，建立深度网络和概率图模型相结合的集成模型，以"端到端"的方式对混合标记样本进行学习，将行为建模的时序信息融入特征学习中，实现行为特征学习和连续行为识别的统一。本项目将面向实际应用环境，建立理论框架，设计关键算法，提高识别准确率，推动行为识别与分析技术的实用化。
基于视觉的智能健康监护关键技术研究	跌倒/近似跌倒检测;智能健康监护;异常步态检测;生理参数监测;视频监控	本项目面向未来养老模式对智能健康监护提出的先进性、普适性要求，针对非接触、零电磁干扰且拥有丰富信息的视频监护方式，基于智能健康监护的基本框架，瞄准其在日常监护中适应日常活动无约束需求时急需解决的关键问题，研究基于视觉的生理参数监测、异常步态检测、跌倒相关事件检测及三者间的关联分析利用。通过提取环境鲁棒的生理参数外部表现特征并抑制体动干扰影响，给出对监护对象无压力无负担的心率、呼吸率鲁棒一体化监测方案；通过提取无约束行进中具有稳定表现的步态参数特征，给出对行走方向、路径无约束的个性化异常步态分析策略；基于事件个性化特征与个人行为知识的融合互补思想，构建跌倒、近似跌倒事件及其具体类型的多层判断分析机制；分析挖掘上述三方面监护数据间的关联规则，并基于关联规则构建异常检测的动态调整机制。本项目研究成果可为推动智能健康监护技术在机构、社区及未来居家养老的大规模普及应用提供理论依据和技术储备。
由概念驱动的多模态多媒体信息融合技术	概念空间;语义层认知;多媒体;多模态融合;语义空间	本项目针对多媒体的多源特性，提出一种新颖的、由概念驱动的多媒体信息融合方法，充分利用模态间信息互补优势，对多媒体信息进行在语义层的挖掘和检索。为解决查询空间与模态权重空间之间的不可直接映射问题，该方法构建一个概念空间作为映射的桥梁。该概念空间是能综合表达用户查询所包含的语义、视觉和上下文信息的一个最紧致概念集合张成的向量空间。该空间可以对查询信息进行向量化，从而为后继的信息挖掘和分析算法提供规范和量化的基础。同时，由于概念集可提前预知，概念空间与模态权重空间的映射关系也可以预先学习或估计。利用这些预学习的知识，该方法使用模糊综合评价的方法将向量化后的用户查询动态地、自适应地映射到模态权重空间，从而解决查询空间到权重空间的映射难题，同时完成对多模态数据的有机整合。本项目研究成果将成为多模态融合技术一个新的分支，为网络信息的高层认知提供基础算法，并为视频的检索、不良信息过滤等应用提供理论基础。
基于混合属性分析的人体行为识别方法研究	属性;行为识别;零样本学习;多任务学习	行为属性需要人为定义，因此很难保证完全描述行为类别的所有视觉信息。针对人为定义属性相对主观的问题，本课题拟研究利用混合属性（数据驱动属性和人为定义属性）对人体行为进行识别。我们拟在以下三个方面开展研究。第一，研究数据驱动属性的生成方法，拟提出语义约束模糊聚类方法，使数据驱动属性既与人为定义属性互补又能考虑特征点之间的时空关系。第二，为了充分利用混合属性的语义特征，拟提出属性约束弱监督多任务学习方法，建立底层特征、数据驱动属性、人为定义属性和行为类别之间的关系。第三，针对混合属性方法中无训练样本类别的分类问题，拟研究多任务学习框架下的零样本学习方法。该研究学习得到的模型可以充分挖掘语义信息，帮助提高属性方法的实用性。
全景聚焦合成孔径成像及其遮挡目标提取研究	多媒体信息处理;视频信息处理	复杂场景与遮挡条件下目标探测与环境感知是当前视觉探测领域的核心难题之一。本项目从合成孔径成像方式的革新入手，研究将合成孔径清晰成像与目标提取统一进行处理的全景聚焦合成孔径成像方法。该方法将传统合成孔径清晰成像范围扩展到焦平面外，在获得聚焦和非聚焦区域均清晰成像的透视成像结果的同时解决遮挡目标提取问题。主要内容包括：（1）针对合成孔径成像时非聚焦区域散焦模糊问题，研究合成孔径非聚焦背景重建方法；（2）针对目标运动导致的无法快速聚焦透视成像问题，研究基于动态聚焦深度估计的合成孔径目标透视成像方法；（3）针对无约束环境下合成孔径目标的提取问题，研究基于清晰度标识的合成孔径目标自动提取方法。本项目的研究在智能视觉监控、军事探测、反恐侦察等多个领域具有重要的理论和应用价值。
非对称视频编解码的多尺度分解重构技术研究	纹理合成;非对称编码;边信息;多尺度;基元图	本项目是对网络传递多径、易错、拓扑等非确定约束下的视频编、解码，研究其非对称分解、重构所映射的一般化编码器信源构造和解码器信息合成，分析视频随机信源在其信息空间内的相关边信息构造性描述问题，藉此通过多元化的信息融合，由非确定的网络输入信号状态构造基于率失真和相似性测度准则最优化所确定的输出信息，以利于探讨视频在网络化应用中的基本描述。提出基于视频相关性多尺度分解的非对称视频编解码框架，建立基于全局相关预测、局部特征重用的失真分析评价，将视频信源按照基于计算机图形基元图的空间纹理渐进细化映射、渐进的非对称分布式编码、图形化的渐进结构重建，进行广义信息融合的视频网络传输，使总体的失真特性可以实现渐进逼近的模型化描述。
分布式视频编码的关键技术研究	喷泉码;视觉感知;边信息;分布式视频编码	分布式视频编码是近年来视频编码领域中的新兴技术，它的独特之处在于其崭新的编码结构，在高效编码效率的同时具有编码复杂度低和鲁棒性高的特点，在无线视频传感器网络、卫星视频通信、移动摄像手机等无线及普适多媒体应用中，呈现出很大的发展潜力，受到了国内外学术界和工业界的广泛关注。.与传统编码技术相比，具有陪集特征的信道编码技术及边信息技术是分布式视频编码的两项独特技术。本项目拟从设计高效的信道编码技术和提高边信息的精度方面着手，从提高纠错性能和采用视觉感知的边信息两方面结合的方式探索提高分布式视频编码效率的方法。主要研究内容包括：1）联合视频信息谱的喷泉码度分布结构，2）基于停止集的码字最优分析方法，3）基于视觉感知模型的边信息生成方法。
彩色/多光谱异源双目视频运动目标分割方法研究	目标检测;运动识别;多源数据融合;立体视觉	视频运动目标分割是视频分析领域中一项极富挑战性的课题。在彩色视频中，当目标与背景颜色相似时，边缘提取、运动估计和深度估计都会面临困难。本项目将多光谱视频的高区分度与彩色视频的高分辨率有机结合，提出一种基于彩色与多光谱视频的异源双目视频运动目标分割方法。在申请人已有的轨迹跟踪和分割模型的基础上，参考现有的多光谱图像分割和配准方法，本项目深入讨论不同分辨率彩色和多光谱视频的精确配准问题，并提出基于异源双目视频同时估算运动场及深度场的方法；在此基础上，进一步研究三维点轨迹和区域轨迹的生成方法；最后，利用多层图模型融合像素光谱、点轨迹和区域轨迹三种不同粒度特征并优化求解。本项目所研究的算法利用了多光谱视频与彩色视频的互补特性，能够准确估计深度场及运动场；所提模型融合多粒度特征，提高了复杂场景下的运动目标分割精度。相应的研究成果可以为智能监控、自主瞄准、辅助驾驶等领域提供前端支持。
基于多尺度分析的无人机航拍人体异常行为检测研究	滤波器组;场境理解;无人机航拍视频;多尺度分析;人体异常行为检测	航拍场景中无人机与人体目标的相对运动，导致地面人体目标的观测存在尺度变化大及背景干扰强等问题，增加了异常行为检测的难度，极大地制约了无人机的场境理解能力。针对上述问题，本课题对航拍人体异常行为的检测方法进行研究。首先探究多尺度分析有效性的机理，设计基于多尺度分析的背景建模更新模型，解决航拍视频中背景干扰强的问题。然后进一步细致分析和表征多尺度轨迹特征有效性的内在机理，基于机器学习的思想进行多尺度轨迹特征的有效提取及二次特征构建；同时，结合多尺度分析和特征融合思想对滤波器组的类型、阶数及方向等参数和特征池化等进行研究，建立更有效的滤波器组架构模型，检测尺度变化大的航拍人体异常行为。课题的研究将为航拍人体异常行为检测提供有效的解决方案和技术手段，提高无人机的场境理解能力和智能化水平，并为其他航拍场境理解任务提供理论指导和技术支持。
基于生活史优化算法的运动捕捉方法研究	搜索平衡;运动捕捉;生活史算法;中度干扰;进化计算	基于无标记点的运动捕捉方法由于能提供一种低成本、良好的人机交互手段，具有广泛的应用前景。然而在复杂情况下存在的多个优化问题是其推广应用急需解决的关键性难点问题。本项目拟在深入研究生态学和传统进化算法的理论基础之上，充分吸收各自领域学科的特点，并加以改造和重构，提出一种新的生活史进化算法，同时针对运动捕捉系统中的高自由度、搜索空间维数高的特性，研究生活史进化算法解决运动捕捉系列优化问题。本课题首先结合图像和视频处理的相关理论，系统的分析运动捕捉方法中存在的一系列优化问题。然后，在分析比较传统进化算法搜索性能的基础之上，结合生活史原理，借鉴中度干扰理论，定义了生活史进化算法的基本模型，并系统理论的分析算法收敛性等重要性能指标，研究基于优化理论的高质量无标记点的运动捕捉方法。本项目探索具有普遍性的优化理论，实现优化理论的创新和运动捕捉的技术突破，促进视频领域和优化领域的研究与发展。
多目主动相机智能监控关键技术研究	目标跟踪;主动相机;智能监控;多目相机;前景检测	当前智能视频监控的发展方向是从单目相机到多目相机、从静止相机到主动相机。本项目结合多个相机和主动相机所具有的优势互补性，针对结构更加复杂、功能更加完备、与实际需求更加贴近的多目主动相机视觉系统进行研究，并通过建立"多目主动相机系统标定→多目主动相机前景提取→多目主动相机阴影去除→多目主动相机目标跟踪→多目主动相机跟踪融合"的完整框架体系，为智能视频监控的研究探索一条新途径。
数字音频被动取证关键技术研究	开集设备源识别;数字音频取证;篡改点检测;语音信息处理;多媒体取证	项目针对数字音频数据面临的易被篡改、伪造、盗用等安全问题，研究数字音频被动取证关键技术，通过直接分析数字音频信号本身，利用开集录音设备源识别算法对数字音频的原始性进行验证，利用数字音频篡改盲检测和定位算法对数字音频的真实性进行检测。项目主要研究内容包括：（1）针对开集录音设备源识别中设备特征的表达问题，研究语音段与非语音段中设备特征的提取与融合方法；（2）针对开集录音设备源识别中设备模型的训练问题，研究集内、集外设备模型的建模与模型参数优化方法，以及集内、集外设备最优判决阈值的训练方法；（3）针对数字音频中插入、删除、替换和拼接等篡改操作，研究相应的篡改盲检测方法，以及精确的篡改点定位方法。项目从设备信息与数字音频的特有关联性出发，利用现代信号处理和机器学习的手段，研究"录音设备指纹"的表征与建模方法，为数字音频被动取证技术的进一步研究提供新思路和理论依据，该研究成果在司法取证、知识产权保护等领域有广泛的市场化应用前景。
基于深度时空轨迹特征的复杂场景人体行为识别	稀疏重构;行为识别;深度学习;特征融合;特征理解	人体行为识别是计算机视觉与图像理解领域的核心研究课题之一。现有行为识别系统受到复杂背景、光照、目标视角和形变等环境噪声的影响，难以应对复杂场景视频数据的挑战。本项目以复杂场景的人体行为识别为对象，采用手工设计特征与深度学习特征融合的方法实现目标描述，以显著提高人体行为识别算法性能。针对复杂场景多源环境噪声，研究波形光流轨迹特征提取方法，消除噪声对特征描述的影响；利用时空信息关联，研究光流轨迹与深度卷积特征融合方法，增强特征的表示能力；采用局部信息约束与稀疏重构模型，实现特征理解和行为识别。项目研究内容涉及了底层特征提取去噪、中层异质特征融合和高层特征理解建模问题。研究成果对于图像/视频目标表示与识别具有重要理论意义，对于视频监控、运动分析、视频检索、人机交互等系统具有应用价值。
基于观看经历的视频QoE评价研究	客观评价;视频体验质量;视频质量评价模型	视频业务QoE评估对改善视频服务性能和保障用户体验具有重要的指导意义。为了能够准确的评价广泛视频业务中用户的QoE，本项目拟从用户真实感知过程角度出发，结合用户的观看经历分别研究QoE技术域的视频质量评估以及真正意义上的用户QoE评估。针对纷繁复杂的视频业务类型和失真类型，结合用户感知特性将不同类型的失真效应划分成各类用户观看事件，从而构建基于事件的统一评估框架来研究各种失真效应对用户即时感知视频质量的影响，建立一种基于用户观看经历的、易扩展、即时网络视频质量评估模型。针对用户的QoE评估，提出结合历史观看经历，利用用户眼动行为和操作行为表征参数预测用户QoE的方法，建立了基于用户历史观看经历的行为参数表征QoE评估模型。为分析现实生活中用户对网络视频业务的体验感受提供重要的参考和经验，为定量预测用户体验质量提供了有效的理论依据和技术支持。
基于图模型与增量学习的网络化智能视频监控研究	图模型;增量学习;智能监控	如今世界几乎已是摄像头监视的世界, 海量摄像头监控网络将是社会重要组成部分。但人眼实时监看所有画面既不经济也不现实，如何分析这些海量网络化视频是监控网络普及的关键。为求实用，已有研究注重单摄像头内事件分析或较少摄像头间画面关联。受摄像视野所限、光照变化、目标遮挡等因素，对整个监控网覆盖区事件分析性能检测率受限、虚警率高。本项目拟对物理上互连成网的摄像监控系统用图结构进行建模，节点属性含区域内提取的事件局部特征, 如视野内有无目标、其拥挤度、运动轨迹、进出时间、光流场有序度等；节点间的边反映区域局部观测信息间关联，如目标进出的时间关联、轨迹的空间位置关联，目标间表观相似性关联、光流有序度关联等。通过代价函数最小化，用增量学习动态适应监控场景变化，"训练"图模型中节点状态和边连接及其对事件检测的权重。不以特定应用为目标，我们探索图模型及增量学习等较一般化的视频监控网络基础理论和方法。
移动视觉搜索关键技术研究	紧凑描述子;量化;查询性能预估;分布式索引;移动视觉搜索	近年来随着移动互联网、智能终端以及云计算的迅速崛起，越来越多的人希望在移动中高速接入互联网，获取实时信息。移动视觉搜索毫无疑问成为未来移动世界中有影响的基础技术之一。移动视觉搜索是指利用移动终端获取的图像或视频作为查询，通过移动互联网检索出感兴趣信息的检索方式。人们通过移动视觉搜索技术，可以快速便捷地采集现实世界的视觉对象信息，从移动互联网获取感兴趣的关联信息。尽管移动视觉搜索技术已经面世，仍未得到大范围地应用。该项目将定位移动视觉搜索面临的技术瓶颈与挑战，包括无线带宽压力、移动端电池消耗、查询迟滞、大规模索引文件、移动端有限计算资源、拍照姿态光线多样性等。从移动端、服务端、用户三方面，对紧凑视觉描述子、多尺度量化、视觉主题模型、视觉搜索性能估计、分布式索引等关键环节开展研究。该项目总体目标是提升移动视觉搜索各项关键技术性能，萃取科学问题，从解决方案、理论方法两方面开展研究。
3D电视对人体健康的影响机制及减控模型的研究	视觉失真;立体视频;减控模型;质量评价	当前3D电视正迅速发展，我国已开播3D试验频道，并计划十二五期间开播10个频道，2012年初我国内地销售的电视机中3D电视机已超过30%,3D电视对公众健康有哪些影响亟待研究。本项目拟通过理论分析与实验研究人眼立体成像原理及成像条件，以及3D电视对人体哪些生理参数产生影响；实验研究3D电视系统各环节中对人体生理参数产生影响的主要因素以及相应的减控模型。.具体内容包括：研究3D电视视觉成像原理（包含具体的成像条件、影响立体成像效果的因素），构建3D电视影响人体生理参数表，研究发现3D电视的拍摄、制作和显示等过程中对人体生理参数表发生影响的主要因素（包括视差、误差、视野冲突等方面），研究提出为保证人体健康对上述主要因素设置合适的阈值和具体减控模型。.预期研究成果可为3D电视节目制作、设备研发生产提供技术指导，为制定3D电视标准和保障公众健康提供理论支持。
面向多视点课堂视频的教学对象体感-情感协同建模技术	教育技术;多媒体信息处理;视频信息处理	教学质量是信息化教育的核心，如何提高课堂教学情境中师生教学活动质量和效率是教育技术的重要内容。本项目基于课堂教学情境中多视点视频数据，重点研究面向课堂教学中的师生教学体感-情感协同分析增强技术，主要包括教学对象体感部位检测与识别技术、教学对象体感-情感协同理解，多视点课教学对象目标匹配、自适应辅助教育服务技术。通过对教学对象体感部位与运动的检测及情感分析，提出基于体感-情感协同计算辅助课堂教学服务系统的构建与应用，促进数字化环境下教学模式的发展。本项目拟通过教育体感与情感数据采集，建模与关联性分析，探索研究教学体感-情感协同计算的教学效果语义建模，同时分析目前国内教学质量评价的实际情况，研发基于多视点体感-情感信号挖掘的自适应课堂辅助教学系统并应用到实际教学内容推荐体系中，并通过实验验证。
AVS压缩域稳健的视频水印方法研究	模糊概念格;非负矩阵分解;视频水印;流形学习;视频语义	视频水印一直是多媒体领域研究的热点和难点，由于视频信号固有的复杂性和大量冗余，使得视频水印面临许多迫切需要解决的问题，如建立包括时间掩蔽效应在内的更为精确的视觉模型、独特的视频攻击方式如帧平均、帧删除、帧插入、帧重组等给水印提出的更高鲁棒性要求，视频水印强的实时性要求等，发展相对滞后。项目组旨在从基础理论方面系统研究AVS压缩域稳健的视频水印方法，通过对视频信号特有攻击方式的研究、运动的视觉掩蔽特性研究，通过研究分析鲁棒性、实时性特征及表现形式，重点研究鲁棒的视频水印方法，包括基于视频语义/流形学习的视频水印方法，研究实时的视频水印方法，包括基于非负矩阵分解/模糊概念格的视频水印方法，以解决鲁棒性、实时性等基础性、共性关键科学问题，项目研究具有重要的学术价值，研究成果可为AVS（Audio and Video Coding Standard of China）视频信号提供完整的版权保护。
基于物理空间与网络空间的社会事件分析的研究	跨媒体分析;图像理解;协同计算;语义理解	近年来，随着照相设备的飞速发展、互联网技术的全面应用以及国家和社会对社会事件的广泛关注，使得基于物理空间和网络空间（二元空间）的社会事件分析的研究势在必行。现有研究大都局限在某个空间或某个独立媒体库上的社会事件，而忽视了二元空间的相互关系。本课题旨在研究基于二元空间的社会事件的分析技术，建立实时、有效、鲁棒的社会事件分析模型，对给定的社会事件，挖掘其各阶段在不同时间地点发生的子事件，提供二元空间中与之相关的样本子集，并给出网络空间样本的置信度。基于此，本项目将首先对二元空间上与给定的社会事件相关的信息样本进行基于"词-时间-地点"结构的语义分析；继而分别对多源样本在跨空间、跨媒体、跨时空三个层次上实现语义上的关联，根据"时间-地点"信息挖掘社会事件的各个子事件；最终，建立一般化结构的多模态样本协同聚类框架，发现属于同一子事件的样本聚类，在物理空间和网络空间上，建立样本置信度的传播模型。
扬声器组空间汇聚特性及声像感知一致的扬声器阵列精简	三维音频;空间汇聚特性;声场重建;多声道精简	面向家庭应用的三维音视频技术成为全球多媒体行业标志性符号，其关键在于利用较少扬声器回放与原3D音频系统听觉感知一致的三维声。传统方法忽略替代扬声器组空间位置选取对重建声场失真及虚拟声像双耳感知定位的影响，导致通过人工测试确定最优扬声器精简阵列的工作量巨大，亟待研究感知一致约束的三维多声道音频精简技术。本项目首先研究替代扬声器组空间位置变化对声场重建失真的约束规律，分析声场重建失真约束的替代扬声器组汇聚特性，提出最优替代扬声器组选取准则，指导扬声器阵列自动精简；其次结合声音空间方位恰可感知特性及运动轨迹时空关联特性，研究替代扬声器组空间位置变化对虚拟声像双耳感知定位失真的约束规律，分析双耳感知定位失真约束的替代扬声器组汇聚特性，提出优化替代扬声器组选取准则，指导虚拟声像感知定位。本项目所提出方法预期在人头区域声场失真降低30%，虚拟声像感知定位主观测试结果提高30%，提升家庭环境3D听觉体验
在无线网络中鲁棒传输视频流的有效方法	格编码;无线视频传输;数字水印;正向纠错编码	随着无线通讯技术的飞速发展，基于无线视频传输的多媒体应用开始走向人们的日常生活。然而，如何在无线通信信道上鲁棒地传输压缩后的视频流是目前推广无线多媒体应用的一个极大的难题和挑战。一方面，压缩后的视频流对任何比特错误及其敏感；另一方面， 由于信号衰减和干扰，无线信道中固有地包含大量随机和突发比特干扰和错误，导致无法正确解码接受到的视频流。本项目首次提出利用数字图像水印技术实现零冗余正向纠错编码，以实现在仅具有有限带宽的无线信道上视频信号的鲁棒传输。基本思想是利用格编码技术将对视频流的正向纠错编码信息转换成数字水印嵌入到图像帧中，而不是传统地作为冗余比特插入视频流中，这样没有损失任何有效带宽；而且，由于数字水印的鲁棒性，即使经过无线信道，从失真的图像帧中仍然能够恢复嵌入的水印，进而得到正向纠错编码信息以恢复视频流中的比特错误，提高解码后的视频播放质量。
基于深度学习条件随机场的多目标跟踪方法研究	条件随机场;数据关联;神经网络;多目标跟踪	多目标跟踪目标个数不确定、训练样本数不足等问题，制约了深度学习在多目标跟踪领域的应用。为此，本项目拟采用结构化深度学习思路，将卷积神经网络（CNN）、条件随机场（CRF）优势相融合，充分挖掘神经网络的学习与推理功能，在真正意义上设计出一种端对端多目标跟踪方法，为类别个数不确定的数据关联问题及相关应用提供技术支撑。主要内容包括：（1）多目标跟踪建模：将多目标跟踪问题转化CRF图模型下的二元类别标定问题；（2）CRF势函数设计：利用神经网络强大的中高层特征学习能力、目标轨迹在时空域中的结构特性及先验知识，设计适用于神经网络实现的CRF势函数，构建有效的类别损失函数；（3）CRF推理：采用递归神经网络RNN的序列处理模式，提出基于投影梯度下降的CRF状态推理策略及实现方式，将CRF参数学习与推理统一嵌入到神经网络框架中。
监控视频的高动态范围化及其在辐射域处理	相机响应函数;高动态范围视频;辐射域图像处理;图像合成;监控视频	视频监控已成为公安部门取证和破案的重要技术手段。针对目前视频监控系统所拍摄的图像分辨率低，加上光照变化、运动模糊和距离的不确定，导致监控画面难以辨别的问题，本项目提出无需多次曝光，无需对现有监控视频系统做任何改动的情况下，实现高动态范围视频的研究；探讨不同光照下摄像头响应函数计算方法；提出在辐射域进行图像处理，如去噪、去模糊及运动图像合成。与传统图像复原模型相比，本方法符合成像原理，避免了因为传统模型不精确以及场景动态范围过宽造成图像像素饱和所带来的一系列处理问题。通过本项目的研究，以期把人眼看不清的图像清晰化，为开发一套具有自主版权的图像/视频处理系统打下坚实的基础，为公安系统，交通管理等需要视频监控的部门带来便利。本项目研究成果对图像/视频处理，计算机图形学及计算机视觉等领域有较高的学术价值。
基于两级颜色通道的图像高保真分色研究	颜色信息处理;印刷图像分色;颜色复制	本项目创新地提出了基于两级颜色通道的图像高保真分色方法。新方法一方面通过扩充基色数量来扩大分色图像的色域范围，另一方面通过增加对应基色的浅色级通道来提高图像阶调层次的复制质量。新方法试图将图像分色由传统单级模式转变为两级模式，以提高颜色复制的保真度。新方法拟采用的研究方案是：①首先对两种传统图像分色方法进行改造使其适用于多通道图像分色，即使用基于色域分区和胞元划分改造的纽介堡印刷呈色模型和基于分区特征样本集的经验模型来完成从色度值到基色值的第一级分色转换；②然后通过大量实验找到基色通道和相应浅色通道之间的匹配关系，并确定各浅色和相应基色通道之间的取值阈限，构建从基色通道到所有颜色通道（含浅色）的第二级分色模型。本项目研究成果不仅可直接应用于传统高保真印刷复制行业，在彩色喷墨印刷和纺织品喷墨印花领域也有着重要的应用前景，本项目对我国自主研发数字印刷和数字印花的输出控制系统具有重要意义。
融合多先验运动补偿插值的显著感知帧率上转换算法	时空显著性检测;运动补偿帧率上转换;显著感知;多先验融合;最大后验概率	现有治安视频监控系统拍摄帧率较低，导致顿挫、运动模糊和色彩失真等不良效应出现，给案件侦破工作带来一些困难，因此本项目拟以后处理方式采用运动补偿帧率上转换（MC-FRUC）算法提升视频帧率，增强视频流画面观感。现有MC-FRUC忽略了人眼视觉特性，从而导致运动估计过分追求真实运动造成计算资源浪费，与此同时，运动补偿内插过程也未主动利用各种图像先验信息，从而制约了内插精度提升。为此，本项目旨在提出一种新颖的融合多先验运动补偿插值的显著感知MC-FRUC框架，以拓展现有MC-FRUC的理论体系。本项目研究创新点包括：提出融合多特征的时空显著性检测方法，提取人眼视觉感兴趣区域；提出显著感知的运动估计算法，对感兴趣区域中的运动向量强化提纯，保证人眼视觉关注区域的运动准确度；提出建立运动补偿内插的最大后验概率（MAP）模型，融合多种图像先验知识，采用非线性优化方法复原待插帧丢失的结构信息。
基于快速权重循环网络和多通道深度网络的行人再识别研究	快速权重循环神经网络;多媒体信息处理;多通道深度网络;行人再识别;视频监控	行人再识别是多摄像头下智能视频监控的一个重要研究方向，在刑事侦查、行人检索、人员监控和分析等方面具有重要应用。为克服遮挡和复杂背景的干扰，本项目基于视频进行研究。行人动态特征的有效提取是进一步提高系统识别率的关键，但行人视频长短不一，帧率变化以及断续等问题使帧间动态特征提取非常困难。快速权重循环记忆网络具有类似人类大脑的记忆和学习模式，除具有短时和长时记忆外，还具有中间长度记忆，这种具有伸缩性的记忆联想模式非常适合行人视频这种不等长序列的特征提取和识别问题。因此，本项目提出用快速权重循环神经网络提取行人帧间动态特征的方法。为充分利用行人的外观特征、帧间动态特征和空时联合特征,本项目提出以行人视频、图像序列，平均行人图分别输入快速权重循环网络、卷积神经网络、二岔卷积网络，提取行人多类特征。构建多输入形式，多网络结构的多通道深度网络，提高行人再识别系统的识别率。本项目的顺利实施具有重要意义。
基于轮廓关注度和多域可伸缩的感兴趣区视频编码研究	可伸缩视频编码;安防监控;感兴趣区编码;轮廓编码	安防监控系统正向着智能化、网络化发展，基于视觉感知和网络适应性的智能化压缩是安防领域对视频编码提出的新要求。鉴于图像的不同区域存在重要性差异，全景图像和感兴趣区的清晰度要求不同，需要对视频序列进行差异性编码。因此本项目研究基于轮廓关注度和多域可伸缩的感兴趣区（ROI）视频编码算法。首先，通过混合精度自适应的轮廓编码方法，对任意形状的ROI进行准确高效的描述。然后，针对监控中ROI的一般运动特点，提出基于透视变换的运动估计算法，提高ROI帧间预测效果。并对残差系数进行频域层次重排，设计自适应量化机制，实现ROI质量优先的渐进分级。最后，在空域分级机制中，通过研究视频序列内容特征的相关性，提出基于时空域相关性的模式选择算法以及改进的层间模式映射算法，进一步去除层间信息冗余。算法预期的解码视频主观质量有明显提高，ROI区域的客观质量能提高3dB以上。本项目研究成果将进一步满足安防产业的专业需求。
自回归维纳滤波语音增强方法研究	自回归模型;语音编码;语音增强;线性预测;维纳滤波	本课题以目前移动通信中普遍使用的线性预测语音编码技术为背景，通过构建能量依赖的有限状态语音谱包络先验码书，研究复杂环境下的自回归（AR）维纳滤波语音增强方法。该方法将利用极大似然估计确定最终的语音AR谱包络，并借助估计的噪声谱和观测信号谱之间的相关性修正维纳滤波器，以达到平衡语音和噪声功率的目的。另外，该方法还将对观测信号进行相空间重构来改善噪声估计性能，并用深度信念网络和模拟退火等算法优化语音的AR谱包络码书。该方法不需噪声分类，非常适合移动通信中噪声类型和噪声能量逐帧改变的非平稳噪声抑制。
基于初始简图的媒体内容强鲁棒水印感知模型与算法	媒体内容保护;初始简图;强鲁棒性;感知模型;内容水印	数字媒体产业的发展对版权保护、盗版追踪、内容监控提出了更高的要求。数字水印技术在满足这些要求上具有天然的优势。但是传统水印无法解决联合攻击、盲检测等媒体应用环境带来的强鲁棒性问题，以及高清、高保真等媒体内容体验需求带来的低感知性问题，是阻碍其得以应用的关键。.本项目以初始简图分解为切入点，对新一代的内容水印技术进行研究。借助于初始简图和多级小波分解，对图像/视频内容的感知特性和感知层次进行分析，建立适合于水印嵌入的基元/纹理感知模型和掩蔽阈值的计算方法；结合人类感知系统的内容掩蔽效应和视觉熵，研究建立适合于水印嵌入的内容信息量度量方法，对图像/视频的内容特征和感知层次进行信息度量，寻找适合水印嵌入的鲁棒特征和范围；在此基础上，研究基于初始简图的图像/视频内容强鲁棒、低感知水印系统模型；最后将理论与方法应用到数字媒体内容产业，根据具体安全需求，设计实施相应的强鲁棒、低感知的内容水印算法。
多媒体问答中的若干关键问题研究	答案类型;镜头标注;视频检索;多媒体问答;重排序	近年来多媒体数据的爆炸式增长给检索技术带来了新的机遇和挑战：如何高效地满足用户信息查找的需求。在此背景下，多媒体问答技术应运而生。与检索技术不同，多媒体问答致力于直接返回给用户精确的答案而非根据相关性排序的信息列表。本项目以申请人在多媒体问答及相关领域的前期工作为基础，探索提出多媒体问答的完整技术路线，并围绕技术路线中若干亟待解决的问题展开研究：提出多媒体问答中答案类型的自动选择，以建立多媒体问答与检索技术之间的联系；提出融合显式和隐式语义概念的视频检索和社会化媒体中视频的镜头标注，着力提升视频检索的性能从而间接促进多媒体问答的发展；提出主题多样化视频重排序算法，以确保检索结果相关性的同时最大化信息覆盖，便于摘要技术分析合成得到精确答案。在此基础上，搭建分布式数据处理平台，实现多媒体问答系统的在线发布。
基于隐私区域的视频加密技术研究	视频加密;视频编码;人脸检测;隐私区域	视频加密技术是保护多媒体信息安全，促进网络多媒体应用快速健康发展必须解决的关键技术。本课题针对保护视频信息安全的实际应用需求，开展基于隐私区域的视频加密技术研究，统筹考虑隐私区域提取，编码和加密三者相结合的情况下对算法复杂度，安全性和编码效率的影响，建立高效的隐私区域视频加密框架。研究与编码相结合的人脸检测方法，利用编码过程中产生的信息快速准确地提取隐私区域，提高隐私区域检测速度；针对基于隐私区域的视频加密过程中特有的误差漂移情况，研究预测受限的视频编码方法，提高视频编码效率；研究基于压缩感知的视频加密方法，提高视频加密安全性；针对加密区域与非加密区域共存的特点，建立一种新的加密视频的视觉安全性评价模型，更为准确的评价隐私区域加密视频的视觉安全性。在以上工作的基础上，构建实验验证系统。争取在基于隐私区域的视频加密技术方面取得突破，促进的多媒体信息安全技术的发展。
基于ＭＰ时频特征的电影音频场景语义推理研究	时频特征;场景语义推理;音频事件	随着电影的日益增加，为了更好地分析、索引和管理越来越庞大的电影数据，方便人们快速检索到自己想要的信息，对电影进行内容分析和理解变得越来越迫切，针对目前电影音频内容分析与理解策略所存在的音频事件改变检测没受到重视、场景语义推理没被有效处理等问题，本项目主要探索电影音频内容分析与理解的实用方法，重点研究以下四个方面的问题：1）时频特征提取；2）音频事件改变检测；3）音频事件识别；4）场景语义推理。旨在通过上述四个问题的研究，弥补当前电影音频处理策略所存在的缺陷。 本项目的研究内容是语音及音频信号处理、模式识别与理解等领域的研究热点，理论上具有一定的挑战性，在应用上是研发音频内容分析及理解系统的重要基础。同时，对提高音频处理系统的实用性，加快我国信息产业的发展具有重要作用。预期发表EI索引论文3篇、SCI索引论文2篇、申报专利1项。
基于回归神经网络的语音分离关键问题研究	单通道混合语音分离;人工神经网络;语音增强;麦克风阵列;语音分离	随着大数据和互联网+时代的到来，语音分离是智能语音交互应用在实际复杂场景下实用化的关键技术之一。但传统的语音分离技术特别是单麦克风情况下，由于模型假设等先天性的缺陷，在通用性方面很难达到实用化门槛。而近年来随着深度学习技术的兴起，结合大数据的语音分离方法提供了一个非常有前景的新方向，在传统方法不能较好处理的一些场景下取得了很好的效果。因此本项目将围绕基于回归神经网络的语音分离方法在实用化时面临的模型推广性和复杂度等问题展开研究，包括噪声和语音数据的构造、回归神经网络的设计和优化以及和麦克风阵列技术的结合等；并考虑各种定制化应用，以期能够在单通道和多通道语音分离的实用化方面取得关键性突破。本项目不仅对语音通讯领域具有巨大的研究和实用价值，而且其研究成果还将对提高语音识别、语种识别、说话人识别等各种语音应用系统的鲁棒性有着重要意义。
基于压缩感知的无线胶囊内镜视频图像分析与处理	视频图像处理;机器视觉;压缩感知;视觉特征表示	作为新兴的消化道检测技术，小肠胶囊内镜每次检查约产生三万幅图像，医生平均需一小时浏览视频。压缩感知理论突破了Nyquist采样定理的瓶颈问题，解决了视频图像数据冗余、医生阅片负担重的难题。本项目通过基于压缩感知理论的新思路来实现视频图像数据的分析与处理。首先，针对小肠视频图像数据量大的问题，探索适合该类视频图像的稀疏基，设计新的低复杂度的稀疏分解算法以确保处理后的数据足够稀疏；其次，针对稀疏数据，提出一种结构对称性好、采样均匀、测量值权重均等的确定性测量矩阵，来保证内存需求少、算法高效；再次，在后期重构算法上，将图像重建转化为目标泛函最优问题，提出广义全变分P范数重加权优化算法，快速实现视频图像的精确重构；最后，在前述工作基础上，提出基于压缩感知理论的病变分类识别算法，实现动态纹理视频数据的筛选分类。本项目为下一代胶囊内窥镜的研制和推广奠定良好的基础，具有很好的实用价值和社会意义。
大规模网络视频话题跟踪及线索关键技术研究	近似图像检测;突发性特征;主题检测与跟踪;网络视频	社交网络的流行使得网络视频爆炸式的增长，浏览海量网络视频时的一个关键任务是话题的检测与跟踪。然而现有的视频搜索引擎仅根据文本关键字的相关度进行搜索，使得用户无法从众多的结果中找出视频之间的关联并跟踪事件的发展。本课题研究大规模网络视频话题跟踪及线索关键技术。突破现有视频搜索引擎的搜索习惯，项目首先研究基于局部关键点的大规模近似图像检测算法研究，实现高效、准确、可扩展的大规模近似图像检测。在此基础上，研究文本和视觉近似图像突发性特征，探索突发性特征之间的互补与关联，结合多模态融合技术集成各信息源的优势，对话题检测与跟踪进行理论分析和研究，用以检测热点事件、跟踪事件发展、建立话题结构、构建事件-文本-代表性视频片段间的映射，提供全新的搜索功能和新颖的搜索体验，探索更加适合互联网视频话题检测与跟踪的新思想和新途径，清晰地展示事件结构，方便用户浏览与搜索。
交互式多视点视频系统编码性能及绘制图像质量评价模型研究	交互式多视点视频系统;编码性能;关联度模型;绘制图像质量评价;评价模型	交互式多视点视频系统是未来视频系统发展的方向，多视点视频编码、虚拟视点图像绘制是其两大关键技术。定量评价系统中与编码方案相关的各项性能及虚拟视点图像质量，对于选择设计合理的多视点视频编码方案与图像绘制方法，提高系统综合性能是至关重要的。.采用数学工具对多视点视频编码方案的时域视点间预测参考关系进行描述，从预测结构与方案的关联度数学表示入手，建立关联度与各编码性能及各编码性能间的关系模型；利用随机图论建立编码方案随机访问等性能评价模型；利用数学规划方法建立交互式多视点视频系统综合评价模型，提出面向不同应用需求的、在多视点视频系统相互制约、相互矛盾的各项性能中寻求合理平衡点的多视点视频系统优化设计方法，将为交互式多视点视频系统性能优化设计提供理论分析工具。.从虚拟视点图像绘制特点出发，利用它与参考图像间的相似性评价其质量，进而评价视点间图像质量的波动，有助于设计性能优秀的虚拟视点图像绘制算法。
无重叠视域多摄像机目标跟踪系统若干关键问题研究	无重叠视域多摄像机;协作目标跟踪;目标跟踪;表现模型;时空模型	近年来，视频监控系统正在向大型化、智能化方向发展。无重叠视域多摄像机目标跟踪是大型智能视频监控系统的核心问题之一。项目针对无重叠视域多摄像机目标跟踪中的若干关键问题开展研究，提出一种基于贝叶斯理论的无重叠视域多摄像机目标跟踪框架，并且给出目标表现模型约束和摄像机拓扑关系约束相结合的计算模型。主要研究内容包括：①研究多特征目标表达问题，提出一种基于目标反射图的颜色转移模型，该模型能自动适应光照变化。②研究摄像机拓扑关系估计问题，提出一种能适应拓扑关系动态变化的弱监督在线学习方法，自动获取拓扑关系。③研究多特征目标关联问题，提出一种描述型关联和多核学习判别型关联相结合的关联模型，以体现不同特征的作用。④研究全局优化目标关联问题，提出一种带约束优化的离散粒子群算法，快速求解多目标最优路径问题。研究成果在提高视频监控系统的智能性、丰富学科建设和保障社会安全等方面具有重要意义。
欠采样相关图像集重建理论与算法	图像重建;视频重建;压缩感知	压缩感知理论能够以远低于香农采样定理的速率进行欠采样，降低了超高分辨率信号获取的难度。该理论在无线视频监控、无线多媒体传感器网络、动态核磁共振医学成像等领域的应用都得到了广泛的关注。在上述应用场合中，欠采样相关图像集的重建问题至关重要。针对该问题，本项目研究如何充分应用相关图像集内的先验信息，以获取最优的重建图像。主要研究内容为：1) 同时考虑待重建图像的先验结构特性及残差图像的稀疏性，建立性能优异的图像重建模型；2) 分别研究所提出的图像重建模型相应的高效求解算法，算法鲁棒性强、收敛迅速；3) 考虑不同色彩通道间的相关性，将所提出的重建模型扩展至彩色相关图像集重建问题，进一步提升图像重建质量；4) 提出复杂度较低的"预测-重建"结构辅助前述模型完成整个欠采样图像集的重建。本项目的研究，可以为压缩感知在多媒体信息采集领域中的应用提供理论参考和技术支持。
基于感知视者及视频码流中矢量特征的视觉舒适度增强的3D视频解码	3DTV;视差调节;视频码流;舒适感重绘;立体视觉感知	随着与3D视频相关产业的兴起，3D视频的电视播放、网络播放、移动设备播放成了可能，且呈现日新月异的昌盛期。然而，观看3D视频引起的视觉疲劳问题越来越成为3D视频相关产业发展的瓶颈，如何增强观看3D视频的视觉舒适度问题成为目前的研究热点。项目以"视者为本"为研究着眼点，利用感知视者及视频码流中矢量特征关联理论与技术，研究视觉舒适度增强的3D视频解码理论与技术。通过研究建立视者观视位置和角度等信息与双眼可融合视差之间的相关模型，提出自适应的视差调整方法使辐辏与调节一致解码算法；研究 3D视频解码中的视差矢量分布特性与解码视频垂直视差之间的相关性，提出舒适度增强3D视频解码算法；研究运动矢量和视差矢量关联分布特征与视差变化特征之间的相关性，提出相应的3D视频舒适度增强的解码算法；提出3D视频观视舒适度的量化评价方法；给出较完整的3D视频舒适度增强的解码算法。项目对于3D视频产业发展具有现实意义。
基于多尺度卷积神经网络模型的自发性人脸表情识别对跳转问题的研究	情感计算;表情识别;深度学习;人机交互;情绪识别	跳转被定义为用户停止观看视频的行为。分析理解跳转行为是人机交互领域长期的热点及前沿问题。对跳转行为的研究长期受制于传统问卷反馈方法的局限性，即用户反馈时的偏见。本课题另辟蹊径，提出了以情感计算为理念、基于表情自动识别的方案解决跳转预测问题。现有的表情识别方法约束用户头部姿态固定，仅关注面部表情引起的肌肉运动形态。在面向真实的环境下，非约束的自发性人脸表情识别的研究还处于起步阶段。本课题提出无回路有向图框架下的多尺度卷积神经网络（DAG-CNN）深度学习模型针对非约束的自发性表情识别，结合用户观看时的表情视频、偏好反馈问卷、以及跳转行为三类数据，建立跳转模型，拟解决如下关键问题：（1）基于DAG-CNN的多尺度特征提取；（2）基于DAG-CNN的自发性笑容强度动态预测；（3）基于新用户表情的跳转概率动态预测。本课题预研结果已被IEEE Trans收录，评审一致认为跳转预测问题新颖且重要。
基于人类3D视觉感应的2D到3D视频转换关键技术研究	人类视觉感应;深度图估计;二维转三维	2D到3D转换是解决目前3D视频内容缺乏非常重要的解决方案，同时，如何获得对人类视觉舒适的3D视频仍然是该领域的重点与难点问题。本项目主要研究基于人类3D视觉感应的2D到3D视频转换技术，从分析和理解人类3D视觉感知机理出发，选择和提取3D视觉信息感知特征，建立时空融合的3D视觉感知模型，在模型基础上进行深度图估计并利用时空联合滤波器对其进行处理，然后而利用3D视觉掩蔽效应，对DIBR渲染空洞进行处理，进而得到高质量的3D视频。同时，利用3D视频质量评价体系进行学习并指导3D感应模型中的参数配置，最后将算法应用到现有2D到3D转换软件系统中。本项目的研究成果，能够为制作更加舒适的3D内容提供理论依据和技术方法，对推动我国3D产业的发展具有重要意义。
面向语音表示及分离的结构化深度学习研究	深度学习;马尔科夫蒙特卡洛抽样;结构化学习;语音分离;语音表示	语音信号存在着大量的可变因素，例如不同说话人、说话语气、背景噪声、其他说话人的声音、回声等。人类的听觉感知系统可以轻易过滤掉干扰信息，并提取出有用信息，对语音的表现形式和环境的变化具有良好的适应性。深度学习模拟人脑对感知信息的处理过程，该方法为语音的表示和分离提供了新的思路。本课题以深度学习的理论和算法为基础，针对语音信号的表示和分离问题，通过研究和改进结构化深度信念网络模型，突破训练过程中的模型拓扑结构不确定、运算复杂度高、优化问题非凸等关键难点，获取语音信号更好的层次化表示，实现不同信源以及噪声的分离，为后续语音处理任务提供更好的前端模型。
数字图像原始性鉴别和篡改盲取证研究	数字图像盲取证;数字媒体来源鉴别;数字图像篡改取证	数字图像盲取证是国际上近年倍受关注的多媒体信息安全前沿研究领域，是指取证方仅从得到的数字图像就可进行取证的崭新技术。本申请以面向司法证据支撑的数字媒体原始性鉴别和数字图像篡改伪造为背景，研究不依赖图像内容的数字图像媒体来源认证和数字图像篡改盲取证技术和方法。.研究的重点包括：针对媒体来源认证，从多空间数据特性角度研究成像过程和处理方法产生的数字媒体来源鉴别。针对数字图像伪造和篡改，研究典型的数字图像篡改伪造操作建模和参数估计的检测和定位方法。针对实用情况，研究对多种常见篡改伪造操作联合应用的检测取证技术。研究成果为数字图像取证提供应用基础理论和方法支持。
基于多低维模型协同约束的压缩采样图像视频重构	稀疏表示;压缩采样;低维流形;低秩表示;图像/视频重构	压缩成像技术在军事与民用等诸多领域具有广泛应用前景，而压缩采样图像及视频的高性能重构是其中亟待解决的关键问题，成为当前该领域的研究热点。传统基于稀疏约束的重构方法由于约束模式单一、优化稀疏基受限，因此导致重构质量欠佳。针对该问题，鉴于图像与视频具有更多低维模型并存的特征，拟开展基于多低维模型协同约束的压缩采样图像/视频的重构方法研究，以达到有效提升压缩采样效率和重构性能的目的。主要内容及创新：充分探讨基于块/条带分割的图像及视频的空时域相关及高阶统计相关特性，以低秩表示和流形学习理论为基础，结合分层分割处理与拓扑聚类等技术，探索图像/视频的低秩表示、低维流形表示等更多低维模型；分析图像/视频压缩采样的低秩与低维流形模型的嵌入性能，发展基于稀疏、低秩与低维流形等多低维模型协同约束的压缩采样图像/视频的重构方法与优化实现技术，为压缩采样图像及视频的高效重构提供新思路和有效解决方案。
基于非线性语音谱分析的单通道语音增强研究	助听;语音增强;语音修复;语音处理	单通道语音增强面临两个根本性问题：一是谱估计方差既可能产生"音乐噪声"，也可能造成语音失真；二是当前的噪声估计算法难以跟踪非平稳态噪声，低估噪声会导致大量的噪声残留。针对这两个根本性问题，我们验证了倒谱后处理能在不增加语音失真的情况下抑制部分非平稳态噪声，本项目将进一步开展基于非线性语音谱分析的单通道语音增强研究。相比于基于线性谱估计的传统方法，采用基于倒谱分析和重分配谱图的非线性语音谱估计具有如下优势：首先，利用倒谱分析可以将噪声从语音信号分离出来；其次，利用重分配谱图可以充分利用语音帧间和频间相关性。本项目拟对语音倒谱进行理论研究，研究其统计特性，该理论研究成果既应用于提高噪声跟踪性能，又应用于后处理抑制残留的非平稳态噪声。同时，进一步对重分配谱图进行理论研究，利用语音帧间和频间相关性抑制非平稳态噪声。该研究的理论成果将解决实际环境中的单通道语音增强问题，为实用化扫清障碍。
光场成像的轴向超分辨率方法研究	数字重聚焦;光场成像;超分辨率;轴向分辨率;计算摄影	光场成像具有先拍摄后聚焦的可交互式重聚焦能力，轴向分辨率是衡量其数字重聚焦性能的重要指标。现有光场成像系统存在成像分辨率折衷的瓶颈，导致光场图像质量不高，且重聚焦能力不足，从而限制了光场应用的拓展。本项目拟研究轴向分辨率模型及数据处理阶段的轴向超分辨率方法。主要内容包括：1）针对双平面模型光场成像系统，研究光场采样特性、数据处理过程及成像方法对轴向分辨率的影响，构建非线性轴向分辨率模型，并探索轴向分辨率特性的量化评价方法，以确定影响轴向分辨率的关键因素；2）在不改变硬件系统设计的前提下，研究高精度光场数据解耦及轴向超分辨率图像生成方法，并进一步探寻光场图像质量的优化方法。本项目属于计算摄影学领域的前沿理论与方法研究，旨在解决双平面光场成像系统轴向分辨率不足的问题，并为突破光场成像分辨率折衷瓶颈提供新的思路。研究成果对丰富光场成像理论、提升光场图像质量、拓展光场成像应用具有重要意义。
基于感知的深度视频信号处理与编码研究	处理;视频信息;深度视频编码;深度感知	自由视点系统在教育培训、娱乐、交通、银行、医疗和文化遗产保护等领域具有广阔的应用前景和巨大的市场价值。连续准确的深度视频获取、高效率低复杂度深度视频编码是自由视点视频系统的关键问题。目前针对上述关键问题的研究主要是从信号处理的角度出发，没有结合人类视觉感知机制。本项目研究深度感知计算模型，并将其进一步运用到深度视频的处理和编码之中，主要包括（1）探索人类的深度感知机制，从虚拟视点绘制和显示的角度研究人类恰不可察觉的深度变化，建立深度感知计算模型；（2）在深度感知计算模型的理论基础上，研究深度视频相关性特征，提出深度视频处理方法，提高深度视频的时空一致性，提高深度视频的压缩效率和虚拟视点绘制与显示质量；（3）提出基于深度感知计算模型的深度视频编码方法，进一步提高深度视频的压缩效率，降低深度视频编码复杂度。本项目的研究能为深度视频信号的实时压缩和传输、高质量的虚拟视点绘制和显示提供理论基础。
基于光场的高动态范围超分辨率成像研究	光场成像;流形学习;高动态范围;超分辨率;压缩感知	高动态范围与超分辨率成像是多媒体与计算机视觉领域的热点与难点问题，光场成像则是目前国际上研究的前沿课题，将它们进行综合研究带来新的挑战。本项目探索光场采样与重建的基本原理，分析影响成像的根本因素，研究高动态范围和超分辨率的光场成像的理论与技术。（1）首先，探索包含照度在内的光场数据与成像动态范围和分辨率之间的内在联系，应用稀疏理论研究对场景的光场和照度数据同时采样的有效方法。（2）然后，分析光场的成像特性及影响因素，研究适合高动态范围和超分辨率处理的光场成像模型；探索场景中深度与照度信息与光场超分辨率、高动态范围处理之间的联系，应用流形学习理论解析出场景的连续深度图与照度图。（3）最后，将研究问题归为四维光场的重建，并分解为二维的像平面和镜平面的重建。对像平面应用贝叶斯框架下的先验假设从场景的深度图与照度图实现重建；对镜平面应用压缩感知理论建立稀疏字典实现重建；综合二者得到四维光场的重建。
基于码流的网络视频无参考质量评估方法研究	时域联合;视频质量评估;压缩失真;网络视频质量评估	视频已逐渐成为宽带及无线网络的主要业务，对网络视频进行便捷有效的质量评估，是开展网络视频应用的基本保障，同时具有重要的理论意义。本项目将研究在没有参考视频的情况下，仅利用码流信息对网络视频进行符合人眼主观感受的客观质量评估。主要创新性研究包括：考虑人眼时、空域掩盖效应，研究基于量化因子的视频帧压缩失真模型；根据率失真特性分析，研究根据压缩速率和量化因子预测视频时、空域复杂度的方法；结合视频的时、空域复杂度，预测数据丢失对视频帧主观质量的影响，建立出错视频帧质量评估模型；考虑帧率变化、停顿、连续低质量等因素，建立符合人眼视觉特性的视频帧质量时域联合模型。结合上述研究，形成系统的基于码流的网络视频无参考质量评估方法。相关成果亦可间接用于失真度量，是优化视频编码技术、视频通信机制的重要理论基础。
基于多特征融合的二维视频立体化精确深度信息提取方法研究	多特征融合;图像匹配;2D转3D;深度提取	立体视频显示给人们带来新的视觉革命，在科研、医疗、娱乐等领域有广阔的应用前景。二维视频立体化是解决目前立体视频内容短缺的重要手段，也是当前的研究热点。深度图的提取是二维视频立体化的关键技术，针对目前技术提取的深度信息精度较低的问题，本课题研究基于多特征融合的二维视频立体化精确深度信息提取方法，主要包括：（1）基于运动分析、图像匹配和边缘修正的空间深度图提取，提高深度信息的空间精度；（2）基于场景切换检测、时域滤波优化的时间深度提提取，提高深度信息的时间精度；（3）基于图像特征和人眼视觉特性的深度建模，以及基于内容自适应的多特征深信息度融合机制，提高深度提取的可靠性和鲁棒性；最终形成二维视频精确深度提取算法模型，构建全自动二维视频立体化实物演示平台。
网络自适应多描述视频编码的研究	视频传输;多描述编码;误匹配;小波变换;网络自适应	从多描述编码的角度研究强健的视频小波编码，针对目前多描述视频编码方案不能灵活改变描述数和冗余率的缺点，提出多描述树编码结构以实现可灵活改变描述数和冗余度的多描述视频编码。研究并推导出多描述树的冗余－率失真（RRD）关系，根据当前网络带宽和分组丢失概率从RRD关系中求出多描述树的阶数、描述数及各节点的码率分配，实现网络自适应多描述视频编码。研究误匹配控制准则，在信道状态较好时采用每个描述独立预测的方法消除误匹配，信道质量较差时采用描述合并，交叉分组的算法，把一个描述分为多个分组传送。达到既消除误匹配，又不会引入额外码率开销的目的。研究利用描述间的相关性和冗余信息重建丢失分组的算法，进一步提高解码视频信号的视觉效果。本项目的研究成功，将为互联网和无线移动信道上不同需求的用户提供一种多质量、高可靠性的实时视频服务的新方法，也为自主网、MIMO等多径传输网提供一种均衡负载和有效的多视频流生成方法。
时间解耦的多域复用三维高速多光子显微成像理论及关键技术研究	计算重构;三维显微成像;时间解耦;计算摄像	脑科学研究迫切需要发展大尺度、高速、高通量三维多光子显微成像系统。本课题针对多光子显微成像中成像尺度与速度之间的固有矛盾及数据通量瓶颈，提出空间间插采样、时间解耦计算重建与空时复用原理结合的计算成像方法，开展时间解耦的多域复用三维高速多光子显微成像理论及关键技术研究，并以此建立清醒动物在体神经网络功能成像平台，在验证系统性能并反馈指导理论、技术创新的同时，有望揭示神经网络信息处理规律。
支持增量式稀疏编码的在线协同目标跟踪研究	目标跟踪;在线学习;协同跟踪;稀疏编码	基于视频的目标跟踪由于其在民用和军用领域具有极其重要的应用价值，因而目标跟踪现在仍然是计算机视觉中的研究热点之一。由于目标图像易受到姿态、形状、光照的变化以及遮挡等因素的影响，想要实现稳定可靠的目标跟踪仍然有许多亟待解决的问题，如目标易丢失，样本数据的不平衡性等。针对以上问题，本项目将以基于增量式稀疏编码的跟踪，基于主动选择的SVM检测和基于协同机制的在线学习为攻关内容对复杂状况下的目标跟踪问题进行基础研究探讨。本项目的创新之处：拟提出基于结合1、2范数的稀疏编码及其特征选择算法和在线的目标子空间更新方法；考虑设计利用K均值聚类选取最有代表性负样本的策略来提高SVM检测器的学习速度和识别能力；拟利用协同机制解决跟踪器与检测器所得样本不一致的问题；提出的目标跟踪框架能实现对跟踪器与检测器的同步更新。本课题将有利推动模式识别、机器学习和视频监控理论、技术和应用。
基于群体社会力分析的视觉传感网络盲区状态研判	盲区事件检测;群体受力分析;群体运动分析;人群行为监控;社会力模型	以大量摄像头组网实现对公共场所群体行为的无缝监控在保障客流人身安全方面有着重要的作用，但实施成本较高。故利用少量稀疏分布的摄像头组网对大范围监控区域实现无盲区群体行为监控更具理论意义和应用前景。本项目将通过对群体运动所受社会力驱动的分析，探讨建立盲区群体运动状态判断的理论方法：首先，研究群体运动区域一致性分割方法，获取分割后的群体运动特征；其次，拓展运用社会力模型对群体进行受力分析研究，利用人际距离学理论，探索视域内、外群体运动状态之间的关系，建立视域外运动状态推导模型；最后，通过综合分析毗邻盲区的各监控点所获取的群体运动状态，建立该盲区群体运动状态研判模型，实现利用稀疏摄像头对公共场所密集群体的"无缝隙"网络化监控。项目的成功实施将有助于以较低成本扩大网络监控的范围，能够指导交通工程部门规划、设计和完善其交通设施，能够为急性灾害预警及疏散系统的建立提供有效数据辅助。
融合言语产生系统发音信息和中层鉴别性表征的说话人识别与语种识别	说话人识别;中层鉴别性表征;语音产生;语种识别	(限400字)：说话人识别与语种识别一直是语音信息处理领域的研究热点。传统方法主要是利用音素层，声学层和韵律层的信息。本文旨在从言语产生系统发音信息和中层鉴别性表征这两个方向展开说话人识别与语种识别的研究。本项目拟利用电磁发音仪采集一个以汉语为主体的较大规模的函盖多个语种或方言多个说话人的言语产生系统发音轨迹数据库，并以此为基础研究不同说话人和语种在发音层上的差异并提出新特征。研究基于多个参考说话人及语种的语音到发音逆求解方法来估计普通信道下的发音特征以用来提高识别性能。本项目还拟把图像场景分析中的最新研究热点中层鉴别性图像块思想用于语种识别和说话人识别上以提高系统综合性能。我们将研究中层鉴别性表征在语音上的中层定义，分段，代表单元学习，表征，后端分类等一系列核心问题。本项目不仅为说话人和语种识别提供两种新途径，也为言语产生和副语言信息听觉认知模型带来新观点，具有重要的理论意义与实际价值。
计算资源约束条件下的视频编码优化技术研究	计算资源约束;视频编码优化;计算耗费定量调控;计算耗费动态调度	多媒体终端设备在处理器功耗和计算性能方面的限制成为制约新一代网络视频通信业务发展的极大障碍，如何实现计算资源约束条件下的"计算耗费－码率－失真"联合优化是视频编码中亟待解决的瓶颈问题。本项目以此为研究目标，为从根本上解决设备功耗和计算性能变化时、如何在计算耗费调整与率失真性能间取得动态平衡的问题，探索相应的理论及技术支持：以建立"计算耗费－码率－失真"三者均衡关系模型作为研究的核心点，以计算耗费的定量度量和计算资源的动态分配与调度作为研究的切入点，以计算耗费定量可调的率失真性能联合优化的视频编码器设计作为研究的重点，深入分析其中的关键技术和解决方案，最终搭建编码计算耗费、码率、失真多维性能指标可自适应调控的视频编码系统，对上述模型、方法和技术进行测试验证。本项目预期的研究成果将对推进视频编码优化控制领域的基础理论研究及其实用化，推动新一代网络通信中多媒体业务的发展具有实际意义。
双耳交互计算模型与空间听觉研究	双耳声定位;双耳交互模型;语音定位	复杂声学环境下语音信号处理的鲁棒性研究一直是重点和难点。听觉生理学和心理学研究表明人的双耳结构决定了听觉系统的鲁棒性。因此本项目基于双耳声信号处理框架，研究听觉神经对双耳声信号的交互、融合处理机制，提出相应计算模型，具体包括：研究基于子带互相关函数的空间线索，建立空间方位识别模型；建立前、后向结构的反射声抑制模型，融合均衡抵消处理过程，建立听觉系统优先效应的计算模型，实现混响环境下的空间方位识别；基于协方差矩阵实现短时子带噪声估计，在定位模型中将子带信噪比作为可信度度量，实现子带自适应选择。本项目模拟人耳听觉系统处理结构，给出完整的双耳交互计算模型，实现基于空间线索的目标语音检测和分析，提高现有语音信号处理系统对复杂声学环境的鲁棒性，为语音信号处理系统的鲁棒性研究提供新的研究框架。
基于流场统计建模和聚类的高密度人群多重运动轨迹重建	高密度人群;背景建模;轨迹重建;视频监控;光流	在我国，防范高密度人群中的公共安全突发事件具有迫切的实际需求。以单一非刚体为目标的跟踪技术无法解决高密度人群中目标相互遮挡后的跟踪轨迹碎片（broken trajectories）重分配问题，难以满足运动分析的精度要求；基于光流瞬时速度矢量场的流矢量聚类方法难以描述多状态运动轨迹。本研究立足现有视频监控中的流场人群分析技术，瞄准其在实践中遇到的多状态运动轨迹在复杂背景下的精确描述问题，拟将光流场无参数统计建模、半监督聚类、动态规划等技术相结合，不以个体特征，而是以流场统计分布特征为基元，研究其实现多模式运动轨迹重建的方法，强调其在复杂光照条件下的鲁棒性。建立一个包含高密度人群、多重运动模式、复杂光照条件的视频数据库，验证高密度人群运动轨迹重建算法性能。预期在主流SCI期刊和高水平国际会议上发表论文5~7篇，申请发明专利1~2项，培养硕士研究生2~3名。
计算摄像学中大深度范围场景抖动模糊研究	流形学习;场景深度;图像重构;抖动模糊;计算摄像	实现非静止拍摄平台上的清晰图像获取是国际多媒体领域前沿的研究热点与难点，该方面的突破在军民两用领域都具有重要的研究意义。本项目拟以统计学习理论和计算摄像理论为基础，探索大深度范围场景的抖动图像降质模型及反解清晰图像的病态性根源，研究大深度场景长曝光拍摄中清晰图像重构的理论与技术。具体的研究内容包括：统计分析自然场景深度信息的内在规律，并采用流形学习方法进行场景深度信息解析；在单一场景深度的假设下探索从模糊图像重构场景细节信息固有的欠定性，提出基于编码光路的计算图像采集机制和相应的的计算重构方法，并搭建验证性原型系统；针对大深度范围场景的拍摄，建立深度相关的抖动成像模型，并结合场景深度解析结果提出大深度范围场景长曝光设置下捕获清晰图像的方法。
全光场相机的成像理论和方法研究	迭代重建;掩膜设计;采样理论;全光场相机;全光函数	本项目旨在研究全光场相机成像理论，克服当前全光场相机的不足，对数据获取方式、光场相机的采样理论和离散化方法、高精度图像重建方法等基础科学问题开展研究。项目拟研究掩膜的优化设计理论和方法,通过多目标优化成像指标，建立一种易于实现、成本适中的随机分形掩膜设计方法，增加通光量，有效提高曝光时间，同时提供更多的结构信息和频谱信息；基于Fresnel和Fraunhofer理论，通过引入采样基函数和光场相机变换的形状因子，建立全光场和探测器之间的映射关系，研究全光场相机的探测器分辨率和重建图像分辨率之间的数学关系，建立基于重建点的光场相机采样理论，这一理论将指导建立光场相机成像的离散化模型，形成新的重建方法；研究基于倒置几何CT的理论和重建方法，通过光场相机成像的几何对称性，建立基于几何对称性结构的高精度快速分块迭代光场重建方法。
基于自适应频率尺度变换的骨导鼾声识别关键技术研究	自适应频率尺度变换;鼾声检测;骨导音	打鼾是睡眠过程中呼吸削弱的征兆,20%的人都会打鼾, 其中15%的打鼾者患有睡眠呼吸暂停综合症,其死亡率高达40%，我国大约有 3750 万人的健康受到该病症威胁。本课题对利用骨导音采集的鼾声进行自动识别中的关键技术进行研究。包括对于骨导鼾声采集位置的研究；建立大规模骨导鼾声音频及同步体态数据库。在鼾声特征参数提取方面，根据鼾声、呼吸信号、语音及咳嗽等信号分布计算F-ratio，按照每个频带对鼾声识别的贡献率的大小重新安排滤波器的分布，提出鼾声自适应频率尺度变换新方法，从而更好的获取鼾声音频信号特征。利用受限波尔兹曼机对鼾声特征向量进行降维研究，将原始数据特征向量中各个元素间的相关性体现到高层特征表示中，并降低特征参数维数。通过同步采集的睡姿及鼾声信号，定量分析两者间相关性。利用睡眠呼吸行为事件的上下文关系建立鼾声行为统计模型，并利用隐马尔可夫模型方法建立鼾识别验证系统。
放疗中人体胸腹表面的动态三维测量及区域呼吸运动分析与时空一体预测	高斯过程;结构光;放射治疗;相位展开;深度信息	放疗中呼吸导致胸腹肿瘤和胸腹表面同时移动变形，前者造成剂量偏差影响疗效并导致并发症，后者可望用来推断肿瘤移动变形。针对放疗需求，研究基于一幅GRB复合条纹图案的傅里叶条纹分析结合时间相位展开的人体胸腹表面动态三维测量方法，其中，三频时间相位展开新模型准确度高并可判断剔除大误差点，增加时间变量形成三维傅里叶条纹分析可减小频谱泄露和重叠；研究胸腹表面呼吸运动的数学描述，包括采用特征量描述区域呼吸运动和采用准周期函数描述单点呼吸运动；研究胸腹表面呼吸运动分析方法并得到其运动规律，包括点、区域和全局呼吸运动的分析方法和运动规律；研究区域特征时空一体化呼吸运动预测方法，采用区域特征量并同时预测时间滞后和空间相关。这突破了以往放疗中仅针对胸腹表面点进行三维测量及呼吸运动分析与预测的局限性，将为放疗中肿瘤呼吸运动的检测及分析与预测提供理论基础和技术支撑，并可应用于其他表面动态三维测量和运动分析与预测。
外形信息理解的技术基础	形状匹配;识别与理解;模型简化;形状分析;三维外形信息	三维外形信息，特别是点云数据是当前数字几何处理、多媒体信息处理的重要研究对象。外形信息的处理与形状分析、形状识别与理解、简化与可视化是三维外形信息研究中面临的三个主要问题，其中，形状识别与理解是一个挑战性的问题。本项目以点云为主要研究对象，依据学科发展分析和工作积累，根据已有视知觉理论，应用信息处理技术、数学、计算机科学技术研究上述的三个问题。主要研究内容有四个方面：三维外形信息的处理与形状分析、外形的形状匹配、三维形状的识别与理解、三维离散模型的简化和可视化。技术创新在于点云数据的内蕴几何量与特征线的估计、点云数据拓扑特征的提取及其结构化表征、深度图像分析与点云几何特征分析的结合、离散模型的简化和可视化、点云与体素数据的形状分解方法、三维形状的识别与理解。技术难点在于拓扑结构特征的提取与表征、与视觉感知一致的形状分解、实体的语义描述。
全光采集增强技术与模型研究	光场成像;光场相机	备受关注的手持式全光相机，因其紧凑的光路设计，在带来便捷的可移动性和低应用复杂度的同时也导致其成像质量、光场视场角和景深非常受限，直接影响其推广应用。本项目面向手持式全光相机的动态观测这一光场未来应用，研究全光采集增强技术与模型：首先，建立全光系统响应和快速光场校正方法，定义光瞳调制函数，适应异构全光成像调制光路，校正采集光场，提升成像质量；进而，提出一系列系统层多光场融合技术，适应异构多光场几何关系，有效提升光场采集视场角和景深；最后，基于全光系统响应和增强的光场，建立多对象精准逆投影模型，优化光线追踪，补偿成像系统光学偏差，实现从像空间到物空间的精准投影。该研究成果将以基础理论、算法技术到优化控制方面的原始创新，服务于实时检测、医疗成像等领域基于光场信息的跨越式发展，具有重要的理论意义和广泛的应用价值。
用户参与度影响下的实时视频QoE评估及跨层传输方法研究	低复杂度建模;真实视频流仿真系统;视频跨层传输优化;视频体验质量;视频质量评价模型	视频应用对国家安全、国民经济和人民生活意义重大。随着大量新兴视频业务的涌现，用户不再是单纯的视频信息接收者，而是能够参与到视频播放的各个环节，主观能动性不断放大。探究用户参与度与视频体验质量(QoE)之间的作用机理对提升视频用户满意度具有理论意义和应用价值。本项目以用户参与度影响下的实时视频QoE评估和跨层传输为研究对象，阐明用户参与度、视频内容、网络特征及播放状态等对用户体验的影响机理，揭示跨层参数配置与视频QoE提升之间的内在规律，建立基于用户参与度的视频QoE模型，构造并求解QoE驱动的视频跨层传输优化问题，开发真实视频流QoE评估和跨层传输仿真系统。创新点：以用户为核心、视频业务发展为导向，将用户特性和新兴视频业务特性有机融合，建立新的视频QoE评估体系；构造视频QoE驱动的全局统筹跨层优化问题，同时对多层参数进行优化；搭建真实视频流仿真系统对所提模型和算法进行性能验证和参数修正。
面向三维数字视频的视觉注意力模型及其应用研究	三维视频处理;显著性检测;视觉注意力;三维视频智能适配显示	随着三维成像和显示技术的飞速发展，基于视觉感知机理的三维数字视频分析技术已成为多媒体处理领域的研究热点，其特点在于使用有限的计算资源分析人眼关注的视觉信息并获得符合人类认知的分析结果。本项目针对三维数字视频分析技术中存在的共性基础问题，通过研究影响三维视觉注意力的因素及其作用方式，建立不同视觉特征对三维视觉注意力的影响机理，提取三维视频的不同视觉特征并研究相应视觉特征感知模型；根据Gestalt视觉感知理论深入研究三维视觉特征融合机理并建立视觉特征融合模型，以构建最终的三维视觉注意力模型；同时基于构建的三维视觉注意力模型设计智能适配显示算法。本项目的研究将形成一套面向三维数字视频的视觉注意力建模理论与方法，为各类三维数字视频处理应用提供基本的视觉显著信息表达与提取方法；同时提供基于视觉注意力模型的三维数字视频智能适配显示方法的应用框架，为三维数字视频处理及应用提供关键技术与理论支持。
非现场说话人认证语音真实性检测关键技术研究	语音唇动一致性;说话人认证;信道模式噪声;挑战响应;活体检测	说话人认证应用日益广泛，但自身安全问题研究不足。回放攻击是最容易实施、危害最大安全问题，本课题旨在为单纯语音和音视频两种普适性接入方式下的回放攻击探索解决方案。研究内容包括：1）以认证语音获取信道模式噪声分析为依据的以检测获取设备及传输信道真实性为重点的回放语音检测方法；2）以检测认证语音获取时间和内容真实性为重点的基于认证实体注册信息的挑战响应回放攻击检测方法；3）以说话人真实性和样本获取时间真实检测为重点，通过融合音视信息时空相关性，以特定发音单元定位的语音唇动一致评估为依据的回放检测方法,同时音频与视频的自然时延以提高一致性估计的准确性；4）录音、回放设备差异对回放语音检测的影响；5）回放攻击检测对说话人认证系统的影响及对策。.   本课题研究具有重要理论意义和社会意义。拟发表学术论文16篇，申请国家专利2项。
多源监控视频大尺度人群异常行为感知研究	群体行为分析;因果推理;流体场;多源视频;原子事件	近年来，随着我国政治、经济、文化与社会活动日趋活跃，大型活动已经成为促进经济发展和文化交流的重要载体，对大型的群体活动的有效监控成为城市管理必不可少的一部分。针对大尺度人群监控问题中群体规模大、事件范围大、时间跨度大的特点，本项目结合本学科的发展趋势和申请者相关的工作基础，通过汇聚流体力学、机器学习和计算机视觉领域的应用和理论拓展的研究成果，利用拉格朗日粒子动力学和因果关联性分析的相关理论，对多源大尺度群体监控问题进行研究，揭示多源大尺度群体事件的演化规律，提出相应的群体行为分析模型，实现拥挤群体的异常行为的快速高效感知。本项研究将形成一套完整的研究方案及相关技术路线，以期望对大尺度群体的智能视觉感知技术进行突破与创新，对于提高我国计算机视觉相关领域的基础研究水平具有重要的科学价值。同时，对提高我国群体性事件的防控能力，实现城市公共安全智能化、信息化管理具有重要的现实意义。
基于在线距离度量学习的自适应视觉跟踪方法	在线距离度量学习;跟踪状态判定;模板库更新;自适应视觉跟踪;特征显著性预判	外观建模和特征匹配是影响视觉跟踪成败的两个关键环节。现有方法通常"预先指定"且"割裂考虑"二者，导致跟踪性能下降。距离度量学习(DML, Distance Metric Learning）理论为解决这一问题提供了契机。本项目拟对在线DML框架下的视觉跟踪机理和方法进行系统研究，以实现快速长程持续跟踪。具体包括：（1）研究基于特征显著性预判和压缩降维的外观建模，揭示特征描述子对目标自身特性的刻画能力，建立预判函数与特征描述子之间的对应关系；（2）研究匹配度量的局部在线增量学习方法，分析局部数据空间分布和目标运动特性对度量更新的影响，推导数据驱动的高效连续解析解；（3）研究跟踪状态判定和闭环反馈机制，建立自适应的模板库更新模型，有效克服跟踪漂移。通过本项目的研究，可以为复杂动态场景下的鲁棒视觉跟踪提出切实可行的解决方案；同时，取得的成果也将充实扩展DML理论本身，为其他领域的应用提供参考。
高密度复杂场景中群体异常行为检测方法研究	深度神经网络;特征编码;异常行为检测;主题模型;群体运动分析	高密度复杂场景中群体异常行为检测是智能视频监控领域的重要研究方向，对其开展研究具有重要的理论意义与应用价值。现有的方法通常存在局部特征有效性不足、全局特征缺乏判别性以及行为模式难以准确学习等问题，为此本项目针对局部特征提取、全局特征聚合和和行为模式学习等关键问题开展深入研究，主要包括：研究基于卷积神经网络的群体行为特征提取方法，解决人工局部特征忽略数据特性且缺乏学习能力的问题；研究基于词典学习和紧凑编码的群体行为全局特征聚合方法，解决现有无监督方法获得的编码特征判别能力不足的问题；研究融合上下文LDA主题模型的群体行为模式学习方法，准确学习群体行为模式；最后，分析上述研究内容间的耦合关系并构建整体检测算法框架，面向高密度复杂场景提出各阶段均具有自学习能力的群体异常行为检测方法。
信息确定度自适应的监控视频高效编码研究	高效压缩;信息确定度;自适应;监控视频;多流封装	不同于传统的面向电影电视的娱乐视频，每天24小时连续采集的监控视频中，往往只有包含特定语义信息的视频片段才会提供用户需要的信息。根据特定语义事件发生的概率-信息确定度，有效地去除监控视频中用户不感兴趣的信息冗余，将大大提高监控视频的整体编码效率。本项目以申请人在视频编码与传输、智能监控等方向的前期研究工作为基础，基于现代信息论、统计认知理论与视频编码方法，探索监控系统信息确定度感知的监控视频高效编码理论与方法。拟通过研究监控视频基于低层特征上下文的语义提取、信息确定度的贝叶斯网络建模感知、确定度自适应的多维度可伸缩编码、信道空域-时域资源最优化分配的多流封装，有效去除蕴涵在监控视频信号中用户不感兴趣的信息冗余，获得监控视频编码效率的突破性提升，为提高我国监控视频编码的基础研究水平起到积极的作用。
多视点视频自适应压缩感知与并行多级预测重构研究	重构;自适应;边信息;多视点视频;压缩感知	多视点视频（MVV）在三维电视、自由视点视频、远程医学诊疗、无线多媒体传感器网络、视频监控系统等领域有重要应用。压缩感知（CS）图像传感器成本低、能效高、存储和带宽需求低，是解决MVV系统海量视频存储与传输瓶颈的有效方法。然而， 现有的MVV压缩感知研究基于非自适应压缩投影，重构复杂度高、且精度低，不适合非平稳MVV应用。尽管发展了基于贝叶斯感知、稀疏性模型逼近和自适应分块采样等感知策略，但这些方法不能用于视频实时压缩采样。据此提出MVV的自适应压缩感知和并行多级预测重构研究。该研究基于场景内容的稀疏性和运动特性自适应调整MVV的压缩采样率和帧速率，实现MVV自适应压缩感知；解码端利用时间和空间相关性产生自适应边信息，通过并行多级预测重构处理，实现MVV的高精度和低复杂度重构。最终获得一套具有自主知识产权的MVV自适应压缩感知与快速高精度重构理论与方法。
降雨视频分析及雨天运动目标检测关键算法研究	雨滴检测与消除;倒影检测;目标检测;视频图像;动态背景	现有关于视频运动目标检测的研究，往往笼统考虑场景中可能出现的干扰因素，缺乏专门针对某类气象场景的研究。针对降雨这类天气干扰，包括运动雨滴和雨天倒影等因素，本项目从雨这一特殊气象的物理特性和视频特征出发，构建能够适应于降雨天气的、避免雨滴和倒影干扰的视频运动目标检测算法。研究内容包括：1) 创新的利用现有运动检测算法中被忽视的误检信息，通过二次分类识别动态背景类型，构建雨天运动前景检测算法。2)针对现有视频雨滴检测与消除算法大多只适应于静态背景或仅存在缓慢运动的情况，揭示运动雨滴成像规律，构建雨滴成像系统模型，提出动态场景下雨滴检测以及不干扰兴趣目标的雨滴消除算法。3)针对现有研究大多关注日照天气下无色阴影的情况，研究雨天有色倒影形成的物理模型，揭示倒影覆盖前后图像的光度变化规律，提出雨天倒影识别算法。
基于浸入式光栅的偏振超光谱成像技术研究	超光谱;浸入式光栅;遥感探测;偏振;图像获取	在科学遥感探测领域中，光谱仪的应用十分广泛。其中基于浸入式光栅的光谱设备以其克服了小体积与超高光谱分辨本领之间矛盾的特性，成为目前国际上的研究热点，而国内尚未见相关报道。同时，将浸入式光栅应用于偏振光谱成像光学系统的研究在国内外也尚无涉及。本项目主要针对小型紧凑、结实易用的偏振超光谱成像应用需求（深空遥感探测、对地遥感观测等），提出一种以浸入式光栅为色散元件、利用偏振分束器同时获得正交线偏振图像信息的新型偏振超光谱成像方案。通过理论分析、系统仿真、优化评估等手段，对浸入式光栅的特性及其在偏振系统中的应用、成像系统总体匹配优化设计等方面所涉及的若干基础理论问题和关键技术问题，展开具有针对性和探索性的研究，所获得的成果对于偏振超光谱技术在遥感探测等多个领域的发展具有重要的理论意义与实际价值。
精神压力下基于物理模型的变异语音生成机理探索及检测方法研究	气流流态;变异语音;物理模型;语音生成机理;生理特征	压力、情感、心理紧张引起的说话人发声变异一直是语音领域的研究热点。因变异语音生成机理复杂，且缺少统一的表征和描述，使得精神压力下语音的检测识别存在着一定局限性。为此，本研究基于传统模型，建立说话人变异语音生成的物理模型，揭示精神压力状态下说话人发声生理系统及其中气流流态的变化规律，探索变异语音的生成机理；通过物理模型模拟，设计生理特征估计算法，建立压力相关生理特征与声门波参数的关联，提取与压力因素有关且拥有物理意义的声门波参数；以说话人生理信号作为压力异常状态的客观评价标准，在语音收集的过程中对样本进行标注。重点解决：（1）建立针对变异语音的物理生成模型；（2）设计基于物理模型的特征提取算法，进行压力下变异语音识别；（3）通过说话人生理信号进行压力的客观评价。研究成果不仅可以处理语音中的言语和非言语信息，而且可为语音技术的相关研究领域问题的解决奠定了理论和实践基础。
适用于无线多媒体传感器网络的图像压缩算法及多节点协同图像传输技术研究	图像压缩;多节点协同;方向优化重叠变换;无线多媒体传感器网络	作为传统无线传感器网络的一种特殊应用，无线多媒体传感器网络（WMSNs）使人类视野扩展到任意物理空间，在国家安全、环境、医疗等领域具有非常广阔的应用前景。WMSNs具有处理任务复杂化、图像数据处理与传输能耗呈现"均匀"分布等特点，能否有效解决因数据处理复杂带来的高能耗、高成本问题，成为无线多媒体传感器网络能否走向实用化的关键。基于此，本课题以理论和算法研究为主线，理论探索、算法分析与实验验证相结合，克服现有的图像压缩方法在WMSNs这一应用环境中存在的不足，以基于方向优化重叠变换（DLT）的图像编码技术作为基点和突破口，设计低功耗的图像传感器节点以及适用于WMSNs的多节点协同图像传输方案，力求在突破其中某些关键问题的基础上，形成和建立一套适用于无线传感器网络的图像压缩理论、算法和实现方案，为推动无线多媒体传感器网络的实用化进程提供理论与方法支持。
基于霍夫森林—部分有向条件随机场的视频多目标跟踪方法研究	部分有向条件随机场;遮挡推理;轨迹关联;霍夫森林;多目标跟踪	受目标外观和运动模式的变化、遮挡等诸多因素影响，复杂场景下的多目标跟踪颇具挑战性。本项目利用随机场图模型，研究新的多目标轨迹关联方法，主要内容包括：（1）多目标跟踪问题建模。提出部分有向条件随机场模型（PDCRF），将多目标轨迹关联问题转化为随机场模型下的多类别标定问题；PDCRF模型是传统CRF模型的推广，不仅考虑轨迹片之间的关联，同时还刻画了两对轨迹对之间的关系。（2）基于HF—PDCRF框架的CRF推理。一方面，SW-cuts算法根据建议分布、后验概率的比值，实现MH跳转和CRF推理；另一方面，通过霍夫森林学习，融合目标的外观和运动特征，以非参数形式为MH跳转接受率的计算提供可靠的概率估计；HF—PDCRF将CRF模型学习和推理统一到一个框架之中，简化了传统的CRF模型求解过程。（3）研究新的遮挡推理模型，在此基础上设计"孤立点"响应与目标轨迹的匹配策略，提出有效的遮挡问题处理方法。
视频编码实时处理算法研究与VLSI实现	H.264;模式选择;视频编码;运动估计;VLSI	新一代视频压缩标准H.264在实现更高编码效率的同时具有更高的计算复杂度，需要消耗大量的时间和系统资源。因此，实时编解码器实现面临巨大挑战，需要寻找高效的优化算法。本课题针对H.264视频编码关键技术和VLSI系统架构进行深入研究。.算法方面，面向VLSI硬件实现及实时应用，设计基于搜索窗中心预测和中途截止的自适应运动估计算法和基于自适应门限的帧间/帧内联合快速模式选择算法。.在VLSI实现方面，设计基于宏块编码的四级流水结构和帧间预测VLSI结构，合理分配每级流水链的运算负载；利用新型存储空间映射方法，设计高效SDRAM控制器结构；设计高效的去块效应滤波器硬件加速结构以实现编解码系统的实时滤波。
特征自学习机制下的密集群体内多人交互行为异常感知	自学习;视觉感知;稀疏特征;密集群体;互动行为	密集群体不仅为违法犯罪事件提供了更加隐秘的实施空间，而且存在小范围异常迅速波及大范围区域的可能。因此，及时发现并预警密集群体中异常事件与民众的公共利益和社会长治久安息息相关。然而，群体视频监控图像普遍存在目标遮挡严重、单目标分辨率低、异常行为运动特征不显著等特点，导致遵循多目标检测跟踪或群体运动流分析思路均局限于特定的群体密度和异常类型。本项目拟建立一种基于特征自学习机制的密集群体多人交互行为异常感知算法架构，在固定视角下，利用密集群体流动性分析获取异常预判区域，再采用多层自学习稀疏特征描述多人互动行为时空区域，并结合行为人的运动轨迹、空间分布、关注区域等信息实现密集群体中的多人交互行为识别和异常感知。本项目的研究成果不仅对公共场所异常行为智能检测及预警，刑侦案件辅助侦破等公共安全事务的智能化发展有积极的推动作用，还能为人机交互,环境控制和监测,体育及娱乐分析等多个领域的应用提供研究基础。
复杂监控场景下融合红外和可见光双模信息的小目标事件检测方法研究	双模融合;复杂监控场景;显著性检测;细粒度识别;小目标事件检测	围绕较大监控场所中（车站、广场等）的小目标事件检测可靠性和时效性需求问题，提出在大规模数据中基于局部时空搜索的研究思路，利用红外和可见光成像互补性，以及显著性/似物性检测、细粒度识别等最新技术，以期突破"如何高效地降低搜索空间"和"如何有效地区分小目标事件与相似杂波"两个关键问题，达到提高检测可靠性和时效性的研究目的。项目主要进行：1）分析复杂背景下兴趣目标的可见光和红外成像特性，建立双模成像特性描述模型；2）通过现场拍摄等手段构建双模视频数据集；3）基于成像特性描述模型和显著性/似物性检测最新成果，研究高效的事件候选区域检测方法；4）基于细粒度识别最新成果，研究小目标事件细粒度识别方法；5）进而研究一个完整的、有较高可靠性和时效性的小目标事件检测算法。项目的完成将为当前监控的系统升级，以及未来新型监控系统的研制提供理论与关键技术支持。研究成果可以直接服务于车站、广场等较大场所的智能监控。
多维信号结构保真的矢量稀疏表示模型研究	稀疏表示;图像重建;视频重建	多维信号的结构保真与高效表示是信息学科领域的关键技术，在视频图像压缩、医学影像分析、多光谱信号处理等领域有着广泛的应用。其难点在于如何采用少量的基元来获得对原始信号有效信息的完整重建。现有方法通常将多维信号降阶成多个二维标量信号而分别独立表示，由此会导致信号某些维度上的结构失真。结合前期研究基础，本项目拟通过对多维信号的矢量稀疏表示模型的研究，为常见的多维信号处理任务提供一种普适的、结构保真的分析工具。主要创新之处包括：（1）研究和构建基于四元矩阵分析的矢量稀疏表示模型，以解决多维信号通道间结构失真问题；（2）研究和构建基于张量分解的矢量稀疏表示模型，以解决多维信号时空结构失真问题；（3）研究和构建基于四元深度神经网络的多维信号表示模型，以解决多维信号分布式结构失真问题。
自然场景光场成像中非干涉确定性相位恢复研究	非相干;光场成像;光场分析;相位恢复;强度传输方程	光场的振荡频率极高，常规光学传感器只能直接记录光场强度，因此包含物体形状细节和深度等更重要信息的相位只能从强度测量中恢复。经典的非干涉确定性相位恢复技术通过求解强度传输方程从强度中恢复相位，在相干光场中获得了广泛的应用，但该方法仅适用于相干、单波长情形。具有非相干和多波长特性的自然场景的光场相位恢复问题仍具有挑战性。 本项目拟构建自然光场相位恢复理论分析、数值计算和实验体系的整体框架。首先拟采用更为严格的非傍轴理论描述非相干照明下自然场景聚焦平面附近光场特性，构建新的描述强度和相位关系的微分方程；然后结合Green函数理论探讨多波长情况下相位解缠的物理原理；再用多强度测量结合高阶导数改进原有计算强度偏导数的处理方式，以提高算法的抗噪声能力；同时突破均匀照明近似约束，寻找更有效的相位计算方程数值求解方法。该研究将为全光场重构、军事、防御（如伪装的识别、隐蔽测距）等方面提供新的技术支持。
基于视觉注意模型的结构化图像分析技术研究	视觉注意模型;结构化学习;图像处理;图像分析	随着图像数据量的迅速膨胀，对图像信息的分析理解和有效利用已成为亟待解决的问题。本项目拟结合申请人的前期工作，基于人眼视觉选择性注意模型，尝试采用结构化学习的思想，研究对图像进行多层次语义解析的结构化图像分析方法。将把视觉特征信息用于图像的分析处理中，以提高分析处理的性能。并将针对图像分析中的特定任务，设计一种结合自底向上和自顶向下选择性注意机制的视觉计算模型，计算得到的图像显著度信息不仅可作为结构化学习中的基本特征用于图像的分析识别，还将有效处理结构化学习处理结果的"虚警"问题。本项目的研究成果可被广泛应用于视频监控、医学图像分析、互联网搜索引擎等领域中。
基于冗余字典和感知压缩的空间音频对象编码	冗余字典;卡尔曼滤波;空间音频对象编码;压缩感知	高性能数字音频编码技术是当前通信技术和多媒体技术的重要基础。随着应用对音质和压缩率要求不断提高，传统的基于香农采样定理和频域分析的处理技术，难以跟上日益提高的音频应用需求。面对挑战，目前具有前景的解决途径包括：基于对象的音频编码技术和基于感知压缩理论的信号处理方法。本项目研究通过结合基于音频对象的多通道编码技术和感知压缩技术实现高音质的多通道编码技术。其中基于音频对象的编码技术能够有效降低通道间信号冗余，而感知压缩技术能够进一步消除冗余，实现高质量音频的高效编码。和现有的MPEG多通道编码方案比，所提方案计算复杂度低，通过研究对语/乐音信号均具良好稀疏分解能力的冗余字典，使得算法能够抑制噪声和干扰；相同数据速率下的信号质量性能超过现有的空间音频对象编码。具体研究内容分：空间音频对象参数信息提取与恢复；针对语乐音信号的稀疏分解基计算；测量值的矢量量化编码方式以及根据感知压缩特点建立心理
适应移动云计算的自由视点合成、自适应卸载与功耗优化	自适应卸载;功耗优化;移动多媒体云计算;自由视点视频;自由视点合成	云计算通过卸载终端负载，使移动终端享用高复杂度的多媒体应用成为可能。但是，对于当前备受关注的自由视点视频，因其现有的视点合成技术在合成质量约束下生成的中间数据量大、技术复杂度高且不易拆分，直接应用云计算卸载无法保证移动终端功耗的降低。本课题研究适应于移动云计算的视点合成技术，以实现移动终端功耗最小化为目标，利用特征抽样、图像、深度与几何信息预测，研究基于深度DCR等高表征、基于视间、时域运动补偿以及基于图像特征聚类的新型视点合成技术，在合成质量约束下实现系统层到算法层的跨层数据/负载精细可拆分。进而通过多维负载的全局映射和终端功耗特征定义，建立面向移动云计算的视点合成终端功耗模型和实时动态多约束优化与控制方法，实现视点合成负载在移动终端和云端间的自适应卸载，使终端实现自由视点合成的功耗最优化。该研究服务于下一代多媒体应用向轻型终端的演进和"云"化发展，具有重要的理论意义和广泛的应用前景。
基于图建模和图嵌入框架的视频指纹研究	图嵌入框架;版权保护;图建模;视频指纹	本项目以基于内容的视频指纹为主要研究内容，结合当前的研究现状与发展趋势，采用图建模和图嵌入框架进行研究。利用视频时空特性，建立视频图模型，以图顶点度和二叉树理论选取视频代表帧、分散帧；结合马尔科夫随机场、能量优化以及图割理论进行视频帧主要内容的提取，实现视频数据的第一级约简；根据视频内容认证的要求，通过对图嵌入框架的研究，提出针对视频数据特点的维数约简算法，实现视频数据的第二级约简；进而，利用峭度理论，结合低维空间映射点的统计特性和几何特性构造视频指纹。本项目在保证视频指纹鲁棒性和区分性的基础上，对视频高维空间的图建模、图嵌入框架下的视频维数约简、基于统计特性和几何特性的视频指纹的生成和匹配等关键问题展开研究，将图论应用于视频分析中，结合图嵌入框架对视频数据进行双重约简，获取基于内容的视频指纹。对基于内容的互联网视频认证和管理技术的发展具有重要的推动作用和研究意义。
音频事件检测技术研究	音频语义单元;音频事件检测;深度学习;音频词典	面对海量的音视频数据，如何对内容进行快速有效的解析与表示，并建立满足实际需求的事件检测框架已变得极为迫切。音频事件检测技术能够从音频信号中直接提取人们关心的事件信息，是数据有效管理和信息快速获取的关键技术。针对音频成份单一的简单音频事件检测技术在国内外发展相对成熟，而面向音频成份更为丰富的复杂音频的研究工作则刚刚起步。经典的音频事件检测方法,由于未显式考虑音频内在的语义结构，难以对复杂的音频事件进行准确的检测。本项目以各类现实生活场景中的实际音频作为研究对象，研究复杂音频的事件检测问题，主要包括音频信号的层次化表示，基于内容挖掘的音频词典构造和音频语义结构发现，以及基于深度学习的音频语义单元识别和音频事件检测算法。音频信号的语义表达以及相关的机器学习问题是本项目探索的关键科学问题。本项目的研究对复杂音频内容的理解和使用具有重要价值。
面向语义事件的视频故事单元关联分析与跟踪关键技术研究	相似度计算;相似关键帧识别;故事单元;"多线程"跟踪;关联分析	基于语义的视频分析是视频研究领域的一个热点问题。然而视频语义获取面临很多实际困难，因此在视频分析研究中缺乏类似于文本领域开展的"话题探测与跟踪"研究，而开展面向语义事件的视频故事单元关联分析与跟踪研究能够利用视觉信息实现基于语义事件的报道分析与跟踪，在信息检索、情报分析、辅助决策等领域具有广泛的应用，具有重要的理论和应用价值。本项目以实际服务需求为牵引，研究以故事单元为基本语义单位的视频关联分析系统模型，在此模型基础上，对一系列关键技术进行深入研究，包括：相似关键帧识别技术、故事单元关联分析技术、故事单元相似度计算技术、故事单元"多线程"跟踪技术。项目研究能对报道相同事件的故事单元进行关联和"多线程"跟踪，可以体现事件报道变化的历程，改善信息的组织与检索方式。不仅可以提高视频处理的智能化程度，而且可以为更高层次的用户个性化需求奠定技术基础，推动视频挖掘技术的进一步发展。
基于表观模型学习和运动模式记忆统一架构的目标跟踪方法研究	卷积神经网络;在线学习;长短期记忆;视频跟踪;递归神经网络	目标跟踪问题是视频信号处理领域长期以来的一个基本问题和热点问题。近年来，在经典目标跟踪框架中引入深度卷积网络提取视觉特征构建表观模型，作为一条可行思路显著提升了传统目标跟踪方案的综合性能。然而随着该领域所涉及的应用场景日趋复杂，对于外观剧烈改变、前景严重遮挡等挑战性问题而言，继续在经典目标跟踪框架下进行算法改进所带来的局限性越发明显。针对此现状，本项目提出在统一的深度学习框架内重构经典方法，从知识学习和记忆的视角研究目标跟踪问题；一方面通过卷积网络基于样本之间的相似性学习表观模型，一方面通过递归网络记忆目标乃至全局图像的运动模式；最终实现特征提取、知识记忆和目标跟踪的统一结构，提升跟踪器在差异场景下的综合性能。本项目研究成果不仅对视频目标跟踪方法的进一步发展具有重要意义，其中对于复杂空时网络在线训练等理论问题的讨论还可为深度学习相关领域的发展提供新思路。
基于认知计算模型和电影理论的多线索视频语义提取	故事片;语义结构;认知模型;视频语义;电影理论	近年来，基于内容视频检索的研究方兴未艾，随着视频结构化以及索引技术的日渐成熟，对视频语义的分析与提取成为了视频研究的核心，也成为视频检索能否被广泛应用的关键一环。目前，视频语义的研究主要集中在新闻和体育等场景简单的视频上，对故事影片的语义分析则甚少。本项目将以故事片为研究对象，从可计算的电影理论（电影计算模型）、认知模型的运用和多语义线索及语义组合3方面来对视频语义的提取进行探索，建立视频底层特征与高层语义之间的内在联系，为跨越语义鸿沟提供一条可行的途径。2006年，互联网进入视频元年，因此本项目的开展不仅具有理论意义，而且具有潜在的市场前景。
基于分布摄像机的目标跟踪与行为分析若干关键问题研究	目标匹配;行为分析;特征表达;视频信息;智能分析	视频监控是公共安全的重要技术保障，出于扩大监控范围与节约成本的目的，摄像机多为分布式安装，视域重叠或不重叠情况共存。监控智能化是解放人力，提高监控及时性和有效性的必然途径。目标跟踪与行为分析是其核心问题之一。本项目从分布式环境下目标及其行为的多模态特点出发，研究其中涉及摄像机间信息融合的以下关键问题：网络拓扑估计与互标定、目标匹配、协同跟踪及融合多摄像机信息的行为分析。在摄像机网络拓扑估计中结合重叠视域检测，建立混合的网络拓扑表达。针对目标表观多变的特点，基于流形泛化学习研究目标不变特征表达方法。利用群组匹配的思路解决因严重遮挡而难以准确分割目标和匹配跟踪的问题。对目标行为进行局部行为与全局行为的层次表达，融合多视图、多特征，实现目标运动的多模态刻画。预期的研究成果包括10篇以上高水平论文，申请2项以上发明专利，并建立一套成果演示系统。相关成果将可直接应用于提高分布式视频监控的智能化水平。
基于多摄像头网络和多尺度分析的组群与集群行为识别研究	集群行为识别;多摄像头联合行为识别;多尺度行为分析;视频监控	行为识别与分析技术在智能视频监控等应用中有着极为重要的作用,然而目前行为识别技术的研究仍然难以满足视频监控等应用的发展和需求。本项目拟结合申请人在行为识别和事件检测方面的前期研究工作以及模式识别和机器学习理论的发展趋势，分别从识别模型的构建和特征分析等方面对行为识别与分析领域中的几个重要问题进行重点研究并提出解决方法，主要体现为：(1) 提出基于网络传输模型的新方法，有效解决利用多摄像头实现联合行为识别的问题；(2) 提出新的多尺度特征分析及结构化模型，实现对组群中的各个尺度行为进行完整分析的目的；(3) 提出基于热模型的一致运动区域分割及行为分析等方法，突破高密集场景下对集群行为进行有效提取、分析、识别的难点。本项目的的研究成果将有力推动行为识别技术的研究及应用，为行为识别技术在智能视频监控等系统中的应用提供新的理论依据、关键技术、和可行算法。
基于张量结构稀疏模型的高光谱成像信息处理	张量模式;稀疏表达;多重线性代数;高光谱成像;计算摄像	高光谱成像是探测与成像技术的一场深刻革命，同时也带来了信号与信息处理方法的变革，光谱分析和图像分析如何有机结合，以充分利用高光谱成像提供的丰富数据信息，是我们面临的巨大挑战。高光谱成像信息的外在数据表达是三阶张量形式，而内在的光谱、纹理、几何和光照特性之间存在复杂结构关系和信息冗余。张量代数和稀疏表达是信息处理和机器学习领域的新兴理论，和高光谱成像信息的数据处理形式和生成机制具有一致性。本项目在探讨张量结构和稀疏表达的内在关系、融合模型、及优化算法基础上，研究高光谱成像数据的张量结构稀疏表达机理，基于张量结构稀疏模型的张量稀疏分解/变换、张量结构特征提取/选择、张量结构稀疏回归和分类等方法，以及在高光谱成像数据的去噪、压缩、解混、匹配、识别和检测等关键问题上的应用。形成比较系统的张量结构稀疏理论，为高光谱成像数据处理提供新的处理和分析工具，并为其它物理系统的信息处理提供借鉴和参照。
面向无约束视频的时空显著性模型及其应用研究	时空显著性模型;无约束视频;区域级显著性图;基于显著性的视频处理;视频信息处理	近年来用于视频的时空显著性模型已逐渐成为国际前沿的研究热点，但目前各类模型的普遍缺陷是难以有效处理无约束视频，其时空域特征的复杂性会导致现有模型的显著性检测性能严重下降。为有效克服现有模型的缺陷，本项目提出基于区域级时空域特征的时空显著性模型。首先，提取区域运动轨迹描述符及帧内/帧间区域相似性矩阵等时空域特征，以增强对象区域和背景区域的可区分度。然后，系统地提出区域级时域/空域显著性度量、显著性帧间传播与调整、基于置信度的显著性融合及显著性帧内扩散等方法来生成区域级及象素级时空显著性图，以有效提升对无约束视频的显著性检测性能。最后，提出适于无约束视频的时空显著对象检测与分割方法，利用窗口轨迹显著性、区域级对象分割与显著性修正的联合优化及象素级局部修正，来提升检测与分割性能并充分验证所提出模型的有效性。预期研究成果不仅将丰富并发展显著性模型的研究，而且将推动基于显著性的视频处理技术的发展。
平板显示器件Mura缺陷的计算摄像检测研究	Mura缺陷;平板显示器件;计算摄像	平板显示器件年产量1.7亿平方米，是计算摄像研究中的重要空间光调制器件，更是消费类电子产品的核心部件。平板显示器件工艺和结构复杂，存在低对比、边缘模糊的Mura缺陷。Mura产生机理研究因高精高效检测技术的缺乏而无法取得突破性进展，长期制约了产业发展。本项目针对Mura检测这一是弱特征光信息重建国际难题，充分考虑平板显示器件的空间光调制器本质，在计算摄像学思想指导下，耦合采集光谱调制图像，形成调制图像数据库，挖掘Mura缺陷在调制能力上的本质特性，学习理解弱特征探测的自然规律，总结归纳Mura的表征模型，构建非空/频域滤波的弱特征缺陷快速提取和判别方法。同时搭建验证平台实现反馈优化，从基本原理和系统构架两个层面改变目前平板显示器件Mura缺陷检测的体系。力争在科学原理方面促成对弱特征缺陷检测规律的新认识；指导工业检测实践，为Mura缺陷产生机理研究提供支撑。
基于稀疏运动轨迹与图论的运动摄像机下的视频运动目标检测研究	智能视频分析;目标检测;图论;运动识别;视频图像	随着运动摄像机在智能交通、公共安全、犯罪侦查、机器视觉等领域的广泛应用，从运动摄像机拍摄的视频中提取出运动目标，进而追踪并分析目标行为，成为了智能视频分析系统中亟待解决的关键技术。然而视频背景与运动目标之间的运动混叠和运动视差，使得大量现有的检测算法无法准确检测出运动目标。为了解决运动摄像机对视频运动目标检测带来的难题，本课题开创性的引入运动轨迹稀疏模型，有效去除冗余数据，提高检测效率。并进一步借助图论在表述事物之间各种关系的强大能力以及高效的算法，分割出赋权无向图中运动目标子图与背景子图，从而检测出运动摄像机下的视频运动目标。通过研究，本课题欲揭示运动轨迹的稀疏模型影响运动目标检测效率的规律；阐明稀疏运动轨迹的赋权无向图模型适用于移动摄像机下的视频运动目标检测的原理；建立高效的视频运动目标检测方法。这将成为智能视频分析在国民安防领域建设的一个重要技术突破，具有重大的社会效应和经济价值。
无监督语音层次结构联合建模及其应用	语音建模;声学模型;语音分析	当前的语音识别与合成系统是建立在音素、词等语音层级结构之上的有监督机器学习过程，需要大量语音学专家知识以及充分的标注训练数据。本项目旨在采用无监督的方法自动学习得到语音中的音素、词等语音结构单元，解决语音处理技术中过度依赖人工标注和专家知识的问题。首先，当前研究将不同语音结构单元单独建模、割裂研究，建模方法和数据高度相关,模型选择需要大量的人工干预。针对这些问题，以非参贝叶斯模型作为建模手段，研究语音层次结构联合建模方法,同时解决模型选择问题。其次，针对语音特征提取中未能充分考虑时序和语音单元可变长的特点，利用神经网络强大的特征学习能力,以语音层级结构为"弱监督"指导信息,得到既嵌入语音重要时序信息又具有区分性的语音特征。最后，利用自动学习到的语音层级结构，实现无标注抄本、无任何语言专家知识的零资源(Zero-resource)条件下的语音处理，包括语音关键词检测、语音文档的语义分析等。
中英文混合语音识别中声学建模关键技术研究	知识迁移;语音识别;数据增强;声学建模;词典构建	随着智能语音技术的快速发展以及人们沟通交流的国际化趋势日益加剧，高性能的中英文混合语音识别技术成为迫切需求。然而，传统的中英文语音识别大多注重于研究中英文句间切换的情况，这使得其难以满足当今大多数用户的需求。本项目致力于研究中英文在句内混用的语音识别混合声学建模技术，建立统一的技术框架，针对其中的关键科学问题展开深入探讨。具体内容包括：对中英文混合语音数据量及其声学环境进行增强，提高声学模型深度学习统计建模的准确性和鲁棒性；提出结合语音识别错误中的反馈信息、语音学知识和已有的数据驱动算法，构建更合理的中英文混合发音词典，消除中英文音素差异带来的负面影响；从深度特征表达和声学模型自适应两方面实现非母语英语口音特性和英语语言属性的知识迁移学习，提高混合声学模型对英文发音变异的鲁棒性；搭建一套中英文混合语音识别示范系统，并与相关企业合作进行成果推广及应用。
基于分布式麦克风阵列的说话人定位与跟踪方法研究	非线性滤波;说话人跟踪;分布式麦克风阵列;声源定位	本项目研究基于分布式麦克风阵列的说话人定位与跟踪方法，它在多媒体通信、人机接口、机器人、军事等领域有广泛应用价值。主要研究内容为：(1)应用最大似然等理论，研究分布式麦克风阵列的校准方法，有效地估计麦克风阵列的几何位置；(2)应用无导师聚类方法和矩阵理论中的盖氏(Gerschgorin)圆估计方法，构造语音信号源数的判决准则，进行说话人数目的估计；(3)应用随机集合理论和模糊K均值聚类方法，识别和选择能提供有效信息的最佳节点麦克风，以减少计算复杂度；(4)考虑到分布式麦克风阵列位置的估计误差，研究稳健的时延估计方法，并用总体最小二乘和最大似然理论，研究说话人定位方法；(5)考虑到说话人运动模型和分布式阵列的特点，用多传感器多目标跟踪中的数据融合算法，采用分布式非线性Kalman滤波和Bayes递推滤波技术，研究说话人跟踪方法；(6)建立基于分布式麦克风阵列的说话人定位与跟踪实时处理系统。
非特定人自然语音情感识别的建模方法研究	情感计算;语音识别;非特定人语音情感;声学建模;音频信息	语音情感识别研究如何通过语音信号辨识说话人的情感状态。本项目研究非特.定人自然语音情感的感知建模与识别，对于揭示人类情感活动的机理和探索人类智能行为的.本质，具有重大的意义。研究重点在于如何将特定人、离散情感的语音情感识别发展为非特.定人、连续情感的语音情感识别。明确区分心理情感状态空间、情感计算空间、情感文字描.述空间，研究它们的内在性质和相互关系。把基本情感论和情感维度论结合起来，研究支撑.情感计算空间的构建方法，确定情感计算空间与情感文字描述空间的映射关系，以及不同人情感计算子空间之间的映射关系。研究非特定人情感共性表达的声学特征提取算法。建立一个非特定人自然语音情感识别的原型系统。
通信生态系统中DASH视频业务QoE评估研究	通信生态系统;视频质量评价;DASH;体验质量	在通信生态系统中，用户使用视频业务的体验质量（QoE）受到系统多方面因素的复杂影响，哪些因素是影响QoE的主要因素，如何利用这些影响因素及其他信息对QoE进行评估，这些问题均尚不明确。本课题针对现有视频业务的主流：基于HTTP的动态自适应视频流（DASH）业务，研究通信生态系统中的QoE评估方法。首先分析通信生态系统中DASH视频业务影响用户QoE的主要因素，构建基于子体验质量的分层QoE评估框架。然后针对两项重要的子体验质量，分别研究基于感知累积效应的视频感知质量评估模型，和基于用户行为的内容感兴趣程度评估模型。进而将子体验质量进行联合，建立考虑用户感兴趣程度的QoE评估模型。课题旨在为DASH视频业务的QoE评估提供理论基础和系统的解决方法。相关研究成果预计能够为研究各类网络视频业务QoE的感知机制提供科学依据和方法，并为保障相关应用的体验质量提供解决方案，具有重要的理论和实际意义。
基于分布式麦克风阵列的多说话人跟踪方法研究	非线性滤波;说话人跟踪;分布式麦克风阵列;声源定位	本项目研究基于分布式麦克风阵列的多说话人跟踪方法，它在多媒体通信、人机接口、机器人、军事等领域有广泛应用价值。主要研究内容包括：(1)应用矩阵理论中的盖氏(Gerschgorin)圆估计方法，构造语音信号源数的判别准则，进行说话人数目的有效估计；(2)根据语音信号特点，应用高分辨率空间谱估计理论，研究分布式多说话人声源定位方法；研究稳健的时延估计技术，并用总体最小二乘和最大似然理论，研究多说话人定位方法；(3)考虑到说话人运动模型，应用分布式多传感器多目标数据融合技术，采用分布式非线性卡尔曼滤波和贝叶斯递推滤波，通过Gossip算法，研究分布式多说话人跟踪方法；(4)基于随机有限集合理论，将说话人状态和说话人数目统一用随机有限集表示，应用贝叶斯集合滤波技术，结合分布式一致性融合策略，研究说话人数目变化情况下多说话人跟踪方法；(5)建立基于分布式麦克风阵列的多说话人定位与跟踪实时处理系统。
基于特征概念网的网上离散文本信息舆情分析研究	内容安全;文本分析理解;概念网;舆情分析;多群体蚁群算法	在内容安全领域，网络舆情分析是近年来才开始备受关注的全新课题。鉴于该方面的研究起步晚，且其所涉及的一些核心理论与技术尚未得到很好解决，目前这一方面的研究成果相对来说很少且性能上存在明显不足。BBS/论坛等上的离散文本信息是网络舆情分析的重要数据来源，鉴于上述原因以及其本身所具有的网络语言特征显著等特殊性，对于这类文本信息的舆情分析已成为网络舆情分析领域中最困难的问题之一。该项目的研究目标是为互联网上离散文本信息舆情分析难题提出有效的解决方案并在此基础上实现相应原型系统，为此，项目提出了网络离散文本舆情分析模型，并针对模型中涉及的核心问题，分别提出了离散文本复原及标注方法、基于特征概念网的文本表达方法及基于多群体蚁群算法与统计数学模型的舆情信息分类/聚类及趋势预测方法。预期研究成果可望对内容安全、文本信息处理等相关领域的研究在理论上起到促进作用，也可望在网络舆情管控方面具有良好的应用前景。
病理嗓音识别及嘶哑嗓音修复研究	病理嗓音;基音频率;语音识别;语音修复;共振峰	病理嗓音主要是由于声带和喉的各种疾病导致其闭合或振动异常而发生，致使其声学性质发生改变，在临床上表现出不同程度的声音嘶哑、失真等。目前国内外关于这方面的研究侧重于正常嗓音与病理嗓音的诊断、分析和评价来辅助医学治疗，并未实现不同病理嗓音种类的精确诊断，也鲜有病理嗓音修复方面的研究。本项目拟研究表征病理嗓音特征的参数，采用自适应权重分配与支持向量机相结合的算法，实现病理嗓音的细分。并依据基音频率偏离和共振峰上的能量分布异常，采用小波变换与混沌时间序列经验模型并结合混合高斯模型算法实现基频的估计和修正，对共振峰则采用贝叶斯滤波算法进行跟踪及修正，最终实现病理嗓音的修复。这项研究不仅对嗓音学和喉科学的深入探索有重要的学术意义，并可直接应用于语音通信和语音识别系统等诸多领域，具有广泛的应用前景。
无人驾驶中4D场景实时解析算法研究	多目标视频跟踪;目标检测;场景理解;无人驾驶	无人驾驶车辆近年来成为学界工业界研究热点，但现有的无人驾驶车辆平台仍然高度依靠激光雷达等测距传感器进行场景解析。这些传感器虽然精度很高，但是昂贵的价格阻碍了无人车辆走入民用市场。此外，现有的无人驾驶平台利用激光雷达无法对场景及目标障碍进行充分的识别解析，理解能力不足。本研究应用最新的计算机视觉和深度学习方法，开展基于视觉3D技术的场景解析研究。申请人利用课题组现有的无人驾驶平台，使用单目和双目摄像头作为研究设备，在底层通过单目图像和双目深度图像异质融合完成3D特征深度学习，中层通过3D卷积神经网络进行实时检测和长短记忆单元实现目标状态确认，高层语义约束下的动态拓扑图多目标跟踪，最后进行时间空间4D场景目标解析，实现复杂动态场景内端到端的多目标识别跟踪系统，提高无人驾驶对交通场景解析的实时性，准确性。
基于微透镜光场成像的3D视频获取关键技术研究	微透镜标定;光场成像;3D视频获取;深度获取;超分辨率重构	自由视点视频（Free viewpoint video，FVV）是视频领域的新热点，它允许人们从任意角度观看视频。为了真正实现任意角度的FVV观看，首先要从采集端做好3D视频纹理信息与深度信息的获取。本课题在深入研究光场成像理论的基础上，采用微透镜阵列光场相机模型，研究基于光场成像的纹理与深度获取技术，以期获得高质量的3D视频。具体研究内容包括：（1）基于深度学习的光场微透镜标定，（2）基于场景特征的自适应光场深度图像获取，（3）基于时间相关性的光场纹理图像超分辨率重构。这三个内容分别从微透镜标定方法、深度图像的获取质量和速度、纹理图像的超分辨率重构等方面进行研究，可以实现高质量的3D视频获取。本项目对高效3D视频源的获取以及3D视频合成技术的推广具有重要的理论意义和应用价值。对促进我国3D视频技术发展、自由视点电视技术研发、取得独立知识产权有重要影响，研究前景广阔。
面向混响环境的多口音语音识别研究	混响消除;语音增强;语音识别;口音识别;声学信号处理	语音处理技术作为最为自然的人机交互方式近年取得快速发展。面向混响声学环境的多口音语音识别是人机语音交互下一步要取得重大突破的关键，然而其性能还非常低。针对以上问题，本项目将研究面向混响声学环境下的多口音语音的互补语音特征提取原理和方法，互补语音特征的互增强算法以及环境与口音快速自适应的多任务学习算法。在互补语音特征提取方面，研究基于相位域的声源与声道特征分离和提取原理，并利用人类的听觉特性改进相位信息在混响声学环境下的鲁棒性。在语音特征互增强方面，利用混响声学环境下的多口音语音包含的多种特征的互补性和相关性，研究基于深度神经网络的各种互补特征的互增强算法及其特征间的关系。在多任务学习方面，研究利用迁移学习的算法生成多任务学习的训练数据。同时，设计语音增强、语音识别、口音识别、声纹识别多任务的目标函数，通过全局最优化训练模型的参数，并提出了环境与口音快速自适应的算法。
基于对称群的三维模型空间特征分析	对称群;模型相似度;对称空间;三维模型对称特征	三维模型特征提取是虚拟现实技术研究的基础问题，本项目提出利用对称群理论实现模型特征提取，建立欧几里德空间对称群操作到几何模型旋转、平移、缩放等对称操作的映射关系，分析三维模型空间对称特征。本项目用数学基础理论作为有力支撑，研究一种有效的特征提取方法，并应用于三维模型相似度评价中。项目的主要技术创新在于提出三维模型的几何对称操作基于欧几里德空间对称群的代数计算方法，建立三维模型几何对称操作的代数描述；提出对称空间构建方法，利用主曲率计算几何对称操作参数，构造对称空间元素；提出对称空间元素值以及对称空间元素之间距离计算方法。通过对称群性质及操作代数定理证明三维模型对称特征的理论可行性。将对称特征与其它特征提取方法比较，前期实验研究结果表明能够更好的描述三维模型本质几何拓扑特征。针对于三维模型检索应用，提出基于对称特征方法的相似度比较方法，检索效果得到较大程度提高。
基于感知与记忆模型的移动视频通信动态体验质量研究	视频质量评价;视频体验质量;视频质量评价模型	移动视频通信是多媒体技术的重要发展方向。为实现其高质量应用，核心问题之一是建立相应的体验质量评价模型，并将其作为指标以优化相关技术。考虑到移动视频通信场景的复杂多变特点，进行动态的体验质量研究尤为重要。为此，本项目将充分利用移动视频特性，探究源端、网络、终端和用户场景中多种因子对体验质量的作用关系，并实现其联合模型表示；深入结合人类感知记忆理论模型和主观测试方法，建立用户记忆与期望对体验质量的作用模型，重点交互研究实时和长期体验质量之间的动态关系模型，以构建移动视频通信动态体验质量研究体系；最后，基于上述体系对移动视频通信动态体验质量优化提供目标和理论模型支持。与传统研究相比，本项目注重与人类感知记忆的交叉学科方法，同时关注移动视频通信体验的移动性、实时性和动态性，着重研究实时和长期体验质量的交互作用关系。本项目对其它网络下的视频通信、非实时视频传输及语音传输等也具有广泛的理论指导意义。
面向复杂图像与视频的高性能显著性检测研究	显著性检测;局域化回归;显著性图质量评估;多邻域多尺度特征;深度卷积网络	近年来显著性检测模型的研究取得了持续进展，但在多个图像/视频数据集上的测试结果表明，对复杂图像和复杂视频，已有的各种模型的显著性检测性能严重下降。本项目将研究从三条新思路来有效提升显著性检测性能。1）系统地构建深度卷积网络来实现区域级显著性度量与象素级显著性融合的有机结合，并能充分提取多邻域多尺度的高层语义特征和低层视觉特征，以有效提升对复杂图像的显著性检测性能。2）系统地提出基于深度卷积网络的显著性图质量评估模型、结合显著性图质量的相似图像筛选方法及基于流形排序的图像间显著性传播方法，利用相似图像来有效增强原始图像的显著性图质量。3）提出基于全卷积网络的象素级显著性预测方法及基于局域化回归的区域级显著性估计方法，实现从通用到特定的显著性检测，以有效适应各类复杂视频并充分利用测试视频的帧间相关性来提升显著性检测性能。预期成果可有效推动显著性检测模型研究的深入发展及其相关应用的性能提升。
基于轨迹的网络视频话题动态发现、跟踪和预测	话题检测与跟踪;话题预测;多模态谱嵌入;网络视频;话题轨迹	本项目面向网络视频监管的实际需求，开展针对大规模网络视频的话题自动发现、跟踪和预测的关键技术研究。.针对网络视频信息丰富，但单模态特征可靠性差的特点，提出多模态谱嵌入的表示方法，充分挖掘多模态特征之间的关联和互补性，从多个高维特征空间中提取隐含的稳定模式，得到低维的稳定的多模态网络视频表示，为后续话题检测和跟踪提供基础；.针对海量且动态增长的网络视频流，提出一种新颖的基于轨迹模型的话题发现和跟踪方法，通过轨迹的动态生成记录话题的发展过程，算法具有可扩展性；同时将话题发现和跟踪统一在轨迹模型下，综合事件点的局部信息和整条轨迹的全局信息，实现话题发现，更具合理性；.并在此基础上，采用随机游走模型对三维空间中的话题轨迹进行表示，以此进行话题热点排序和趋势预测等深入分析，为政府部门的监管提供决策支持。本项目的最终研究成果将在国家网络视频监管系统中进行验证，为国家网络视频监管提供关键技术。
色散模糊解耦的光谱计算成像研究	计算采集;光谱成像;计算重构;色散模糊;模糊解耦	光谱成像在诸多重要领域如化学成分分析、材质识别、环境监测、医疗诊断中具有重要的作用。然而，当前光谱成像技术广泛存在分辨率低、系统复杂和精度不足等问题，实际应用受到很大制约。.本项目拟从研究光谱信息在色散模糊图像中的耦合机制以及解耦方法出发，探索建立色散模糊解耦的新型光谱感知理论；进而，研究自然光谱图像数据的先验概率分布规律，探索自然光谱图像先验约束的色散模糊解耦优化方法，突破光谱图像计算重建的关键技术；最后，研究基于色散模糊耦合的新型光谱采集机制，构建高效光学采集系统。.本研究的新型光谱成像方法具有高采集效率(大通光量)和高重建精度(高信噪比)的优点，且系统无需复杂标定。
基于弱线性回归树在线学习的自适应视频目标检测算法研究	目标检测;在线学习;多实例学习;线性回归树	本项目针对视频图像中的目标检测问题，基于在线学习理论与线性回归树的构造方法，研究具有自主学习能力的目标检测系统。采用弱线性回归树算法构建系统检测模型，利用线性回归树组合特征的能力提高模型检测性能。通过弱线性回归树的系数更新方法实现检测系统的在线学习，加快系统在线学习速度，保证系统持续学习的效果。采用粒子滤波对系统检测到的目标进行跟踪、验证，从中获得在线学习样本，实现检测系统无需人工干预的自适应学习。为了减少验证错误对系统在线学习的影响，引入多实例学习提高系统的鲁棒性。该项目的研究成果将为智能视频监控中的目标检测等实际应用提供一种新方法，并丰富基于在线学习的目标检测、识别理论。
基于元胞混沌压缩感知的帧时空稀疏化视频并行重构方法研究	稀疏表示;视频重建;压缩感知	视频监控作为人类视觉信息获取的一种动态模拟和强化扩展，在现代世界各国的社会综合管理、安防系统构建等领域有着不可替代的重要作用。但是，随着视频监控在高清、实时、全天候等方面要求的不断提高，由视频大数据引起的数字洪灾等处理难题日益突出。为此，研究以压缩感知理论为基础的新型视频处理框架，已经成为国内外学术界的关注热点。本项目以元胞混沌模型、帧时空双向稀疏化、贪婪迭代并行化等创新思路尝试解决压缩感知视频处理在采样和重构各环节面临的问题。本课题的创新点包括：拟运用元胞混沌模型及改进，提出更优的压缩感知观测矩阵生成机制；根据视频帧在时、空域的特点，拟研究针对帧差感知数据的稀疏性度量函数和基于先验场景建模的稀疏字典构建方法；考虑贪婪迭代中内积运算的独立性，拟通过其并行化实现重构速度的大幅提高。本项目的开展有利于缓解视频监控系统中的数字洪灾难题，而且可以为大数据背景下的视频监控智能化提供更好的理论支撑。
基于大样本的海上复杂环境下弱小目标检测研究	卷积神经网络;大样本深度学习;回归方法;选择性搜索;稀疏编码	基于深度学习的目标检测方法可有效区分背景和前景、对目标变化和遮挡更加鲁棒，是目前目标检测领域的热点研究方向之一。现有深度学习的目标检测模型在很大程度上依赖于训练集质量及训练方法，但对于考虑大样本数据集质量的预训练深度模型的研究较少，同时不能实现模型在线自适应更新。基于此，本项目以我南沙和西沙岛屿亟需开展海上复杂场景下弱小目标检测研究为背景，拟扩展现有大样本数据集训练思路，从自适应角度出发推导一种考虑样本质量的动态训练模型；同时将训练样本权重的思想引入大样本训练深度模型中，设计相应的逐个样本动态权重模型。具体包括：考虑大样本数据集质量的预训练深度模型研究、考虑自适应的海上视觉目标表述与模型更新研究、考虑回归方法的深度学习实时海上目标检测研究，最终实海上弱小目标实时检测目的。本项目研究思路具有一定的创新性和工程实用性，其预期成果可直接应用于基于无人机的海上大范围连续动态监控领域。
流量付费因素影响下用户视频满意度评估研究	视频质量评价;移动视频;视频体验质量;视频质量评价模型	随着互联网的广泛应用和我国"提网速、降网费"政策的落地，使用数据流量观看移动视频将成为一种趋势，而流量付费对用户视频满意度将会产生直接影响。如何在准确的视频满意度评估和预测基础上，为用户提供高质量低花费的视频服务，已经成为亟待解决的重要问题。本项目以视频满意度评估为研究对象，探索流量付费与用户视频满意度之间的定性定量关系，揭示视频编码参数与传输模式的联合选取影响用户视频满意度的机理和内在规律性，建立流量付费影响下的个性化视频满意度评估模型；其目标是提出一套全新的满意度驱动下的视频编码-传输联合优化方案。创新点：1）以"用户满意度"为核心，将流量付费和用户个性化特征两个因素纳入评估体系；2）采用"实证分析"和"数学建模"相结合的方法，揭示流量付费影响视频满意度的机理和内在规律；3）基于不同应用场景，提出满意度驱动的视频编码-传输方案。
时空约束的协同视觉显著性检测与目标跟踪	显著目标分割;目标跟踪;视觉显著性检测;显著目标检测;运动检测	视频显著性检测与目标跟踪通常作为两个独立的问题，或者把显著性作为先验知识单向地应用于目标跟踪。尽管近年来深度学习的引入提升了显著性检测的性能，然而面对复杂的动态场景，现有的显著性模型尚不能完整地凸显显著目标和有效抑制复杂背景。本项目提出协同视频显著性检测与目标跟踪的统一模型框架，旨在同时实现稳健的视频显著检测与目标跟踪。首先提出一个高阶语义引导的混合运动能量滤波模型，试图有效估计目标运动能量并滤除无关背景区域。根据运动能量分布，提出基于多维特征聚类的可靠区域检测算法提取可靠的显著目标与背景区域，进而以此为基础建立时空约束的显著性检测优化模型。然后提出了基于显著性空间正则化约束的目标跟踪模型得到目标的定位框。该定位框与显著图一同作为高阶语义进一步优化混合运动能量滤波模型和显著性检测优化模型，从而衍生出更优显著图进一步优化目标跟踪模型。以此协同促进机制，达到显著性检测与目标跟踪的性能最优化。
监控视频中多视关联的显著运动对象检测与跟踪技术研究	显著对象;多视监控视频;多视关联;对象检测与跟踪	多摄像机视频监控中的对象检测和跟踪已经成为监控视频分析领域中的一个研究热点，但相关的算法和技术还不成熟，特别是复杂环境下多摄像机运动目标的检测和跟踪还未能有效解决，多视角显著运动对象的关联分析模型与理论还不成熟，制约了新一代智能视频监控系统的进展。本项目以多摄像机监控视频为对象，针对多视关联的显著运动目标检测与跟踪问题，采用以视觉显著分析为中心的多视监控视频运动目标关联分析框架，重点研究多视监控视频的视觉显著性学习、多视监控视频中的对象关联分析、多视监控视频中的显著对象检测和跟踪等模型、方法和关键技术。
基于自然图像特性的比特深度上转换关键技术研究	视频图像处理	高动态范围技术具有高亮度、广色域等优点，是我国当代信息及技术发展的重要主题之一。尽管高动态范围已成为主流高端电视的必备技术，高动态范围的内容数量十分有限，限制了其发展与应用。为了弥补高动态范围数据源的巨大缺口，满足普通观众对画面质量的需求，本项目旨在通过研究比特深度上转换方法，将已有的大量标准动态范围内容恰当准确地转化为高动态范围内容，以实现真正意义上的高质量视觉享受。针对现有算法的缺陷，本项目主要研究基于自然图像特性的图像建模问题及亮度优化方案，以得到更好的高比特深度内容。具体来说，本项目试图通过挖掘自然图像特性，解决基于自适应模型的图像块描述问题、基于势场的连通域建模问题、基于高阶导数先验的亮度优化问题及高比特深度图像的自动优化问题。本项目的研究成果将有助于弥补高动态范围内容的缺口，为我国高动态范围技术的发展与应用提供技术支撑。因此，本项目具有十分重要的研究意义和很高的实际应用价值。
基于内容的流行音乐结构分析的研究	音乐语义理解;音乐结构分析;基于内容音乐信息检索	随着多媒体数字化技术的发展和国际互联网的普及，流行音乐数据库呈现爆炸式增长。人们希望能对音乐数据库中的每首歌曲的语义区域建立语义层面的索引，从而能方便人们对日益庞大的音乐数据库进行有效快速检索。基于内容的流行音乐结构分析，就是为了满足这样的应用需求而诞生的。本课题以实现计算机自动分析流行音乐的结构为目标，结合多媒体理论与系统、信号与信息处理、机器学习与模式识别、音乐理论知识、计算机人机交互等学科领域的最新研究成果，提出了:引入音乐自然音阶的音频特征抽取算法来准确表征音乐信号的音质，旋律和节奏特性、采用机器学习算法的自下而上的音乐语义单元理解模型、采用模版匹配算法与音乐知识相结合的自上而下的音乐语义区域检测模型等一系列方案，并首次提出了将自下而上和自上而下相结合方法论的指导来对流行音乐结构进行分析，以提高自动流行音乐结构分析的正确率。
基于语义的图像合成	图像融合;颜色迁移;图像缩放;图像合成	图像合成是一种高效的图像获取、加工手段，是多媒体信息处理和计算机图形学中的热点问题，并且在平面设计和影视制作方面有着重要的应用。本项目的研究内容为如何将基于语义的机理引入图像合成算法的设计与优化中，以提高合成结果的质量。主要研究内容包括三个方面：图像缩放、图像色调编辑和图像融合。技术创新在于多模态特征图像场景内容结构分析与表示、基于语义的图像重定位、基于语义的图像/视频色调编辑和高质量时空一致性融合等。主要技术难点在于图像内容结构分析的高效表达、多模态特征的归一化表示和图像合成中语义相关机理的使用。
具有信息隐藏功能的脑电信号生物识别新方法	隐蔽报警;多媒体信息处理;脑电信号;统计学习;生物特征识别	脑电信号记录了大脑的神经系统活动，反映了大脑的功能状态，蕴含着可以检测的认知信息。同时脑电信号具有隐蔽性、不可仿制性、不可胁迫性，应用到身份识别中，会提高现有生物特征识别系统的防伪和防恶意入侵性能。本项目将采取以神经生理学分析为基础，研究微弱脑电信号的可靠数据获取，利用模式识别和机器学习的方法，研究意念、动作和脑电信号的关联性描述、分类和检测方法，针对高端安全应用，实现具有信息隐藏功能的脑电生物信息的身份识别系统。同时本项目所形成的相关理论和算法，有助于促进神经科学和脑电信号计算模型的结合，并推广应用到临床诊断、脑机接口等领域中。
自然场景统计的二维视频立体重建	自然场景统计;三维重建;反馈控制;二维转三维	立体视频具有高沉浸感、高逼真呈现的特点，在航空航天、军事训练、医疗教育、文化传媒等领域有着广阔的应用前景，是未来信息系统的前沿技术。然而，当前立体视频产业面临着内容匮乏、观看不适等瓶颈问题，造成这些问题的本质是目前对于自然场境深度感知规律的认知不足，以及立体视频生成方法在精度、效率、稳定度方面存在问题。 本项目拟研究自然场景统计的二维视频立体重建。通过深度图数据库的建立和统计分析理论建立自然场景深度的概率模型，探索深度感知的自然规律；然后，运用自然场景深度先验信息研究高精度二维视频深度估计方法；进而研究时域稳定、空域平滑的立体视频重建方法并构建加速平台，通过重建立体视频的人因分析结果反馈优化深度感知模型。 本项目旨在实现高精度、高效、稳定的二维视频立体重建方法和实际系统，为揭示自然场景的深度感知规律和缓解当前立体视频产业的内容困境提供支撑。
计算摄像中多视场光场高精度成像方法研究	光场成像;光场超分辨率;多视场;深度估计	光场研究，作为计算摄像学的核心研究领域，在航天、军事、医疗、教育、影视、公共安全等领域有着广泛的应用。针对现有光场成像技术面临的视场单一、建模精度不高、成像分辨率低下等问题，本项目着眼于计算摄像学中多视场光场高精度成像这一热点问题展开。提出多棱面环形反射镜＋微透镜阵列进行多视场光场采集的成像方法，通过对光路和光学元件进行优化设计，实现高质量的多视场光场采集；同时，基于多视场光场采集原理，建立目标景物深度估计的计算模型，提出完整的多视场深度信息提取方案，并基于深度信息，开展数字重聚焦算法和对象三维建模的研究。最后，提出基于傅里叶切片理论的光场超分辨率方法，解决光场成像空间-角度分辨率之间的矛盾，实现高精度的光场图像重建，从而提高了对成像目标的重建精度，对多维景物的采集、重构和内容生成机理等方面的研究也起到重要的作用。
率失真优化的视频编码控制技术研究	Lagrange优化理论;率失真优化;码率控制;视频编码控制技术;比特分配	视频编码控制技术是网络多媒体通信的关键技术。利用优化技术改进视频编码控制技术，对提高视频编码效率及改善视频通信性能具有重要意义，是视频编码技术研究的热点问题。.    本项目面向低码率网络多媒体通信环境，针对视频编码标准最新的进展，研究具有较低计算复杂度、率失真优化的视频编码控制新技术。为了有效提高视频编码效率及通信性能，将应用率失真理论，构造率失真联合测度的编码复杂度模型及预测模型，建立新型率失真模型，在此基础上，利用Lagrange优化技术建立率失真优化的比特分配方案；结合不依赖于量化参数、自适应的率失真优化技术，建立高效、精确的图像宏块编码控制结构；进一步研究与新型编码结构相适应的码率控制算法，在满足通信带宽限制条件下，尽可能地降低视频图像编码质量损失。
面向多媒体信息检索的语音处理关键技术研究	说话人信息;非文字语音信息;关键音段;多媒体信息检索	多媒体信息已经成为互联网的主体信息之一，目前基于内容的检索技术研究重点是图像、视频及音乐；对语音信息，一般采用语音识别技术将语音转换成文本，然后采用文本检索的方式加以处理。而ASR所得到的转换文本存在识别不准确、集外词、结构信息和非文字信息丢失等多种缺陷。如何直接利用语音信息提高多媒体检索效率和人机交互的友好性没有得到足够的重视。针对这些问题，本课题重点研究1）多媒体中音频分割及分类；2）关键音段确定； 3）说话人信息提取方法及其在信息检索中的应用；4）语音信息和视频信息在多媒体检索中的相互作用方式。 .本课题有非常明确的应用前景：多媒体检索。理论上也具有很大的挑战性，研究内容日益得到人们的重视，对加快我国信息产业的发展有重要作用。预期发表学术论文10篇，申报专利1项。
频率压缩语音信号识别机理的研究	助听;语音增强	听力损伤是排名第一的神经传导型功能疾病。频率压缩技术是当前助听设备研发的热点，其充分运用听障病人的低频残余听力，将语音信号压缩到低频区间来促进言语识别。和传统助听器及电子耳相比，基于频压技术的助听设备具有有效识别语音高频成分和低成本的优势。但是，频压语音信号的识别机理尚未被深入研究，本课题研究成果对于充分了解频压语音信号的识别机理，和设计新型低成本、优化汉语识别性能的助听设备有重要意义，有助于听障病人的言语交流和生活质量提高。具体而言，本课题将研究1）语音信号携带的重要声学参数和其它因素（噪声和动态范围压缩）对于频压语音信号识别率的影响；2）客观估计识别率的模型；3）识别率的语言性（汉、英语间）差异；和4）听觉训练对于提升识别率的贡献。本研究课题预计发表6篇国际期刊文章和12篇会议文章，申请1 项国家发明专利，联合培养1名博士后、2名博士生和3名硕士生，联合组织2次国际学术交流活动。
盲人视觉辅助应用中的自然场景文字提取关键技术研究	文字检测;文字标牌;目标跟踪;穿戴视觉;透视矫正	盲人视觉辅助应用中的自然场景文字有效提取仍然是一个亟待解决的问题。自然场景中文字呈现的多样性、盲人在行走过程中的头部旋转以及非正面拍摄引起的文字几何失真等因素，都构成了这一应用中文字提取技术的瓶颈。本项目拟研究：（1）基于BOVW模型的文字标牌检测的高效学习方法；（2）检测-跟踪-模版更新相结合的文字标牌跟踪方法和穿戴式视觉对跟踪的稳定性影响；（3）基于不变特征约束的标牌文字透视矫正估计方法。本课题将理论分析和实验研究相结合，旨在建立自适应决定自然场景目标种类个数的非监督字典学习模型，探索体现文字标牌特点的强区分性特征，实现盲人行走过程中文字标牌的实时稳定跟踪，消除非正面拍摄造成的文字几何失真，为盲人的视觉辅助应用奠定理论基础。
融合多源图像与光流运动的旋转背景下对地运动目标检测研究	背景重构;目标检测;运动识别;视频图像	对地运动目标的高精检测是战机实现精确打击的关键问题。目前国内外的研究成果主要针对战机平飞或大范围盘旋时的运动目标检测，当战机急剧转弯导致图像地面背景剧烈旋转运动时，会产生大量漏检、虚警。鉴于此，本项目首次提出融合多源图像与光流运动的旋转背景下对地运动目标高精检测方法及半物理实验验证。建立数学模型描述战机、光电探测平台、摄像机的空间运动与姿态变化多因素联合影响下的图像地面背景与目标的运动特性，提出地面背景旋转运动剧烈程度的定量衡量指标，确立地面旋转运动背景中运动目标检测的理论依据。为综合利用可见光与红外图像及其图像中的运动信息，在配准可见光与红外图像基础上，融合红、绿、蓝、红外热辐射四维信息和光流运动，在图像高维融合光流场计算过程中实现多源图像信息融合。构建包括整体地面背景旋转运动与局部目标运动信息的图像运动场，从中重构纯地面背景旋转运动场，据此分离地面旋转背景与运动目标，实现运动目标检测。
基于压缩感知的高精度实时视觉跟踪方法研究	贝叶斯推理;词典优化;稀疏恢复;视觉跟踪;压缩感知	作为计算机视觉领域的经典问题之一，视觉跟踪具有重要的理论与应用价值。由于视频数据规模巨大，且目标外观易于发生变化，视觉跟踪也是计算机视觉领域最富挑战性的问题之一。本项目研究基于压缩感知的视觉跟踪方法，通过压缩感知的欠采样能力减小由大规模视频数据带来的沉重计算与存储负担，同时利用稀疏恢复对目标外观进行建模，提高跟踪器对于外观变化的鲁棒性。具体地，本项目研究适应于视觉跟踪需求的压缩感知测量矩阵的设计与实现方法，由此提高测量矩阵兼顾计算复杂度与特征稳定性的能力。其次，本项目发展目标外观的联合稀疏表示与词典优化模型。基于该模型，通过在稀疏恢复过程中动态地更新稀疏表示词典来处理目标的外观变化，从而消除或减轻由外观变化引起的跟踪精度恶化。同时，本项目在贝叶斯推理框架下求解基于上述模型的联合稀疏恢复与词典优化问题，从而避免因算法参数人工设置不准确而引起的算法精度下降，同时提高跟踪过程的自动化水平。
高品质音频信号的变换域稀疏压缩与精准重构研究及其在移动终端中的应用	稀疏压缩;精准重构;移动终端;数字音频	高品质音频一般是高码率的海量数据, 由于移动终端受带宽和存储容量的限制，目前其上的实时音频播放信号都是采用高压缩率的有损方法，用户无法获得高品质的音频信号，离"身临其境"的体验有很大距离。本课题通过对音频信号的变换域基函数研究，找出能使音频信号稀疏转换的条件和空间域，通过变换域的稀疏转化，使高品质音频信号被置换成异域中的稀疏信号并被压缩再在接收端被精准重构。同时，分析级联编码和多样性传输信道对音频信号在整个移动信道传输中受损情况并建立相关补偿模型，通过空间域的变换和精准重构技术的研究，结合信道的联合编码，研究对受损音频的补偿方法。本项目拟以一种全新的观点揭示出音频信号通过变换域进行稀疏、压缩再被精准重构的机理、变换条件和核心算法，以及级联编码及多样性信道对音频的损伤及补偿方法，探索将研究成果应用于移动终端实现高品质音频信号再现的技术路线，为在移动终端上的应用提出创新性的解决方法。
基于麦克风阵列的智能会议转写记录系统中的语音增强问题研究	智能会议系统;语音解混响;语音降噪;麦克风阵列;语音分离	随着社会的发展和科技的进步，能够自动实现从语音到文本进行会议记录的智能会议转写记录系统可以有效地提升会议效率，降低人力投入，且有利于会议结论可追溯性，有着广泛的应用前景。为了保证后端文本转写记录的精确度，前端的语音增强处理是一个至关重要的问题。本研究项目以智能语音会议转写记录系统为研究背景，从会议室环境下的声学场景和麦克风阵列模型入手，分析影响语音听觉质量和语音识别率的各种因素，对包括干扰和噪声消除、语音解混响和语音分离在内的一些语音增强中的重点难点问题，利用诸如高阶张量滤波、稳健宽带波束形成、多通道线性预测、区分性及多特征字典学习和深度学习等理论，研究干扰和噪声消除、解混响和多说话人语音分离的有效方法，为智能语音会议记录系统的发展提供必要的理论依据和新的解决思路。
基于波内频率调制的音色模型研究以及在单通道音源分离中的应用	单通道音源分离;音色模型;贝叶斯蒙特卡罗方法	非线性欠定音源分离技术是音频技术中的热点和难点问题之一。本课题针对音色的非线性本质，从非线性信号的波内频率调制现象入手，对乐器声音信号的频率结构进行分析，通过Hilbert-Huang Transform得到对信号的非线性表征，并以此为基础提出新的音色模型。我们的初步研究结果表明，这种新的音色模型可以将音源的非线性部分转化为线性部分，从而将大大提高非线性欠定音源分离的效果和鲁棒性。本课题的研究对于音乐信息理论，核心软件产品和新一代音频编码技术等方面具有重要的意义。
基于视觉一致性约束的监控目标精确检测研究	目标检测;监督学习;视频监控;视觉一致性约束	监控目标的精确检测是目前智能视频监控系统深度应用面临的一个迫切需要解决的关键科学问题。本项目针对视频监控系统的复杂场景下目标视觉不一致对目标精确、鲁棒检测带来的挑战，一方面将基于范例的相似性检测模型与基于统计的检测模型相融合扩展，研究基于视觉一致性约束的目标检测方法与模型，将视觉不一致目标的检测转换为视觉一致的子类目标检测，以克服传统的统计检测模型存在的视觉不一致带来的检测精度不足等问题。另一方面，将深度卷积神经网络与领域知识辅助的监督学习相融合，提出一种能够支持知识与数据联合驱动的新的深监督学习模型,以领域知识的充分利用来提升深度模型的学习效能。通过上述两个方面的研究，力争有效解决监控目标检测中因视觉不一致造成的检测精度和鲁棒性不足问题，获得监控视频目标检测精度和鲁棒性上的性能突破，为提高我国智能监控视频的基础研究水平起到积极的促进作用。
基于时空结构约束与特征学习的目标跟踪研究	目标跟踪;模糊学习;表观模型;时空结构约束;特征学习	目标跟踪是多媒体信息处理、计算机视觉等领域的研究热点之一。目标跟踪可以用于军事侦察、视频监控、交通监测等军事和民用领域，具有广泛的应用前景。然而，由于现实场景中存在遮挡、目标形变等复杂因素，如何实现准确、鲁棒的目标跟踪仍然是一个十分具有挑战性的任务。本项目拟围绕表观模型这一核心模块的构建，在模糊学习框架基础上，通过挖掘视频序列中的时间和空间相关性信息，并利用特征学习技术对目标跟踪进行深入研究。首先，本项目拟联合模糊学习和流形学习策略，设计基于多图正则的模糊分类器并构建表观模型，以实现对视频序列中时空结构约束的有效利用；其次，本项目拟在模糊学习框架下，利用特征学习技术实现对不同跟踪目标的自适应特征提取，提高对表观模型表示的准确性；此外，本项目拟设计基于栈式去噪自动编码机的判别更新策略，引导对表观模型的在线学习。本项目拟将新建立的跟踪算法在多个公开测试集进行验证，并将其应用于实际场景。
语音识别中的稀疏性深度学习	语音识别	基于深度学习(Deep Learning)的深层贝叶斯网络技术(Deep Bayesian Network, DBN)为语音识别带来极为显著的性能提高，被认为是语音领域的又一次革命。然而，当前的DBN方法只有在大数据集上才能发挥其效能，并容易受到噪声和信道变化的干扰。DBN的这些困难很大程度上可以归因于其全结点连接结构带来的弱先验约束。本项目提出稀疏性深度学习方法，利用稀疏编码（Sparse Coding)理论，通过在DBN的特征或结构中加入稀疏性约束，使学习得到的网络更简洁，更具有对语音信号模式的代表性，因而降低对大规模训练数据的依赖，并增加对噪声和信道变化的鲁棒性。同时，DBN的深层结构可以使我们得以系统研究稀疏性层次化语音模式。
深度光谱联合计算成像及其高维信息重建	光谱成像;计算重构;超分辨率;深度成像;压缩感知	视觉传感器的终极目标是对七维全光函数的解析。由于成像元件的物理限制，现有相机最多只能解析四维光信号。本项目将基于计算成像理论，结合最前沿的深度与光谱成像技术，探索深度光谱联合成像及其高维信息重建的新机制与新方法。特别地，本项目拟运用多路相机联合观测系统，首次实现动态场景的三维立体超光谱重建，即五维光信号解析。同时，发掘深度与光谱在三维时空中的先验知识及关联性，结合前沿视觉学习方法，提出新的高维信息互补重建算法。研究内容包括：1）双相机编码光圈压缩感知光谱成像；2）跨模态深度光谱联合成像；3）深度光谱联合成像在视觉分析中的应用。本项目将进一步突破现有视觉传感器的局限，为全光函数的解析奠定基础。
基于上下文感知的不良影像分类	上下文信息;语义主题解析;多线索集成;智能分析;不良信息过滤	本项目主要研究多媒体通信中淫秽色情不良影像的过滤方法。不良影像内容复杂、语义信息丰富，基于低层特征的检测方法不足以描述其内容，从而易导致误判。本项目从实际应用中抽象出科学问题，旨在借鉴人类的认知机理，结合最新的视觉信息认知计算方法，根据统计推理模型提取图像隐含的语义主题，结合概率图理论充分利用不良影像中共生的上下文信息，建立新的计算模型和方法，从语义角度判定不良信息。主要研究内容包括：(1)图像隐含主题语义认知与解析；(2)基于鉴别性形变模型的人体敏感器官检测；(3)结合语义上下文的不良影像多线索集成判决。本项目涉及认知计算和统计学习的最新理论，需要针对不良影像的特点，从新的角度进行研究。研究内容具有重要的理论意义和广阔的应用前景。本项目预期在理论上有所突破，为多媒体影像语义建模、内容分析与理解方面的研究奠定理论和技术基础。
面向非刚体形变的三维形状表示与分析关键技术研究	非刚体形变;主动学习;形状分析;度量学习;形状表示	形状是客观世界物体的基本属性之一。不同物体形状之间不但千差万别，即使对同一物体来说，其自身的非刚体形状变化也极其丰富。这给高效地管理与分析形状媒体带来了挑战。现有形状分析研究工作在非刚体形状表示、形状相似度衡量、形状对应关系计算等方面中还有很多问题亟待解决。针对这些问题，本课题拟深入研究非刚体形变下的三维形状表示方法，具体内容包括：通过联合整体与局部特征来构造更为鲁棒的形状表示模型；构建度量学习模型来增强形状相似度量的区分性；构造基于主动学习的图匹配算法，提高三维形状对应关系计算模型的性能；建立三维形状媒体管理与分析系统，实现对具有非刚体形变的三维形状进行有效的检索、分类与匹配。
少数民族特色视觉艺术的云南重彩画风格化绘制及科学理解研究	云南重彩画;风格化绘制;纹理绘制;视觉艺术科学理解;人体变形	风格化绘制让计算机以更艺术、更反映人主观意识的方式来表达客观世界,在多媒体信息处理领域具有较大的研究和应用价值。云南重彩画是少数民族特色视觉艺术的杰出代表，融合中西方绘画艺术特色，在国内外享有盛誉。本项目针对其鲜明的中国线条画和西方油画特点，分析归纳其在构图、线条、纹理及色彩使用上的特点和规律，探索、研究相应的风格化绘制核心算法。主要研究内容包括重彩画人物形体绘制特点学习和归纳、基于3D人体模型的2D人物变形、重彩画白描图绘制，特有纹理绘制和云南少数民族织绣纹样设计等多项关键技术。同时开展视觉艺术科学理解的研究，基于统计和信息处理的方法，分析、提取、归纳反映画派风格的特征，对其进行定量的数字化描述，并在此基础上探索风格化绘制效果客观评价的途径。项目研究内容可推广到其他视觉艺术流派的风格化绘制和科学理解，研究成果可用于影视制作、动漫设计、画作真伪鉴定等行业，促进了多媒体信息处理技术的发展。
面向高刷新频率的视频帧速率变换算法	电影模式识别;插值;帧速率变换;高清晰HD;运动估计与补偿	高端平板显示器工艺的快速发展带动其刷新频率于2009年初达到200Hz，视频帧速率变换已经势在必行。帧速率变换算法是视频后处理（Post Processing）算法流水线中的一个重要模块，它的主要功能是通过插值把原有视频源的帧速率调整到显示器的刷新频率。本项目针对传统算法容易产生的视频跳动（judder）、模糊（blur）、运动物体的光晕（Halo）以及遮挡效应，面向硬件IC实现，研究并实现一种高性能、低复杂度的帧速率变换算法，该算法包括能够剔除无效帧的电影模式识别算法、保持运动向量场平滑连续性的运动估计算法以及区域区分的自适应运动补偿型插值算法。该项目的完成为我国高端平板显示与HDTV IC的发展奠定坚实的算法理论基础。
心音特征提取和身份识别中新方法研究及应用	心音子波族;心音合成模型;PCG形变模型;独立子波函数码;心音身份识别	本项目针对心音生物特征识别的基本原理和关键技术开展创新研究，提出一种以实时性和高识别率为目标的心音生物识别新方法。首先研究独立子波函数码快速提取算法、心音子波族（HSWF）构造方法和基于HSWF、内心音震动特征、PCG形变特征的三种心音合成模型等基础理论，以构成一种心音特征识别的基本理论架构，并据此基本理论进行心音身份识别系统的设计以充分描述心音信号在时域和频域上产生差异的原因，解决由于心音生理机制的特殊性所造成的特征参数存在变异问题；其次研究能体现心音细节特性的表征形式，通过引入心音特征向量分布相图、周期-功率-频率3D图等特征参数表征形式，拓展生物特征参数提取与形象表示的方法；还研究心音信号采集装置，智能预处理技术和建立高效的鲁棒的心音分类器；最终使实际心音身份识别率达到98％以上。本研究成果将丰富生物信息识别的新内容，并为研制具有自主知识产权的新型智能心音处理设备提供理论和实验依据。
基于高阶正则化半监督学习的多跟踪器框架模型及融合策略研究	协作目标跟踪;目标跟踪;动目标;视频跟踪;遮挡目标跟踪	基于单分类模型的跟踪器适应性问题是制约复杂多变场景下任意目标跟踪效果提升的关键所在，而多跟踪器协同工作可以充分实现相异模型结构之间的优势互补从而平衡不同场景干扰之间的差异，降低分类误差，有效提高跟踪器的通用性。项目通过研究主流跟踪器所用生成模型和区别模型之间的共性机理，针对单一跟踪器存在的模型适应性差及全局参数更新不鲁棒问题，项目创新性地提出利用高阶正则化方法，构造基于多模型约束的多跟踪器复合框架模型，并通过半监督在线学习开展相关理论建模，参数优化和实验测试三方面的研究工作，验证所提出的框架模型既有对多类型跟踪器学习过程及结构化输出的融合能力，又有对真实环境中光照、遮挡、形变及相似背景等复杂应用场景的较强适应能力。进而研究统一框架下多模型参数的选择性更新及联合累积误差临界甄别问题，最终突破现有跟踪策略在复杂多变环境中的普适化限制，验证研究成果在视频摘要、视觉导航等方面应用的有效性及可靠性。
基于多模态概率主题模型的实体相关文本可视化	文本配图;图像语义分析;多媒体信息处理;图像理解	自动关联和整合互联网上存在的海量多媒体信息，是帮助人们直观、高效地理解信息和获取知识的重要途径之一。其中，将实体（如人、地点、产品）的相关文本（如新闻、游记、产品评论）可视化，即自动根据文本语义补充图像信息，是亟待解决的核心问题。现有方法难以准确提取实体及对实体的描述；且缺乏对实体、文本和图像的联合建模和关联挖掘，难以优选出充分关联语义的图像。本项目着眼于多元异构信息的关联表征，通过建立多模态概率主题模型，挖掘实体、文本和图像信息之间的关联信息，实现高质量的实体相关文本可视化：1) 基于概率主题模型和自扩展实体词典，准确识别文本中的实体；2) 基于实体主题模型，从海量文本中挖掘多重实体知识，据此提取对实体的描述；3) 基于多模态概率主题模型，从多种来源的图像中优选与实体及描述语义一致的图像。本项目所研究理论与技术可应用于各种领域的实体相关文本可视化中，具有很高的学术价值和可观的经济价值。
面向智能信息处理的高级音频信息认知规律及其应用研究	音乐旋律认知;听觉显著度;听觉内源节律;智能音频信息处理;音频信息认知	缺少有针对性的人类认知模型的指导和对认知规律的深度融合，是限制当前智能信息处理技术快速发展的首要原因。本项目面向智能音频信息处理技术IIP-A中的基本问题，以事件相关脑电位(ERP)技术为研究手段，立足于探索人脑音频信息认知的基本规律，并通过实际应用加以验证，具体研究：听觉内源节律及其在音频节奏认知上的规律，音乐认知对音乐旋律的加工规律，音乐认知中的听觉显著度现象，对音频情感认知规律等问题，将ERP信号拓展为信息相关脑电位IRP信号，建立音频ERP和IRP特异性成分的数学模型、演化规律模型和计算模型，探寻IRP指标、认知规律以及音频信息之间的映射关系，构建相应的音频信息认知机制模型，通过研究时序性事例学习的认知特点提出相应的机器学习方法，对认知模型进行实用化实现，并通过解决IIP-A中的若干关键问题加以验证和提升。本项目对认知科学、智能科学和信息科学等的发展都具有重要的理论意义和实用价值。
海量网络视频中的复杂事件检测技术研究	上下文;视频事件检测;多模态;样本采集	本项目针对当前海量网络视频内容分析这一重大需求，提出一套完整的视频事件检测技术，包括视频事件训练数据的自动采集、多模态视频特征表示和基于上下文分析的事件学习算法。在训练数据采集方面，拟提出一种基于多重文本相似度的度量方法，对网络关键词检索结果进行过滤，进而得到高精度的事件标注；在多模态视频特征表示方面，采用图聚类方式生成视音频联合词袋，深入探索模态间的关联关系；此外，本项目将设计事件检测的上下文分析算法，利用基本概念（如目标、场景）的检测结果提高复杂事件的检测精度。该算法采用有向图来对事件-概念关系建模，以充分发掘事件-概念间的因果及共生关系。本项目的研究成果将为网络视频内容分析奠定一定的理论基础，并为网络视频检索、内容监管等一系列重要应用提供系统化解决思路。研究的成果也将通过国际权威视频分析评测活动检验其性能（如美国国家标准局的视频检索评测TRECVID）。
3DTV中编码效应消除和高质量双目视图生成研究	稀疏表示;编码效应;图像质量;图像复原	3DTV是广播电视领域的一种新的播放模式，它可提供更加自然、生动的家庭视觉娱乐，其中存在的编码效应和带宽问题已经成为实际应用的瓶颈问题。本项目旨在分析降低图像质量和立体效果的编码效应机理的基础上，设计基于稀疏表示的冗余3D字典，提出基于稀疏表示的编码效应消除方法；在同时考虑图像变换和实时渲染以及裸眼3DTV技术特点的基础上，建立基于非闭合区域最小化的高质量双目视图生成方法，改善3DTV的图像质量和立体效果；期望在获得3DTV的高质量双目视图和克服当前播放系统的带宽限制上取得实质性进展。
编解码复杂度均衡分配的视频编码理论及应用研究	复杂度分配;分布式视频编码;均衡式视频编码	目前分布式视频编码（DVC）得到的率失真性能与预测视频编码（PVC）相比还有着较大差距。为了弥补这种差距，必须在编码端采用运动估计，而这与DVC轻量级编码器的出发点相违背。这一困境是因目前视频编解码复杂度的分配过于对立而导致的。为了给能量受限移动终端视频应用提供更多的灵活性，提出一种融合了PVC和DVC技术的均衡式视频编码（BVC），通过在编码和解码端分享运动估计计算复杂度，来实现复杂度的动态分配。重点研究PVC,DVC及均衡式视频编解码复杂度建模及编解码复杂度优化机制问题，对编码系统的运动估计中像素的读和写操作引起的数据传输进行建模，建立编解码复杂度及其优化分配的模型，在此基础上设计均衡式视频编码系统及相应置信传播译码算法，并将均衡式视频编码系统通过移动终端在实际无线通信环境实现，对进一步推广移动终端中的视频通话等能量受限应用具有重要实际意义。
三维信息中形状基元的识别、提取及应用	相似性规则;形状基元提取;形状基元识别;层级结构;高效RANSAC方法	3D建模的高效性和高精细性是多媒体信息处理、虚拟现实、逆向工程等研究中的一个亟待解决的技术挑战。本项目根据拓扑知觉理论，按照视觉认知自顶向下的整体性，利用机器学习分割与标注3D模型中的实体对象，采用RANSAC、流形学习等方法识别与提取3D形状基元，通过高维数据集聚类等提取相似性规则和基本相似单元，建立基于形状基元或基本相似单元的层级结构，实现3D对象或场景三维信息的与图形认知层次一致的理解和高效表达。有利于实现相应三维信息的高效重建、渲染、编辑等。主要研究形状基元和相似性规则的准确快速提取、基于形状基元的层级结构分析、基于层级结构的3D重建等。主要创新是快速、准确的形状基元提取方法；3D模型相似性规则的高效提取方法；基于形状基元、相似性规则及相似基本单元的3D模型层次结构的构建等。技术难点是如何准确快速地提取形状基元和相似性规则、构建符合视知觉信息感知组织和分类融合基本原理的层级结构。
几何纹理运动重建与数据驱动的真实感动画生成	三维运动重建;三维场景重建;立体重建;多视点三维重建	动态三维重建与动画在军事、医疗、体育、娱乐等领域有着广泛的应用前景，其所提供的视角可变、运动可变的全方位感受带给人们视觉上的立体感、沉浸感和新鲜感。现有采集机制与图形学处理方法难以满足应用所需的"低成本"、"实时估计"、"真实感强"的特点，采用低成本采集设备实现精确高效的动态三维重建与动画是国际前沿挑战难题。本项目瞄准体感相机快速发展与应用的契机，开展几何纹理运动重建与数据驱动的真实感动画生成方法研究：以信号的稀疏表示为理论依据，探索采用一台体感相机对人体场景几何纹理运动进行采集、感知与理解的理论与方法。研究多视角几何纹理的联合分割与稀疏重建方法，探索实时的自适应多优先级运动估计及变形的理论与方法，发现动态特征的连续性平滑变化规律，研究基于稀疏表示的深度导向动画生成方法。力图揭示动态三维人体场景几何纹理运动特性的表示机理，建立数据驱动的真实感动画生成平台，在理论和关键技术研究上取得突破。
超高清自由视点视频感知质量模型与绘制研究	视觉感知;虚拟视点绘制;自由视点视频;超高清;感知质量模型	超高清自由视点视频(UHD-FVV)系统是下一代视频应用领域的发展方向，UHD-FVV的感知质量评价和绘制是系统实现的关键。当前质量评价模型不能评价UHD-FVV失真对感知质量的影响，当前绘制方法不能同时满足高感知质量与低绘制复杂度的要求。本项目拟建立UHD-FVV感知质量模型和预测模型，并应用于深度视频增强和虚拟视点绘制。具体内容包括：提出基于人类视觉感知特征的主观质量评价方法和基于深度神经网络的虚拟视点质量评价算法，建立UHD-FVV感知质量模型；分析影响感知质量的因素，建立感知质量预测模型；提出深度视频增强算法，为虚拟视点绘制提供精确的深度信息；提出感知加权像素插值、空洞填补、失真检测与消除以及视点融合方法，从序列级和帧级优化虚拟视点绘制过程，提高绘制质量、降低绘制复杂度。本项目将在感知质量模型和绘制方法等方面取得创新成果，为UHD-FVV系统的产业化应用奠定理论基础。
低数据资源下语音识别系统中声学建模方法研究	语音识别;低数据资源;声学建模	现代语音识别系统严重依赖于用来训练模型的训练数据的多少，当训练数据不足时，识别率将大大降低。收集大量精确标注的训练数据费时费力，是部署任何一个语音识别系统的主要开支。低数据资源语音识别已经成为近年来本领域的一个研究热点，本项目重点研究低数据资源情况下语音识别系统中的声学建模方法，我们建议通过综合利用下面我们提出的方法来提升声学模型在低数据资源下的性能：在串联或者联合系统中，采用基于稀疏精度矩阵的高斯混合-隐马尔科夫模型（GMM-HMM），一方面对输入特征之间的复杂关系精确建模，另一方面有效防止模型过拟合；采用多任务学习的方式，充分利用已有训练数据的信息，并与多语言联合建模方法一起使用；在深度神经网络（DNN）的训练过程中，采用基于输出节点融合的多语言联合建模方式，借用其他语言的训练数据；在DNN的训练过程中，通过增加噪声的多样性来提升模型的性能。
面向智能养老视频监控的运动目标检测关键技术研究	运动目标检测;背景模型初始化;视频监控;压缩感知	本项目面向未来智能养老视频监控系统大规模应用，考虑数据传输存储及隐私保密需求，从普适性出发研究基于张量填充的背景模型初始化，从实用性出发构建基于压缩感知的在线前景重建优化模型，注重先进性给出了基于自适应压缩感知的前景检测方案。利用流形学习理论找到张量分解具有唯一性的子空间，提出了基于张量填充的背景模型初始化方案，为准确感知养老监控场景提供技术支持；利用初始化背景模型给出基于压缩感知的在线前景重建优化模型，并结合先验信息和前景目标显著性等特性对优化模型进一步约束改进，可满足养老监控对传输存储数据量及对前景目标检测准确性的要求；提出借助先验信息自适应设置视频数据各帧的压缩比，增强对前景目标稀疏度随时间变化的适应性，为压缩感知条件下进行鲁棒的前景检测提供解决方案。本项目的研究成果可为推动智能视频监控技术在多层次养老服务体系中的大规模普及和应用提供理论依据和技术储备，对养老服务产业化具有深远意义。
信号的稀疏、低维、精简性表达方法及其在语音处理系统中的应用研究	降维处理;说话人识别;语音增强;语音识别;压缩感知	本项目研究探索一种基于数据稀疏性、降维及精简性表达方法，以期构建绿色系统的方法，并研究将其应用到多种语音处理系统的可行性及合理性。本提案工作主要分为两个部分：理论研究和语音信号系统应用研究部分。在第一部分，我们重点研究三种基于稀疏性的新型算法：（1）新型的稀疏性主特征子空间分析算法。并着重研究其在去噪上的确定性；（2）新型的稀疏性可区别线性子空间分析算法，并创造出一套全新的具有唯一性和确定性的可区别性子空间分析方法的理论框架。(3)新型的稀疏性多维高斯混合模型建模方法，并研究其基于最大概率估计的训练学习算法。在第二部分，我们将主要研究将上述三种方法应用于各种语音系统的可行性。其中包括：（1）稀疏性语音增强系统， 研究稀疏性主特征子空间分析法， 及稀疏性高斯混合模型法； (2) 稀疏性说话人识别系统。 研究稀疏性可区别子空间分析法， 及稀疏性高斯混合建模法。（3）稀疏性语音识别系统。
动态场景深度场高效感知与计算	深度计算;三维信息处理;视频信号处理;立体视觉;深度感知	以深度场为核心的三维视觉在军事、航天、医学、制造、数字内容等领域有着广泛的应用前景，动态场景深度场的感知与计算是其实现从静态场景向动态场景跨越式发展的关键，涉及计算摄像、图像感知与优化等多个学科方向的交叉，是当前国际研究的前沿与热点，面临感知精度低、空域质量差、时域重构难的挑战，核心问题包括光信息编码方法、物体表面-光成像模型、深度场数据时-空变化规律等。本项目力图揭示动态场景深度场其感知与计算之间的本质联系，研究时-空联合复用的光信息编码方法，建立时-空域多分辨唯一性结构光模板与解码计算模型，实现动态场景深度场精确感知；研究物体表面与几何特性、光学特性下的表面-光成像模型，构建该模型约束下的空域质量优化方法；研究物体运动特征与深度场数据的时-空变化规律，建立时域密集鲁棒重构方法。在理论与关键技术研究上取得突破，实现动态场景深度场的高效感知与计算平台，推动深度场为核心的三维视觉的广泛应用。
基于快速视觉注意模型和深度学习的视觉跟踪	深度学习;视觉跟踪;视觉注意;稀疏傅立叶变换	视觉跟踪广泛应用于视频监控、机器人等领域，其困难主要来自于目标外观变化、背景杂乱、遮挡和突变运动等方面。快速高效地进行视觉信息筛选和自动学习良好的特征将有效解决这些问题。本课题拟将视觉注意机制和深度学习方法引入到目标跟踪，并对其展开深入研究: 首先，利用稀疏傅立叶变换对视觉注意机制进行建模，拟提出基于稀疏傅立叶变换的快速视觉注意计算模型,用于筛选对目标跟踪而言最为重要和有用的视觉信息;其次，研究可在线训练的深度学习方法，并结合考虑视觉注意机制，在线自动学习那些能引起人眼注意的、并能从背景很好地将目标区分出来的图像特征；最后，建立融合了视觉注意机制与深度学习方法的目标跟踪框架，视觉注意机制检测出目标最有可能出现的区域，基于这些区域进行候选样本采样；使用之前学习到的特征对候选样本进行评价，从而实现更为稳定和更接近于人类认知机制的目标跟踪算法。最终建立一个适用于动态场景的稳定的视觉跟踪原型系统。
基于广义近似消息传递与深度学习的压缩相位恢复	非线性压缩感知;多媒体信息处理;深度学习;广义近似消息传递;压缩相位恢复	物体衍射场的相位通常携带着物体的重要信息。快速准确地从衍射图样中恢复出相位信息是多领域共同关注的重要课题。针对相位恢复在利用物体稀疏结构与建模成像噪声等方面的不足，本项目基于广义近似消息传递(GAMP)与深度学习(DL)研究低采样率、强鲁棒性、快速收敛的压缩相位恢复。内容包括：1)基于GAMP构建符合物体稀疏结构特性与探测器工作原理的相位恢复方案，根据被高斯-泊松混合噪声污染的强度测量值重建物体的清晰轮廓与复杂纹理。2)构造并训练符合GAMP相位恢复运算结构的新型深度网络，基于DL求解压缩相位恢复这一稀疏非线性反问题，并实现模型参数的自适应优化。3)将自适应级联字典与参数化双线性广义近似消息传递(P-Bi-GAMP)引入相位恢复，在应用中优化配置与物体内在稀疏结构匹配的超完备字典，并基于DL实现P-Bi-GAMP相位恢复的优化。研究成果在超高分辨率衍射成像领域具有重要的理论意义与应用价值。
早期阿尔茨海默症的言语特征变异性及其神经机制研究	特征提取;声学分析;阿尔茨海默病;神经机制;言语障碍	阿尔兹海默病（AD）是老年痴呆最常见的类型，认知功能呈进行性且不可逆性损害。AD早期发现有助于对患者进行早期干预，延缓认知损害进程。语言障碍是早期AD的重要临床表征之一，且与AD病程发展各阶段密切相关。因此，分析AD语音的变异信息将为AD早期筛查、诊断提供重要信息。然而，当前尚未找到高敏感性、高特异性地反映AD语言神经信息传导损伤的语音特征集。本课题拟从行为与脑机制角度，探究：1）中国普通话语种早期AD患者异常语音特征的提取方法；2）AD患者脑语言功能网络损伤影响言语产生的机制；3）探索AD的脑语言功能网络损伤特征与异常语音特征的关联性，获得对AD敏感的语音特征集；4）建立多任务深度学习的分类模型，实现对早期AD患者的识别。项目的研究成果不仅对AD患者脑语言功能网络损伤的神经机制研究有重要的学术价值，且为远程、大范围AD患者早期筛查提供一种重要技术手段和理论依据，具有良好的临床应用前景。
基于感知哈希和流形降维的视频复制检测技术研究	流形学习;视觉关注模型;视频摘要;感知哈希;视频复制检测	本项目以基于内容的视频复制检测技术（CBVCD）为主要研究内容，结合当前的研究现状与发展趋势，采用视频时空域关注特性建模和视频流形降维的方法进行研究。以人的时空域视觉关注特性为依据，建立新的以运动、颜色为主要参考因素的Bottom-Up时空域关注模型，并以之为基础形成视频摘要；根据视频复制检测的特点，通过对流形降维方法的研究，提出相应的基于视频摘要的流形降维算法；进而，通过以低维空间嵌入点为控制点构造B样条曲线的方式，生成视频感知哈希。本项目在保证CBVCD鲁棒性和区分性的基础上，对基于时空域关注模型的视频摘要提取、基于流形学习的视频降维算法、基于B样条曲线的视频感知哈希的生成等关键问题展开研究，将视觉针对全局以及局部对象的时空域关注特性应用于视频分析中，以流形降维的方式构造视频的感知哈希，对视频进行基于内容的表征，力争获得符合人对视频复制主观认知的检测结果。
基于稀疏时频分析与二元掩蔽估计的耳语音可懂度增强研究	耳语音;欠抽样实值离散Gabor变换;时频分析;二元掩蔽估计;可懂度增强	耳语是一种能量极低的特殊发音方式，其传递的信息易受噪声干扰而被掩蔽。传统语音增强方法无法提高耳语音可懂度，而现有的基于机器学习的二元掩蔽方法仍有不足。本项目研究噪声环境下通过去噪提高耳语音可懂度的单通道语音增强方法。该项目在我们前期工作观察到稀疏时频谱有助于提高耳语音可懂度基础上，拟于稀疏联合时频域，探索通过估计时频块的二元掩蔽值提取语音能量为主的时频块，进而利用这些稀疏时频块稳定重建增强后的耳语音的相关理论和技术。主要研究内容包括: 以过抽样实值离散Gabor时频分析为基础，研究欠抽样实值离散Gabor变换及展开理论，解决欠抽样时信号稳定重建难题，从而建立耳语音稀疏时频谱表示模型；为了克服基于有监督机器学习的二元掩蔽值估计方法的缺点，本项目还将利用卷积非负矩阵分解理论研究基于稀疏时频谱表示的无监督二元掩蔽值学习方法，最终获得可懂度得到大幅度提高的干净耳语音。
基于人声检测及分离的多版本流行音乐检索关键技术研究	歌声分离;歌声检测;多版本音乐识别	近年来，基于音频指纹技术的信号级音乐识别已经达到了很高的准确度，但是机器仍然无法像人类听觉那样准确地识别同一音乐的多个版本。本课题结合歌声检测和歌声分离技术来研究多版本音乐识别问题。研究内容分为以下五个方面：(1)采用与现有算法从细到粗检测歌声相反的思路，基于音乐结构分析并结合音乐领域知识从粗到细地进行乐句级歌声检测；(2)结合音乐领域知识，首次研究打击乐器对歌声检测性能的影响；(3)基于计算听觉场景分析CASA框架设计歌声分离算法，利用模糊分类与匹配在一定程度上解决音乐信号和声重叠这一挑战性的难题；(4)围绕歌声主旋律这一多版本音乐中最本质的不变因素，集成上边歌声检测和歌声分离算法，设计一种翻唱歌曲检索算法，为解决在歌曲结构发生变化时仍能正确识别这一研究难题提供一条新的思路。(5)建立公开的歌声检测和翻唱检索测试数据库，并通过集成以上研究成果实现演示系统。
基于时空显著特性的行人再识别方法研究	半监督哈希;相关反馈;时空显著性;视觉显著性;行人再识别	人们对社会安全的需求日益提高，面向监控视频的行人再识别技术，可以有效地提高公安部门的快速反应能力和破案效率。行人再识别研究的是：在视频中识别出特定的某个可能出现过的行人目标的问题。本课题拟围绕该问题展开以下三方面的研究内容：(1)针对行人再识别问题中遮挡、视角变化、光照变化的挑战，研究基于时空显著特性的行人表面特征模型；(2)针对行人目标匹配中基于传统距离度量方法匹配速度慢的问题，研究面向海量数据的行人快速检索方法，以适应在海量监控视频中的应用；(3)为了弥补行人再识别中训练样本不足的问题，研究面向行人目标检索的反馈学习方法，利用相关反馈技术来增加训练样本数量，提高行人匹配的准确性。本课题在面向监控视频的行人再识别研究方面具有重要的科学意义，在面向社会安全领域的重大需求方面具有现实的应用价值。
监控视频大数据中表观相似对象的判别式再标识方法与技术	表观相似对象再标识;判别式学习;监控视频大数据;视频监控	"找不到"有价值的信息是监控视频大数据应用所面临的一个核心技术挑战，而无约束环境下视觉表观高度相似对象间的有效标识和区分则是解决"找不到"问题中的难点。针对这一技术挑战，本项目围绕监控视频大数据中表观相似对象的再标识这一关键科学问题，从无约束环境下鲁棒的对象表示和高效快速的判别式对象再标识两方面开展研究，突破多模态奇异区域对象表示模型、基于深度学习的对象表示方法、多核流形学习对象再标识方法、融合监控视频编码的高效对象再标识方法等关键点。项目将搭建高清摄像机网络目标追踪原型系统，预期能实时处理16路以上高清监控视频，指定目标追踪准确率超过80%。
基于畸变自适应和时空拓扑约束的深度神经网络架构的行人重识别方法研究	时空拓扑约束;畸变自适应;行人重识别;深度卷积神经网络	行人重识别技术在公共安全视频监控、智慧居家养老防护和智慧校园安全管理等领域有着非常广泛的应用。本项目结合申请者过去对人群监控和行人跟踪等智能视频分析的工作基础，通过汇聚计算机视觉、机器学习等诸多领域的研究成果提出基于畸变自适应和时空拓扑约束的深度神经网络架构的行人重识别方法。主要研究：（1）面向视频数据行人重识别的深度卷积神经网络设计；（2）畸变模式分析及其在深度卷积神经网络中的应用；（3）时空拓扑约束建模及其在深度卷积神经网络中的应用。旨在对行人的全方位的视觉信息进行利用，并融合各种先验知识来约束行人重识别模型的学习,以提高行人重识别系统的性能（识别率、识别速度和鲁棒性等），满足实际视频监控应用中锁定跟踪或目标在海量视频数据中的检索等实际应用需求，为提高我国城市公共安全管理智能化、信息化水平做出贡献。
保护云端监控视频隐私的密文内容检测技术研究	云视频监控;密文内容检测;隐私保护	云视频监控可利用云端的存储和计算能力，并支持异构终端随时随地访问。监控摄像头仅需将视频数据传至云端存储，云端进行运动检测或分析，必要时发送告警信息。云视频监控面临特殊挑战：数据在公共网络传输和在第三方不可信云端存储带来隐私泄漏问题。为此本课题提出支持密文内容检测的隐私保护方法，允许第三方（如云端）在加密视频上直接进行运动检测或分析而无需解密，即可在保护隐私的同时满足云端的内容检测需求。本课题将针对H.264和HEVC压缩视频，探索一系列密文检测方案和对应加密方案，以满足不同应用场景对隐私保护和内容检测的多样化需求——从运动对象形状轨迹的检测与识别、保护形状轨迹的运动存在性判定，到隐私泄漏程度参数可控以应对动态变化的隐私保护和视频分析需求，并探索评估不同加密方案隐私泄漏程度的量化评价模型。本研究将吸引相关领域研究人员与业内人士加入对这一激动人心的新兴领域的研究，推动云视频监控的发展和普及。
多光谱颜色成像技术及应用研究	多媒体信息处理;外观再现;颜色测量;多光谱成像;系统校正	多光谱成像技术能够精确地获取场景中的颜色光谱信息，在诸多领域具有重要的应用价值。本项目开展多光谱颜色成像及其在纺织颜色管理中实际应用的研究。在多光谱颜色成像方面，提出新型快速滤片轮结构，使得多光谱相机的成像效率得以极大地提高，并从光照及几何等关键环节对多光谱成像系统进行校正，解决多通道图像模糊及光谱重建的材质相关性问题，为研制通用型高精度成像光谱测量仪奠定基础。在实际应用方面，首先研究人眼对织物色差的评价特性，提取织物的结构和统计信息，并在此基础上建立织物图像颜色质量客观评价的数学模型；其次研究基于低维度RGB材质数据的高维度光谱材质建模，以及基于共线光源配置的光度立体视觉技术的服装表面重建，使得服装表面在典型光谱光照环境下得以高保真再现，从而实现颜色信息在生产环节中的一致性传递。通过本项目的研究，期望能为多光谱颜色成像的技术发展及相关实际应用做出一些贡献。
基于图模型的人体运动捕获数据检索研究	图模型;视频;运动识别;目标识别;检索	随着计算机动画技术的广泛使用以及运动捕获装置的普及，人体运动捕获数据急剧膨胀。对运动捕获数据进行高效编辑及重用的迫切需求，已使得多媒体检索领域面临新的挑战。运动捕获数据检索涉及复杂时间序列信号处理及数据存储结构设计，本项目在深入分析其特点的基础上，选用复杂系统建模的有力工具- - 图模型对其进行表达与处理，以使得检索效率最优化。本项目重点研究基于图模型的人体运动捕获数据检索问题，具体的研究内容包括：运动捕获数据基于内容和数值的表达方法研究，运动捕获数据基于内容和数值的相似性度量机制研究，运动捕获数据降维及数据存储方式研究等。在以上理论和关键技术研究的基础上，构建运动捕获数据基于多种形式查询的检索系统框架。本项目具有前瞻性和挑战性，其研究成果可用于电影特技制作、军事模拟训练、高水平运动员训练等领域。本研究在理论和关键技术上的突破对于探索复杂时间序列相关问题具有重要的理论意义和实用价值。
基于多源视频协同分析的大尺度群体事态理解和预测模型研究	人群事态预测;多源协同分析;异常行为监控;群体运动分析;人群行为监控	随着我国社会和经济的高速发展，由此带来流动人口增加速度、局部区域人员密集程度及聚集规模都呈现大幅度增加趋势。如果缺乏有效的管控手段，极易发生意外突发事件，导致严重后果。本课题结合申请者过去的工作基础，在深入研究群体事件发生、发展和演化规律的基础上，通过汇聚群体动力学、计算机视觉、机器学习和流体动力学等诸多领域的研究成果，研究基于泛在监控网络的多源协同大尺度群体事态理解和预测模型。本课题(1)提出了基于流体动力学的群体行为识别模型和主动学习框架下的乏样本异常事件捕捉算法，以期实现对临界高危区域检测和突发事件源头控制；(2)通过融合网络拓扑先验和局部视场事件关联得到事件拓扑流，实现群体事态预测，以期望遏制突发事件蔓延，避免衍生和次生灾害。总体来说，本课题将从群体行为建模、异常发现和趋势预测等角度进行研究，力求实现相关理论的突破和创新，对提高我国城市公共安全管理智能化、信息化水平具有重要意义。
视觉注意模型在语义视频搜索中的应用	视觉认知;选择性注意模型;语义;概念;视频搜索	语义视频搜索是在视频内容理解基础上实现的视频快速搜索过程。在当前视频资源爆炸式增长的形势下，从语义层次上实现有效的视频搜索变得越来越重要，也有利于海量视频内容的监管和安全。但由于语义鸿沟的存在，满足这种需求仍然是一个极具挑战性的课题。在底层特征和高层认知之间增加一个语义概念层能够间接地建立起底层特征与高层认知间的联系，从而缩小语义鸿沟。但现有算法存在认知模型不够完善、视频内容表示不够理想、协同训练不够有效等不足。本项目将深入研究视觉的认知机理，特别是选择性注意机制，在此基础上构建新的结合what-where信息的视觉注意模型；基于新的注意模型，从视频概念的协同训练、音视频概念融合、概念的扩展性等方面提高视频搜索的准确率，为跨越语义鸿沟提供一条可行途径。
基于视频属性－目标特征在线匹配的视觉跟踪研究	在线特征提取;目标跟踪;在线学习;视频属性;场景建模	对于视觉跟踪中目标姿态和尺度改变，遮挡，光照变化，运动模糊以及背景杂波等情况，现有跟踪算法中几乎没有一种方法可以通用于以上所有视频。原因在于不同运动特性或视频属性对应的目标有效特征描述不尽相同。针对这一问题，本课题提出了一种可随视频属性变化而自适应选取特征的视觉跟踪方法。首先提取用以统一描述各类视频属性的所谓属性向量；其次通过离线学习和聚类的方式学得"属性向量－特征"匹配库；然后在线检测当前视频段的属性，一旦检测到视频属性发生变化，将激活学得的"属性向量－特征"匹配库从而自适应选择与属性向量匹配的特征；最后建立目标－场景关系模型，联合在线获得的特征共同实现对目标的跟踪。该算法不仅可以根据目标的运动特点和视频属性在线选取目标的有效特征，而且考虑了跟踪情况下的场景信息，能够有效应对各类复杂视频，并为视觉跟踪问题提供一个统一的框架。