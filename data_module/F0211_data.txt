基于查询词级联关系的高阶信息检索问题研究	张量;信息检索;信息检索问题;信息检索模型;信息需求	传统信息检索系统的输入通常是一系列平行的查询词，只能较为粗糙地反映用户的信息需求。在实际应用环境中，用户给出的多个查询词之间往往存在着一定的层次关系，用户实际需求的文档不仅要包含特定的查询词，而且这些查询词在文档中的相对位置还需要满足特定的多重从属关系，即满足查询词级联关系。这种基于查询词间级联关系的信息检索问题称之为高阶信息检索问题，它在一定程度上统一了已有的一些研究方向,如舆情分析、时间链分析、发展趋势分析和文本情感分类等。本课题试图建立统一模型对高阶信息检索问题进行建模和分析，挖掘查询词间的深层次关系，以更通用的方式解决高阶信息检索问题。在该模型中，文档和查询都被抽象为文档张量和查询张量，文档和查询的匹配过程转化为文档张量和查询张量之间的相似度运算，可以更直接地处理在传统信息检索模型中本质上被简化为一阶的高阶信息检索问题。
网络信息自主整合关键技术研究	半监督学习;自主整合;信息检索;垂直搜索;文本分类	随着网络信息的迅速膨胀，准确性、个性化成为新一代搜索引擎的重要目标。虽然分类搜索能够比通用搜索获得更高的准确性，但受限于分类搜索构建需要过多人工干预，构建成本高、类别体系难以灵活设置，领域覆盖率也较低，难以满足用户多样化的分类系、较高的检索召回率等需求。为此，项目提出了网络信息的自主整合方法，首先通过对用户个性化分类体系的描述，借助互联网来自主构建每个类别的标准语料库，解决信息源查找与验证等关键问题，改进现有特征选择与半监督学习方法，完成分类器的自动训练，并将所得到的分类器用于网络信息的自动分类整合。通过网络信息自主整合，不仅能够降低专业搜索引擎的构建成本，提高分类体系设定的灵活性，同时更能用于完成对现有通用搜索引擎的海量信息进行分类整理，提高其检索精度。项目的实施为解决当前信息检索系统所面临的关键问题做出有益探索，并为本体构建、语义计算、文本聚类与分类等领域的研究与应用起到积极促进作用。
基于搜索反馈的移动用户个性化要素型事件摘要模型研究	用户分析;搜索过滤;事件抽取	移动用户个性化事件摘要是社会计算、信息抽取以及自然语言处理领域中一个重要研究课题，移动用户个性化事件摘要是以移动用户为中心的概要化事件知识表示，它能被搜索引擎用以更加复杂的智能搜索任务。当前系统地开展移动用户个性化事件摘要的研究工作较少。据此，本项目提出了使用搜索引擎反馈过滤、用户已有知识体系分析以及提出要素化的事件模型去进行移动用户个性化事件摘要构建模型的研究课题。具体地，本课题包括以下几个主要方面：（1）提出一个移动用户分析模型，可以分析出移动用户兴趣和已有知识分布，可用其作为搜索反馈过滤的依据；（2）提出基于搜索反馈的奖惩型内容过滤方法，可以移动用户兴趣和已有知识分布给予搜索引擎反馈内容分别进行过滤后；（3）提出要素型的事件模型以及基于该模型的事件摘要系列研究以及方法，该方法通过该构建模型自动从过滤结果中抽取事件要素的模板以及事件要点，进行事件模型填充，组合成用户满意事件摘要。
基于枢轴语言的汉越句法统计翻译方法研究	树到树;统计机器翻译;枢轴语言;越南语;汉语	在国家一带一路战略背景下，汉越双语机器翻译对推动两国在政治、经济、文化等方面交流有非常重要的作用。课题将针对汉语与越南语语法差异大、语料稀缺特点，开展面向汉越语言差异的树到树句法统计翻译及基于枢轴语言（英语）的句法统计翻译方法研究。首先，分析汉越语言差异特性，将语言特点融合到树到树学习与解码过程中，提出适合汉越语言特性的树到树句法翻译方法；其次，针对汉越语料稀缺问题，提出以英语为枢轴语言的汉越短语翻译方法，基于枢轴语言提取大规模概率化汉越短语翻译规则表；然后，分析汉英、英越短语句法树对应关系，提出基于枢轴语言（英语）的汉越树到树翻译方法，利用大规模枢轴语言（英语）获得具有一定规模的汉越短语树句法翻译规则；最后，针对不同翻译方法的优缺点，提出汉越树到树翻译、枢轴短语翻译及枢轴树到树翻译的融合方法，解决汉越双语翻译面临的语言差异及语料稀缺等难点问题，对汉越翻译有着非常重要的理论与实际应用价值。
藏语语义本体的概念识别和上下位关系获取技术研究	本体扩充;语义本体;知识获取;上下位关系	在句处理过程中，语义知识可以有效解决歧义字段切分、名实体识别、新词、术语识别等关键问题。语义本体是用于描述知识的共享概念模型的显示的形式化规范说明。本课题采用半自动本体创建策略，由藏语知识工程师手工编辑上位本体，利用电子词典的语义释义获取概念同义词。在汉英多语言本体和标注语料上，进行基于上下位关系的模式匹配获取新词，按照语义相似度排序后交给知识工程师，修订后再扩充到本体中。本课题深入研究藏语本体创建中的关键技术问题，主要研究内容包括：藏语本体概念的属性结构，使每种概念的结构能够充分表达对应的语法及语义知识；藏语中体现上下位关系的模式表示和获取方法；基于HowNet义原和本体的词汇语义相似度的计算方法；开发支持藏文的本体编辑工具。本课题的研究将有助于开展藏语句层面的信息处理，同时对开展藏文机器翻译、信息检索、自动摘要提供有效支持。
新闻与社交媒体协同的主题演化摘要研究	主题演化摘要;平衡优化;主题分析;跨媒体协同;语义关联	现有主题摘要研究普遍忽视了主题在网络传播中的动态性与跨媒体协同共振性，因而缺乏对主题的多维联合观察及动态深度解析。鉴于此，本项目提出将主题摘要范畴从单信息源下的静态文本拓展到多信息源下的动态文本，以生成新闻与社交媒体联合的主题演化摘要为目标。针对此目标，我们提出了建立跨媒体文本间语义联系的混合关联方法，既能缓解社交文本的数据稀疏问题，又能扩充新闻文本缺失的社会维度；为了克服主题分析大多仅针对同质文本且分析结果仅包含同种类型对象的局限性，我们提出了基于异质对象协同建模分析的子主题发现方法，能自动聚合不同类型的对象来协同诠释子主题；为了生成联合视角下反映主题发展演化轨迹的摘要序列，我们提出在统一的框架下融合对信息覆盖性、多样性、跨媒体互补性、连贯性等多因素的平衡优化策略。本研究对揭示异质的跨媒体信息在组织、挖掘与提炼主题要旨及主题发展动态方面的协同价值具有重要的意义。
基于云计算和MapReduce的区域医疗大数据分析关键技术研究	大数据挖掘;MapReduce模型;形式化建模与自动化测试;区域医疗;隐私保护	大数据分析与挖掘是实现区域医疗服务的关键支撑技术之一。基于云计算和MapReduce模型的区域医疗数据除具有一般大数据的4V特征外，还具有生命周期长、数据模式和关系复杂、异构性和分布性等特性。因此，区域医疗大数据的挖掘无法直接采用传统的方案实现。以心肺性职业病、呼吸系统传染性疾病和肺部肿瘤为具体研究对象，以疾病模式分析、疾病异常检测和个性化治疗等为具体的应用，深入探索医疗大数据挖掘系统的形式化建模和检测、分布式挖掘算法，以及用户的隐私保护问题。提出基于openEHR Archetype和rCOS的区域医疗系统互操作建模方法和测试技术；针对具体医疗应用，提出一系列基于机器学习和MapReduce模型的分布式医疗大数据挖掘算法，并采用基于统计学的工具验证；在隐私保护方面，采用多元逐步回归模型和数据加密技术隐藏用户的敏感数据，以及基于同态数据加密技术和安全多方计算的方式实现隐私模式的保护。
大规模复杂信息网络的表示学习与应用	信息网络;社会计算;自然语言处理;表示学习	网络是表示对象之间复杂联系的重要形式，普遍存在于日常生活与科学研究中。信息社会中很多网络节点拥有丰富的文本等外部信息，形成典型的复杂信息网络。面向复杂信息网络的分析技术具有重要的研究价值与应用意义。复杂信息网络具有高度动态，多源异质和信息丰富的特点，为复杂信息网络的表示与分析带来巨大挑战。最近深度学习与表示学习取得重要突破，本项目旨在研究复杂信息网络的表示学习问题，探索基于分布式表示学习的复杂信息网络分析方案，有效融合网络结构与节点文本信息，形成更具区分性的网络表示，在节点分类、社区发现、动态分析、信息传播等方面展开深入研究，同时改进网络分析的效果与效率。复杂信息网络分析是社会计算的前沿学术问题，本项目预期成果将全面提升信息网络分析的精度与深度，显著推动相关领域的理论与应用发展。
面向辅助翻译的统计机器翻译自诊断和自纠错方法研究	错误自诊断;复述词图网络解码;自纠错;译文置信度估计;概率潜变量模型	目前面向工业界尤其是软件本地化领域的统计机器翻译系统仍然无法真正满足实际翻译质量要求，而且无法高效、准确地对翻译错误进行自动识别和评价，也无法提供一种可行、可靠的错误自校正策略，所以大多作为人工翻译的辅助工具。在机器翻译领域，译文质量置信度研究和源语言端翻译难度研究是两个独立的热点研究问题，本申请将其有机地结合在一起，提出具有自诊断和自纠错功能的统计机器翻译方法研究。该研究针对翻译错误自动识别和翻译错误自动校正的关键问题和难点问题，分别提出基于概率潜变量模型的多级置信度估计方法进行低置信错误率的错误识别及置信度估计、基于高质量的复述的词图网络进行翻译错误自校正。该项目中关键技术的攻克，将大大提高机器翻译系统自身错误诊断与校正能力，提供更高效率的人工辅助翻译，不仅在学术上具有重要的理论创新意义，而且具有重要的工业应用指导意义和广阔的企业应用前景。
面向相关性反馈的搜索引擎用户点击模型研究	相关反馈;用户行为分析;搜索引擎;点击模型	结果排序技术是搜索引擎技术研究中的核心问题，而建立用户点击行为模型， 挖掘纷繁复杂的用户行为数据中蕴含的隐式相关性反馈信息则是这一技术问题的重要进展 方向。面对搜索结果中广泛存在的富媒体展现形式和多模态交互方式，以各搜索结果展现形 式相同为主要前提的同质性假设不再成立，这使得当前绝大多数点击模型在真实搜索应用环 境中受到越来越大的挑战。与传统点击模型构建方式不同，本项目提出应当基于海量规模用 户行为日志数据和眼动实验数据进行分析挖掘，对搜索引擎用户交互过程中客观存在的结果 展现形式、用户行为偏好和查询需求类型方面的异质特性进行深入分析与模型特征提取。在 此基础上，更加全面的描述用户点击行为，协助搜索引擎构建具有异质性描述能力的点击模 型，并借助机器学习方法实现对搜索结果相关性的估计，以更好的提升搜索引擎的结果排序 性能。
面向社交网络的药物不良反应的隐含知识发现	关系抽取;文本挖掘;命名实体识别;观点挖掘;社交网络	目前药物不良反应对于人的生命健康造成很大的危害，如何快速识别和发现药物不良反应具有非常实际的意义。在移动互联时代，来自社交网络的药物评论是挖掘药物不良反应非常有价值的信息源。本课题的研究目标不仅仅识别出药物的不良反应事件，同时，基于生物医学文献的隐含知识发现，找到可能的解释路径。因此，将药物不良反应的知识发现过程分为两个部分，一是假设生成，二是假设检验。其基本流程如下：首先，通过社交网络采集用户评论信息，利用基于词向量和神经网络的命名实体识别方法、基于依存关系的事件抽取方法，获取药物、不良反应症状以及背景信息，形成药物不良反应的假设；然后，利用生物医学领域丰富的语义资源，采取基于哈希图核方法抽取药物与症状、药物与基因的关系，利用深度学习方法进行病理路径聚类和评分，构建药物不良反应的隐含知识发现模型，对于不良反应给出可能的解释路径，辅助医学研究人员对于药物不良反应做出判定。
基于多词驱动与卷积神经网络的生物事件抽取研究与应用	多词驱动;卷积神经网络;生物事件抽取;肺结节;触发词	海量生物医学文献中蕴藏着庞大的生物医学知识，如何运用信息抽取技术从中抽取和发现新的医学信息用以辅助疾病的早期诊疗，已成为一个新兴的研究热点。针对现有生物事件抽取方法对多词组成的触发词的识别关注不够，又存在标注语料有限、特征稀疏、泛化性能差等问题，（1）采用基于词向量的神经网络算法，关注多词组成的触发词识别，建立多词驱动的生物事件触发词识别模型，融入词袋上下文及依存句法上下文的词向量信息，解决触发词歧义和特征稀疏等问题。（2）结合词向量语义信息，建立基于卷积神经网络的深度学习模型，充分提取整句范围内深层次的语义信息，解决标注语料依赖性强，泛化性能差等问题。（3）以辅助肺结节早期诊断医学研究为应用背景，运用建立的生物事件抽取模型，构建肺结节疾病相关的可视化知识网络。本项目研究符合生物医学发展需求和趋势，有望探索基于生物医学文献的事件抽取研究的新途径。
基于正向用户指导的交互式机器翻译技术研究	交互式机器翻译;在线学习;交互式剪枝;正向指导;句法树匹配准则	目前，机器翻译系统的译文质量仍然无法满足实际要求，交互式机器翻译成为一个重要的研究方向。交互式机器翻译是一种机器翻译技术与翻译人员（用户）行为相结合的翻译方式，其中用户行为是对机器译文的反馈，可以指导机器翻译系统产生更准确的译文，对于提高人机交互的效率有着重要影响。然而，现有交互式机器翻译方法对于用户指导的利用还不够充分、深入。本课题针对指定正确译文片段（正向）形式的用户指导，建立交互式机器翻译模型，从三方面深入挖掘用户指导的启发作用：首先，面向基于短语的机器翻译框架，利用交互式剪枝和预测技术实现多约束条件下的候选路径搜索；其次，在传统的字符层约束匹配过程中加入句法结构和上下文语义限制，进一步提高译文的准确性；最后，从用户指导信息中在线学习，结合用户置信度模型来实时优化机器翻译模型。本课题的研究将为交互式机器翻译技术提供新的理论基础和研究思路，促进翻译生产率的提升。
基于语义分析的汉语文本错误自动侦测与纠错方法	文本错误侦测;语义搭配关系;语义知识库;自动纠错算法	电子文本已成为当今主要的信息资源和交流媒介，汉语文本的错误侦测与纠错研究是电子出版、数字图书馆建设、网络媒体及办公软件开发等领域亟待解决的问题。如何发现数字文本中的各种错误并实现自动纠错是自然语言处理领域的挑战性课题，尤其是语义搭配上的错误。本项目的内容是在句法和语义学理论指导下，研究从大规模语料和其它语言知识资源中获取句法语义搭配知识的方法和途径，研究语义搭配关系的表示方法与存储组织技术，构建语义知识库；然后基于语义知识库构建语义级文本错误的自动侦测模型；再针对侦测出的各种错误，构建纠错知识库，并依据它研究候选纠错建议的产生和排序方法，提高纠错建议的有效性。本项目的目的是将字词级的文本错误侦测扩展到句法语义级，通过句法语义分析建立汉语文本字词级和语义级文本侦错与纠错的一体化模型，提高文本校对系统的召回率和精确率。本项目对电子出版、数字图书馆建设、编辑排版软件开发等具有重要的意义。
MOOC数据模型及其对课程与学习评价的效用研究	学习模型;慕课;指标;数据分析;评价	随着MOOC的兴起，教育大数据挖掘正成为一个重要的研究方向。本课题基于北京大学从2013年开始的MOOC实践以及从中不断获得的大量学习行为数据，以困扰目前MOOC发展的课程与学习评价为背景，提出了哪些指标适合评价一门MOOC的优劣？在MOOC进展过程中，哪些迹象表明需要教师及时进行教学策略的调整？除了在线测验和考试的分数外，哪些学习行为有助于判断一个学习者的学习成效等三个问题。项目将结合信息技术与教育技术，采用建立多维数据模型、比对问卷实证关联分析、过程性指标与完成性指标相结合等方法与技术路线，从数据模型的建立、影响评价指标的主要因素、结构化统计数据与非结构化文本内容数据的相互关系、个体学习行为和效果与群体活动的关系等四个方面开展研究，其研究目标包括有关数据模型、计算方法、指标建立与评测等，目标的达到不仅可以加深我们对网络时代学习的认识，而且具有指导改进MOOC教学的应用前景。
面向大规模动态短文本的快速聚类及演化分析技术研究	语义相似度;信息演化分析;动态聚类;短文本快速聚类	随着信息产业的飞速发展，以社会化网络为基础的虚拟交流平台逐渐成为用户参与网络讨论、获取信息的重要工具，而其中的海量动态短文本中蕴含了丰富的知识。因此，如何对这些海量的数据进行聚类分析，进而从这些数据中获取用户关注的信息、并掌握信息的演化过程逐渐成为研究的热点。然而由海量短文本数据引入的"高维向量稀疏"和"语义相似"问题，阻碍了传统的面向长文本的聚类分析技术在其上的应用，因此本项目拟通过分布式词聚类来降低特征空间的维度，拟通过迭代的相似度计算方法来获得短文本间的语义相似度。在此基础上，本项目拟借助实现面向大规模动态短文本的快速聚类来获取信息的演化过程，并依此反映用户的关注点在不同时间段内的整体变化趋势，进而以网格量化其变化幅度，以标签揭示其变化内容。
基于黎曼空间模型的多模态Web图像流形学习及检索研究	多模态学习;流形学习;图像检索;黎曼空间模型;Web	目前多媒体信息检索主要基于向量空间模型，存在众多相似性策略不一致性问题；Web 数据集因其大规模、异构和高维特性更适合看作一个卷曲空间而非欧式空间，黎曼空间模型比向量空间模型更适合描述此类卷曲空间。.本课题从一个全新角度即黎曼空间模型出发，结合Web 图像多模态特性，利用黎曼流形学习和多模态学习进行Web 图像检索研究。针对复杂Web 图像数据，设计多流形重构算法揭示单模态内同时存在的多个不同维数流形结构；在对流形结构分析基础上，设计多模态流形传播学习算法，构建更逼近Web 图像语义的融合流形结构，为检索奠定准确的数据表示基础；以测地线距离为相似性策略核心，提出基于流形结构的检索排序算法，提高检索准确度；最后给出客观的自动评测方法，并迭代反馈来优化算法设计。.该课题将推动流形学习在真实复杂数据集上的研究与应用，提高Web 图像检索准确度，为开发下一代图像搜索引擎提供新思路和理论依据。
大规模概率主题模型的高性能求解	大规模文本处理;概率主题模型;并行计算	概率主题模型是一类重要的文本建模方法，建立在统计学基础上，突出的优点是具清晰的模型语义、丰富的表达能力。在信息检索、文本挖掘、自然语言处理等领域中的应用表明，概率主题模型是一种非常有效的手段。然而，由于概率主题模型求解算法一般都具有较高的复杂度并且是基于串行设计的，不利于在大规模文本处理任务中应用。所以，本项目的研究目标是：探索和挖掘概率主题模型的可并行性，系统性地研究和建立概率主题模型的可扩展求解算法并应用到大规模文本处理任务中。具体的研究内容包括：1.研究针对主题规模具有可扩展性的高性能算法，关键问题是主题集分解算法；2.研究支持数据规模和主题规模协同扩展的高性能算法，关键问题是模型子空间分解算法；3.研究基于GPGPU众核平台的并行算法，关键问题是面向GPGPU硬件架构和编程模型的计算任务的映射方法；4.大规模概率主题模型在信息检索和文本分类等领域中的应用。
面向土遗址预防性保护的WSN异常模式识别研究	证据权重;支持向量机;异常模式;土遗址;危险理论	项目以无线传感器网络在土遗址健康监测中的应用为背景，针对土遗址WSN监测数据的质量问题，以及土遗址WSN监测数据异常模式识别中的个体差异和病害差异带来的挑战，致力于研究并提出面向土遗址预防性保护的异常模式识别方法，探索土遗址赋存环境和生存状态之间的科学规律，以期为预防性保护提供科学决策依据。项目通过引入指数平滑预测模型和投票策略，对土遗址WSN时序监测数据进行有效清洗，为后续的异常模式识别奠定了基础；通过引入危险理论，借助危险信号浓度的量化算法，对土遗址健康度进行科学量化，并以此为依据设置特征权重，构造基于健康度—支持向量机的异常模式识别方法，有效解决面向个体的土遗址WSN监测数据异常模式识别问题。借助于证据权重（WoE）理论，有效描述土遗址多因素耦合作用，并以此为依据设计权重计算公式，构造基于WoE—支持向量机的异常模式识别方法，有效解决面向病害的土遗址异常模式识别问题。
基于句法结构和语义框架的机器翻译自动评价方法研究	语义框架相似度;自动评价方法;机器翻译评价;句法结构相似度	机器翻译自动评价是机器翻译研究的重要工具,也对机器翻译研究起着极为重要的导向作用。然而目前主流的机器翻译自动评价指标都没有考虑候选译文句子的结构，而是仅仅考虑参考译文的若干个临近词的组合是否出现在候选译文中，因而无法从总体上评判译文句子否符合人的造句习惯。这不仅使得现有的机器翻译指标与人工评价的相关度较低，也不利于引导机器翻译研究，使之趋向于生成更符合句法语义结构的译文。本项目将研究基于依存结构的机器翻译自动评价指标。与现有的基于句法语义的机器翻译评价研究相比，我们将仅利用参考译文的句法结构，避免将句法分析器作用于机器译文的弊端，并获得与人工评价更好的相关性。而与基于机器学习的机器翻译评价方法相比，本方法将具有更好的普适性，可用于任何自然语言和领域，并无需针对特定的语言和领域进行参数训练。我们还将研究基于该指标的机器翻译解码算法和调参方法，从而使之能产生具有更好的句法语义结构的译文。
依存句法分析子结构可信度计算研究	依存句法分析;可信度计算;人本计算;句法分析	句法分析是自然语言处理的核心问题，对信息抽取、信息检索、机器翻译等应用有重要的支撑作用。依存句法分析以形式简洁、易于理解、便于应用等优点为人们所重视。虽然目前依存句法分析算法研究取得了一定的进展，但是其准确率仍然不能满足实际应用的需要。为此，本项目并没有将研究重点放在直接提高依存句法分析的准确率这一难题上，而是提出了对依存句法分析结果，尤其是依存句法分析子结构的可信度进行计算这一新的研究任务。通过计算依存弧、依存路径、依存子树等依存句法分析子结构的可信度，并将可信度高的子结构应用于特定应用系统中以及依存句法分析自身，从而提高实际应用和依存句法分析的准确率。主要研究内容包括：依存句法分析的可信度资源构建、可信度计算的建模以及可信度计算的应用等。项目针对的问题（依存句法分析子结构可信度计算）和采用的方法（准同步文法、人本计算方法）均具有一定的创新性。
面向中文的看图造句若干关键问题研究	性能评测;双语数据集;上下文建模;图像句子生成;中文句子生成模型	本项目研究图片句子生成问题：给定一张图片，自动产生一个能描述其主要视觉内容的自然语句。尽管中文是世界上使用人数最大的母语，现有工作专注于如何给图片生成英文句子描述。注意到机器翻译的不可靠性使得我们不能简单地通过翻译英文模型的输出来得到高质量的中文句子。就我们知识所及，目前尚未有公开文献讨论中文句子生成问题。本项目提出面向中文的图片句子生成。由于缺乏开展此类研究所需的中文句子库，本项目以建立双语句子库为起点，在数据、模型、评测三方面进行系统性地研究。更具体地，本项目将研究1)如何构建大规模双语图片句子库、2)如何基于深度网络与双语资源建立图片的中文句子生成模型、3)如何利用图片内容之外的上下文信息及其潜在语义改进该模型、4)如何以更符合中文用户认知的方式自动评价句子质量。本项目的研究成果将为图片中文句子生成、基于语义视觉信息检索、跨语言视觉信息检索等提供数据与技术支持。
基于成熟认知模型的文本归类新技术研究	文本归类;归类算法;文本表示;综合特征模型;认知模型	随着文本归类技术在搜索引擎技术、数字图书馆技术、信息过滤、信息检索、互联网信息监控、个性化信息推送等领域的广泛应用，文本归类技术研究己经成为信息处理的前沿课题之一。现有研究工作忽略了人在文本归类过程中的角色和因素，文本归类技术仅停留在词（词组）匹配、统计和计算的基础上，缺乏对文本内容的认知和理解，该局限性大大影响了文本归类的性能。.本课题将探索与大脑阅读理解相关的成熟认知模型在文本归类上的研究价值和技术实现方式。通过理论分析两个成熟认知模型间的互补关系，研究文本归类技术所必需的信息元素及性质，构建能准确反映文本内容的综合特征模型，将模型特征选择和归纳技术融入归类算法。本课题的研究成果将有利于揭示文本归类技术的认知性本质，创新文本表示的数学模型，促进文本归类技术的认知智能化，提高文本归类结果的精确率和覆盖率，以及为相关文本处理技术在模型构建和创新方面提供理论依据和实证支持。
基于超几何分布的无参概率信息检索模型研究	信息检索;概率模型;超几何分布;鲁棒性	信息检索模型是在大规模、跨域、多态的信息搜索应用中的基础核心技术。现有的信息检索模型严重依赖于参数的调节，存在鲁棒性低的问题，具体表现为检索精度的不稳定性。本课题从文档先验概率均匀分布这一概率检索模型基本假设的有效性出发，提出基于超几何分布的无参检索模型，拟解决现有模型中存在的低鲁棒性和依赖调参的问题。主要研究内容为首先量化定义检索模型鲁棒性，其次检验文档先验概率均匀分布假设的有效性，并提出修正该假设的新方法，进而推导无参超几何模型的可计算和实现的公式，最后结合相关反馈提升检索精度。本项目提出的新模型将在TREC、NTCIR等25TB以上大型标准数据集上通过多种搜索任务进行验证评价，希望无参新模型在统计意义上达到或超过现有带参模型调优后的检索精度。本项目能够进一步推动无参信息检索模型的理论研究，其成果可望提升面向海量、异构数据的检索应用的精度和适应性。
社交-推荐网络中的隐式朋友挖掘	推荐影响力;隐式朋友;社会化网络;推荐系统;用户相似性	伴随着社交网络与传统电子商务网络账户合并的热潮，以社交为手段、以商品推荐为目的的社交-推荐网络已经形成。本研究充分结合用户社交行为和商品行为历史,对目标用户的社交好友隐式推荐关系进行分层次挖掘：对一跳朋友，用同现、时序和共同朋友关系统计社交活动量，用拓扑势模型度量朋友圈内威望，另结合用户间商品行为历史相似度，综合三个因素挖掘其中的推荐主导群体；对二跳朋友，建模用户的偶遇关系，以用户间的商品行为相似性为指导，通过机器学习方法推导偶遇行为次数与推荐影响力的关联，预测隐藏的具有较强推荐影响的间接朋友；对外围用户，通过商品相似性与商品行为历史相似性比较，挖掘共同兴趣朋友，作为社交网络冷启动情况下推荐依据的补充。研究目标是挖掘社交-推荐网络中对目标用户最具影响力的用户群体，其结果对揭示社交-推荐网络中用户推荐影响力的构成、度量与传播规律有重要意义，可为新兴的社交-推荐网络的商品推荐系统构建提供思路。
汉语句法分析中的自动歧义识别和分类问题研究	歧义识别;句法分析;歧义分类	高效的信息处理应用需要有效的文本的自动分析和理解方法，句法分析是文本分析体系中的重要环节。句法分析效果在实际应用中仍然难以让人满意，这主要是由于对句法结构歧义的处理错误导致的。句法结构歧义是指存在相同或相似的句子片段对应多个不同的句法结构的情况。以往的研究大多关注于部分歧义实例的消解、某个具体的歧义问题或特定的语义资源的使用，缺乏通用的歧义处理手段。本项目拟研究在自动句法分析中的歧义识别方法以及面向消解过程的歧义分类方法。首先采用不确定性分析的技术对句法分析中影响分析效果的关键性歧义自动识别；然后结合语言学的歧义理论，根据消解这些歧义所需要的不同上下文和语义知识来源对歧义进行分类，为自动的歧义消解提供依据。
面向大数据的中文词义消歧模型优化研究	词义消歧;大规模数据集;知识获取;模型优化	词义消歧是指确定多义词在自然语言特定的上下文中的意义，它是自然语言处理领域的一个核心问题。无论是何种语言，一词多义的现象普遍存在。尤其是在当今大数据时代，数据呈现规模化、多样化、快速化和价值密度低等特点，词汇的歧义问题就显得更加严重。针对当前大数据环境下文本的特点，以及现有词义消歧模型的缺点，本课题将从四个方面展开研究：1)提出一种基于上下文语境的词义消歧模型。2)提出一种基于语言模型的词义消歧模型优化方法；3)提出一种基于上下文扩展的有监督词义消歧模型。4) 提出一种基于多分类器融合的动态自适应概率加权方法。通过本项目，有望形成面向大规模数据的快速高效词义消歧方法，为大数据时代的智能信息处理研究和应用创造更好的基础条件。
面向统计机器翻译的适应性学习与应用关键技术研究	统计机器翻译;深度学习;翻译知识发现;适应性分析与应用;以图搜图	不同领域、不同情景、不同媒体、不同语体和不同语系下的翻译任务往往有着截然不同的特点与难点。驱动一套后验系统，尝试发现与理解新特点，挖掘新知识，并调整翻译系统以解决新问题的过程，称为面向机器翻译的适应性学习与应用过程。配以适应性分析与建模附件的翻译系统，具有较高的可移植性、复用性和鲁棒性，往往能够付出较小的学习代价执行全新的翻译任务。目前，针对统计机器翻译的适应性研究尚未成熟，现有方法学在突破传统思路方面也略显不足。本课题以优化各类环境下翻译系统的适应性为研究目标，尝试探索新的研究思路与突破口，并重点分析和解决如下关键问题：1）面向多任务多环境的双语资源高效挖掘；2）以语义和概念为核心，对翻译知识进行深度学习和多环境应用；3）知识匮乏条件下的翻译知识获取与建模。尤其，本课题将开展跨场景和跨语系的翻译知识分析，以及借助多媒体（如图像）的双语知识挖掘，这类研究在国内外尚属首例。
搭配驱动意见挖掘研究	情感极性分析;意见挖掘;文本挖掘;意见抽取	意见挖掘的目标是从自然语言评价文本中抽取意见主题属性并分析和意见的情感极性（褒、贬或中性）。意见挖掘研究难点有二：一是未知主题词识别及其同主题概念的自动关联，二是情感词歧义消解以及未知情感词的情感极性分析。本项目提出意见单元和合一搭配表示方法，以主题属性词和情感词的合一搭配结构为主干，涵盖意见内和意见间上下文中出现的情感修饰词、否定词和连词。基于意见单元，我们提出搭配驱动意见挖掘方法，不仅考虑意见的主题属性词和情感词，还能从意见单元的合一搭配关系和情感上下文获取用于意见分类和聚类的重要特征，从而提高未知主题词识别的召回率和情感词识别与极性分析的准确率。该方法可在现有小规模标注评价语料库的基础上通过自举学习，从新的原始评价文本中自动获取未知主题词和未知情感词，实现主题词集和情感词集的自动扩充，从而提高该方法对新领域适应性。
基于用户交互行为挖掘的个性化图像标签推荐研究	在线社会网络;社区发现;图像标签;个性化推荐;用户交互行为	实现个性化搜索是下一代图像搜索引擎的目标，其关键问题是为图像赋予既符合用户兴趣又能有效描述图像视觉内容的标签，即个性化图像标签推荐，进而利用成熟的文本检索技术实现简单高效的个性化图像检索。本项目以图像共享社区为应用背景，以用户之间的交互行为挖掘为切入点，研究个性化图像标签推荐方法。首先，通过模糊综合评价量化用户交互度，构造用户交互图；其次，以目标用户为约束条件，实现面向目标用户并支持增量扩展的社区发现算法；再次，通过改进的主题模型融合图像的各种元数据，求得用户兴趣的主题概率分布和各主题的时间分布，用层次向量空间模型将用户兴趣表示为"用户兴趣向量"；最后，以图像的视觉特征和目标用户的兴趣向量为先验条件，利用贝叶斯定理将候选标签库中具有最大后验概率的标签推荐给目标用户。本项目的实施，将对多媒体信息检索和社会网络数据挖掘的基础理论研究起到推动作用，为下一代图像检索系统提供核心算法与关键技术。
基于语义的汉语新闻文本的零形回指消解研究	句子语义;零形回指消解;词汇语义;篇章结构	零形回指是汉语的一种典型现象，零形回指消解的研究对篇章分析、自动文摘、信息抽取、机器翻译等应用领域都将产生重要贡献。现有的零形回指消解研究大多利用先行词和回指词句法特征的一致性进行消解，一般需要依赖人工标注的句法树库。这是现有零形回指消解方法的局限。本项目将基于广义话题理论，在以往对话题句识别研究工作的基础上，提出两个基于语义的特征：一是候选先行词和回指词所在标点句的词汇语义组合可能性，二是候选先行词和回指词所在标点句构成的简单句的语义合理性，并将它们作为筛选候选先行词的两项重要指标。本研究将构建融合现有语义知识库和本体的词汇语义关系计算方法和基于大数据的基于统计的词汇语义相似度计算方法，并基于此构建词汇语义组合可能性评价模型；然后从大规模语料中抽取句子语义关系模式库，构建句子语义合理性评价模型；最后建立面向汉语新闻文本的零形回指消解研究系统，为机器翻译等与语篇理解相关的应用奠定基础。
面向上下文感知数据的流计算复杂事件处理技术研究	复杂事件处理;流计算;上下文感知;信息系统建模;模板匹配	近年来，通过各种传感设备和互联网技术实时采集上下文感知数据和用户相关的网络信息，提供全面、精确、智能信息服务已逐渐应用在人们的日常生活中。然而上下文感知环境是动态变化的，收集到的感知数据具有乱序性、数据量大等特点，传统的处理方式已无法满足上下文感知应用的数据处理需求。基于此，课题研究面向上下文感知数据的流计算复杂事件处理模型与算法。首先利用数据的模板生成和匹配算法和多层次分布式编程结构解决流计算复杂事件处理中的乱序数据流处理问题；其次研究流计算复杂事件处理中的任务调度、资源分配和任务重组策略以并行高效处理任务；最后结合容错和突发事件处理技术对系统功能进行优化，实现对所输入乱序数据的实时性、高复杂度的分析。课题研究目标是获取上下文感知数据间的关联关系信息，并做出反应与决策，为日益发展的大规模乱序上下文感知数据实时流处理技术提供技术支撑。
面向关联数据的信息检索关键技术研究	Web信息检索;本体排序;联合查询优化;自然语言处理;关联数据	以关联开放数据为代表的关联数据将越来越多的出现在互联网中，因此面向关联数据进行信息检索的研究具有现实意义。本项目将解决面向关联数据进行信息检索的关键技术问题。针对自然语言查询接口问题，分析各种查询类型，识别查询意图，结构化表示问题语义，然后将结构化问题语义与知识库中的资源形成映射，进而完成自然语言-SPARQL语句之间的转换；针对联合查询的效率问题，基于分布式结构化本体数据源，研究数据源选择方法、联合查询优化和执行策略，进而构建联合查询优化模型；针对查询结果的本体数据源排序问题，以多种本体排序算法的结果作为特征，以这些特征为数据源使用各种排序学习算法进行排序学习，使用机器学习的方法优化各种排序算法和排序学习算法的权重，进而构建本体排序通用模型。本项目将对基于关联数据的精准检索和语义网技术的发展具有重要意义。
基于对象的监控视频检索方法研究	信息索引;视频对象检测;深度学习;视频检索;监控视频	进行基于对象的视频检索对国计民生等有重大需求，然而其中存在如下挑战性的科学问题：1) 鲁棒的监控视频对象检测方法；2)有效的视频对象特征描述与索引方法；3）视频对象检索中的相似性度量和排序方法。.针对上述关键科学问题：提出一种融合运动和帧间预测的高效视频对象检测方法。采用动态背景建模获得运动对象区域，利用深度学习获取对象检测的置信度, 课题有效利用帧间视频对象预测以获得静止对象区域。该方法能够抵抗对象尺度、方向、形态及光照等变化。.提出视频对象深度特征描述方法及文件索引结构。该方法对每个对象不同部分抽取深度特征并提取其属性以提升特征在检索中的区分性，通过建立高效的基于对象的文件索引结构，以支持快速查询。.提出一种融合多关键帧及其属性信息的视频对象相似性度量和排序方法。检索中采用对象不同区域及其属性作为约束，进行相似性度量；对相关的检索结果进行聚类分析，使得排序靠前的结果具有较强的互补性。
面向交互式问答的省略恢复技术研究	问句理解;信息检索;省略恢复;交互式问答	交互式问答系统能够通过对话的方式帮助人们获取所需的信息，在教育、医疗、政务及客服等在线咨询服务上得到广泛的应用。然而，由于对话习惯的原因，人们经常使用省略句进行提问及交互，因此正确理解并恢复用户对话中的省略句对于交互式问答系统来说至关重要。在本课题中，我们重点研究交互式问答系统中用户省略问句的恢复技术，针对省略恢复串行模型的错误累积、对话文本的语境信息稀疏、省略恢复的不完备性这三个问题，分别提出省略识别及恢复联合模型、对话主题背景知识图谱以及实体及事件省略恢复统一框架三种方法，实现提高交互式问答系统中的省略恢复性能，进而更加精准地为人们提供在线知识及信息获取服务的目标。在提升人工智能的理解和认知能力方面有着重大的科学意义。
OWL DL公理的统计关系学习方法	DL;语义Web;OWL;统计关系学习;本体学习	本体学习是语义Web能否成功的关键之一。已有的本体学习主要面向术语、同义词、概念、概念层次、关系和关系层次，而公理模式和一般公理的研究很少。已有的公理学习方法包括归纳逻辑程序设计和直接学习描述逻辑，但是只能学习OWL DLP公理或部分OWL DL公理，例如概念的定义公理等。统计关系学习集逻辑、概率论和机器学习于一身，可以学习一阶谓词逻辑，从表达能力上讲一阶谓词逻辑包含所有OWL DL公理。但是到目前为止，还没有采用统计关系学习方法学习OWL DL公理的报道。虽然语义Web数据已经很多，例如链接开放数据，但是公理的完备性还有待提高。因此本项目申请针对语义Web数据的特点，提出一种面向OWL DL公理的统计关系学习模型与方法；研究将统计关系学习模型转换为OWL DL公理的方法；研究基于链接开放数据构造OWL DL公理学习测试基准的方法；基于以上方法和技术，构造OWL DL公理学习工具与应用。
面向交互式问答的问题理解及问题推荐技术研究	问题理解;信息检索;问题推荐;交互式问答;词项赋权	随着Siri及Waston的出现，交互式问答技术越来越引起人们的关注。问答机器人以自动的方式对问题进行理解和回答，在企业在线客服、教育、政务咨询等方面有着广泛的应用。本项目主要开展以下几个的方面的研究：1）问题理解技术。针对交互式问答中，问句中存在子问题、大量的省略现象以及基于匹配的检索模型无法很好解决的问句检索问题，本项目开展了问句拆分、对话中省略句判别及恢复及词项赋权等技术的研究。2）相似、相关问题推荐技术。当用户无法很好给出问题的描述时，相似、相关问题的推荐在交互式问答系统中就显得格外重要。本项目在机器学习和自然语言处理方法的基础上，开展了相似、相关问题推荐技术的研究。本项目的研究内容对于相关研究提供了重要的理论基础；词项赋权、对话中省略恢复等核心技术的研究，对于推动交互式问答技术有着重要的价值。
面向社交位置大数据的用户潜在兴趣地点挖掘	社交关系强度;多样性;众包;位置社交网络;深信度网络	随着位置服务和社交网络应用的不断普及，由地理位置数据、社交关系和用户生成内容等所构成的社交位置大数据已成为当前用来感知人类社群活动规律、分析地理国情和构建智慧城市的重要战略性资源，是大数据科学研究极其重要的一部分。作为社交位置大数据的典型代表位置社交网络也就成为了当前研究者们的研究热点。本课题正是以基于位置的社交网络为研究载体，围绕着用户、地点、标签、图片、博文等元素，提出用户潜在兴趣地点挖掘方法和评价框架：通过分析位置社交网络中不同元素之间的潜在关联信息，比如隐式同现标签关系和用户的常驻地理位置，我们研究了如何提取出有利于预测潜在兴趣地点的特征；分析用户空间历史行为、用户兴趣关联、用户地理位在位置社交网络上的分布情况，我们提出基于深信度网络（DNBs）的用户潜在兴趣地点预测算法；依托众包平台，我们借助群体智能来评价兴趣地点预测算法，这也为位置社交网络背景下的推荐系统模型提供评价思路。
面向医学特定疾病的问题分析和相似度计算模型研究	相似度计算;医学;问题目标识别;问答系统	问答系统以提供精准答案为目标，已成为自然语言处理与信息检索领域的一个重要分支和新兴研究热点。在医学领域中，由于医学文本分析和信息抽取的复杂性，面向医学特定疾病的问答系统研究还存在诸多困难。本项目将围绕医学领域重大慢性疾病，开展医学自动问答的基础科学研究，并以糖尿病这一世界性公共健康问题为出发点，开展医学问题目标的识别与分类方法研究、医学文本数量表达式的表示模型与抽取方法研究、以及基于问题目标特征匹配和等价语义模板关联的医学问题相似度计算模型研究。此外，项目将采集多源异构糖尿病问答数据构建大规模多语言糖尿病FAQ语料库并实现开放使用，最终服务于面向医学特定疾病的自动问答。研究将对面向医学重大疾病的智能问答技术基础研究和实用化研究具有积极的科学意义，并在提供糖尿病人群的防治信息服务、提高糖尿病前期高危人群的预防能力、提升糖尿病患者的自身健康监控等多个方面具有潜在社会意义和应用价值。
融合用户社会影响力和用户个性化特征的社会媒介倾向性检索研究	情感分析;倾向性检索;意见挖掘;观点挖掘;倾向性分析	社会媒介倾向性检索旨在诸如博客、微博等Web 2.0 媒介上检索大众对热点话题的观点看法。社会媒介文本相对于传统文本具有文本短、表达不规范等特点，更重要的是，社会媒介以用户为单位组织文档，包含了大量的用户个性化信息和反映社会影响力的用户交互关系。目前倾向性检索研究尚未能结合社会媒介文本的上述诸多特点，使得检索性能大打折扣。因此，本项目拟研究融合用户信息的一体化社会媒介倾向性检索模型。具体内容包括：①抽取、量化用户显式和隐式交互关系，基于张量表示的方法对用户交互关系建模，采用张量分解方法挖掘用户潜在联系，用以度量社会影响力；②统计分析倾向用语风格、内容自相似度、用户活跃度等个性化特征，基于因子分析模型挖掘这些特征之间的内在联系，以整体度量用户个性化特征；③基于文本内容、社会影响力和个性化特征，设计融合用户信息的一体化倾向性检索新算法，减少缺乏考虑用户因素所带来的性能偏差，提高倾向性检索效果。
数据驱动的特征选择形式化研究	信息检索;显著性检测;特征选择;文本分类	文本自动分类是信息检索与数据挖掘领域的研究热点与核心技术。文本自动分类的主要困难之一是特征空间的维数很高，为此特征选择是文本分类中的一个非常重要的步骤。在文本分类中，存在多个特征选择算法，而对这些特征选择算法的分析基本上是使用实验的手段，缺乏理论分析，本项目首先提出一种对特征选择算法进行形式化分析的方法，寻找特征选择算法需要满足的基本约束，在这组基本约束的基础上，构造高性能特征选择函数的通用方法；其次，由于已有的实验证明在不同的语料集（不同的数据分布）上，同一个特征选择方法表现出不同的性能，因此本项目提出鲁棒的特征选择方法是关于数据分布的一个函数，即，特征选择方法是由数据驱动的，从而提出数据驱动的特征选择方法。概括来说，本项目研究数据驱动的形式化特征选择方法。本项目的研究面对的是文本分类的核心问题，具有重要的研究价值，也具有广阔的应用前景。
基于用户反馈的多策略翻译在线融合方法研究	多策略翻译;用户反馈;在线学习	随着互联网时代对机器翻译的需求凸显，如何利用现有翻译技术满足广泛灵活的用户需求已成为机器翻译研究的巨大挑战。多策略机器翻译方法旨在融合多种翻译模型的优势，是解决这一问题的合理对策。与现有系统融合不同，本课题将多策略翻译视为一种满足多变用户需求的在线学习问题。课题首先以译文融合特征挖掘为基础，尝试解决译文融合时使用的特征与翻译建模过程同构的问题；进而分析翻译系统用户的行为，从中量化用户满意度而不单纯是译文质量作为融合目标，以解决现有自动翻译评价倾向于SMT结果的偏置问题；最终针对复杂多样的实际翻译需求，引入在线学习机制，探索实现基于在线排序学习的多策略翻译融合方法。课题目的是研究适用于机器翻译问题的在线机器学习方法，实现一个性能良好的基于在线学习的多策略机器翻译模型，为建立一种能够综合利用多种翻译模型和翻译知识以满足用户个性需求的多策略翻译机理进行有益的探索。
融合异构信息的低秩分解推荐模型研究	异构信息;协同过滤;张量分解;推荐系统	针对传统个性化推荐技术在稀疏数据可适性、推荐结果可解释性上面临的挑战，设计有效融合信息特征的推荐模型已成为推荐系统领域研究的热点。而现有方法存在异构个体信息偏好冲突、异构社交关系信息偏好冲突、异构上下文信息融合复杂度过高等问题。为此，本课题深入研究并改进融合异构信息的低秩分解推荐模型。通过建立独立的异构主题空间，并予以个性化加权融合，准确描述个性化异构个体信息偏好；通过设计融合异构社交关系信息的数据生成过程和正则化项，以及建立基于图结构的关联度量化方法，准确描述个性化异构社交关系信息偏好；通过将异构空间潜在向量映射到同构空间并加以线性融合的方式，降低融合异构上下文信息的计算复杂度。最后将上述改进整合成统一模型，通过对异构信息的有效融合，更准确地适刻画稀疏数据；同时通过对个性化异构信息偏好的准确描述，更完整的解释推荐结果。本课题将有力改善信息过载时代的用户体验及Web服务的收益。
基于语音、嗓音和呼吸信号的藏语拉萨话韵律模型研究	呼吸信号;藏语拉萨话;韵律模型;EGG信号;语音信号	本项目是利用数字信号处理技术，通过对藏语拉萨话语音、嗓音和呼吸节奏信号的处理，在声学和生理参数的基础上对藏语的语音韵律实行分类和建模。研究分1）建立藏语韵律数据库；2）韵律模型研究；3）合成检验三个方面。建立藏语韵律数据库主要包括：a）基本词汇韵律数据库；b）诗歌短语韵律数据库；c）新闻短句和篇章韵律数据库。韵律模型研究包括：a）语音韵律数据库标注；b）基于呼吸节奏和重置的韵律分类；c）根据不同参数进行语音韵律建模。合成检验包括：a）建立一个小型合成音库；b）藏语韵律模型语音合成检验。本项目的研究目标是建立一套基于语音、嗓音和呼吸信号的能用于藏语拉萨话合成的藏语韵律声学模型。拟解决的关键问题是：1）以语音、嗓音和呼吸节奏信号为基础，弄清藏语拉萨话韵律的基本声学类型；2）弄清藏语基本韵律的声学类型和藏语句法结构的基本关系；3）检验藏语基本韵律类型能否用于藏语的语音合成。
基于Web的热点事件检索和分析系统相关技术研究	事件;话题;评论分析;时序关系;排序	本项目拟通过对事件信息的收集、聚类、时序梳理、评论分析等，对相关事件文档进行系统整理，使用隐性链接分析、命名体识别、结构化信息提取、基于人工词典的文本聚类、定性分析方程等方法和技术，按要素提取事件的简要描述，理清事件的发展脉络，把握事件影响力变化趋势，同时对事件在各阶段的发展进行主流评论分析，让用户对所关心的热点事件能够有彻底、全面的了解和把握。针对在线事件，还可以通过事件话题传播关键点和主要影响因素的分析，预测事件的发展和话题未来变化趋势，并根据需要提供预警。.本项目希望能够从技术上为搜索引擎实现"事件检索和分析"功能提供支持和帮助，从而为广大Web用户了解热点事件和热门话题提供帮助，为企事业单位对和自身相关的事件进行全面的把握和分析提供支持，同时为各级社会管理者及时掌握潜在的网络舆情提供服务。
车联网异构无线网络联合资源管理研究	协同通信;移动云计算;车联网;资源管理;认知无线电	车联网是智能交通系统的核心组成部分，是十二五期间国家和广东省的重点建设领域。然而，目前车联网的发展面临着严峻挑战。车联网是一个典型的异构无线网络。无线资源的异构性、节点计算和存储资源的有限性成为严重制约车联网传输容量、服务质量和隐私安全的瓶颈问题。本项目以资源认知与协同管理为核心思想，结合无线通信、移动计算领域的最新理论方法，旨在提出车联网新型体系架构及联合资源管理方案，有效促进车联网无线资源高效利用、节点资源智能配置、车载服务安全可靠。项目主要研究内容包括： （1）基于认知协同的车联网层次化网络体系架构； （2）车联网异构无线资源多域认知机理与方法； （3）车联网异构无线资源联合频谱管理机制与方法； （4）车联网移动云服务资源管理模型与方法。 本项目以广东省大力建设智能交通为契机，项目组将与地方交通部门和企业保持密切交流，以有效促使项目理论研究成果转化应用，切实服务于交通行业。
句法语义分析与开放域信息抽取融合技术研究	开放域信息抽取;知识图谱;语义角色标注;依存分析;持续学习	本研究基于持续学习框架探索中文句法语义分析和开放域信息抽取相融合的关键技术。人类学习过程具有时间持续性、来源多样性、知识增量性、过程阶段性等特征，具备上述特征的学习框架称为持续学习。现有机器学习多以学习单一类型知识和完成单一任务为目标，不完全具备上述特征，尤其是持续性；中文句法语义分析与开放域信息抽取方面的研究亦是如此。为融合二者以形成持续学习系统，本研究的工作包括两个方面。其一，从两个角度分别进行研究：构建基于树结构的句法语义树库并实现句法语义一体化分析；建立基于句法语义分析的开放域信息抽取系统。其二，将二者融合：基于抽取的信息改进句法语义分析性能，通过关系推理产生新的关系类型和关系约束规则，并以众包方式对自动抽取结果和推理结果进行干预，以避免性能提升瓶颈、确保学习过程的持续性。由此，可迭代地改进中文自动分析与开放域信息抽取，产生高质量的句法语义树库、句法语义联合分析模型和知识图谱。
面向热门争议话题的基于社交网络文本与结构的层次观点挖掘研究	情感分析;观点挖掘;社交网络;信息抽取;概率图模型	作为舆情分析的重要组成部分，面向热门争议话题的观点挖掘是围绕热门争议话题，对主观性文本进行分析、归纳和推理，获取观点的过程。当前的观点挖掘存在以下问题：1）来源的局限性：社交网络中用户表达观点的方式多种多样。单独基于社交网络文本或结构进行观点挖掘都有其局限性；2）粒度的局限性：当前研究主要集中在粗粒度立场分析和细粒度产品属性挖掘，缺乏多粒度观点挖掘。针对上述问题，本项目拟开展以下研究工作：1）研究基于社交网络文本与结构的分布式表示，充分利用多信息源包含的观点信息，解决来源的局限性；2）研究基于概率图模型的层次观点挖掘，既识别出用户立场，又挖掘出其背后的深层次原因，解决挖掘粒度的局限性；3）研究基于分布式表示的层次观点挖掘，综合考虑多信息输入和多粒度输出，有效解决来源和粒度的局限性。进而在此基础上实现一个开放、准确的层次观点挖掘系统，为后续的意见群体检测、舆情分析提供理论支撑。
Deep Web数据集成查询结果抽取与整合关键技术研究	数据集成;Web数据语义标注;Deep;Web数据抽取;重复记录检测;Web	Web可分为Surface Web和Deep Web。Deep Web数据量大、主题专一、数据质量高，其价值远远超过了Surface Web，然而传统的搜索引擎搜索不出这部分数据。为了方便用户高效使用Deep Web数据，大规模Deep Web数据集成的研究已成为一个非常迫切的问题。查询结果的抽取与整合是Deep Web数据集成中的重要环节，存在着许多困难和挑战。本项目拟探讨其中最为核心的三个关键技术：研究查询结果页面抽取技术，充分利用页面的结构特征和内容特征，实现结构化数据的自动抽取;研究查询结果数据语义标注技术，充分利用Web数据元素之间的逻辑约束关系，提高语义标注的准确性，并实现多数据源数据模式的一致性;研究大规模重复记录检测技术，构建领域层次的重复记录检测模型，实现同一领域大规模Web数据库之间自动的重复记录检测。项目成果预期将在商业智能、企业搜索、情报分析等系统中。
基于主题模型的枢轴语言统计机器翻译研究	统计机器翻译;枢轴语言;主题模型	枢轴语言方法能够克服统计机器翻译缺乏双语语料的困境，成为近年来机器翻译研究和产业化的热点之一。然而，由于语言的多样性和稀疏性，目前的枢轴语言建模方法无法充分利用枢轴语言翻译单元的上下文信息，对最终模型产生负面影响。对此，本项目提出引入主题模型来建立上下文相关的枢轴语言统计机器翻译。项目主要工作包括：① 研究基于主题模型的上下文表示方法，克服传统方法存在的缺陷，满足枢轴语言统计机器翻译建模的需求；② 在基于主题模型的上下文表现形式下，研究引入枢轴语言上下文的词语对齐建模新方法；③ 在基于主题模型的上下文表现形式下，研究引入枢轴语言上下文的翻译模型建模新方法。项目充分发挥了主题模型的优势，推动枢轴语言统计机器翻译由上下文无关建模发展为上下文相关建模。项目的开展将为如何更好地利用枢轴语言方法来解决训练资源缺乏问题提供一种新思路，对于资源贫乏语言的机器翻译具有重要意义。
基于迁移学习的地理领域知识图谱构建技术	迁移学习;实体关系抽取;表示学习	知识图谱构建技术是类人智能发展的重要基础。本课题拟针对以地理为代表的特有领域知识图谱构建任务，围绕跨语言处理多潜在空间领域适应性、分布式知识表示等科学问题开展研究工作。在地理等特有领域知识图谱构建过程中，由于其有限的样本标注资源，难以应用深度学习等大规模知识图谱构建技术，本课题基于迁移学习技术，研究不同领域语言之间的语义相关性，挖掘其共享潜在空间，利用普通自然文本资源，提取地理领域实体和实体关系，为知识图谱构建提供基础；在知识图谱补全和推理方面，传统三元组的网络表示形式不能有效的度量和利用实体间的语义关系，计算效率低下，本课题基于分布式表示学习技术，建立图结构与向量空间融合的表示学习方法，实现实体和关系的精确预测。本项目的研究有助于提高特有领域知识图谱构建质量和水平，推动深度学习在自然语言中的应用和促进类人智能水平的发展。
微博热点话题传播模型与可视化研究	社会媒体;情感分析;社会网络;复杂网络分析;微博	微博作为一种新型的即时通信与信息共享服务，造成的"发布革命"让中文微博用户数已经达超过3亿。怎样预见性地发现和检索那些具有广泛传播能力的热点话题，以便尽可能早地掌握情况，具有重大的社会意义和经济效益。本项目旨在全面探索中文微博的基本特征的基础上，研究微博信息快速传播的机制和适合微博特征搜索模型。我们对新浪微博为代表的中文微博的网络结构进行全面分析，为学术界和产业界提供微博数据、微博处理工具和基本结论等系列资源。我们通过情感分析研究微博中的话题性，探索主题传播速度和传播范围的机制并建立能处理海量数据的变粒度传播模型。我们研究反映传播趋势的微博搜索模型，搜索的排名通过机器学习的方法确定确定博主、内容和博主之间交互的不同贡献。搜索返回的相关发帖列表综合考虑了它们的话题性、权威性与新颖性。我们研究可视化的模型来跟踪相关话题的发展过程和搜索的结果，为用户提供快速理解微博数据传播的途径。
基于深度学习的汉字书写风格建模与重建方法研究	建模;汉字;书写风格;深度学习;重建	近年来，汉字书写危机引起国人的广泛关注与警觉，随着计算机与智能移动设备的使用和普及，人们的汉字书写能力显著下降。主要原因之一是，当前除了手写输入外其他面向汉字书写的各种应用的研究与开发还不成熟，在信息技术带来的无纸化趋势的冲击下，需要手写汉字的场合越来越少。本项目拟通过对汉字书写风格建模与重建机理的深入研究，解决包括海量手写汉字数据挖掘、汉字书写轨迹精确匹配、汉字书写风格特征提取等关键技术，提出适用于汉字书写风格建模的深度人工神经网络的构建与训练方法，结合最优形状插值等技术来实现汉字书写风格的精确重建，并使用该风格建模与重建方法来显著提升面向汉字的笔迹鉴定、数字墨水和手写体字库自动生成系统的应用效果。本项目的研究一方面有望解决采用现有方法难以处理的汉字书写风格的建模与重建难题；另一方面将推动汉字书写在计算机与移动终端上的使用与流行，具有重要的理论和应用价值，预期将产生显著的社会与经济效益。
社会媒体中的垃圾用户集团识别方法研究	用户特征;垃圾用户集团区分;学习算法	社会媒体中的垃圾用户集团从事的病毒营销、恶意炒作等活动，严重破坏商业秩序、舆论环境和政府公信力。与传统垃圾用户相比，垃圾集团的操控能力和危害更强。然而，社会媒体的用户数目巨大、用户特征多模、用户间集体协作方式隐藏而复杂，很多垃圾用户识别技术难以适用。本项目拟针对社会媒体环境下的垃圾用户集团识别方法进行创新性研究，包括:（1）研究相似用户名和异常子结构快速查找方法，以解决海量社会媒体数据中的疑似集团定位困难问题；(2)研究用户多模态特征的有效集成方法，利用特征的相关互补性提升垃圾指标计算的精度；(3)研究融合用户个体特征和用户之间协同特征的无监督、半监督学习算法，在挖掘用户协同工作模式的基础上实现对垃圾用户集团的准确识别。.    本项目有望揭示个体垃圾用户和垃圾用户集团之间的内在联系，并为社会媒体中垃圾用户集团的自动区分这一重要问题提供可行的理论支持和技术基础，具有重要的理论意义和实际应用价值。
融合多模态文本关联分析与挖掘的跨媒体社会图像检索方法研究	跨媒体社会图像检索;多模态联想;关联分析与挖掘;多模态关联网络;多模态文本	本课题在传统自然语言处理和信息检索基本理论的基础上，针对互联网环境下大规模社会图像检索的实际需要，侧重于研究跨媒体社会图像检索中多模态文本关联分析与挖掘关键技术，构建融合多模态文本关联分析与挖掘的跨媒体社会图像检索新颖实现框架，并由此引发针对有别于传统文本形式的多模态文本分析与处理、乃至跨媒体社会图像检索策略的深入研究，为社会图像检索用户提供一种高效、精确、易用的智能助手。其中，采取基于自动生成机制构建蕴涵丰富语义和视觉关联信息的多模态关联网络作为重要知识源，有效利用基于多重属性的概念文本项自动抽取模式、跨模态语义评估与消歧模式、跨模态语义扩展与优化模式、跨模态语义排序与过滤模式，特别是跨模态实体-对象语义关联模式、跨模态语义聚合关联模式、面向多模态文本关联分析与挖掘的联想机制等多种新型多模态文本深层次分析、处理、挖掘与联想关键技术，构成功能更加强壮且性能更加完善的跨媒体社会图像检索过程。
基于深度学习的新型生成式摘要模型研究	自动文摘;深度学习;生成式摘要;神经网络模型	大数据时代信息严重超载，为迅速获取有效信息带来障碍，因此智能文本摘要的方法研究和系统开发具有广阔的应用前景。尽管自动文摘已有半个多世纪的研究历史，由于现有语句抽取式和模板填充式摘要方法的内在局限性，机器摘要和人工摘要之间的差距尚无法逾越，开发新型摘要模型乃当务之急。受人工智能、深度学习和神经网络模型的最新研究成果鼓舞，我们大胆提出全自动生成式摘要的目标。我们立足于语言文字的独特性，以摘要为目的，研究文本理解和文本生成中所遇到的相关困难和关键问题。我们致力于分析、设计和实现数据驱动的神经网络框架及模型，包括探讨文本理解和生成的层级建模和协同学习机制、焦点信息的关注机制、模型自我完善等机制，及其相应策略和算法，以应对文摘全自动生成所带来的挑战，并在此基础之上开发相应的系统和应用。该项目的研究内容具有重要的研究价值和深远的学术影响。针对某些关键技术的前期研究结果亦表明，该项目的实施切实可行。
基于hLDA层次主题模型的中文多文档摘要研究	摘要润色生成;层次主题模型;中文多文档摘要;无监督多文档集建模;多特征摘要句抽取	多文档摘要是一种文本浓缩技术，旨在为多篇文档生成一篇能概括主要内容的摘要，对海量信息服务具有很好的应用价值。本项目的特色是采用hLDA为中文多文档数据集建模，与中文语言特点相结合进行结果分析与模型优化，探索性能更好适用性更强的中文多文档摘要新方法。hLDA是一种无监督贝叶斯非参方法，不仅能在大规模离散无结构数据中挖掘潜在主题，组织成更符合人类认知的层次语义结构，而且能自动适应开放数据集的增长。相对已有的英文hLDA摘要，本项目的创新点主要有：专门针对中文多文档语料集展开研究，将实现一种简单易行的无监督方法，不需要借助理想摘要的指导,对hLDA建模结果在中文语言应用上的优缺点进行深入分析，包括结合中文词法、句法分析及相似度计算等对主题路径的聚集与分离、词语层次分布等详细信息与人类认知的语义结构进行比较，并进行模型优化，充分利用潜在主题路径及主题间抽象层次关系，融合语言特征来实现文摘句抽取。
基于集成学习的生物医学文本信息抽取方法研究	主动学习;多Agent元学习框架;信息抽取;集成学习	本课题研究的主要内容是基于集成学习的生物医学文本信息抽取方法，以提高生物医学文本信息抽取的性能。生物医学文本信息抽取是生物医学研究中不可缺少的环节，但目前现有成果距离真正实用还有一定距离。本研究提出的面向生物医学命名实体识别的多Agent元学习框架,使用不同的学习Agent和局部特征选择法选择不同的敏感特征集合识别不同类别的命名实体类型，克服了使用单一学习算法选择相同特征集合识别所有命名实体类型的缺点，提高每一类的识别性能尤其是小类别识别的性能，系统性能明显优于基于单学习模型使用全局特征选择方法的识别系统。提出的面向生物医学命名实体关系识别的基于TSVM与主动学习融合的集成学习策略，在小规模已标注语料环境下比有监督学习方法更优越。这为今后的实际应用提供了一个较好的解决方案。
基于视觉关注的图像复制检索技术研究	人眼关注模型;复制检索;基于内容;复制不变特征	基于内容的复制检索（CBCR）是近几年在信息安全、多媒体检索的研究过程中发展起来的新技术，对于数字多媒体版权保护、多媒体监控管理、多媒体信息检索等领域有着重要的理论意义和应用价值。如何使得CBCR的检索结果更符合人的主观关注特性，是现在的一个研究热点。本课题针对图像的CBCR，从建立人眼关注模型入手，以人眼关注区域的局部特征和各局部特征的整体结构为依据，使得CBCR的检索结果更符合人主观意识；利用独立分量分析、尺度不变特征变换、粒子滤波等高阶统计、非线性信号处理方法，结合人眼关注区域，探索新的局部复制处理不变特征的提取方法；提出融合多特征的相似性度量法则，达到提高图像复制检索精度的目的。作为新技术的探索研究，本课题将尝试人的主观实验与信号处理技术相结合的方法，力争从突出主观关注特征的方面找到提高CBCR精度和速度的突破口，为多媒体信息检索的发展起到推动作用。
面向汉语篇章语义分析的框架推理技术研究	语义线索;知识库;篇章分析;阅读问答;语义推理	篇章语义分析是自然语言处理领域的一个核心问题，篇章的非结构化特征及语义线索隐含性，给篇章语义分析带来了巨大挑战。本课题基于认知机理，采用框架语义学、机器学习等领域的相关理论和技术，从汉语篇章深层次框架语义分析的科学问题和实际应用两个方面着手,探索基于汉语框架网的篇章级框架语义推理技术，建立面向汉语篇章语义分析的框架语义推理技术理论与方法，并实现面向阅读理解的应用验证系统。具体研究内容包括：（1）构建汉语篇章级框架语义结构化表示体系；（2）研究篇章中框架元素语义线索推理技术；（3）研究篇章中片段关系语义线索推理技术；（4）建立面向框架语义推理研究的语料资源与评价体系；（5）针对阅读理解中的篇章语义一致性判断、观点支持及概括理解等难点问题，研发基于框架语义推理技术的阅读理解应用验证系统。项目研究成果将丰富并发展汉语篇章语义分析理论与方法，形成面向汉语篇章深层次语义分析的框架语义推理技术体系。
基于协同计算的社区问答意见型问题分析与答案生成研究	计算语言学;社区问答;自然语言处理;信息抽取;问答系统	社区问答是Web 2.0背景下产生的一种新的以"提问-回答"为主的信息共享和交流方式。不同于传统的自动问答，社区问答以"用户"为中心，具有明显的协同性，用户与文本内容（问答对）之间存在着复杂的信息关联，文本内容与用户标签协同以及用户交互反过来赋予文本内容更丰富的语义。社区问答中意见型问题占有很大比重，严重制约了社区问答分析的智能化水平。但是目前已有的研究工作主要集中在事实型问题的分析、答案检索以及用户行为建模等方面，对意见型问题分析和答案生成的研究工作相对较少，特别是缺乏系统性的研究。本申请课题以社区问答中意见型问题分析与答案生成为研究对象，以协同计算为研究方法，研究内容包括：（1）融合社会关联和协同计算的用户问题情感极性分析；（2）基于稀疏表达和分布式计算的相似问题协同检索；（3）基于局部关联和协同分析的答案自动生成。本申请课题的研究成果将为问答系统以及意见型问题的分析提供参考。
大规模WiFi轨迹隐含知识图谱挖掘研究	WiFi连接轨迹;基于位置的社交媒体;知识图谱;移动社交网络;数据挖掘	WiFi无线接入已经成为移动互联网时代手机用户的基础生活需求，大量WiFi热点也成为智慧城市信息基础设施的重要组成部分。深入研究大规模WiFi动态连接及周边环境特征，有助于规范公共WiFi接入服务，助力国家数字城市战略。本项目提出对城市规模的WiFi连接轨迹与移动社交网络蕴含的语义内容进行挖掘，通过图形化的方式进行融合建模和隐含知识发现，以提供WiFi知识图谱在优化连接、城市规划、商业推荐等方面的应用。研究首先对WiFi连接轨迹应用语义地点识别、行为建模和多上下文相似度融合的群组发现方法，从时空上反映WiFi的用户移动特征；其次，对移动社交网络的多媒体内容进行分析，通过图像多概念探测的方法，融合文字内容构建主题模型，反映WiFi热点的周边环境特征；最后，将用户、位置、内容等上下文语义描述建模成包含异质属性的超图，通过高阶张量表示及隐含语义分解的方式从多个切面完成知识发现。
中日英新闻二型模糊多粒度翻译方法研究	隐马尔可夫;机器翻译;粗糙集;人工智能;粒计算	随着经济全球化和自媒体、互媒体、社交网络的兴起，跨语言交流急需克服障碍、解除制，提高信息传播的广度、深度和速度。美中日是世界GDP前三位的重要国家，中日英新闻翻译尤为重要。本项目研究中日英新闻二型模糊多粒度翻译方法，引入可解释的粒度，描述句内关联、句间呼应和上下文信息，通过模糊C均值聚类进行粒度化，进而构建一种新的二型模糊多粒度隐马尔可夫模型，该模型具有上下双层结构，底层利用隐马尔可夫模型中的概率关系描述自然语言中的概率性，而自然语言中的模糊性通过上层模糊来描述，多粒度则由枢轴空间模糊C均值聚类形成；提出二型模糊粗糙集多粒度约简算法获取多粒度规则和知识；研究多个层次地模式匹配，形成一种新颖的基于多粒度模式的机器翻译方法，并构建新的中日英跨语言新闻翻译系统。
新型社会网络模型及在社会媒体文本摘要和图像标注的应用	社会媒体;社会网络;文本摘要;主题模型;图像标注	以微博和共享媒体等组成的社会媒体正日益成为人们获取实时信息的重要来源。但社会媒体上的信息格式、传播方式和信息质量都和传统的静态网页有很多不同，急需新的理论模型和算法。由于社会网络模型可以很好地表示用户之间、文档之间、图像之间、和用户与文档之间各种不同关系，本课题将以社会媒体文本摘要和图像标注为应用背景，研究面向社会媒体信息处理的社会网络模型以及应用。具体包括研究社会网络的动态拓扑进化特性、网络节点的影响力计算及与节点所发送信息质量的关系；如何利用异质社会网络中的不同性质关系合成和节点属性来计算异质网络中的对象相似度，并应用到社区发现和图像标注；研究能反映网络社区中会话型信息流的动态主题模型，并研究如何利用该模型和网络信息质量计算的结果，改善对数据流形式的文本摘要。该研究的目标是基于社会媒体信息处理的视角，探索新型社会网络,并应用到更多的社会媒体信息处理应用中。
汉语考试中海量作文多层面全自动评分技术	自动阅卷;作文自动评分	本项目以国家民族汉考办提供的MHK考试材料为基础，研究少数民族汉语考试中海量作文自动评分技术。项目将作文评分分为前期的异常作文诊断和后期的正常阅卷两个阶段分别给出解决方案，并将异常作文诊断细化为体裁异常、通顺度异常、作弊异常三大方面，将正常阅卷细化为汉字、词语、句子、篇章四个层面进行研究。结合前期研究结果，提出本项目的重点是：在句子和篇章层面进一步深化前期成果；研究利用海量数据实现无需人工标注的全自动评分模型生成问题。本研究成果可以广泛应用于各种大规模汉语考试，提高汉语考试中的作文阅卷效率，降低阅卷成本，减少人工阅卷的主观差异。
汉语缩略语识别以及歧义消解技术研究	歧义消解;缩略语;缩略语挖掘;缩略语识别;原形语	缩略语是新词的主要来源，而新词对自然语言处理中的词性标注，词义确定与消歧，命名实体识别及共指消解等造成了严重障碍；在中文信息处理中，还造成了分词的极大困难。与一般新词不同，缩略语在构成上表现出特有的规律。本课题的目的就是系统地研究汉语缩略语的规律，探讨缩略语处理的若干关键技术。主要包括：(1)根据大规模的语料与缩略语-原形语对照表，研究缩略语的构成规律及词性表现规律；(2)利用所获规律，研究汉语缩略语的识别技术以及具有缩略语识别能力的汉语词处理模型；(3)研究从文本中挖掘缩略语-原形语对，自动扩充缩略语-原形语的对照表；(4) 探讨如何在文本中预测缩略语所对应的原形语以及如何消解缩略语的歧义，并针对上下文信息不充足的情况，研究缩略形式向原形语的还原转换。本项研究将有助于解决缩略语对中文信息处理诸多环节的困扰，并为相关应用提供支持。
基于稀疏隐语义分析与众包的查询意图发现与推荐算法研究	查询意图推荐;查询意图发现;众包;稀疏隐语义分析	准确地理解用户查询对于提高各类搜索引擎的服务质量至关重要。本项目以查询-点击日志、搜索结果内容以及开放知识库为主要研究对象，采用多层堆叠的稀疏隐语义分析模型以及众包作为主要技术手段，按照查询意图表示、查询意图发现、查询意图推荐的研究步骤开展研究。具体内容包括：基于多层堆叠的结构化稀疏隐语义分析模型的查询意图发现方法，自动从数据中学习得出合适的隐查询意图数目；基于泛化主动学习框架的结合众包-隐语义分析的查询意图发现方法，建模众包工人的工作质量，挑选对算法最有贡献的工人-任务配对进行众包；以及基于效用的多样化查询意图筛选与推荐方法。本项目旨在有机地结合众包与稀疏隐语义分析算法，同时发挥人脑与机器的长处，以从查询-点击日志为主的大规模异构数据中高质量地发现用户查询对应的多种隐查询意图，并选择最具效用的若干隐查询意图推荐给用户。
基于神经网络的跨语言实体链指研究	段落向量;词向量;神经网络;实体链指;跨语言	跨语言实体链指技术将一种语言的上下文中的名称链接到另一种语言知识库的相应实体上。这种技术打破知识的语言鸿沟，一方面能够最大程度地利用互联网上由不同语言表示的知识库，另一方面也能为缺乏知识库的语言的信息处理提供支持。跨语言实体链指的难点在于如何计算由不同语言表示的文本之间的相似度。本项目深入研究基于神经网络的上下文语义表示方法。通过基于词向量的翻译技术，缓解未登录词对跨语言文本相似度的影响；通过基于段落向量的翻译技术，利用上下文中的全局信息计算跨语言文本之间的相似度；通过将不同语言映射到同一个段落向量空间，实现不经过翻译直接计算跨语言文本相似度的方法，从而减少翻译步骤带来的错误级联。
汉语多文档意见信息聚集和融合方法研究	意见聚集;意见挖掘;多文档意见文摘;意见融合	如何有效发掘并以一种自然的方式聚集和融合散落在多个意见文档中的大量的、多样的、冗余的意见信息是目前意见挖掘和意见自动文摘要研究的热点，也是面临的主要挑战。本项目拟以大规模语料库调查为基础，探索不同领域的汉语意见信息表达的内在结构和模式以及意见信息结构表示模型；在情感分类和意见抽取基础上，采用基于语料库的机器学习方法，同时融合语义、句法和修辞等多种语言学特征以及领域情感知识，面向多个领域研究汉语多文档意见聚集和融合方法及关键技术，重点解决意见信息正规化(涵盖跨文档意见实体共指消解和意见复述识别)、基于意见信息结构的意见句子融合和领域情感知识自动获取等关键问题；进而构建一个基于文本-意见信息结构-文本模式的汉语多文档意见自动文摘技术框架及系统。本项目的实施不仅可为意见问答、意见检索和意见跟踪等系统奠定理论和技术基础，而且在政务智能、商业智能和舆情分析等领域具有十分广阔的应用前景。
言语听障评估与沟通训练关键技术的研究	认知;言语听障评估;多模态;沟通训练;言语习得	本项目将言语工程、语音语言学、耳科学、临床医学相结合，重点探讨言语听障评估与沟通训练的新方法及其关键技术。研究言语音位及其变体的知觉恒常性，建立汉语声韵母听感等价类，优化汉语听障评估词表的设计方法和评估策略；分析言语习得中的"误听"和"误说"与言语认知过程中的感知、记忆、决策的关联，提出面向计算机辅助语言学习系统的发音纠正分级提示方法；融合语音、脸像、图像、文字等跨媒体信息，建立言语沟通的多模态计算模型与交互行为模式。通过相关研究成果，进一步推进听觉感知、声学参数、语言理解与认知机制相结合的研究，构建并推广"言语听障评估与沟通训练平台"，为听障言语测听、言语沟通训练、以及人机交互中语音信息的感知和理解，提供必要的理论基础和关键技术，具有广泛的应用前景。
基于深度学习的手绘草图图像检索方法研究	类草图;深度学习;手绘草图;图像检索;关联匹配	在传统的图像检索领域，基于关键词的检索需要大量有效的图像标签，而基于内容的检索则需要用户已有相似的图像样例，这些都不利于检索应用的有效进行。随着手持触屏设备的普及，手绘草图作为图像检索的输入变得越来越有实用价值。本项目研究通过手绘草图检索海量自然图像的方法，主要内容包括（1）研究自然图像与草图之间视觉差异的转换方法，从而形成针对图像的类草图自动生成机制；（2）采用深度学习的机制，研究针对手绘草图与自然图像类草图同时适用的融合多模态属性信息源的深度高可区分特征表示；（3）研究涵盖局部到全局的层次化相似性评估架构，从而形成精准的深度关联匹配度量机制；以及（4）研究检索结果的评价模式，以形成有效的相关图像判别与优选机制。通过本项目的研究，预期将在一定程度上揭示手绘图案与自然图像之间的深层次关联，从而从计算机科学的角度为理解人脑的视觉抽象机制提供一定的理论依据，并研发完成一个实用的检索系统原型。
基于结构信息的神经网络机器翻译研究	神经网络机器翻译;机器翻译;结构信息;句法分析;基于句法的机器翻译	神经网络机器翻译以大规模参数来建模翻译的整个过程，是近年来流行的研究方向。当前的神经网络研究中主要使用基于单词序列的端到端模型对源语言进行建模和目标语言进行生成。项目组认为，上述基于单词序列的模型虽然已有很强的学习能力，但是忽略了源端和目标端的结构信息，从而限制了神经网络机器翻译系统的进一步提升。为此，项目组提出以组块、依存关系、短语结构等常见的基于语言学的结构信息为例，研究基于结构信息的神经网络机器翻译。具体而言，本项目的研究内容包括基于组块、句法等多层次的语言结构信息进行源端的编码表示，在目标端解码生成和源端目标端对应等多阶段对结构信息的协同利用，以及结合外部分析工具和模型隐变量自动学习的多来源结构信息获取方法。从而从结构信息的编码表示、协同利用以及获取学习三个角度，推动神经网络机器翻译研究的发展。
基于字依存的中文精细结构标注及其学习算法研究	半监督学习;非监督学习;依存结构学习;字依存	中文信息处理的基础问题是确定句子层的基本结构信息，包括的处理任务从词的切分开始直至确定句法语义成分。本项目将重点解决目前中文信息处理中的两个关键性的基础问题，一是如何有效而弹性地定义中文句子的基础结构，特别是能够有效涵盖包括词法层在内的精细结构信息；二是如何有效率地学习这些基础结构信息，同时有效地提高句子一级的学习性能。主要研究内容包括：1）在语言学理论的指导下，研究基本的字依存树定义方法，探索一种具有较少的争议性以及符合语言学直觉的中文基础结构关系的表示方法；2）在研究现有的基于整个句子层面的机器学习框架的基础上，探索既能有效的实现特征表达同时又能高效的学习框架和新的学习模型，以更好地完成依存关系及其派生出来的各种结构化信息学习，同时能够在实用性环境下提升整句学习的性能；为了充分利用有限的学习资源，探索新的半监督度量方法，以便有效地降低标注的人力成本同时进一步地改进学习性能。
基于元信息关联网络的半结构短文本主题语义建模研究	半结构短文本;群体智能;概率主题模型;语义约束	在面向互动的Web2.0时代，富含价值的短文本是最重要的信息载体之一。与短文本频繁共生的元信息是加速信息流动的标配，为短文本带来重要的结构和共识语义网络关联信息。目前的短文本语义模型侧重考虑扁平内容，而未能充分利用这种群智语义信息，以致对短文本的复杂变化非常敏感。本课题拟综合考虑元信息关联网络和文本内容，在概率主题模型中引入网络模型思想解决半结构化短文本的主题语义建模问题。研究内容包括：1.针对特征稀疏，基于元信息网络构建主题模型，利用元信息网络中语义路径关联相关但未共现的文本；2.针对语义松散，研究概率框架下非独立特征的约束语义学习方法，约束元信息和文本主题潜在结构；3.针对语言高噪，学习元信息稳定核心网络，降低群智信息中的结构先验噪音；4.通过知识访问应用任务验证其有效性。研究成果将为低成本的群智高效利用提供策略，极大提升计算机自动处理半结构短文本的能力，为广泛的知识访问奠定基础。
流式文档排版格式的智能化分析与优化方法	自动化排版;文档信息处理;文档语义分析;文档理解;文档格式	流式文档因其用途广、信息量大、价值高，是一类重要的数据资源。本项目针对流式文档格式优化的要求，探索智能化的文档语义分析方法。试图借鉴自然语言处理和机器学习的研究方法，理解排版元素所表达的语义，综合利用流式文档中蕴含的低层格式信息、文本特征和结构特征，构建统计模型和规则，识别文档的逻辑构件和整体结构，从而为文档排版格式检验和格式重排等关键应用奠定基础。本项目重点研究文档排版规则的构造方法、基于本体的文档构件划分方法、基于机器学习的文档构件识别方法、文档语义的层次化分析方法以及基础语料库建设。主要创新之处是，以流式文档的排版元素为研究对象，研究流式文档的语义，以扩展文本理解的范围；信息提取中充分发挥流式文档的优势，可弥补传统方法的不足；采用分层的语义分析方法，可降低构件的领域相关度，简化排版规则的描述。本项目对于规范文档的格式、合理展现文档，高效利用文档，发挥文档大数据的作用具有重要意义。
引入涉身认知机制的汉语隐喻计算模型及其实现	相似点;语境;隐喻理解;自然语言理解;涉身认知	隐喻既是一种普遍存在的修辞方法，又是一种基本的认知方式。隐喻的计算理解是自然语言处理领域亟需解决的重要问题。现有的隐喻计算模型主要存在以下三个问题：缺乏从涉身认知机制入手的知识表示理论；缺乏语境信息的有效利用；没有考虑隐喻相似点的动态选择与学习机制。本项目以自然语言处理为背景，全面整合现有工作基础，从语境信息的有效利用出发，提出并论证一个融合隐喻涉身认知机制、利用语境信息的汉语隐喻相似点选择方法，并给出算法实现。研究内容包括：①基于本体论方法，建立一种引入涉身认知机制的隐喻知识表示理论；②基于语料库统计方法和认知逻辑学，提出隐喻理解过程中语境信息的表征与利用方法；③基于知识表示方法和语境信息，提出一种利用语境信息的汉语隐喻相似点动态选择方法；④设计和实现一个汉语隐喻认知计算实验平台等。预计本项目的研究成果可用于改进现有自然语言理解系统，如人机对话、智能检索和机器翻译等。
汉语篇章连贯性分析计算模型研究	计算模型;句子衔接方式;篇章修辞关系;自然语言理解;篇章连贯性	篇章连贯性是语篇理解的基础。目前，相关研究刚刚起步，特别是对篇章中句子间的衔接方式以及修辞关系等相关文献还比较少见。然而，篇章中句子间的衔接方式和修辞关系是连贯性机制中的核心问题，同时也是难点所在。本项目将结合汉语自身的特点和规律，从以下三个方面开展汉语篇章连贯性分析的计算模型研究：1）研究基于句子间衔接方式的篇章连贯性计算模型，通过计算相邻句子中主位和述位的相似度来刻画篇章连贯性，同时融入更多的世界知识信息。2)研究基于句子间修辞关系的篇章连贯性计算模型，通过融合句子间实体和事件的因果、并列、转折和解说等修辞关系来刻画篇章的连贯性。3）最后利用联合学习机制将篇章中句子间的衔接方式和修辞关系加以融合，建立统一的汉语篇章连贯性检测平台。本项目开展的研究工作对于推进汉语篇章连贯性分析的研究，推动计算语言学研究和汉语信息技术的发展具有理论意义和应用价值。
基于叙事模式分析的无监督新闻事件语义抽取研究	无监督新闻事件语义要素抽取;核心事件识别;叙事模式分析;多媒体事件语义;事件模板生成	新闻事件语义抽取是信息抽取研究中的热点问题之一，是大规模实时新闻数据管理研究中的关键一环。本课题针对传统新闻事件抽取工作对于人工标注数据的依赖问题提出建立一种针对新闻事件语义要素的自动分析模型，并尝试借助概率统计方法将多媒体语义信息融入到新闻语义要素中。贯穿本课题的一个中心思想是如何减少人工参与，更多地利用新闻资源庞大的数据规模来挖掘新闻事件的叙事模式，进而抽取核心事件的语义要素。本课题的主要研究内容包含以下四个方面：基于叙事模式的新闻事件分析研究、基于事件语义链的核心新闻事件识别研究、无监督新闻事件语义要素抽取研究以及针对多媒体新闻语义要素融合的研究。本项目通过对新闻进行事件语义层次上的重构实现对实时新闻数据的自动事件语义要素抽取，为自动构建知识库、基于事件的信息检索等高级应用打下坚实基础。
语料标注标准的自动迁移研究	语料库;标注标准;迁移	人工标注语料库是自然语言处理统计建模的主要知识源。语料库的构建通常需要语言学工作者付出大量的劳动，昂贵且耗时。然而对许多语言来说，却存在着严重的资源浪费现象，即同一自然语言处理任务存在着多个不同标注标准的人工语料库。因此，提出一种自动化的融合或转换算法，既能将不同标注标准的语料库知识融合起来，又能将语料库从一种标注标准转为另一种标准，从理论和实践角度都具有重要的意义。该问题可形式化为标注标准迁移问题，本提案为标注标准迁移提出一种高效且通用的迁移策略，用于将不同标注标准的知识融合起来（标准融合）或将一种标注标准的知识转换为另一种标准（标准转换）。我们设计出判别式的统计模型，以自动地学习不同标注标准之间的融合和转换规律。该工作既可以整合不同语料库以搭建更高精度的自然语言处理分析器，又能够为语言分析和语料库构建提供统计层面的启示，最终有助于推动整个统计自然语言处理的发展，更好地为社会服务。
读者视角的跨领域隐式情感分析理论及关键技术研究	情感分析;跨领域情感;观点挖掘;隐式情感;舆情分析	互联网蕴含了众多用户交流的观点与情感，从中分析读者用户的隐式情感表达在挖掘公众兴趣与需求，了解社会发展动态，提高服务质量等方面都非常重要。但对于数据分布不一致的跨领域文本，词形相似的语句或文档可能引发读者不同甚至对立的情感反馈，因此给精准地分析其隐式情感带来了极大的挑战。本项目将用句子、篇章及组合语义分析方法，重点研究如下内容：1）设计句子层的规范化与自动标注方案，以补充跨领域隐式情感分析训练数据集；2）建立篇章层的语义分析模型，实现对跨领域隐式情感的有效抽取；3）提出基于多层组合语义的分类算法，以提升跨领域隐式情感分类的精准度。研究成果不仅将解决隐式情感标注的领域及句子语义不足、跨领域的隐式情感抽取及分类不准等研究难题，还能为开发一个具有跨领域隐式情感标注、抽取及分类功能的实用系统奠定基础。
面向微博公共事件的反向社会情绪识别及演化分析研究	情感分析;反向社会情绪;信息抽取;语义关联;微博	社会转型期的社会矛盾容易在微博上引起公众的强烈互动和情绪感知，当公共事件的负面情绪形成群体效应时，会引发反向社会情绪。反向社会情绪是一种与社会发展和社会需要相背离的、严重影响社会和谐稳定的情绪状态。已有工作仅从宏观思辩视角研究反向社会情绪，本项目拟从信息处理的视角量化评估社会情绪，并将反向社会情绪限定为公共事件在微博上呈现出与官方媒体情绪基调明显相异的社会情绪。以公共事件在官方媒体和微博上的报道及其评论为研究对象，研究内容包括：(1)以信息抽取、语义关联技术为基础，研究公共事件社会情绪的表示与评估方法；(2)以官方报道与微博评论的社会情绪差异为基础，研究反向社会情绪自动识别方法；(3)以时间序列单位时间窗口内社会情绪的频率分布差为观测值，研究基于隐半马尔可夫模型的反向社会情绪演化模型。研究成果有望为政府管理部门及时发现和预警反向社会情绪提供支持，也将拓展微博公共事件与社会情绪研究的范畴。
基于无监督知识提取和多关系表示学习的自动问答关键技术研究	自动问答;领域知识表示;实体关系抽取;机器学习	面向海量领域文本的自动问答技术是当前人工智能和大数据应用的一个重要分支，主要难点是如何提取海量的领域文本知识以及怎样理解用户提出的问题。本项目旨在实现具有无监督知识学习能力和问句多关系语义表征的自动问答技术。主要包括：1）通过构建神经稀疏主题模型，结合关系指称先验信息，无监督地提取实体关系，生成作为自动问答答案备选的知识。2）考虑问句的多关系推断路径，提出不确定性多关系翻译表示模型TransGP，然后结合领域文本构建实体标注词汇共现图，生成问句的上下文信息，设计基于双向LSTM以及注意力机制的神经网络，得到多关系问句的嵌入表示。3）构建基于实体优先级的EP-K-D树的答案搜索模型，结合基于神经网络的最短路径方法MRSP，生成较低计算复杂度的答案实体关系子图，并概括为自然语言描述语句。研究成果可有效减少自动问答对已有知识的依赖，为用户提供高效准确的问答服务，并极大地扩展自动问答的应用领域。
面向海量数据流处理的隐式世系跟踪容错方法研究	开销;容错;故障恢复;离群数据;流处理	为了解决传统以MapReduce为代表的批量计算在实时处理方面的瓶颈，流处理方法成为大数据处理的研究热点。然而海量数据流处理过程中的大量状态同步与性能干扰严重影响数据处理，离群数据增大故障误判概率。本项目从流计算开销模型、负载均衡、离群数据发现、故障恢复策略研究面向海量数据流处理容错，1）研究开销敏感弹性负载均衡，建立基于面积的非线性开销敏感模型与基于标准熵的均衡模型，减少高时延抖动，为流处理网络拓扑增加反馈，解决现有流处理网络无法运行迭代递归优化算法的问题；2）研究基于低水位滑动时间窗口的离群数据发现，在低水位滑动时间窗口内有效区分数据延迟到达与数据处理故障，减少故障恢复误判次数；3）研究基于批量状态依赖的并行上游备份故障恢复策略，减少故障恢复时层叠的重复计算、故障恢复状态重构时间和数据重放数量。该项目研究及其成果提高流处理的可用与可靠性，对推动流处理应用具有重要意义。
面向中国英语学习者的英文作文全自动评分及诊断反馈技术研究	分类;诊断反馈;聚类;特征选择;作文离题识别	中国英语学习者人数众多，迫切需要针对中国学生特点的、有效适用于大规模英文作文数据的全自动评分算法，以解决中国现有英语教学和大规模英语考试中英文作文批改量大和难度大的瓶颈问题。现有作文特征提取和自动评分技术主要面向以英语为母语的学生作文，针对中国英语学习者的全自动作文评分及诊断反馈技术的研究成果还不多见。本项目主要进行以下几方面的研究：(1)研究能够呈现中国学生英文写作特点的特征提取算法；(2)针对作文分数具有不平衡分布的特点，研究基于不平衡数据有效分类的作文自动评分算法；(3)研究基于增量聚类的作文自动评分算法；(4)研究基于多文档主题词提取的作文离题识别算法；(5)研究不依赖于大规模作文错误语料库的语法检错及正确推荐算法。研究内容同时将推动中文作文自动评分、小语种作文自动评分以及英语主观题自动评分等相关场景中的应用。
现行蒙古文和标准音单词级对接标准码语料库建设	标准音;现行蒙古文;对接语料库;单词级	（1）广泛搜集已有书面语语料，以人工方式确立蒙古语书面语单词输入键码。单词要达到37000-40000词级,达到目前的最多。（2）设计编制基于UCS和符合国家新标准的蒙古语标准音码位的计算机键盘输入软件。计算机键盘布局要充分考虑目前比较通行的"方正蒙文书版"、"蒙古文WPS Office2002"组合系统等以及其他诸输入系统。（3）采用转换接口的技术来矫正基于不同编码方案，尤其是用户的不规范输入文档。蒙古语标准音和书面语对接转换由计算机来完成，将过滤转变的标准音码最后变为书面语形式输出，这就需要研制蒙古语标准音和书面语对接模块软件。诸输入法形成的数据只需向本系统提供每个字符的码值就可使用本系统的矫正功能，使得系统在不同的输入法中基本畅通使用。（4）建立蒙古语书面语、标准音拼写规则，实现单词级书面语和标准音语料库之间的互相转换。（5）为今后口语化的键盘输入法研制、词组研究积累经验，奠定基础。
面向网络百科的知识抽取研究	信息检索;文本挖掘;自然语言处理;信息抽取;知识工程	在Web2.0的推动下，网络百科作为群体智慧的平台得到了飞速发展，已经成为了一种取代传统印刷版大百科全书的颠覆性创新。网络百科不仅为用户提供了丰富的信息，也为计算机的智能应用系统提供了潜在的大规模的知识。但是，以普通文本为主的网络百科很难被计算系统自动使用，只有结构化的知识库才能被智能系统有效利用。因此，根据信息抽取、网络百科发展现状和面临的挑战，以提高网络信息服务的智能化水平为目标，结合网络百科知识在信息组织和语言表达等方面的特点，开展面向大规模网络百科的知识抽取研究，具有重要的应用价值和科学意义。本项目以维基百科、互动百科和百度百科等网络百科的开放信息为对象，针对信息抽取领域新出现的开放性、适应性和规模性需求，研究开放的、可扩展的、具有较高自动化程度的信息抽取方法，将网络百科中弱结构的文本信息转换成可以被其他智能系统直接利用的结构化的知识，从而推动网络信息的智能处理。
面向聊天机器人的文本情感分析关键技术研究	情感分析;聊天机器人;情感回复生成;意见挖掘;情感原因发现	聊天机器人作为互联网新时代技术的产物，以背后强大的知识库和计算能力为人类提供私人服务和情感慰藉，受到学术界和工业界的广泛关注。虽然目前聊天机器人的各项技术研究取得了一定的进展，但由于情感识别忽视了用户信息和隐式情感、缺乏情感原因发现技术以及情感回复缺少情感和用户信息的融合等问题导致其很难做到真正的善解人意。本项目结合人机对话的特点，针对系统中情感分析技术的缺失，提出了一套适用于聊天机器人的情感分析研究任务，包括情感信息识别、情感原因发现以及情感回复生成三个基本任务，分别对应聊天机器人的情感识别、理解和表达三个情感功能。具体内容包括：基于用户建模的情感分类、基于跨篇章背景知识的隐式情感识别、基于句法表示和强化学习的情感原因发现以及基于情感、原因和用户信息相融合的回复生成技术等。本项目旨在深入研究聊天机器人环境下的各项情感分析技术，完善聊天机器人的智商与情商，使其与用户进行更富人性化的交流。
基于多源异构特征表达的跨媒体问答研究	多媒体计算;跨媒体信息检索;字典学习;问答检索;特征表示	随着互联网海量数据类型愈加丰富，多媒体问答正成为工业界和学术界共同关注的研究重点。传统问答技术主要基于文本数据展开，是一种多模态检索方法，很难直接应用于多媒体问答检索任务。本项目拟采用跨媒体计算基本理论和方法，对多源异构数据学习得到一致表达，进而挖掘其关联模式，从而用户查询语义意图和被检索数据底层特征之间存在的"语义鸿沟"在多媒体问答中实现对不同媒体类型之间的内容跨越。本项目拟基于互联网海量图像数据作为数据对象，通过对多模态数据特征的鲁棒学习，基于弱监督学习的图像目标语义解析和不同粒度层次上的异构特征融合表示开展研究，从而实现更精准的跨媒体问答服务。本项目提出多模态正则化鲁棒字典学习，基于深度多示例学习的图像目标语义解析此外和多粒度异构特征融合的跨媒体问答的研究方案。此外，本项目基于上述研究开发原型系统及开展实证测试，既为媒体大数据提供问答检索平台，又为跨媒体检索发展提供理论和技术支持。
面向业务流程的服务划分，推荐及管理关键技术研究	生命周期管理;服务计算;业务流程;划分;推荐	本课题依托项目组之前在服务计算领域的研究成果，探索从业务流程的角度去研究服务及演化过程，围绕服务与之所处业务流程的关系，开展服务的划分、推荐和治理的研究。通过研究服务组合的历史并采用关联规则挖掘分析服务依存关系，并在此基础上依靠层次分析法逐步抽取服务候选单元。为了将合理划分的服务更好地参与到业务流程中，在关联规则分析的基础上，提出了隐式服务偏好评分方法，利用改进的协同过滤方法实现服务的推荐。同时，进一步研究服务随着业务改变而不断演化的生命周期管理机制，引入可量化的利益相关人分析框架，使得服务始终能够与所涉及的业务流程保持关联性，确保服务始终处与一个合理的粒度。具体研究内容包括：1）基于业务流程的服务划分技术；2）面向业务规则的服务推荐技术；3）基于利益相关者的服务治理技术，并最终搭建一个面向业务流程的服务综合管理原型系统，验证方法和技术的有效性。
融合多网络社区身份的用户话题兴趣建模研究	用户链指;用户兴趣建模;主题模型;社交媒体	随着互联网技术的发展，社交媒体服务在真实生活中的作用日益重要，很多用户同时拥有多个网络社区帐号，即社区身份。针对"同一用户多社区身份"这一趋势，设计有效的跨社区话题兴趣模型成为改善社交媒体服务和用户体验的关键。已有工作主要面向单一社区的兴趣建模，不能充分融入多社区的文本语义信息与用户属性信息，可能具有数据稀疏性和有偏性等问题。本项目深入研究面向多社区身份的用户话题兴趣建模。通过同时刻画链指对自身的特征信息与链指对之间的关联关系，建立基于概率因子图的多帐号联合链指方法，更为精确地解决跨社区链指问题；通过引入实体与实体关系，设计面向多社区身份的话题兴趣主题模型，同时刻画话题跨社区表现形式的多样性、用户多社区身份的兴趣关联性与差异性；在文本信息的基础上，进一步在建立的主题模型中融入用户多社区的属性信息，改进兴趣建摸，加强兴趣归因解释。本项目将有力改善围绕话题兴趣打造的网络应用服务和用户体验。
基于多社会媒体的用户建模技术研究	用户兴趣建模;多视图表示学习;多社会媒体;用户属性预测;社会媒体分析	随着各种各样的社会媒体相继兴起，越来越多的用户同时参与到多个社会媒体当中。这使得用户生成数据逐渐呈现多源异构特点，并逐渐凸显了传统基于单一社会媒体用户建模技术的片面化缺点。本项目旨在研究基于多社会媒体的用户建模技术。针对用户数据数量大、噪音多、多源异构的特点，重点研究基于多社会媒体的用户多视图表示学习技术。基于用户的多视图表示，本项目进而探究基于多社会媒体用户建模研究的核心问题，包括跨社会媒体用户匹配和用户属性预测问题等。其中，针对用户属性预测，本项目首先提出基于多社会媒体的用户单一属性预测算法。算法充分挖掘用户的多模态数据，避免基于单一文本数据的用户属性预测算法的局限性，同时有效解决了非活跃用户数据不完整的问题。其次，考虑到用户复合属性预测所涉及的属性之间存在不同程度的联系，本项目创新地结合多任务学习思想，提出相应的用户复合属性预测算法，从而提高用户属性预测的整体性能。
甲骨文编辑和编码技术研究	甲骨文;编辑;图像特征;编码;算法	本项目以甲骨文字的采集、编辑和编码算法为主要研究方向，提出了基于原始骨片和拓片的甲骨文字采集、编辑的方法，并就其应用技术进行了进一步的分析和研究；依据甲骨文字的文字特征和图像特征，研究了甲骨文字采集过程中的自适应的、有效的、智能的阈值选取方法，对于甲骨文骨片中存的文字字形特征多变、背景变化复杂这一现象，我们提出了文字编辑过程中的智能化的机器学习方法，并对这一方法进行了进一步的探讨；针对甲骨文字编辑过程中的编码技术，提出了基于整体和局部综合特征的编码方法。该算法的研究工作，将有助于推动对甲骨文数字化技术的研究和应用，也有助于推进现代汉字编码技术的研究，促进民族文化的发展以及中外文化交流与传播。
语气挖掘中的领域移植问题研究	信息检索;语气分类;语气挖掘	监督与非监督方法是解决语气分类问题的两种有效办法。监督方法通常具有很高的精度。但监督方法对每个领域都需要大量有标签的训练样本，这就大大制约了它的移植能力。另一方面，非监督方法(比如基于通用语气词典)则不需要训练集，所以说，非监督方法具备一定的移植能力。但是它的精度常常受到限制，难以满足实际需求。因此，研究一种具备移植能力的高精度语气分类方法具有重要的现实意义。为了达到这个目标，我们试图从三个方面来寻求解决方案：监督方法的领域移植模型、监督与非监督方法的融合移植模型、领域词典的自动构建模型。监督方法的领域移植模型的基本思想是通过寻找新旧领域之间的"共性词"，来建立一条旧领域通向新领域的桥梁；监督与非监督方法的融合移植模型的基本思想是充分挖掘非监督方法的移植能力与监督方法的高准确性；领域词典的自动构建模型的基本思想是对每个新领域自动构建一个适合该领域的语气词典。
基于参数估计理论的信息检索风险研究	信息检索;风险控制;参数估计;查询扩展;个性化检索	风险最小化框架和收益-风险框架对信息检索模型的设计产生了广泛和持续的影响，但是对这两种框架下两类风险间的关联性目前仍缺乏形式化分析，例如对两类风险之间何时存在矛盾以及能否同时规避等问题尚未利用解析方法进行深入研究。若两类风险存在矛盾，设计检索模型时常会陷入减小某类风险的同时却加大另一类风险的两难困境，这将阻碍信息检索模型的实质性进展。针对上述问题，本项目将基于参数估计理论（如偏差-方差理论），形式化分析检索模型中相关性估计的两类风险之间的关联性，并研究相关性估计的风险下界，寻找进一步发展信息检索模型的突破口。同时，我们也将运用偏差-方差理论设计检索性能的整体评价指标，使其能够兼顾基于性能均值的传统指标和基于性能方差的风险指标。通过理论分析和实证评价，发展针对不同查询或不同用户的自适应相关性估计方法，并进一步地将这种方法应用于改善信息检索模型（如查询扩展模型和个性化检索模型）的整体性能风险。
支持查询语句复述的概念扩展查询方法研究	信息检索;复述;概念扩展;云模型	目前基于语义的扩展查询已成为研究热点，但存在的主要问题是：概念扩展查询技术先扩展查询词再检索，是从词级层次来扩展查询语句，尚不能从句子摘要层次语义上支持查询语句的复述，也不能从篇章层次语义上消除语义不相关的检索结果，这限制了查询扩展在搜索引擎中的实用化。本项目把自然语言处理领域中复述理论和人工智能领域中云模型理论结合到信息检索领域中的概念扩展查询技术。其研究内容和特色包括：①提出了 "概念的语义指纹"中不确定性特征的获取方法，补充和完善了概念的语义形式化描述；②引入了"句子摘要"语言单元，提出句子摘要级的复述方法，提高了计算机对查询语句的语义理解能力；③提出基于语义指纹的文本检索方法，将"基于语义知识库的方法"和"基于潜在语义分析的方法"有机结合，取长补短。研究成果将不仅有意义于搜索引擎中概念扩展技术的实用化，而且为将来再深入探索支持概念扩展的网络媒体监控技术奠定前期的理论和实现基础。
垃圾邮件过滤的优化目标、建模及顺序回归研究	顺序回归;垃圾邮件过滤;在线顺序逻辑回归学习算法;字节级n元文法;评价指标优化	垃圾邮件过滤是网络信息处理中的重要问题，基于机器学习方法的垃圾邮件过滤技术是目前的研究热点。现有研究一般将过滤问题视为二值分类问题进行解决，存在着模型优化目标和性能评价指标不一致的问题，导致模型优化结果产生偏差，过滤性能受到很大影响。本课题拟通过直接优化评价指标来提升过滤器性能，将垃圾邮件过滤问题转化成排序问题进行建模，探索基于顺序回归学习的垃圾邮件过滤新模型；拟提出在线顺序逻辑回归学习算法，解决顺序回归学习中的邮件得分偏移问题；综合应用TONE算法和重采样技术，拟提出参数权重更新算法，解决顺序回归学习中在线调整模型参数时的处理速度问题，满足垃圾邮件实时过滤的要求；拟提出基于字节级n元文法的特征提取方法，解决垃圾邮件信息伪装和隐藏的问题。本课题力争在垃圾邮件过滤的理论和方法上有所创新和突破，旨在大幅提高垃圾邮件过滤的性能，推动信息过滤技术的发展。本课题的研究具有重要的学术意义和实践意义。
基于句法结构和语义信息的指代消解研究	单文档指代消解;中心理论;待消解项识别;跨文档指代消解	指代消解是自然语言处理的一个研究热点，在自然语言的篇章理解中举足轻重，也是信息融合的基础。本项目在中心理论的指导下，从句法和语义两个层面重点解决目前困扰指代消解研究的三个关键问题：一是如何获取和利用有效的结构化句法信息；二是如何更好地利用语义信息；三是如何在单文档指代消解研究的基础上进行跨文档指代消解的研究。本项目首先提出了基于中心理论的动态指代解析树，利用树核函数直接计算动态树之间的相似度，有效集成各种结构化句法信息，在此基础上探讨了待消解项识别及其在指代消解中的作用；同时，以语义角色为载体，首次将中心理论从语法层拓展到语义层，深入探索了句中不同谓词的各种语义角色在中心理论中的作用，从语法和语义两个层面来提升指代消解的性能；最后，以单文本指代消解为基础，提出基于实体指代链的聚类和相似度计算方法，有效刻画数据集所固有的自然聚类簇结构，实现跨文本的指代消解。
基于数据驱动的中文自然语言生成关键技术研究	上下文无关语法;噪声信道模型;自然语言生成;概念短语层级树	如何让计算机生成人类可以理解的语言，是一个重要的科学问题，同时也是实现人机自然交互、机器翻译、文本摘要等任务的重要技术手段。本课题以中文自然语言生成为具体任务，探索语言理解过程中的形式化理论及统计学习方法在语言生成中的应用，为提升现有语言生成技术的可重用性及鲁棒性、降低系统开发代价寻求有效途径。研究内容包括：1.基于上下文无关语法的生成空间描述，借鉴语言理解中的句法分析方法，自动构建以语言生成为目的的概念短语层级树；2.基于噪声信道模型的生成决策规划，进行深层结构及表层结构的统一实现，充分利用基于知识驱动的语言模型及基于动态规划的解码算法的概率特性及领域无关特性，提高系统的可重用性及鲁棒性；3.针对中文自然语言生成系统的评测数据及评测技术研究，研制并开放一套用于汉语语言生成技术评测的标准数据及基础工具，为汉语语言生成技术提供科学一致的评测方法。
汉语语义选择限制知识自动获取及其应用研究	词语相似度;隐喻识别;语义选择限制;知识获取;机器学习	语义选择限制刻画谓语对论元的语义选择倾向，是一种重要的词汇语义知识，对句法分析、语义角色标注、词义消歧、指代消解、隐喻计算等自然语言处理任务都有重要作用。手工构建的语义选择限制知识库不能很好地满足大规模文本处理的需要，本项目研究汉语语义选择限制知识的自动获取及应用，内容包括：（1）知识获取方面，提出结合汉语特色的语义选择限制获取模型，把汉语构词与汉字部首等特点与语料库分布、词典知识结合起来计算论元相似度，基于多知识源构建基础搭配库，研制标准测试集对模型进行评价。（2）知识表示方面，针对词语层面的语义选择限制知识可理解性差的缺点，通过语义类映射将其转化为语义类层面的知识，从而提高知识的可理解性，构建语义选择限制知识库并总结语言规律。（3）知识应用方面，把自动获取的语义选择限制知识融入机器学习框架进行隐喻识别，在大规模隐喻识别基础上对隐喻与语义选择限制之间的关系进行定量分析。
社交媒体中的多样性检索研究	多样性检索;微博检索;社交媒体	传统网页检索中，查询词的歧义与不确定性使得检索结果需要多样化来满足不同用户的需求。社交媒体检索中查询词更短，同样需要对检索结果进行多样化。本项目通过有机结合多样性检索与社交媒体分析，从面向社交媒体多样性检索的查询意图建模方法、面向社交媒体数据特征的文本表示方法、适用于社交媒体数据冗余处理方法、基于社交媒体话题（事件）演变与多样性检索之间关系分析和社交媒体本身特点与多样性检索之间关系分析等五个方面开展研究，拟提出结合社交媒体中热点事件子话题信息抽取技术、融合语义相关性和社交媒体特征的文本质量度量模型和数据冗余处理方法、结合社交媒体特征的多样性检索模型构造方法，力求在用户生成内容表示模型、社交媒体话题结构与话题演变、社交媒体特征与信息检索之间的内在联系等关键科学问题的研究中获得进展和突破。本项目将形成面向社交媒体多样性检索的一系列方法和关键技术，为深化信息检索与社交媒体分析提供支持。
基于交互行为感知的MOOC学习导引机制研究	学习导引;慕课;远程教育;网络教学;行为感知	针对MOOC的高师生比和高自由度带来的学习过程干预不足的问题，在对学习者行为进行测量分析的基础上，从宏观和微观两个层面建立自动学习导引机制。宏观层面上，利用重叠社区发现机制，建立基于兴趣相似度的学习共同体，组织学习者开展如互助问答等协同学习活动；挖掘课程间的继起关系，构建合理的课程知识拓扑，给予学习者恰当的学习路径导引。微观层面上，通过对优质学习者行为模式的挖掘，标注正确学习行为和关键知识点，对学习者行为进行提示，矫正用户学习习惯；聚合多个知识源构建知识图谱并融入视频学习过程，避免频繁在视频学习与资料查阅间切换思路，专注投入预定学习轨道。最后，通过大规模仿真和真实环境下的部署测试，对导引机制的效能进行评估，为正确干预学习过程，提高学习效果提供理论和实践依据。
基于用户言语行为的微博内容挖掘研究	用户影响力分析和建模;言语行为识别;社会网络;微博挖掘;基于信息抽取的自动文摘	微博是人们行使各种交际活动的社会网络。本项目根据语言学的"言语行为"理论，提出以言语行为为线索，探索微博用户的交际模式和交际规律，并以此为基础进行相应的话题内容抽取提炼和用户影响关系研究。项目主要涉及三方面的技术。首先，由于言语行为不能从微博数据中直接获取，本项目致力于内容导向的微博用户言语行为识别。针对微博文本的高噪音度和人工标注语料的匮乏，我们提出适合微博特点的特征提取方式和依赖少量人工标注语料的半监督学习方法。其次，本项目致力于基于群体言语行为的信息提取和微博上的自动摘要，开发不依赖除噪过程的关键词提取和基于模板的概括式摘要技术。再次，本项目致力于基于个体言语行为的用户关系网络的建模，根据个人用户言语行为的变化和与周围用户言语行为的关联建立概率模型，从而识别有影响力的用户群体。这些研究内容具有理论和实践上的重要意义。针对某些关键技术的前期研究结果表明，本项目是切实可行的。
网络信息检索用户行为可靠性分析关键技术研究	查询需求;用户行为可靠性;网络信息检索;用户行为分析;检索日志分析	用户行为分析是当前信息检索研究和应用中的一个重要方向。当前研究工作基础是"群体智慧假设"（高频查询中大多数用户的一致行为是可靠的）和"点击相关性假设"（被用户点击的结果与查询相关）。它们随着研究的深入已经不能满足要求：1、无法研究互联网检索中占独立同查询总数80%以上的大量非高频查询行为；2、点击行为与相关性并不完全一致，现有工作缺乏对不同行为的有效性和重要性的区分。因此，针对用户行为可靠性的研究由于其必要性及基础性地位开始受到国内外研究和产业界的重视。本项目基于大规模用户日志研究网络信息检索的用户行为可靠性。研究从单次查询点击、独立检索会话（session）、及用户三个层次展开，分析用户检索交互行为模式，特别是深入研究非高频的查询及点击行为，建立多层用户点击行为可靠性模型，构建完整的用户行为可靠性分析框架，并提出有效的融合方法，为信息检索用户行为分析及相关应用研究提供重要基础。
基于任务的跨领域异质可解释的推荐方法研究	用户画像与建模;协同过滤;异质推荐;个性化推荐;可解释的推荐	个性化推荐技术能够挖掘和满足用户需求及潜在兴趣并通过主动推荐来吸引用户的访问点击，近年来在研究界与产业界都受到持续增长地关注，并展现出巨大的应用前景。但当前的个性化推荐研究及应用存在两个主要缺陷：一是多局限于领域内、甚至网站内的同质性结果推荐，无法满足用户完整的任务需求；二是大多数情况下无法给出推荐理由，使得推荐结果对用户缺乏可信度和吸引力，影响了推荐的效果。针对这两个核心问题，本项目拟开展基于任务的跨领域、异质、可解释的推荐方法研究。课题将依托通用搜索引擎及浏览器用户行为信息，融合网络中不同网站上的用户产生内容，1. 研究面向推荐问题的跨领域异质数据表示与整合；2. 构建用户画像，建立用户潜在需求与偏好模型；3. 设计可扩展性强、计算效率高的并行化跨领域异质推荐框架；4. 提出可解释的个性化推荐方法，并设计实现基于任务的推荐系统验证平台。最终将实现个性化推荐技术在新的理论和方法上的突破。
面向Web话题的多文档文摘研究	自动文摘;动态演化性;多元性;Web话题;话题分析	作为一种能从海量信息中快速、准确地获取有用信息的手段，自动文摘技术越来越引起人们的重视，尤其是如何从海量的Web话题信息中提取文摘内容的多文档文摘技术作为一个新的研究点，引起了研究界和产业界的广泛关注。Web话题带有内容多元性、动态演化性等特点，由此给Web话题的多文档文摘方法的研究带来了众多的挑战。面对Web话题分析的挑战，本课题在Web话题的特点分析的基础，从面向话题的多文档文摘方法的研究入手，分别从文摘计算粒度、话题表示与模型优化两方面开展面向话题的多文档文摘的研究，同时针对面向Web话题动态演化性的文摘需求，开展了动态多文档文摘的研究。本课题内容立足于研究Web2.0环境下面面向话题的自动文摘技术，既有重要的研究价值，又有广阔的应用前景，将为网络舆情分析、信息内容安全等重要应用提供关键技术支持。
基于概念拓扑结构的大规模协作式标签视频检索研究	概念检测;视频检索;协作式标签;概念网络;大规模	随着视频处理规模的急剧增长，依赖于小规模专家标注数据集的传统视频检索方法已不能满足大规模数据环境，迫切需要寻求尽可能减少或避免专家人工干预、利用样本相对多样化的大规模视频数据集、并且能够同时处理大量视频概念的新方法。针对上述需求，本项目提出了一种基于概念拓扑结构的大规模协作式标签视频检索方法；通过对协作式标签信息进行优化，并基于统一化的概念相似度度量建立概念网络，最终基于概念拓扑结构来联合式地训练多个概念分类器。该方法完全避免了传统方法所依赖的专家人工干预过程，能够自动地获得成千上万的具有较强泛化能力的概念分类器，从而将为新的多媒体应用提供一个很好的基础性平台。
基于用户标签软约束话题模型的微博资源建模研究	话题模型;信息检索;微博资源;用户标签	用户使用微博的重要原因是信息搜集与分享。分享的消息不仅可以包括文字描述，也可以加入外部引用(URL)。我们将出现在微博消息中的URL称为微博资源。微博资源的重要性体现在：(1) 数据量大；(2) 时效性好；(3) 社会影响力大；(4)内容质量高。从微博资源中进行有效的信息获取是用户的自然需求，也是许多系统应用的基础。虽然微博资源广受工业界关注，但在学术界，相关研究刚刚起步。.本课题拟对微博资源进行系统性研究，通过全面分析微博资源的统计特性，构建微博资源内容模型，利用微博消息文本、用户标签提高对网页内容的理解。课题计划使用话题模型来建模消息、资源、用户标签三者的关系，并建立话题与用户标签的直接联系；针对用户标签特点，提出用户标签对话题模型的软约束假设，即要求文档话题与关联的标签话题有关系，但不完全限定在关联的标签话题内。所提模型可以广泛应用在推荐任务以及检索任务中。..
大规模社会网络的分析技术研究	相似性;社会网络;权威性;社会化媒体;团体发现	本申请以微博媒体为例，研究面向大规模社会网络的分析技术。针对微博媒体的两种实体（用户、资源）的表示问题，定义了一种基于XML格式的实体描述文件，然后在微博文档的特征向量表示基础上，运用LDA模型提取用户的兴趣主题，生成用户的主题向量；在计算微博实体之间的关系强度方面，提出了一种基于内容相似性和链接相似性相结合的微博实体相似性计算方法；也提出了利用子空间学习算法来预测实体之间的关系强度的方法；在微博的社会网络挖掘方面，提出了基于可重启动的随机漫步算法（Random Walks with Restarts，RWR）的微博实体的权威性计算方法，用于信息的推荐、搜索；研究基于GN算法的微博社会网络的团体发现算法。本申请的研究成果具有重要的科学意义和应用价值，一方面，它支持多样性的社会化媒体的信息聚合、推荐和搜索等应用；另一方面，它也为新兴的计算社会学的理论研究提供重要参考。
融合用户、上下文和系统：基于量子理论的信息检索模型研究	上下文;多元表示;基于用户的检索系统性能评价;信息检索模型;动态和多维相关性	本项目将研究基于量子理论框架的新型信息检索模型和方法论，用以融合复杂信息对象的多元表达，复杂信息需求和多维度相关性的刻画，以及上下文情境，用户的认知状态和决策生成（例如，判定哪些信息是相关的以及在何种意义上是相关的）。我们的理论灵感源于认知科学、人工智能和决策支持等相关领域最近迅速发展的"类量子"理论模型，尤其是其对观察者的中心位置的强调以及对心智与实在之间交互关系的建模，可自然解释人们进行概念联想、评价可能性（主观概率）和产生决策的思维过程。我们将发展有效整合于量子范式下的复杂信息对象、复杂信息需求和多维度相关性的多元表示，动态上下文多元表达和演化模型和决策函数（基于量子概率、量子叠加和干涉）。在此基础上，我们将实现一个初步原型系统，测试量子范式作为未来以用户为中心的自适应性信息获取系统的建模原则的可行性。最终的系统有效性将通过一系列基于状态迁移的仿真用户实验和真实用户满意度评价来验证。
基于概率主题模型的词义计算及应用研究	词义消歧;词义计算;词相似;概率主题模型;新义发现	词义计算是计算语言学研究领域中最基础和最重要的问题之一，目前该研究面临三个重要难题：（1）已有词义消歧技术主要利用句子级和文档级信息，忽略了主题级信息的挖掘和利用。（2）基于语料库的词相似计算均在词形层面上进行，无法获得多义词在词义层面的相似词。（3）新词新义问题日益突出。研究发现，以LDA为代表的概率主题模型利用统计方法挖掘出语料中隐藏的主题，这些主题和文档、词、词义存在密切关系。据此，本项目拟开展如下研究：第一，提出"一个主题一个义项"假设，揭示主题、词、词义三者之间的关系。进一步地，设计并实现概率词义主题模型（sLDA），在获得更明确主题的情况下，更准确地完成全文词义消歧。第二，引入主题敏感词概念，使词义层面的相似度计算成为可能。第三，有效利用词在语料库上的时空分布信息，研究基于主题的新义发现算法。本项目将进一步推进词义计算研究的发展，并对信息检索等应用提供有效的技术支持。
面向互联网大数据的用户兴趣挖掘及预测研究	用户兴趣挖掘;评分预测;用户兴趣预测;推荐系统;主题情感挖掘	互联网应用积累了海量的丰富数据，包括人的属性、物的属性、人与人的社交关系、人对物的互动关系。例如，用户浏览新闻、购买商品、签到旅游景点等，并且通过文本评论分享自己的经历。本项目拟利用这些数据，挖掘和预测用户的兴趣，这具有重要的商业、广告和人文价值。本项目将研究以下内容：1)建立基于社区、地区、时间和互动类型的主题情感模型，以挖掘用户对事物的细粒度兴趣。2)通过融合矩阵分解和基于核函数的多属性非线性回归，提出新的混合评分模型，以预测用户对事物的总体评分。3)建立主题情感挖掘模型和混合评分预测模型的联系，即通过主题情感模型估计历史用户-事物评分矩阵，作为混合评分预测模型的输入，以解决互联网应用中历史评分矩阵缺乏问题，从而提高混合评分预测模型的可用性。4)利用互联网大数据和用户实验数据，评价本项目提出的模型的效果。本项目开发的用户兴趣挖掘及预测技术，可应用于推荐系统，为大众和商家带来便利和利益。
面向社会舆情的中文事件抽取及其可信度计算的研究	社会舆情;中文事件抽取;联合模型;事件推理;可信度计算	互联网为社会公众提供了前所未有的舆情表达新手段，如何从海量舆情信息中获取有价值内容成为目前急待解决的一大挑战。事件作为表述社会舆情语义的基本要素，从海量文本中抽取事件并计算其可信度是快速、及时、高效地分析社会舆情的基础。本项目将在话题结构理论和语义一致性理论的指导下，根据中文所特有的语言特点，研究面向社会舆情的中文事件抽取及其可信度计算方法，重点解决其信息缺失问题、全局优化问题和可信度计算问题。主要特色如下：1）基于话题结构理论，提出了新颖的跨事件、跨实体和跨角色的事件推理方法，解决中文事件缺省问题；2）基于语义一致性理论，提出了根据事件间内在关系进行事件抽取的联合学习模型，解决全局优化问题；3）基于篇章结构理论和事件间的关联性，提出了一个利用贝叶斯网络进行推理的事件可信度计算模型。本项目对于探索人类语言理解的认知机理，推动面向社会舆情分析的语义知识获取方法的发展，具有重要的科学意义。
基于多源数据的学生需求发现及信息资源实时推荐机制研究	网络用户行为分析;多源数据;实时推荐;用户兴趣模型;深度学习	在泛互联网时代，大学校园形成一个独立的网络社区。与电子商务网站相比，该网络社区记录了社区内用户的全部上网行为信息。面对校园网络社区内庞大的流量数据和各种应用数据， 如何获取学生的动态上网兴趣模型并帮助不同知识背景、不同年级和不同兴趣爱好的学生对其需求的信息资源进行过滤和挖掘、实现信息资源精准推荐是迫需研究的一个问题。基于该问题，本项目利用校园网络社区中的多源数据，对学生信息资源需求进行动态分析和建模；研究有效的网络信息资源影响力评价机制，建立资源与需求之间的匹配；利用深度学习策略，设计实时的精准推荐模型，满足学生对信息资源的需求。在此基础上，基于已有的Hadoop分布式数据处理平台以及TensorFlow深度学习开源框架，建立个性化服务模型，实现对特定信息资源需求群体的高质量精准推荐服务。
基于深度学习的抄袭检测研究	语义匹配;深度学习;生成对抗网络;抄袭检测;序列标注	本课题开展基于深度学习的抄袭检测研究。针对抄袭语料匮乏问题，提出了基于生成对抗网络的抄袭句自动生成模型。该模型利用变分自编码将离散的文本映射到连续的空间，扫除了生成对抗网络在自然语言处理领域应用的主要障碍，为句子的自动生成提供了新的方法。对于释义抄袭识别问题，针对自然语言（句子）多粒度特性，利用卷积神经网络建模语言的多粒度表示，并使用张量神经网络建模相同粒度下句子间的交互关系，形成基于多粒度张量神经网络的文本语义相似度的新建模方法。针对源检索局部匹配敏感特性，以连续卷积、连续池化为手段，提出了局部语义匹配卷积神经网络，解决了源检索的建模问题，并为具有相同性质的信息检索提供解决思路。分析抄袭检测文本对齐本质，探索了传统方法和深度学习融合的建模方法，融合了深度学习语义相似度计算优势和2D CRF擅长多对多对齐的优势，为此类问题的解决提供了范例。
汉字书写质量的自动评测技术及其应用研究	形式化描述;自动评测;汉字书写;字形匹配	汉字书写质量评测是计算机辅助汉字书写教学的重要应用，该技术是汉字教学、字形计算、模式识别等领域尚未很好解决的重点难题之一。汉字书写质量评测与汉字识别在根本任务、对象、方法上有本质不同。现有研究成果不能让学习者在无人值守的情况下完成汉字书写质量的自动评测和意见反馈。本项目利用手写输入设备采集包括书写过程在内的手写汉字信息，以汉字教学中的标准汉字和手写汉字为研究对象，对汉字书写的正确性和美观性评测进行基础理论和应用研究。主要内容包括：面向汉字书写质量评测的汉字字形形式化描述方法及汉字特征提取方法；与汉字书写质量评测相关的一系列自动化算法；以及汉字书写质量评测结果的可视化反馈技术等。本项目旨在通过对汉字书写的细节特征和宏观特征的全面、自动评测，来改进目前传统的汉字书写教学方法，为HSK、汉字应用水平测试等各种应用场合提供技术支持，更能够为汉语国际推广起到推动作用。
结合领域知识的端到端论辩挖掘方法研究	论辩挖掘;文本表示;语义理解	伴随着人工智能技术的发展，对互联网上用户产生文本进行深度理解成为当今研究的一个热门话题。论辩挖掘（Argumentation mining）面向包含用户针对特定话题相关看法的论辩性文本展开研究，旨在对不规则的论辩性文本进行论点信息的提取和分析，以产生结构化输出，从而实现对用户逻辑推导过程的深入挖掘。相关的技术可以为社会、政治和科学领域的决策者以及研究人员提供自动化的论辩性文本分析工具，为企业市场营销创造新的前景。本课题针对当今论辩挖掘研究的三个局限性（论点表示中语言特性的缺失、模型中领域知识的缺失以及模型中子任务关联性的缺失），研究结合语义和结构信息的论点表示方法，结合领域知识的端到端论辩挖掘模型以及多领域的语料集合的构建。相关的研究内容充分考虑算法理论与应用领域的对接，能够对相关领域的论辩性文本分析应用的开发提供直接的算法和技术支持。
基于神经网络的领域自适应中文序列标注方法的研究	中文序列标注;神经网络;中文分词;领域自适应;词性标注	序列标注问题是自然语言处理常见的问题之一。本课题拟针对中文序列标注任务中的分词任务(字序列标注)和词性标注任务（字词序列标注）展开研究。现有常用分词和词性标注工具在拥有大量标注数据的新闻领域有着较高的准确率，但将上述工具应用至非新闻文本，系统性能发生骤降。例如哈工大LTP分词器，在新闻语料的F1值为91.2%，但在专利文本为87.1%。上述现象的产生是由于用于训练系统的始源域数据（新闻）与测试的目标域数据（专利）差异较大。本课题拟采用基于深度神经网络的领域自适应算法解决在中文序列标注过程中由于数据领域不同带来的系统性能骤降的问题。实验中，以Chinese Treebank语料作为始源域数据，专利、小说、微博等语料作为目标域数据，对自适应中文序列标注系统进行测试。本课题建立的领域自适应分词和词性标注系统，具有较强的新词发现能力，可应用于专业文本处理系理系统，诸如科技文献内容分析系统。
基于结构化学习的语义角色标注方法研究	语义角色标注;语言学知识;结构化学习;机器学习;谓词论元结构	结构化学习是机器学习领域一种新的学习算法。它处理的主要是那些输出有一定结构的问题。语言是一套有结构的符号系统，结构的特点几乎体现在自然语言处理的各个方面。本项目研究基于结构化学习的语义角色标注方法。将在语义角色标注领域展开结构化机器学习算法的研究。具体地，将研究如何利用传统语言学知识，准确地把握作为语义角色标注问题输出的谓词论元结构，充分地挖掘论元之间存在的关系，并把这种关系抽象到形式化模型上，进而利用结构化机器学习算法有效地解决这个问题。结构化机器学习无论在理论上还是在应用上都有着广泛的应用前景。将结构化机器学习算法应用于语义角色标注中是一个新的研究思路，既可进一步挖掘谓词论元结构的信息，提高语义角色标注的水平，也有利于促进结构化机器学习在应用方面的研究。该项目的研究成果也将为自然语言处理其它领域使用结构化机器学习算法，以及为将传统语言学知识更多地纳入到自然语言处理模型框架中提供参考。
社会化网络社区中跨域推荐技术研究	跨域推荐;信息系统;社会化网络社区;个性化推荐	随着社会化网络社区中资源的大量增加，越来越多的网上社区采用推荐技术来方便用户获取信息。而传统推荐算法在用户兴趣信息缺失或较少的情况下很难给出准确的推荐结果，这被称为冷启动问题或稀疏问题。跨域推荐是缓解该难题的有效途径，即利用用户在其它服务或社区中的信息来优化目标服务的推荐准确度。本项目旨在利用丰富的社会媒体及多渠道网络信息，实现不同服务或社区中用户的自动识别和对应，定义和计算属于不同类别或媒体资源的相关性，进而跨域迁移用户兴趣，预测用户在目标服务中的兴趣，最终实现社会化网络社区中的跨域推荐以缓解传统推荐算法面临的冷启动或稀疏问题，同时寻求跨域推荐的合理解释，方便用户获取和选择信息。本项目将研究多种跨域推荐算法，搭建原型并力求在实际系统中应用推广。
面向大数据、少资源、跨领域汉葡机器翻译方法研究与实现	复杂形态语言;汉葡机器翻译;资源匮乏型语言;图标签传播;领域自适应	作为澳门官方语言，汉语和葡语是联系中国与葡语国家之间重要的纽带，研究汉葡机器翻译有着重要的科学和社会意义。与汉英相比，汉葡机器翻译研究面临几个主要的问题：1）汉葡非常缺乏语言资源，尤其是大规模平行语料；2）汉语和葡语存在严重的词形态不对称现象，葡语具有复杂的形态变化，导致数据稀疏，影响翻译效果；3）领域自适应能力差，跨领域的翻译质量显著下降。为此，本项目拟围绕这些问题展开创新性研究：1）研究基于图模型和大数据领域特征的汉葡双语语料资源构建方法；2）研究基于图模型和大数据的葡语形态信息的学习算法，和面向复杂形态的翻译模型；3）研究基于图模型和大规模语料的领域信息学习方法，和面向跨领域的机器翻译模型；4）基于上述研究成果，构建一个跨领域汉葡机器翻译平台，面向学术界共享资源和成果。本项目的展开将为汉葡机器翻译研究作出重要贡献，并为其他类似语言对机器翻译研究提供参考，具有重要的科学意义和应用价值。
基于Constellation模型的自然场景文本检索方法研究	图像聚类;场景文本识别与检索;局部特征描述;Constellation模型	自然场景中文本的识别与检索是近年来字符识别领域研究的一个热点问题，现有的研究方法大多以传统的OCR技术为基础，首先检测和定位场景图像中的文本，然后分离字符前景与背景，OCR识别字符，最后检索文本。然而自然场景图像同传统的扫描文本图像存在着明显的差异，字符文本存在于杂乱的背景之中，拍摄视角的不同造成文本具有较大的几何变形，存在光照变化、字符颜色不统一的现象，字符可能发生局部破损、断裂和被遮挡，这些现象造成了此项研究到目前为止很难取得令人满意的结果。本项目提出将Constellation模型引入场景文本检索的研究，利用图像的局部特征描述对场景字符建模，通过模型组合实现对自然场景图像中文本关键词的直接检索，避免了传统研究方法在检测，背景分离和识别中所遇到的困难。本项目为自然场景文本识别与检索开辟了一种新的研究思路，将推动此领域研究的进一步发展。
面向英汉双向跨语言图像检索的文本分析关键技术研究	文本分析;ImageCLIR);Information;双语概念语义网络;Retrieval;统计学习;跨语言图像检索(Cross-Language;Image;跨语言信息检索(Cross-Language;CLIR)	为使信息用户充分利用丰富的多语种多媒体网络资源，跨语言图像检索应运而生，即以不同语言描述的用户查询与具有多语标注/字幕的图像之间的匹配问题。跨语言图像检索研究位于跨语言信息检索、图像检索、文本分析三者之间的交集领域，目前对于其所必需的相关文本分析技术，虽然相对独立的研究较多，但离完全解决仍距离很远。特别是如何适用于针对大规模多样化信息源的跨语言图像检索这一特殊环境中，依然是一个需要关注与解决的难题。本课题正是在传统跨语言信息检索和图像检索基本理论的基础上，侧重于研究跨语言图像检索中涉及相关联文本信息的知识源构建、未登录词项处理、查询翻译、词义评估与消歧、查询扩展与优化、及排序与垃圾信息过滤等重要文本分析问题，从而建立一种融合相关联文本分析关键技术的跨语言图像检索实现框架，由此引出针对英汉双向跨语言图像检索更为深入的研究，为更加有效地利用文本分析技术来提高跨语言图像检索性能提出一条崭新途径。
面向中文文本信息融合的句子排序研究	中文句子排序　信息融合　MDS　优先关系图　基本要素	Internet的发展使得各种信息急剧增加，信息检索是人们高效获取所需信息必不可少的渠道，文本信息融合技术可将来自多个信息源的文本信息片段综合整理，有效地减轻了对检索结果的阅读负担。将多个信息源（文档）的信息组合成逻辑性强、一致性高的一篇文本，需要对相应的信息片段（句子）进行排序，排序的结果直接关系到所生文本的可读性。目前国内对文本信息融合中句子排序的研究只局限于在多文档自动文摘或问答系统中简单提到，还没有把它专门作为一个课题进行深入的研究，国际上也没有专门针对中文文本的句子排序研究。本项目通过人工分析与数据挖掘相结合的办法，分析人在中文句子排序时的行为模式，总结出句子排序时可用到的各种特征，并对其进行量化，在此基础上集成各项特征，设计排序模型，通过句子与句了之间关系构建有向图，用改进的PageRank方法对图中节点进排序。最后将排序模型集成在文本信息融合系统中，提文本信息融合结果的质量。
移动互联网中基于历史行为的用户偏好在线学习机制	社区发现;用户偏好;用户行为分析;上下文感知;信任度	移动用户偏好的准确获取是信息系统为移动用户提供及时准确的个性化服务的关键。然而，庞大的移动用户群、种类繁多的网络服务以及用户使用的移动网络服务有限等因素导致在移动用户偏好学习过程中存在响应时间长、数据稀疏等问题。本项目以移动互联网中的用户偏好在线学习为研究对象进行深入研究。具体内容包括：①利用波动率确定影响移动用户偏好的上下文以及影响程度、采用关联规则计算上下文之间的相关度；利用皮尔森相关系数计算上下文实例之间的相似度、构建基于上下文相关度和上下文相似度的上下文量化模型；②计算移动用户之间的信任度并构建移动社会化网络、构建移动社区划分模型和移动社会化网络演化模型；③利用小波变换对学习数据进行预处理、构建移动用户偏好衰减模型、利用二分网络和链接预测方法缓解数据稀疏性问题、分析移动用户偏好的类型并挖掘移动用户长期偏好的变化规律、构建基于上下文感知和社会化网络的移动用户偏好在线学习模型。
云数据库查询模式集自动生成与检索关键技术研究	模式图;查询模式;关键字检索;检索日志	随着云计算与数据库的广泛应用，越来越多的普通用户迫切希望直接访问云端海量带有结构信息的数据。然而，现有云数据库的查询方式，制约了普通用户的需求。如何使普通用户可以便捷、高效检索云数据库，已成为国内外学术界与企业的研究热点。本课题采用数据库与信息检索相结合的方法，研究如何利用云数据库模式，实现普通用户快速、准确检索云数据库的新方法：拟采用模式图描述云数据库模式，研究云数据库的模式图抽取方法，设计模式图节点查询意向度算法；提出基于模式图的候选查询模式集自动生成方案；研究用户通过关键字检索意向查询模式的方法；分析检索日志，改进查询意向度的计算与查询模式集的生成与检索过程。本课题主要攻克云数据库模式抽取、查询模式集自动生成和查询模式集检索排序等目前尚未解决的科学问题。本课题研究内容符合数据库领域最新研究趋势，有望取得有一定影响力的成果，在云数据库关键字检索领域打开新的研究视野。
基于海量语料自然标注信息的汉语自然语块分析	自然语块;自然标注信息;合理性评估;海量语料;语言边界	语块分析将复杂语句划分为较细粒度的片段，可以有效降低信息处理复杂度。本课题以海量汉语语料中标点符号、边界标记、功能词等自然标注信息作为语块划分知识源，提出自然语块的概念，特指在海量语料中稳定、频繁出现，具有明显边界特性的语言片段。自然语块不受语法规则约束，在处理汉语边界划分问题上具有其优势。 本课题研究无监督的汉语自然语块识别方法。利用海量语料中自然标注信息挖掘语言边界知识；研究基于统计的语块边界特征提取方法，对语言边界知识建模；将自然语块分析转化为状态空间搜索问题，研究搜索空间裁剪和快速解码算法。 自然语块边界划分具有柔性，针对不同应用，对应的合理划分也不同。课题研究从不同侧面评估自然语块合理性的方法。研究语块粒度控制和参数训练方法。分析自然语块对海量词典的覆盖度，考察其对汉语词汇知识的描述能力；从同构性角度分析自然语块与中文分词、汉语韵律短语的一致性，对自然语块分析性能作出评价。
跨语图像检索中融合视觉信息的多语翻译与集成方法研究	查询翻译;词义消歧;图像标注翻译;跨语言图像检索;结果集成	跨语言图像检索可以使用户检索到与查询采用不同语言标注的图像，具有重要的研究和应用价值。针对跨语言图像检索中文本信息上下文缺乏的难题，本项目采用以图像视觉信息作为上下文以辅助多语翻译和集成的思想，研究一种融合图像视觉信息的多语翻译和集成新方法。首先，研究一种基于图像集合视觉相似性的查询翻译机制，提高查询翻译的准确率，从而改善目标语言图像检索的准确性。其次，在此基础上，研究一种基于检索性能预测和重排序的结果集成机制，实现对多个单语言检索结果的高效集成。最后，在结果集成之后，研究一种基于图像层次式聚类的图像标注翻译算法，提高对检索结果中图像标注的翻译准确率。项目将在中文标注图像集和英文标注图像集上验证方法的有效性。本项目的研究成果，对于跨语言图像检索、机器翻译等具有重要的理论和应用价值。
微博热点事件的情感趋势分析与预测研究	文本情感分析;情感趋势分析;社会计算;情感预测;深度学习	随着社会网络的快速发展，以微博为代表的文本已经成为互联网信息发布的重要形式，也为民意的分析与预测提供了新的途径。本课题以中文微博为对象，探索针对热点事件的情感趋势分析与预测方法。在综合获取各种用户特征和文本特征的基础上，课题引入深度学习方法进行热点事件的情感分析，进而以多维情感特征为基础对用户情感趋势进行量化，最终通过贝叶斯模型综合多种信息对事件的情感趋势曲线进行拟合，完成预测建模。从应用角度看，该课题是舆情深入分析的关键技术，对于了解经济活动和社会事件中的人群态度、探索社会群体心理规律具有明显的实用价值，支持政治、经济和生活合理决策。从理论上，该课题是对非结构化的社会信息进行多元统计分析和计算的有益尝试，引入深度学习提高情感分析效果，并采用贝叶斯模型提高趋势预测效果。
组排序学习方法的研究与应用	信息检索;排序学习;查询扩展;机器学习	信息检索是当今互联网时代获取知识、了解世界的重要手段，排序则是其研究的核心问题。针对排序进行优化的排序学习方法对于信息检索的研究以及互联网的发展都有着重要的意义。组排序学习方法通过组样本的损失函数构造为排序学习方法的研究提供的新的方向，能够有效的提高信息检索任务的准确率。当前组排序学习方法的研究正处于理论研究，亟待完善的阶段。针对这种情况，本项目从理论和应用两个方面展开研究。理论研究方面重点从排序学习方法损失函数构造入手改进已有的组样本排序学习方法，通过对多损失函数融合模型、直接优化评价方法的研究来完善组排序学习方法。应用研究方面主要将组排序学习方法的应用于查询扩展、电影排名预测等问题的研究。本项目的研究有助于提高排序学习方法的研究水平，为排序学习方法的应用提供新的思路与理论依据。
基于深度神经网络的端到端自动问答系统研究	深度神经网络;自动问答;语义推理;语义表示学习;自然语言理解	自动问答是指给定背景事实，系统可以分析用户用自然语言提出的问句，结合背景事实进行自动推理，并最终给出答案。自动问答也是人工智能、自然语言处理以及信息检索领域的热点研究方向之一。传统的自动问答系统框架一般分为很多模块，每个模块都分别构建。整个系统存在错误传播问题，并且很难进行端到端的训练，给整个系统优化造成了很大的困难。本项目通过深入研究面向大规模真实数据的开放领域自动问答系统中的关键问题（比如知识库嵌入、事实检索、语义推理、答案生成等），借鉴人类认知机制，探索有效的基于深度神经网络的语义表示以及推理模型，构建可以端到端学习的自动问答系统。整个系统不需要额外的深层自然语言处理工具以及逻辑推理工具，以减少对人工设计特征的依赖，降低开发自动问答系统的成本，并促进自动问答系统的发展。此外，本项目也会对相关的自然语言处理以及深度学习关键技术进行深入研究，具有重要的理论意义与实际应用价值。
上下文情景语义感知的组推荐模型研究	情景建模;上下文感知;社交推荐	本项目将上下文感知计算方法应用到推荐系统的模型研究中，通过上下文情景的分析与推理，实现用户组的推荐。本项目利用上下文情景感知技术，融合智能手机，传感器网络和社交网络的多源数据，对这些数据进行情景建模和推理，从而得到上下文的线索，形成上下文情景的语义感知模型，获得情景的高层语义知识。再结合用户丰富群体行为，通过组推理的方法来预测用户的组的行为模式，推荐满足用户组的需求。这些研究的开展，能自动地发现环境中可用的资源和服务，主动提供适应用户组需求的服务，为用户组提供相应的智能服务。
面向微博的地理兴趣点抽取及其用户行为意图分析研究	Web信息抽取	微博实时的信息分享使得基于微博内容开展用户位置研究变成一个重要研究内容，这类技术的发展对个性化地理服务、广告营销和智慧城市等领域提供了科学技术层面的支持。现有研究工作主要依赖于用户的主动地理信息分享，由于其位置分析精细度较低并且用户行为意图信息不明，这些技术很难支撑上述应用。本课题旨在通过分析用户微博内容，依次研究微博地理兴趣点（POI）抽取算法， POI地理位置推断算法和用户关于POI的行为意图分析算法，实现细粒度地获知用户的地理位置、活动计划和内容的目标。项目将采用文本挖掘与自然语言处理相关技术理论，重点研究:（1）POI词条的语义语境特征的抽取、转换和表征方法;（2）基于空间行为模式与空间主题分布的POI位置推断方法；（3）用户关于POI的时间趋势特征抽取与度量方法。本项研究对于推动文本处理技术的进一步发展以及满足应用领域对用户地理信息分析的需求，具有重要的科学意义和应用价值。
汉语篇章衔接性分析：指代、省略及其消歧研究	篇章衔接性;省略;指代消解	篇章衔接性分析是篇章理解的基础，而指代和省略是衔接机制中的核心问题，同时也是难点所在。受限于语料资源，目前国内外对于汉语篇章衔接性中指代和省略的研究进展缓慢。本项目将结合汉语自身的特点和规律，针对汉语篇章衔接性中的指代和省略问题展开研究。首先建立较大规模的汉语篇章衔接性标注语料库；在此基础上，通过先行事件候选的触发词识别、动态事件指代关系树的获取以及适用于事件指代消解的基于实体指代链的上下文相似度计算方法的研究，提出并实现综合使用多层面信息的事件指代消解方法；对于汉语中的省略，将从句法、语义和语用三个视角识别省略及对其进行消解；最后再利用联合学习机制将指代和省略消歧融合，建立统一的篇章消歧平台。本项目开展的研究工作对于推进汉语篇章衔接性分析的研究，推动计算语言学研究和中文信息技术的发展具有重要的理论意义和应用价值。
多文档事件信息融合方法的研究	零形指代项识别;信息融合;多文档;事件抽取;事件间关联度模型	目前主流的事件抽取方法一般基于单一文档，所获得的事件信息不完整（如信息缺失）和语义不够明确（如代词指代）。同时，很多事件在互联网中存在关于该事件的大量报道，如果能把这些报道有效融合起来，就可能获得一个表述完整、语义明确的事件描述。相关研究尚属空白。本课题通过对零形指代项识别、多文档单一事件信息融合和多文档复杂事件信息融合等关键技术的研究，重点解决事件信息抽取中事件信息的完整性和语义明确性两大问题。特别是，本课题从单文档中事件的上下文信息和多文档中事件的结构化和平面信息等方面入手，提出了新颖的基于结构化信息的零形指代项识别方法、事件相似度计算模型、事件元素可信度评价模型和用于复杂事件融合的单一事件间的关联度模型，用于进一步提高单一事件和复杂事件信息的完整性及明确其语义。通过本课题的研究，可获得内容更完整和更全面，语义更明确的事件信息，从而可为各种需要语义信息支撑的自然语言处理技术服务。
自然语言处理中的覆盖域界定和聚焦点识别研究	计算模型;聚焦点识别;覆盖域界定;数据不平衡;树核函数	覆盖域界定和聚焦点识别研究分别从作用面和作用点两个层面确定用户感兴趣的文本片断和关注对象，相互补充，相辅相成，在自然语言处理研究中具有广泛的应用价值，是实现句子级深层语义理解的重要基础之一。目前，覆盖域界定研究在建模和有效利用结构化句法信息的方面存在缺陷，聚焦点识别研究刚起步。本课题将在语言学理论指导下，从建模、结构化句法信息利用和数据不平衡问题研究等多个角度，深入研究自然语言处理中的覆盖域界定和聚焦点识别问题。主要研究内容包括：1）基于浅层语义分析的覆盖域界定模型；2）基于树核函数的覆盖域界定研究；3）基于竞争机制和中心理论的聚焦点识别研究；4）面向数据层面和算法层面的数据不平衡解决方案。同时，针对中文语料库缺乏问题，本课题将构建一定规模的高质量中文覆盖域界定和聚焦点识别语料库，深入开展中文覆盖域界定和聚焦点识别研究，缩短与英文相关研究的差距。
量子保密信息检索及其应用研究	隐私;保密信息检索;量子保密信息检索;对称保密信息检索	量子保密信息检索是量子密码学和信息安全研究领域的一个重要问题。本项目拟采用将量子密码新理论和经典保密信息检索技术相结合的方法，研究量子保密信检索及其应用中存在的若干问题。重点研究以下几个方面的问题：已有量子保密信息检索方案的安全性分析及改进，将多种量子特性和量子信息原理应用于量子保密信息检索方案的密码分析技术中，提出新的密码攻击手段，并给出改进方案；研究信息论安全的多服务器量子保密信息检索方案的设计、分析以及安全性证明理论；研究信息论安全的单服务器量子保密信息检索方案的存在性。预期研究成果将为量子保密信息检索的进一步研发提供理论基础和算法支持,并为其它相关量子密码协议的设计、分析和安全性证明提供理论参考。
基于稀疏表示技术的大规模医学图像检索新方法研究	稀疏表示;医学信息系统;医学图像检索	现有的大规模医学图像检索方法在精度和速度方面无法满足实际应用的需求。本项目提出一种新思路，探索最新的稀疏表示技术在大规模医学图像检索中的应用，以突破检索精度和速度的瓶颈，为医学图像检索系统实用性的增强提供新方法和理论基础。.首先采用特征包技术综合医学图像的各类特征，通过训练产生过完备的特征字典，并对特征包进行稀疏投影以得到稀疏特征，获得比现有方法更好的特征融合效果，从而提高检索精度；此外，稀疏字典和稀疏表示系数的数据量远小于传统特征的数据量，可显著降低特征存储空间。然后利用稀疏特征相似性度量和索引算法进行检索，计算量低于传统特征的相似性度量和索引，提高了检索速度。最后利用相关反馈技术对系统各部分的算法进行修改，获取最好的总体性能。总之，基于稀疏表示技术的新方法有望在检索精度、速度和存储空间等性能上超越现有方法，对大规模医学图像检索系统综合性能的提高具有重要意义。
基于形成演化机理的事件探测、推理与感知方法研究	事件探测与追踪;推理;潜在事件;感知;事件形成演化机理	在大数据互联网时代，事件探测与追踪技术受到了舆情监控、决策支持、应急管理等应用领域的广泛关注，该技术能够辅助决策者基于互联网信息快速发现需要关注的事件并追踪其发展趋势，对维护国家安全与社会稳定具有重要意义。然而，在实际应用中现有方法仅聚焦在已发生事件的探测上，却忽略了突发事件及连环事件在发生之前的潜在征兆，故而难以基于潜在征兆在事发之前进行事件的推理预测。此外，人对事件的感知以及知识和经验在事件探测过程中往往被忽略导致探测精度有限。针对上述问题，本项目拟以事件形成演化机理为驱动，提出基于潜在事件关联的可视化图模型以扩展传统的"模式-发现"概率模型，为新的"推理-感知"事件探测模式提供关键技术支撑。研究内容包括：面向潜在事件的"前兆-衍生"推理模型；基于认知模型的事件可视分析方法；基于人机协同的事件探测与感知方法。研究成果可广泛应用于自然灾害早期预警、社会危机应急管理、网络攻击防范等领域。
基于整句层面的中文语义角色标注关键技术研究	全局推断;领域适应方法;鲁棒性;稀疏谓词;整句层面语义角色标注	一个句子中的全部谓词联合起来表达了句子的完整语义。然而，目前主流的语义角色标注方法仍然停留在单个"谓词"层面，忽视了句子中谓词与谓词之间的语义关联，这就导致很多只能在句子层面获取到的结构和语义信息严重缺失，从而使得语义角色标注的准确率急剧下降。因此，本项目紧紧围绕整句层面的语义角色标注展开如下创新性研究：1）研究基于"整句"层面的语义角色标注框架，兼顾考虑句中多个谓词语义角色标注之间的语义关联；2）研究统一框架下的全局推断模型，力保联合标注模型能够输出全局最优、高度一致性的语义标注结果；3）借助深度学习强大的表征和抽象能力，研究稀疏谓词的标注方法和领域迁移方法，提升标注模型的鲁棒性和泛化性。本项目的预期研究成果将使现有的语义角色标注理论从"谓词"层面提升到"整句"层面，该成果将丰富和发展现有的语义角色标注理论方法，并能推动相关技术的发展，具有重要的理论研究意义和实用价值。
电子商务推荐系统健壮性研究	侦测算法;博弈;健壮性;推荐系统	随着电子商务的蓬勃发展，个性化推荐系统在网络商务中成为一个日益重要的服务工具。这种系统用于监控在线用户的购物喜好并使用这些信息来提供符合每个用户特殊需求的商品或服务。近期的研究表明这样的系统有被滥用的嫌疑，推荐系统所基于的评分数据经常被一些恶意用户实施攻击、故意篡改以操纵系统输出。因此，如何保证系统的健壮性以抵御恶意数据的入侵已成为个性化推荐的主要挑战之一。本项目将从几个方面对此问题进行调查，并使用博弈论、图论以及其它一些工具来考察攻击的效果、分析数据库的结构、识别攻击文件等，以设计有效可靠的侦测和对抗攻击的算法，提供一个可抵御噪声或恶意数据的具有高健壮性的推荐系统。
基于个体及群体影响力量化分析的动态网群组织(CMOs)演化规律及规模预测研究	影响力量化;移动社交网络;动态网群组织;自组织信息系统	近年来，随着人们衣食住行的在线化，动态网群组织(CMOs)已然成为真实社会中个体或群体及其社会行为在网络空间中的映射。在物理社会中，个体通过亲情、友情、爱情、同窗情等关系连接在一起；在网络社会中，用户通过生成内容进行交互，产生动态连接，形成网络群体。由于网络的"时空压缩"效应，CMOs可以在极短的时间内、以极低的成本从广阔的网络空间中累积大量的能量，甚至释放到现实社会中，产生巨大的效益或破坏，这使得因网民互动行为而形成的CMOs成为制造社会事件的核心力量。本项目拟以真实社交媒体大规模数据为基础，从用户组织行为结构、言论语义分析以及两者结合的角度对CMOs中的个体及群体的影响力进行量化建模与分析，在此基础上对CMOs的演化规律进行分析并规模预测，使CMOs分析成为热点事情预判及舆情引导的有力辅助管理手段，为保障社会稳定与安全提供有力的技术支持。
基于情感语义表示的隐式情感分析	中文信息处理;情感分析;观点挖掘;倾向性分析;隐式情感分析	隐式情感表达作为情感分析研究领域重要挑战之一，已成为影响情感分析精度和发展的重要因素，因此本课题的目标是建立隐式情感分析的框架和模型，旨在提升情感分析的精度。首先，以认知语言学为指导，确立情感语义知识收录原则、质量保障及扩展机制，进而构建情感常识及情感隐喻的资源，为文本的隐式情感分析研究奠定必要的语义资源基础；以表示学习和深度学习为基础，在文本分布式表示过程中融入主题及文本中蕴含的情感因素，实现对文本的深层理解与表示，为文本的隐式情感分析研究提供必要的情感语义表示单元；最后，以情感语义资源和情感语义表示为基础，深入分析不同类型隐式情感表达的特点，提出基于冲突检测的隐式情感表达发现机制，再结合概念空间划分及主题注意力机制模型实现对隐喻型和事实型隐式情感表达的情感分类，从而实现提高情感分析研究精度的目的。
关键词抽取与社会标签推荐相结合的中文文本主题词自动标注方法研究	中文信息处理;信息检索;主题词自动标注;关键词抽取;关键词分配	主题词是人们快速了解文本内容、把握其主题的重要方式之一。文本主题词标注已广泛应用于搜索引擎、新闻服务、电子图书馆等领域，具有重要的科学意义和广泛的应用价值。本项目将进行以下几方面的研究：构建面向典型应用的大规模Web主题词标注语料库；研究适合中文主题词标注的词语边界和粒度确定方法；研究关键词抽取和关键词分配相结合的主题词标注方法;研究在社会标签推荐中充分引入标签之间关系的方法；研究适合中文社会标签系统特点的动力学模型和演化模式分析模型；研究综合考虑主题词粒度、边界和演化等特性，能够与时间基本同步的中文主题词自动标注方法及系统，并在热点事件跟踪、用户兴趣发现等典型任务上验证其有效性。本项目预期成果将大大丰富和深化中文主题词自动标注的研究，在相关计算方法和技术上实现一次跃迁，对Web规模的信息组织与检索乃至网络时代的中文信息处理研究具有重要意义。
中文语义依存分析资源构建及分析技术研究	语义分析模型;语义依存分析;语义关系;语义分析	句子语义分析是自然语言处理的核心问题，但由于技术手段的限制，目前研究还仅限于语义角色标注等浅层分析。语义依存分析是一种深层语义分析方法，该方法为句子中每个词找到其所依存的词，并标注它们之间的语义关系，最终构成一棵语义依存树。这种语义分析方式以其形式简洁、易于标注、便于应用等优点，逐渐受到重视。对于信息抽取、问答系统等语言信息处理应用技术，仅依靠词汇、词性等文本表层的信息已经很难取得突破性的进展，必须利用更深层次的语义信息。为此，本项目针对汉语语义依存分析问题，提出了一整套研究内容，包括确定汉语语义依存关系体系、构建大规模语义依存语料库以及研制高效准确的语义依存分析模型。试图在词义消歧的基础上，利用词汇语义信息，越过词性标注和句法分析，直接进行语义依存分析，从而提升汉语语义分析的性能，为相关应用技术提供更有利的支持。
基于深度神经网络的句子篇章一体化的依存分析	深度神经网络;篇章分析;结构化机器学习;依存分析;语义嵌入	本项目拟研究基于深度神经网络的句子-篇章一体化的依存关系模型，将依存关系作为基本的表达手段，使用依存结构连接句子和篇章两级的标识架构，改进已有的篇章分析研究。具体来说，我们篇章分析将充分利用包括字嵌入向量、词向量、句子卷积向量在内的多层语言处理信息。在基本的学习模型上，我们将综合考虑简单前向神经网络、卷积神经网络和递归神经网络。本项目有望帮助进一步改进典型的深层篇章分析处理任务，并达到对于文本特性更加全面深入理解的目的。
汉语句法结构和事件结构的联合分析研究	联合模型;事件结构;事件抽取;句法分析	汉语句法分析旨在让计算机理解句子的句法结构，它对于许多自然语言处理任务十分重要。事件分析旨在自动抽取句子中的事件，它在舆情分析等应用系统中起到了很大的作用。句法结构，特别是依存结构，体现了句子中词与词之间的相互关系，而事件结构体现了谓词和论元之间的关系，所以他们之间有区别但更有联系。以往工作都是单独地对句法和事件进行分析，没有充分利用两种结构的联系。因此本项目提出句法结构和事件结构的联合分析模型。该模型一方面利用神经网络来自动抽取特征，另一方面利用结构感知机来加强句法和事件的联合结构预测。另外，由于句法结构和事件结构常常存在不一致现象，因为本项目拟根据汉语事件触发词模板来微调句法结构，使其微观上保持句法结构的依存信息，在宏观上使句法结构和事件结构更趋一致，进而帮助联合模型提升效果。
云存储环境下长期保存的电子文件凭证性保障方法和关键技术研究	电子文件;云存储;长期保存;凭证性;管理信息系统	云存储代表了信息技术向集约化、规模化与专业化发展的趋势，改变了电子文件管理的技术架构和实现方法，能提供更为先进、高效的电子文件管理方式。但在云存储环境下，长期保存的海量电子文件其凭证性更加难以保障，给电子文件的正常管理带来极大危害。本课题从电子文件的定义和规范入手，根据信息安全理论分析满足长期保存的电子文件的凭证性保障所需的安全需求，提供相应的安全技术支持，构建基于安全需求的长期保存的电子文件云存储凭证性保障方法和技术体系；重点研究并设计长期保存的电子文件云存储真实性、完整性和可靠性一体化保障方法；进一步可根据实际安全需求，附加具有新安全属性的一体化保障方法；并采用可证安全理论进行形式化的安全证明。通过本课题的研究，在云存储环境下，长期保存的电子文件的凭证性保障方面取得原创性的理论研究成果和关键性的保障方法突破，推动我国电子文件管理的快速发展。
基于信息觅食的探索式搜索查询推荐方法研究	信息觅食;扩散激活;查询流图;查询推荐;探索式搜索	如何有效的支持探索式搜索是国内外研究的热点，已经成为了信息检索领域研究的重要发展方向。本课题从现有查询推荐方法在帮助用户缩短探索式搜索的学习过程时存在的不足出发，以信息觅食理论为基础，通过将概念的学习价值及用户对概念的理解程度分别作为搜索过程中的收益与成本，研究基于信息觅食的探索式搜索查询推荐方法。本课题从建模体现概念学习价值的搜索经验出发，以探索流图为基础，建立基于概念学习随机过程的概念学习价值计算算法；从构建基于本体的概念知识网络出发，将用户掌握的概念作为激活点，建立基于扩散激活的用户对概念理解能力的计算算法。在此基础上，以最小化探索式搜索学习过程为优化目标，应用基于信息觅食理论的最优化方法推荐具有学习价值、且能够被用户逐渐理解的查询词，帮助用户有效缩短探索式搜索的学习过程。本课题的研究即针对当前查询推荐应用的迫切需求，也将为探索式搜索技术研究提供新的思路。
基于势能导向的互联网视频资源分布式情感搜索模型研究	分布式网络架构;势能引导;情感搜索;数字情感;情感分发网络	在当前信息爆炸的时代，互联网上视频资源数量的急剧增加并未带来用户体验感的大幅度提升，主要原因是缺乏专门针对用户主观感受进行视频情感搜索或推送的有效机制，尤其是缺少扮演基石角色的视频情感搜索理论模型。然而，现有的研究成果还无法提供有效的解决方案。一方面，情感分析的研究过于注重于对情感进行正面和负面的极性判断，而忽略了情感的多元化表达和强度问题。另一方面，在面向资源搜索的分布式网络结构上，相关研究集中在解决以内容搜索为目标的网络架构设计上，而非以情感搜索为目标。鉴于此，本项目提出情感资源的"势能"概念，围绕情感资源的表达性和适配性两大科学问题，构建视频情感数字化框架和基于势能的分布式情感搜索基础模型，重点研究满足"数字情感"和"情感搜索"两大要素的情感分发网络体系及情感资源的适配策略。本项目的预期成果将从理论和应用上迅速促进分布式网络领域的发展，具有重大的学术研究意义和商业应用价值。
汉语文本推理的资源建设和统计分析研究	资源建设;文本推理;语义依存分析;对数线性模型;文本蕴涵	文本推理是指文本描述的命题间的逻辑关系，目前主要策略是获取推理规则并根据规则进行推导。本项目把文本推理的判断转化为一个受限的语义依存分析问题，从而以一个崭新的角度考察文本推理。为此，我们拟建立大规模的汉语文本推理标注资源、探讨有效的分析策略并应用于问题回答和关系抽取两个具体任务。本研究将文本推理从文本蕴涵扩展至预设和隐含，并将这三种推理形式综合到一个统一的框架中；提出并研究基于语义依存分析的推理判断且探讨基于对数线性的二阶段区分性分析模型。本研究有助于处理较复杂的推论形式，探究汉语文本推理的基本特性、比较不同推理形式的异同、评估文本推理对应用系统的贡献，对推动汉语文本推理评测平台的建设也有重要意义。
基于词向量表示的大规模知识图谱构建方法研究	词向量;知识图谱;文本挖掘;特征表示	大规模知识图谱的构建是计算机实现智能推理的基础。特征表示是制约知识图谱构建效果的一个很重要的因素，传统特征表示方法存在特征表意能力差、缺乏语义可计算性、特征设计过程复杂等问题，而基于深度学习的词向量特征表示方法具有丰富的表意能力，是一种全自动的特征学习方法。本课题拟基于词向量学习，对知识图谱的基本元素（如命名实体、关系）形成全新的特征表示，进而研究基于词向量特征和深度神经网络的知识图谱的自动化构建方法，使得大规模知识图谱的普遍应用成为现实。本课题在词向量学习的方法上，通过对深度神经网络结构的调整和引入先验的语言学知识，解决词向量学习的效率、效果问题；在知识图谱各子任务上，一方面在原有算法的基础上，引入基于词向量的词聚类特征，并将该特征与原特征进行有效的融合；另一方面，提出了面向知识图谱的深度神经网络结构设计方法，在此基础上，提出全新的基于词向量的实体、关系识别算法。
面向突发应急的云计算资源组织优化方法研究	信息服务;资源组织;云计算;应急;优化	云计算为应急信息系统建设开辟了一种新模式，同时也对云平台的服务质量提出了更高要求。云资源组织优化是提高系统性能的有效手段，而现有方法在应对任务突发时的资源快速调整、不确定因素控制及可靠性保障等方面还存在若干瓶颈问题。本项目致力解决这些瓶颈问题，主要研究：1）任务负载预测与资源需求预约，为云资源调整部署提供提前量，缓解应急情况下资源需求紧迫性对系统造成的压力；2）任务动态调度，打破传统调度方法中任务执行时间确定、资源即时可用且性能稳定等理想性假设，控制不确定因素累加，提高调度时效性和准确性；3）云计算资源快速供给，缓解由于资源需求预约偏差带来的资源供给不足问题，在任务减少时进行资源规模平滑收缩，防止系统再扩展滞后的现象；4）可靠性保障，进行多节点同时故障容错处理及虚拟机动态热备份，保障系统可靠执行。通过本项目研究，有望提升云平台进行突发应急任务处理的能力，为应急信息系统建设提供关键技术支撑。
面向失衡数据集的预测分类模型研究	重采样;预测模型;分类模型;聚类;失衡数据集	失衡数据集问题是数据挖掘技术中最具挑战性的难点和热点研究问题之一，其研究具有重要的理论价值和广阔的应用前景。.本项目旨在针对失衡数据集问题进行专项研究，计划采用预测和分类两种思想相结合的策略，探索有效途径来解决数据类别失衡这一难点问题。本人创造性地提出了"基于分割聚类分层抽样逻辑回归的失衡数据集预测模型"和"基于聚类抽样K近邻核变换的失衡数据集分类模型"，两种方法从失衡数据的重采样和算法改进两方面同时入手，分析和研究采样方法与核心算法之间的内在关联性，并有针对性地对一些具体核心问题进行深入探讨与研究，以提高技术层次与研究深度。本人将预测与分类两种不同机理的方法进行融合，相互补充发挥各自的特点，形成面向失衡数据集问题的综合解决方案。最后，在答案抽取和故障检测两个实际应用中检测验证本项目所涉及技术的具体应用效果。
基于大规模部分标注数据的依存句法分析	依存句法分析;人工标注文本;单语无标注文本;双语对齐无标注文本;部分标注数据	依存句法分析一直是自然语言处理领域的关键研究问题，广泛应用于机器翻译、关系抽取等核心任务。目前依存分析的主要问题是面对新闻领域的规范文本时性能较好，但用于其它领域或类型的文本时，性能急剧下降。随着大规模网络数据的出现，依存分析的重要挑战是如何精准分析有别于传统规范新闻文本的网络文本。本项目的研究思路是利用各种类型的标注信息获取大规模句法实例，扩大训练数据的规模和领域覆盖面，从而大幅度提高依存分析处理网络文本的性能。为此，本项目提出一种新的基于部分标注的数据表示方式，允许一个句子只包含部分句法结构。进而从三个层面建模获取大规模句法实例：1) 基于人工标注的方法获取部分标注数据；2) 基于多模型的方法自动从单语无标注文本中挖掘部分标注数据；3) 基于对偶分解的方法自动从双语对齐无标注文本中挖掘部分标注数据。最终，利用大规模基于部分标注的训练实例，建立一个高性能的依存句法分析平台。
汉语复杂网络的性质、结构、演化及其典型应用研究	汉语语言网络;中文信息处理;汉语语言学;复杂网络;算法	从复杂网络这一崭新的视角对汉语进行系统的探索，无论是对汉语本体研究还是对中文信息处理，都具有方法论意义上的创新性,并且涉及复杂系统、语言学、自然语言处理、机器学习、统计学等多学科的交叉，因此具有十分重要的科学意义，已成为当前自然语言处理的研究前沿与热点之一。本项目将主要进行以下几方面研究：利用目前可能得到的一切汉语资源，构造覆盖词法、句法、语义不同层次的各种类型大规模汉语语言网络；对上述语言网络的性质、结构和演化进行分析与对比；提出适合汉语语言网络特点的模体及社区特征发现算法；提出基于不同结构粒度相结合的汉语语义网络演化分析方法；提出基于复杂网络的标签自动生成算法，以进一步研究复杂网络方法在自然语言处理中的典型应用及其相关技术。本项目对汉语语言网络全面、深入的考察与研究, 将大大丰富和深化对汉语的科学认识，得出的一系列结果或结论对汉语语言学、语言认知、中文信息处理等均具有重要参考价值。
问答式信息检索中信息抽取技术研究	问题回答;自然语言处理;信息抽取;阅读理解	问答式信息检索是新一代的搜索引擎，可接收自然语言描述的问题作为查询，在文档集中抽取问题的答案作为搜索引擎的返回结果，它更贴近用户的需求，是一具有广泛应用前景的研究领域。..本项目研究问答式信息检索中的核心技术，即智能化的信息抽取，包括通过模式学习与模式优化构建知识源；挖掘语义关联，基于机器学习方法建立蕴含关系识别模型；以及基于依存关系句法结构进行关联分析；最终，将不同的方法策略应用到Web问答式信息检索（海量信息问答式检索）与阅读理解任务（单文档问答式检索）中，实现答案信息抽取，检验其有效性。本项目的实施以期对发展新一代搜索引擎的自主技术起到一定的促进作用。
基于文字特征的甲骨缀合技术研究	分类;文字定位;缀合;甲骨文;字体特征	甲骨文在汉字文化研究中占有非常重要的地位，但完整的甲骨片很少，多为碎片，所以甲骨缀合是甲骨文研究工作中一项很重要的基础工作，在考古界被称谓甲骨文的"再发掘"。甲骨文是贞人刻在龟甲上的文字符号，不是标准字体，具有很强的时代特征和个性特征，这些特征也正是甲骨文专家进行先分类后缀合的依据，该研究拟采用图像分析技术首先在拓片上定位甲骨文字（包括残字），然后提取甲骨文字体特征，最后通过分类器进行甲骨片分类，从而实现甲骨的自动缀合。该研究有助于甲骨学研究和提高对汉字的认识,该技术也可应用于有字文物的修复与文物真假鉴别以及司法文字物证的修复与鉴别。
多语言环境下文本情感语义计算关键技术研究	文本情感分析;跨语言信息处理;跨语言观点抽取;跨语言立场分析;跨语言情感分类	互联网多语言特性给文本情感分析技术的研究带来了巨大的挑战和机遇。本项目重点研究多语言环境下的文本情感语义计算技术，包括跨语言词语表征学习、跨语言情感分类、跨语言观点抽取、跨语言立场分析，以及多语言观点比对与摘要。本项目的研究目标为提出创新性方法克服情感分析研究领域的语言壁垒，推动面向不同语言的情感分析研究工作的进展，并总结多语言文本中所蕴含的认知和文化差异。本项目将争取在情感分析方面取得新的学术突破，并为业界提供多语言情感资源与情感分析平台。
基于多语用户模型的个性化跨语言信息检索研究	搜索结果优化;多语言用户模型;跨语言信息检索;个性化;查询词优化	网络上信息资源表达语言的多样性与普通网络用户个体所掌握语言的局限性，阻碍了人们对多渠道信息的充分获取。跨语言信息检索已成为解决这一矛盾的必要方法。但目前跨语言信息检索相关研究尚未能较好地考虑用户的兴趣偏好，因此难以获得高置信度以及个性化呈现的跨语言信息检索结果。针对这一问题，本项目拟结合跨语言信息检索和个性化信息检索技术，探讨提高跨语言信息检索准确率和用户满意度的方法。项目将具体研究基于概率主题模型的混合建模方法以构建粒度级多语言用户兴趣模型；基于词图网络的半监督机器学习方法以翻译和扩展查询词；基于语义抽取的结构化分析技术以个性化排序和优化搜索结果；最后通过对所提出的理论与算法进行实验测试和系统原型的实现来验证所提方法的效能。
汉语动名超常搭配处理方法研究	隐喻;选择性限制;超常搭配;省略;生成词库理论	在整个中文信息处理领域，动词和名词的搭配问题可以说是语义分析的核心问题。以往大部分规则和语言学理论都是围绕常规搭配进行，遵循"大词库、小语法"的思想，对于语法规则之外的一些非常规搭配直接纳入到词库范畴，这就极大的限制了自然语言处理的发展。动名的超常搭配主要有两类，一类是省略，一类是隐喻，我们要做的是根据西方生成词库理论的描述思想，为这些规则之外的动名搭配建立有针对性的描写规则和知识表示体系，然后进行分析和处理。内容包括：(1)以动词为核心，构建常规的动名搭配库，提出符合汉语特色的常规搭配语义选择限制获取模型。(2)针对动名超常搭配中经常出现的谓词省略和名词隐喻问题，分别构建以动词的事件结构为特色的动词资源馆和含有名词物性结构及映射规则的隐喻知识库。(3)把自动获取的谓词隐含和隐喻知识融入到机器学习框架，在大规模的语料中，进行具体的超常搭配识别。
跨媒体的语义挖掘与深度关联建模方法研究	跨媒体检索;深度学习;语义网络;特征学习;关联建模	随着网络大数据时代的来临，文本、图像、视频等多媒体内容呈现爆炸式的增长，人们对跨媒体应用的需求也日益增加。海量性、异质性、种类繁多、关系复杂等特点对跨媒体数据的智能分析造成了困难，传统的专注于简单语义和单一媒体的研究思路已不能满足大规模异构数据分析的需求。本项目以跨媒体数据中蕴含的丰富语义信息为研究切入点，拟从三个方面展开：1）现有工作中跨媒体的语义研究匮乏，本项目拟从海量数据中充分挖掘语义信息，研究跨媒体语义相关性，构建结构化的语义网络；2）特征表达能力不足是造成语义鸿沟的关键问题，本项目探索适用于不同媒体特性的特征处理单元，研究基于深度学习模型的层次化语义特征学习机制；3）针对异构媒体数据多样化、语义复杂性等特点，构建自适应的跨媒体关联模型，学习具有语义一致的跨媒体距离度量，研究特征学习和关联建模于一体的端到端的跨媒体检索系统。
新闻话题线索与主题的探测研究	话题检测与跟踪;线索;概率模型;演化;主题	简单的新闻排列与分类组织已经无法满足互联网时代人们快速吸收、理解信息的要求。自动探测话题（种子事件与相关事件的集合）内在结构，表示话题内事件随时间的演化，已成为当今信息过载急需解决的问题之一。本项目研究新闻话题的描述模型，引入概率模型（LDA），建立具有新闻报道特征的新闻话题描述模型；研究新闻话题事件的关联模型，特别是因果关系和细化关系（elaboration）的判断准则；研究话题随时间的演化模型；研究线索与主题的特征抽取与探测算法。通过探测新闻话题的线索（话题的内在结构）与主题（随时间的演化），实现自动组织话题，更好地表示热点话题和基于时间特性话题（例如SARS）的发生与演化过程。
云计算架构下基于语义驱动的信息推荐理论和实证研究	信息推荐;语义计算;数据挖掘;动态迁移;云架构	信息和网络技术的迅速发展使得信息过载呈爆发趋势。信息推荐系统是解决信息超载问题最有效的工具之一，然而现有的信息推荐系统在实时性、鲁棒性和推荐质量方面存在着严重的缺陷。为此，本项目将提出云计算架构下基于语义驱动的信息推荐理论和方法，包括以下五个紧密相关的研究内容：基础数据和用户偏好信息的语义化研究、云计算架构下海量语义化信息索引机制研究、基于语义计算理论的信息推荐方法研究、云计算架构下信息推荐系统动态迁移技术研究和云计算架构下基于语义驱动的信息推荐实证研究。本项目从根本上改变了现有系统重数据数学特征，而轻数据背后所隐含知识语义的现状，为信息推荐提供新的理论和技术途径，并在提高企业经济效益和政府、企事业单位的社会管理服务水平方面将产生重要的作用。
汉语语篇中连贯关系和隐含角色的分析标注研究	隐含角色;连贯关系;事件关系图;语篇结构分析;语段连贯性	汉语语篇的意合型结构，对语篇连贯性计算理解提出了新的挑战。本项目将语篇结构的连贯关系分析和隐含角色回指识别两种技术有机结合起来，把它们落实到内部信息相对自足的语段描述单位上，通过设计有效的汉语语段连贯性描述体系，选择合适的连贯关系和隐含角色回指标记集，将这两种基于关系和基于实体的不同连贯性判定信息整合在基于事件关系图的分析标注结构中，为缺乏显式标记的汉语语篇结构探索出了一条可操作、可计算的局部语篇片段连贯性分析计算途径。在此基础上，研究汉语真实篇章的语段连贯性分析标注方法，开发方便灵活的人机互助标注平台，构建大规模的汉语语段连贯性标注库，探索汉语语段连贯关系分析、隐含角色回指确定和边界识别等核心技术并组织相应的国际评测。其预期研究成果可以方便地推广到汉语语篇的其他指代回指现象，从而大大拓展该项技术在汉语语篇连贯性分析计算中的应用范围，推动中文信息处理技术从句子分析向语篇分析的进化和发展。
基于空间相关性和高噪音不确定多值的面向油田大数据的空间聚类研究	多值对象;高比例噪音;空间聚类;本体;空间相关性	本项目以油藏描述应用为背景，针对油田海量大数据构造复杂，处理周期久，噪音干扰大，需要大量人工参与等问题， 致力于研究探索面向油田大数据的空间相关性、 高噪音、及不确定多值特性的空间聚类方法，并结合领域知识识别有意义的油藏数据划分， 辅助油藏描述和油层识别的等决策。 本项目通过引入网络空间中的空间相关性和空间熵，以及适用于大空间数据Map-reduce的并行数据结构，有效解决空间相关性的描述和计算。同时，将划分看成是数据分布中的模式，并开发基于浸渍实验的递归方法以探测数据分布中的划分，讨论在单变量数据和多变量数上的聚类分析以解决高噪音问题。 然后引入基于使用基于分位数的距离，考虑对象的不确定性和对象之间的相对分布， 解决不确定多值的问题 。最后本项目建立空间聚类和油田数据的本体，和在此基础上提出基于本体的领域知识的空间聚类方法和过程， 同时开发出交互式可视化模型，解决需要大量人工参与的问题。
Web网页时效性评价及其在网页排序中应用的研究	网页时效性评价;时间相关度计算;网页排序;网页重要度计算	Web已成为人们获取信息的主要来源，搜索引擎是获取这些信息的重要途径，但Web上的数据过去与现在、有效与无效并存，这造成检索结果中包含大量过时、失效信息。如何甄别信息的时效性并保证检索结果的有效性成为一个日益重要的研究问题。本项目针对Web网页的特点及信息检索的需要，系统研究Web网页时效性评价及其在网页排序应用中的基础理论和关键技术，主要包括：探讨网页时效性的机理特征，研究时效性度量特征的感知、推断与量化的方法，以及基于多特征的时效性评价方法；研究基于时间的查询理解和分类算法，查询与网页的时间相关度计算方法，时效性敏感的网页重要度计算方法；最后融合以上各项研究成果实现新型的网页排序算法。本项目的最终目标是减少搜索引擎检索结果中的大量过时、失效信息，提高人们获取信息的效率和质量，同时为网页时效性在实时检索、Web信息可信性判别等其它领域的应用研究提供新的思路、理论方法和技术支撑。
面向大规模网络评论文本的产品知识库构建关键技术研究	知识库构建;网络评论;观点挖掘	随着Web3.0迅速崛起，构建结构化知识库作为智能知识服务的重要支撑手段，受到广泛关注。构建特定领域的知识库有助于实现垂直搜索、机器的学习和推理等智能化目标。本申请主要研究产品领域知识库构建的关键技术。产品领域知识库具有知识框架繁杂、更新迅速等特点，使得传统人工构建知识框架方法不适用于产品知识库构建。同时，目前主流知识库主要内容是客观性、确定性的知识。然而，在产品领域，用户对产品的主观性看法具有重要参考价值。因此，主观信息是产品领域知识库不可或缺的重要内容。针对上述特点，本申请以大规模网络评论语料为知识来源，以构建融合观点信息的产品知识库为目标，研究：1）面向大规模网络文本的产品属性框架自动构建方法；2）基于深度语义理解的概率化产品主观信息挖掘方法；3）基于潜在意图分析的虚假评论过滤方法；4）将所构建的产品知识库应用于垂直语义搜索引擎，对以上关键技术进行验证与测试。
位置社交网络中基于用户移动轨迹模式的推荐算法研究	用户行为;信息检索;社会网络;数据挖掘;推荐系统	位置社交网络作为一种新型的社交平台，在方便人们交流和共享信息的同时，也因为用户数量的不断增加，而面临着严重的信息过载问题。因此，如何利用能对信息进行有效过滤的推荐算法来解决这一信息供需矛盾受到了研究者们的广泛关注，成为位置社交网络中具有挑战性的研究课题。目前已有研究成果虽然在一定程度上缓解了信息过载问题，但仍然对能反映用户生活习惯和日常行为的移动轨迹考虑不足，特别是在社交网络的环境下研究基于移动轨迹模式的推荐算法还存在很多空白。本项目从位置感知、移动轨迹模式发现，以及在此基础上的推荐算法的设计三个方面展开研究，旨在通过对用户移动轨迹的深入理解，为用户提供更优质的推荐服务。项目特色在于：把多维社会媒体信息应用在实时位置感知算法中，有效地避免了静态位置感知算法的局限性，为用户移动轨迹的生成提供保证；研究了将轨迹模式和社会关系信息融合在一起的机制，通过深入挖掘移动轨迹模式进一步提高推荐的准确率。
信息多样性和信息摘要的关键问题研究	信息多样性;信息检索;自然语言处理;子话题;信息摘要	如何保证信息的多样性是许多信息处理问题中的共性问题，广泛地存在于信息检索、文档摘要、自动问答、推荐系统、信息网络挖掘等任务中。本课题旨在解决信息多样性中的两个关键科学问题：（1）信息多样性的基本描述单位和度量方法，即什么样内容具有信息多样性以及多样性的程度如何；（2）给定信息需求，如何获得满足信息多样性要求的信息内容摘要，以最大程度地满足所有用户。我们的总体目标是提出描述信息多样性的表示与度量方法，建立统一计算框架使之产生满足多样性要求的信息内容。在这个框架中，不同粒度的信息被统称为"信息单元"，用户需求和信息单元通过子话题空间来描述，信息摘要提供多样化的、结构良好的，多粒度和多模态的内容。为此，我们将研究信息多样性的表示和度量方法；研究信息摘要的组织结构及其抽取方法；建立适用于网络信息处理的考虑信息多样性的摘要算法和理论；研究如何根据信息需求的不同，选择信息摘要的不同表现粒度和不同模态。
基于协同语义计算的社交媒体信息扩散与可信性研究	社会媒体;社会影响力;协同语义计算;信息扩散;信息可信性	以社交网络服务和微博为代表的社交媒体，是人们分享与交流信息的新平台。随着社交媒体的兴起，信息扩散模式发生深刻变化；信息源激增也容易诱发不实信息泛滥，给公共安全带来隐患。因此，社交媒体信息扩散机制和可信性感知问题成为社会关注焦点，是社会计算的前沿科学问题。针对现有研究手段囿于社交网络结构等表层分析的局限，本项目根据用户协同产生的海量内容，对用户、信息的语义属性及其复杂语义联系进行建模。基于对用户和信息的协同语义计算，进一步开展以下研究：研究适用于多用户、多信息复杂情形的社会影响力分析方法；研究信息多通道扩散的分析方法；综合机器智能与群体智能的信息可信性分析方法；研究跨社交媒体的信息扩散、社会影响力与信息可信性的统一分析与预测系统，在典型平台上验证有效性。本项目预期成果将深化社交媒体信息扩散机制与可信性感知的研究，对互联网规模社交媒体的信息组织与管理以及社交媒体时代的中文信息处理均深具意义。
WEB信息融合粒化与聚合技术研究	信息检索;信息提取;粒计算;数据融合;信息聚合	项目旨在通过对信息进行适度粒化与多维聚合，实现对有效信息的同一、可信与显现，以突破各类强大的WEB搜索引擎海量搜索结果淹没、真假难辨、提取困难等难题。 项目针对信息的海量性与计算的复杂性，拟引进b位minwise相似性度量算法、基于GPU并行计算模式及MapReduce云计算与服务框架，结合Web信息粒化与表示模型、信息源的特征度量与可信计算模型，从信源的角度对信息进行有效的去重、清洗及可信标记等静化处理；针对浅层与深度融合的需求特征，研究多维度、多粒度的粒层映射关系模型与多层融合方法，解决搜索结果的统一性与相容性问题，提供对象级、主题级及词级等多级融合技术。 项目将以科技工作者信息为对象开展研究，以验证研究的有效性和实用性。
面向Web主观性文本意见挖掘研究	情感分析;Web主观性文本;意见挖掘;情感词典;评价特征	面向Web主观性文本意见挖掘通过自动的方法对博客、微博、在线评论等Web主观性文本信息进行挖掘和分析。它是智能信息处理、数据挖掘、计算语言学等领域的前沿性课题，通常面临着情感特征空间巨大，有效特征稀疏、情感词典构建困难等问题。本项目主要研究Web主观性文本细粒度意见挖掘、自适应评价特征聚类和领域情感词典自动构建等关键技术。针对细粒度意见挖掘中存在有效特征稀疏和缺乏统一框架的问题，研究基于序列标注学习的融合多级特征的细粒度挖掘模型。针对评价特征聚类中存在的语义关联信息不足的问题，提出基于约束谱聚类的自适应评价特征聚类算法。针对情感词典自动构建中存在的领域依赖性和情感关联信息不足问题，研究如何自动获取领域先验知识和增强候选情感词之间的情感关联信息，提出基于约束标签传递的领域情感自动构建算法，该方法可解决传统领域情感词典构建中需要人工标注领域数据的问题，具有良好的领域适应性。
基于自动选择标注对象的汉语时间语义信息处理方法研究	事件;汉语时间关系;标注对象;自然语言理解	时间语义信息处理是自然语言理解的一个重要任务。目前的研究由于语料库标注一致性低和TempEval评测尚不标准和科学，受到了很大制约。本课题旨在从自动选择标注对象入手，研究有效改进语料库标注质量和克服TempEval评测不足的方法，针对汉语系统地研究时间语义信息处理的理论、方法和技术；重点对影响标注对象确定的关键因素进行测试和分析，探索一种基于关键因素的自动选择标注对象的方法；全面收集和挖掘实际可操作的时间信息表达和传递的规律；研究并实现适合汉语特点的事件时间属性的确定和事件间时序关系识别和推理的方法；谋求在汉语时间语义信息处理技术上有所突破，为进一步建立事件语义链的研究提供新思路和新方法。
基于EMD的复杂声学环境下语音检测与增强	经验模态分解;非线性非平稳信号处理;语音检测;语音增强	话带信号是以语音信号为主，夹杂各种噪声，非线性、非平稳信号。在话带信号中有效的提取语音并对其进行增强会使语音的编码、传输等更加有效并能减少信道的负载。这些都是目前迅猛发展的通信系统（民、军用）所急切需要解决的问题。以往对话带信号的分析都是建立在富丽叶变换基础之上，因此这些分析方法必然受到富氏变换的局限。经验模态分解（EMD）的出现会给话带语音信号的分析注入新的血液。EMD是近几年刚刚发展起来的一种全新的非线性、非平稳时间序列分析方法。本项目主要研究内容如下：.1）半监督回归支持向量机函数估计的方法进行曲线拟合，从中得到更为准确的信号包络，并且能进行预测估计解决端点效应问题； 2）采用信息变差从理论上理论给出模态分离结束依据。采用自适应尺度搜索的方法进行经验模态分解从一定程度上解决模态混叠问题。3）EMD和TEO算子相结合进行语音信号检测；4）EMD结合子空间理论和人耳听觉特性进行语音增强。
基于生理的言语产生动态模型研究	生理;调音模型;言语产生;调声模型;动力模型	研究发音器官在发音阶段的生理特性，研究语言信息从生理层面到声学层面的转换不仅对于认识人类言语产生的生理机制重要的理论意义，而且对于语音参数合成和生理器官合成，以及情感的生理研究都有重要的应用价值。本项目把言语产生过程分为：动力系统、调声系统和调音系统三部分，进行多种生理信号的模型融合，构建言语产生的生理基础模型。主要过程为：1)采集汉语普通话的呼吸、肺部的螺旋CT图像、气流气压、声门阻抗、动态腭位、动态二维X光声道录像和唇形视频信号等一系列生理信号；2)利用编写的生理信号分析程序提取相应的声学和生理参数；3) 利用肺横切面图像、呼吸带和气流气压计,从理论上探讨言语动力的机制问题；4）利用语音、气流和喉头仪信号，建立不同声调的嗓音声源模型；5）利用X光的矢状面声道轮廓和动态腭位横切面的舌腭接触数据，建立动态声道的三维立体模型；6）最终实现语音驱动的言语生理系统。
制造物联乱序事件流复杂事件匹配模型与处理算法的研究	复杂事件处理;乱序事件流;制造物联网;处理算法;匹配模型	制造物联网是实现传统制造过程信息化、智能化的重要手段。由于制造环境多源干忧，制造处理系统异地分布，制造生产过程动态变化等因素影响导致的事件乱序现象势必会影响事件流处理的实时性与准确性。.  本项目开展制造物联乱序事件流复杂事件匹配模型与处理算法的研究，主要包括：研究面向制造物联乱序事件流的有限状态自动机模式共享的复杂事件通用匹配模型，研究质量驱动下缓冲区自适应调节的低时延高准确度的乱序事件处理算法，设计并实现通用匹配模型与处理算法的验证系统。.  本项目将在乱序事件流上的复杂事件通用匹配模型的构建、低时延高准确度的乱序事件处理算法的设计、以及通用匹配模型及处理算法的验证理论与方法的设计与实现等方面形成创新性成果，为制造物联事件流实时高效处理提供理论依据与技术支撑。
融合指代消解和迁移学习的蛋白质交互关系抽取的研究	语义核;蛋白质交互关系;信息抽取;迁移学习;指代消解	蛋白质交互关系的研究是后基因组时代的主要任务，为疾病的诊断、预防、治疗和新药的发现提供依据和启发。目前其文本挖掘的方法主要是从生物医学文献的摘要中抽取关系，但摘要中包含的信息有限，同时指代消解和语料库的领域适应问题都没有得到很好解决，致使抽取的性能较低。本项目针对生物医学文献全文并采用指代消解技术和迁移学习方法进行蛋白质交互关系抽取。内容主要包括：1.蛋白质名识别及标准化；2.建立基于全文和针对蛋白质交互关系的指代消解模型；3.选择句子级和篇章级特征，组合含有领域知识的语义核建立基于全文的关系抽取模型；4.引入迁移学习思想并与主动学习相结合，解决蛋白质交互关系抽取中的领域适应问题。最终获得高性能的蛋白质交互关系抽取模型。并与领域专家合作，构建肝癌的蛋白质交互关系数据库及可视化，为肝癌的研究提供分子生物学知识，同时验证蛋白质交互关系抽取模型的真实有效性。
面向真实环境的异构信息交互式问答理论与方法研究	多模型融合;真实环境;交互式问答;异构信息整合	交互式问答作为新一代信息服务技术越来越受到研究者的广泛关注，尤其是Siri和Watson等系统的成功为人们展示了自动问答系统的广阔发展前景。但在面对真实环境时，往往需要充分利用不同形态、不同结构以及不同来源的信息，用户也会进行多次有关联的提问来获得更加准确的结果，在这种情况下，现有交互式问答技术还难以获得较好应用。为此，本项目提出一种面向真实环境的异构信息交互式问答模型：通过基于上下文语境的问句理解，确保用户以自然语言方式与系统进行连续的信息交流；建立面向真实环境的自适应模型以满足多样化和个性化的信息需求；为扩大解答问题的范围并提高答案可信度，系统采用整合的海量异构信息作为知识源，并利用多模型融合算法提高关键模块对真实问句处理的鲁棒性；同时针对交互过程建立客观、可量化的评测体系。项目的实施将为网络信息处理、人机交互、语义计算、文本聚类与分类等领域的研究与应用起到积极促进作用。
基于Markov逻辑网络的限定领域中文自动问答系统研究	知识库;信息检索;Markov逻辑网络;自动问答系统;限定领域	自动问答系统是人工智能和信息检索领域热点研究方向之一。它接受用户用自然语言提出的问题，然后返回该问题的答案。目前由于开放领域问答系统的研究主要针对单一的、孤立的、基于事实性的问题，并且答案准确率也比较低，对于复杂问题更是难以处理，因此陷入了一定瓶颈。相反在限定领域中，自动问答系统蕴含着巨大的应用价值。由于可以利用领域知识，限定领域自动问答系统可以处理一些复杂问题并提高答案准确率。本课题以限定领域中文自动问答系统作为研究目标，提出以Markov逻辑网络为基础构建领域知识库，并且利用Markov逻辑网络的逻辑和概率两重特征，很好地将信息抽取、知识库查询和答案生成多个环节有机的联系到一起来，并构成自动问答系统。本课题的研究可以极大地推动了相关技术（知识库表示、逻辑推理、信息抽取、句法分析和实体名识别等）的发展，并促进研究与应用的紧密结合。
面向互联网新闻事件的演化式摘要研究	演化式摘要;动态演化;冗余控制;篇章连贯性;多文档自动文摘	面向互联网新闻事件的演化式摘要是自然语言处理的一个新兴任务，其本质是多文档自动文摘。由于互联网新闻事件报道具有动态演化、内容关联和信息重复等特点，面向互联网新闻事件的演化式文摘与传统文摘相比存在诸多不同。本项目将重点研究面向互联网新闻事件的演化式文摘，重点解决其存在的信息冗余度高、篇章连贯性差和缺乏动态演化等关键科学问题。基本思想是，在降低文摘信息冗余的基础上，保证抽取的摘要具有动态演化性且前后连贯，可读性强。基于此，本项目首先提出了一个冗余度控制模型，通过使用不同文本单元之间的相似度来综合考虑文摘的各种特性，融合代表性、信息性和多样性，并使用一个层次化主题模型来形式化表示多粒度文本单元。其次，提出一个基于篇章衔接性理论的文摘连贯性模型，通过使用该模型来指导文摘排序，增强摘要的连贯性。最后，提出一个基于层次话题结构的动态演化模型，按照内容演化趋势来指导摘要的抽取。
滑动窗口上数据流副本近似检测算法及其空间复杂度下界研究	空间复杂度;副本检测;数据摘要结构;数据流	滑动窗口上数据流副本近似检测算法是通过构建高效的内存摘要结构来存储当前滑动窗口中的数据信息，以达到仅需单遍扫描就能近似回答查询元素是否在当前窗口中出现的目的。本项目的研究内容为：基于通信复杂度理论，研究滑动窗口上副本近似检测问题的空间复杂度紧下界；基于随机过程理论，研究数据流摘要结构和近似检测算法。项目将从三个方面开展研究工作：给出任意一个确定性数据流副本近似检测算法所需空间的紧下界，前提条件是给定滑动窗口大小、用户允许的错误率、数据流元素和查询元素分布；设计出一种空间复杂度近似为紧下界的确定性数据流副本近似检测算法；设计出一种可以高效存储并返回非确定性数据流中概率信息的副本近似检测算法。本项目的理论结果将为衡量数据流副本检测算法的空间性能提供可靠的理论依据，本项目设计的算法可直接应用于网络数据检测系统中，能在节省存贮空间的同时提高检测的效率。
文本分类中的文本图表示模型和结构化稀疏模型研究	文本图表示模型;稀疏模型;文本分类	文本分类是自然语言处理研究中的一个经典问题。文本分类技术在网络舆情分析、专利分析等领域具有广泛的应用。本课题针对目前文本分类研究中文本表示模型表达能力不足，分类模型不能充分利用结构化信息等问题，研究基于文本结构化表示的结构化稀疏模型。首先，探索研究结合词法、句法、语义及篇章信息，能够蕴含多层次结构化信息的文本图表示模型；其次，基于文本结构化表示的特性，提出能够针对文本图表示的结构特性，将特征选择和模型学习相融合、具有高压缩性、可解释性等良好性质的结构化稀疏模型；给出结构化稀疏模型优化学习算法；最终基于上述理论成果，构建高性能的文本分类系统。本项目的研究成果将对自然语言处理中涉及结构化特征选择和分类模型的任务提供广泛的借鉴意义。本项目可望在重要的国际国内期刊、会议上发表高质量论文5-8篇，申请发明专利2-3项，研制开源平台系统1个，培养学生5-8名。
基于隐含知识挖掘与时间敏感的知识图谱补全关键技术研究	知识库构建;文本挖掘;知识获取;实体关系抽取;知识图谱补全	在互联网智能化时代，知识图谱是支撑内容理解、智能搜索、自动问答、机器翻译等应用的知识基础。本申请针对知识图谱不完备性问题，研究高效准确的知识图谱补全关键技术。通过隐含知识挖掘和时间维度拓展这两方面对知识图谱本身蕴含的信息进行深入挖掘和充分利用。前者通过基于嵌入式表示的关联规则挖掘方法，在低维语义空间中对于实体关系以及逻辑规则等知识元素进行隐式表示和学习，进而，基于马尔科夫逻辑网对隐含知识进行概率化赋值，以扩充知识图谱。后者将实体关系的关联建模拓展到时间维度，通过融合时序信息和持续时间的联合模型提升知识图谱补全任务的性能。其中，基于时序信息的嵌入式模型假设时间敏感的关系之间具有时序依赖性，其分布式表示可随时间演进而转换，进而将关系时序信息有效编码到知识表示的向量空间；基于持续时间的模型提炼多项时间约束条件，利用整数线性规划进行全局推理和预测。本研究将为大规模知识图谱构建提供关键技术储备。
规则与统计相结合的现代汉语虚词用法自动识别研究	虚词用法自动识别;现代汉语虚词知识库;虚词用法语料库;虚词用法词典;虚词用法规则库	与其它语言相比，汉语虚词在现代汉语中承担着尤其重要的语法表现和语义辨析任务。一般地，在句子中用错一个实词会造成一个词汇理解的错误，而用错一个虚词往往会造成整个句子甚至篇章的理解错误。因此，对现代汉语虚词用法的自动识别研究，将有助于现代汉语精确的机器理解，促进中文信息处理的相关研究。.现代汉语虚词的研究历史悠久，成果丰富。但是目前已有的虚词研究成果大都是面向人用的，很难直接应用于自然语言处理的研究。申请人从计算语言学的观点出发，根据目前汉语虚词知识的研究成果以及对《人民日报》中虚词用法的真实分布信息，着力改进现有的现代汉语虚词知识库，通过附加概率信息的虚词用法规则库，并利用ME、SVM以及CRF等统计模型，探讨规则与统计相结合的现代汉语虚词用法的自动识别。本项目研究成果可直接应用于机器翻译、信息检索、信息抽取、文本情感计算等自然语言处理领域，为中文文本内容的机器理解提供数据基础和技术支持。
异构信息互动模型中的关键技术研究	异构信息;领域知识挖掘;时间序列预测;互动模型	网络信息已成了人们不可或缺的信息源，但其非结构化、来源分散等特点使得深层网络信息处理技术发展缓慢；同时，人们还拥有采用结构化存储的量化数据库，与网络信息相比，其具有结构化、精确化、来源稳定等特点。目前，这两个领域的研究还处于相互独立的状态，由于量化数据的精确性，使它在重要的时间序列预测中起到决定性作用。但单纯基于结构化数据的时间序列预测模型很难预测到在互联网上发布的各种事件或消息对时间序列的突变性影响。为此，项目引入了文本信息影响度计算方法，并通过与传统预测算法融合，建立了基于异构信息的时间序列预测模型。同时，根据预测误差简洁、准确、便捷等特点，建立了基于误差反馈的领域知识发现与模型优化算法，从而为这两种信息之间的相互作用建立起了一个互动模型，并在金融领域建立一个股票价格预测原型系统，用于模型的验证与推广。项目除了为时间序列预测提供了新的方法，也为语言学知识挖掘做出了有益探索。
面向流式大数据检索的增量哈希学习方法研究	哈希学习;流式大数据;增量学习	针对海量动态增长的流式数据，现有哈希学习方法无法随数据变化自适应更新学习模型，并且需要消耗大量的存储和计算资源，致使检索的效率和精度难以满足实际需求。本项目面向流式大数据的高效索引和快速查询，基于流式数据的无限性、时效性和时变性等特点，研究增量哈希学习理论和方法，从精度和效率两个方面提高哈希最近邻搜索的性能。主要研究：（1）深度在线哈希模型，研究流式数据演化规律，建立哈希函数在线更新规则，提高哈希方法的学习效率；（2）自适应多哈希表构造方法，研究多哈希表相关关系，建立自适应更新的多哈希表框架，提高在线哈希模型的检索精度；（3）增量式哈希码扩展方法，研究哈希码互补准则，设计哈希码扩展方法，增强哈希学习模型的可扩展性。研究成果将丰富和完善哈希学习的基础理论和方法，同时为哈希学习技术在多媒体信息检索、大数据挖掘认知和社交网络舆情分析等领域的应用提供技术支撑。
融合知识图谱的文本个性化推荐机制研究	实体表示学习;知识图谱;协同过滤;主题模型;推荐系统	文本个性化推荐系统是缓解大数据时代文本信息过载的主要方法，是信息检索领域的热点研究问题。由于现有基于主题模型的文本内容分析方法仅对文章语义进行粗粒度分析，使得文本推荐算法对用户细粒度偏好描述不准确，并难于为用户匹配长尾内容，影响推荐效果。本课题拟利用知识图谱中丰富的实体关系，解决上述问题，形成融合知识图谱的文本个性化推荐系统。具体研究内容包括：（1）通过实体嵌入表达与文本实体主题表达的协同学习，进行文本内容实体主题分析；（2）通过文本实体主题分析与低秩分解的协同学习，进行个性化实体偏好分析；（3）通过非线性迁移函数与低秩分解的协同学习，进行跨领域个性化实体偏好迁移分析；（4）通过面向嵌入表示的张量分解，进行个性化实体时序偏好分析。面对文本信息过载，本课题将有力改善用户体验，增加媒体商业价值，并为大数据平台积累更多资源，形成良性循环。
自然场景中多模态图像内容的文本描述方法研究	多模态图像内容文本描述;迁移学习;递归神经网络;场景自适应;跨语言	随着可拍照移动智能终端的广泛使用和互联网的快速发展，对自然场景中多模态图像内容文本描述的研究和应用显得日益重要。目前多模态图像内容文本描述技术广泛应用在图像检索、图像分类和网络图像分析等场景中。然而，由于多模态图像中的图像模态和文本模态的异构性导致语义的不可度量，使得传统方法不能直接适用于多模态图像内容的文本描述。本项目针对自然场景中多模态图像内容文本描述的关键技术问题进行研究，提出解决的方法和算法。主要研究内容包括：（1）基于场景自适应的文本检测方法和多信息融合的文本识别方法；（2）融合图像视觉特征和文本语言特征的多模态图像内容文本描述方法；（3）基于多尺度上下文图像标注的多模态图像内容文本描述方法；（4）基于深度迁移学习的多模态图像内容的跨语言文本描述方法。本项目研究成果将促进多模态图像内容理解相关技术的推广与应用。
面向异构Web信息源的语义知识获取和融合关键技术研究	语义知识融合;知识库构建;信息抽取;语义知识获取;语义关系抽取	语义知识是自然语言理解的基石，是实现文本各个层面智能分析的基础，其核心是概念与概念之间的语义关系。然而由于人工编写方法受制于专家构建的时间，低估了语义知识的复杂性和规模，大规模语义知识的缺乏一直是高性能自然语言处理的关键瓶颈。为此，本课题研究面向异构Web信息源的语义知识库构建，包括语义知识的表示、获取及融合方法。研究内容和创新之处包括：1.提出大规模语义知识结构化表示模型-大规模异构概念语义网络，为Web环境下语义知识的表示、存储、推导和计算奠定基础；2.面向大规模异构Web信息源，以面向开放领域、自学习的信息抽取方法为技术手段，以自动语义知识获取和多源语义知识融合为重点研究内容，探索大规模语义知识库的自动构建，推动当前"语义知识瓶颈"问题的解决; 3.以高精度文本检索任务为平台，展示并验证了语义知识的应用。
信息检索中基于用户检索历史挖掘的个性化查询自动补全方法研究	信息检索;查询意图分析;查询自动补全;个性化	查询自动补全是主流搜索引擎的重要服务之一，即在用户输入少量查询字符时，推荐给用户一组可选的查询短语，帮助用户构造查询，从而减少用户构造查询的时间。本项目将研究选择性个性化查询自动补全方法、基于机器学习的个性化查询自动补全方法和个性化的查询自动补全多样化方法。选择性个性化查询自动补全方法将着重分析用户的查询、网页点击等行为，识别用户实时信息查询意图，动态地将个性化嵌入传统的查询自动补全模型。基于机器学习的个性化查询自动补全方法将着重分析特定用户在当前信息检索会话中的行为数据，提取查询自动补全短语与用户行为数据信息之间的个性化语义特征，构建个性化查询自动补全模型。个性化的查询自动补全多样化方法将根据查询自动补全短语与文档的双向关系图，获取查询短语的主题与相关度标记，建立查询自动补全短语的主题概率分布，提出基于贪婪算法的个性化查询自动补全多样化方法，实现查询自动补全短语的准确排序和主题多样化。
基于引用模式分析的学术影响力研究	学术影响力;信息检索;信息计量;科研评价;引用模式	以往的学术影响力研究集中在使用简单数量指标进行学术影响力评价，关注学术影响力本身的研究较少，对学术影响力的发展变化规律的研究尚未见报道。申请人在研究中发现，引用模式分析是学术影响力研究的有效手段。引用模式分析可从整个学科领域或者更大的范围内动态考察学术影响力，解决以往研究中存在的所有引文同等权值、合作作者同等权值、简单孤立处理单次引用、未充分考虑时间变化等重要问题。本项目从引用模式分析入手，以特定学科领域为对象，主要采用文献计量、隐语义相似度分析、基于概率图模型的引文分析、聚类分析、社会网络分析等多种方法，深入研究学术影响力的概念、特征、指标等，挖掘引用模式与学术影响力的关系，进而重点研究学术影响力的发展规律和变化趋势，确定学术影响力的影响因素，构建多层次研究主体的学术影响力评价体系。在此基础上，研究归纳出学术影响力的提升策略以及改进我国科研主体的学术影响力评价体系的新方法和新途径。
面向网络知识服务的中文动态语义分析关键技术研究	知识库构建;语义标注;知识验证;网络知识服务;动态语义	网络知识服务作为新一代信息检索技术的发展方向,能够为用户提供更加灵活、准确、可信的信息检索服务，而适度语义知识的引入及准确、规模化的应用，则是其得以实现的前提。但现有的语义知识库无法根据互联网上的海量信息来反映词条当前环境下的语义变化，从而限制了语义知识在信息检索中的作用。为此，项目在现有语义知识库的基础上，以交互式开放语义知识库构建为起点，通过语义知识库与大规模网页信息的交叉与互动分析,建立基于大规模网页库的知识验证和语义动态特性分析方法，进而建立起一个大规模的、具有快速更新与动态适应能力、语义标注较为准确的语义知识库。并探索将动态语义应用到查询扩展与检索算法、网页自动语义标注方法和检索结果在线聚类算法。通过上述算法的研究,建立起一个可行的动态网络信息语义计算框架，大大提高检索的准确率与查全率，为网络知识服务的实现打下坚实基础，为促进自然语言处理在智能信息检索中的应用做出积极贡献。
社交文本流中的实时事件监测和摘要	事件监测模型;实时处理;社交文本流;事件摘要框架	Web 2.0的快速增长，用户不仅能被动地获取信息，还能够通过在线社区积极参与和表达自己的观点和意见。特别是博客和微博客网站（例如 Twitter，内容短小，可通过电脑、手机、PDA等发布）为网民提供了一种简单快捷的平台，便于交流信息、开展辩论，并形成社交团体和网络社区。社交文本流汇集民众当前观点和意见的即时信息，对于商家、情报分析员和政府是很有价值的。本项目的目的是研究针对社交文本流的通用事件监测模型和事件摘要算法，实现快速有效地发现并摘要事件。更具体地说，我们的研究目标是：1) 事件监测模型：设计一个针对社交文本流的通用事件监测模型2) 事件摘要框架：提出一套新的从社交文本流中摘要事件的框架。概括事件不仅包括事实，而且有事件的社会影响 。3) 实时处理：开发智能搜集系统，以及将事件监测和摘要算法分布并行化，达到面对海量社交文本流能够有实时事件发现和摘要的能力。
动态演化在线系统中的信息推荐问题研究	推荐系统;网络骨架;复杂网络;协同演化;趋势预测	推荐技术的研究在理论和应用层面都有着重大的意义和价值。现有研究主要集中在静态系统的推荐算法，考虑单步推荐的准确性，而实际的推荐系统是动态演化系统。本项目使用二部图来刻画在线推荐系统，从网络演化分析入手，来研究系统动态发展过程中的信息推荐问题。首先，将系统研究网络结构对推荐效果的影响，提取决定推荐效果的网络信息骨架，并设计基于网络的动态调整方法来优化推荐过程。其次，将通过考察推荐系统和推荐网络的协同演化过程，设计具有长期优势的在线推荐算法，不仅满足个体需求，同时优化整个系统。第三，项目还将研究推荐算法的个性化使用问题，探究不同算法的最适用用户群，为不同的用户及其在系统的不同阶段设计最恰当的推荐算法。最后，项目将研究演化推荐网络中的趋势预测问题，力求通过微观的推荐过程来预测宏观的商品流行性演化。项目将不仅在理论上填补信息推荐系统的动态演化研究的空白，而且在实践中能提高推荐系统的长期效果及效率。
面向开放域知识网络的实体语义关系抽取方法研究	实体消歧与链接;知识库扩充;实体关系抽取;抽取质量控制	面对日益膨胀的网络信息资源，"大数据"所带来的压力已逐步逼近；大规模语义知识资源的构建和组织已成为分担这种压力的有效手段。然而现有的信息抽取技术受困于大量人工标注数据而显得力不从心。本项目的核心是在这种大规模语义资源的构建和应用过程中，如何从海量非结构化文本数据中高效的抽取实体间的语义关系。我们首先借助于全局优化方法对分阶段优化的实体消歧与链接问题进行重新建模，并提出了一种离线估计与在线链接相结合的快速实体链接方法。同时，在弱监督学习框架下设计了"单句抽取—多句融合"的两步语义关系抽取模式，并利用多约束的全局优化方法为大规模语义知识资源自动抽取实体关系数据，并提供相应的数据质量评估手段；此外，我们还将探索利用新闻事件分析促进结构化知识资源的动态更新。
基于知识图谱的社交媒体大数据主题发现与趋势预测关键问题研究	主题演化;主题发现;知识图谱;大数据;社交媒体	社交媒体大数据中蕴含着丰富的信息资源，这使得人们能够更有效地发现深层主题以及预测其未来的发展趋势。然而由于社交媒体大数据所具有的多模态、碎片化程度高、强关联和高噪声等特性，使得现有方法在可用性、准确性、时效性与自适应能力等方面存在较大的不足。为此，本项目拟以"理论分析→数值计算→应用验证"为思路展开研究，首先自动化构建与优化大规模概率知识图谱，并将其作为主题发现与趋势预测的语义基石；其次，充分利用多阶张量表示的优点，提出社交媒体大数据的一体化张量表示理论及方法，在此基础上，构建时序层次特征模型进行多粒度特征建模，并借助深度学习技术有效提取社交媒体大数据的深层特征；从而利用概率知识图谱所隐含的数据语义信息以及强大的语义推理能力来实现深层次主题的发现与发展趋势的精准预测。我们预计，本项目的研究成果将在社会公共安全、电子商务、民众医疗健康和互联网深度信息服务等领域发挥重大作用。
基于网上弱标注数据的个性化图像标注研究	弱标注训练数据;自动图像标注;图像检索;个性化;用户	自动图像标注对于用户管理和检索不断增加的图像数据至关重要。现有工作专注于构建通用型图像标注模型，即以一个模型应对所有用户。这种一对多的图像标注模式忽略了不同用户在特定情境下对于特定图像主题的偏好，使得标注准确性受到了根本性的制约。为了满足不同用户对于图像标注的个性化需求，本项目研究一个模型对应一个用户的图像标注新模式。为此，我们提出基于网上弱标注数据的个性化图像标注方法。为了突破训练数据获取的瓶颈，我们研究如何从普通用户在互联网上产生的大量弱标注数据中为特定语义标签选取相关正样本和负样本，以建立大规模通用型图像标注模型。进一步，我们研究从用户历史数据中动态挖掘其个人偏好，并结合图像产生时所处的包括地理、天气等上下文环境信息，对通用型图像标注模型所预测的标签进行个性化的优化排序，从而为每个用户提供可量身定制的自动图像标注模型。本项目的研究成果将为个性化的多媒体信息检索提供技术支撑。
海量实时动态文本流在线主题分析研究	动态文本流;在线学习;主题解释;主题建模	针对传统主题分析技术在本文流的动态性描述和快速处理上面临的挑战，设计有效适应文本流内在特性的快速主题分析方法已成为主题建模领域研究的热点。而现有方法存在刻画文本流动态规律片面、学习算法效率亟待提高、主题解释算法复杂度过高等问题。为此，本课题拟从准确性和效率两个角度深入研究并改进动态文本流的在线主题分析方法。首先，通过层次狄利克雷随机过程和布朗运动等数学模型刻画文本流的主题个数变化、主题演化和词汇变化等动态特性，并通过生成模型方式将这些动态特性与主题模型基本组件进行有机结合，达到准确地刻画了文本流内在规律的目的；其次，通过设计减小梯度下降方向方差的方法提升主题模型在线学习算法效率；最后，通过将主题解释问题转化为概率分布空间中K最近邻查找问题，以准确而高效地解决主题解释算法复杂度过高的问题。通过上述工作，将有效地提升文本流主题分析的准确性和效率。
面向机器翻译的多层次文本嵌入表示学习研究	机器翻译;深度学习;文本嵌入表示;循环神经网络	在机器翻译任务中，文本嵌入表示学习对缓解数据稀疏和使用深层次语义知识具有重要意义。然而，现有研究面临着双语文本嵌入表示学习难度大，不同层次文本之间语义关系不易建模的难题。对此，本项目拟对如何利用多语言多层次语义信息来学习面向机器翻译的文本嵌入表示展开深入研究。项目主要工作包括：（1）基于图结构的双语词汇嵌入表示学习；（2）基于双向注意机制的双语短语嵌入表示学习；（3）基于词图的长短时记忆神经网络句子嵌入表示学习；（4）融入主题信息的层次循环神经网络文档嵌入表示学习；（5）引入多层次文本嵌入表示的机器翻译建模研究。项目充分发挥了深度学习的优势，它的开展将为如何更好地利用文本嵌入表示学习来解决传统机器翻译面临的瓶颈问题提供一种新的思路，对机器翻译的研究发展和产业化应用具有重要意义。
基于多源信息融合的元数据自动抽取方法研究	元数据;信息抽取;数字图书馆	如何从非结构化或半结构化文本中自动获取元数据信息，即元数据抽取问题，是当前数字图书馆乃至整个信息服务领域的研究热点与难点之一。现有方法仅依赖文档本身的内容信息，难以逾越信息缺失与自身内容错误等障碍，不可避免地要引入大量人工审校,对抽取结果进行修正和补全。为此，本项目拟研究基于多源信息融合的元数据抽取方法，通过挖掘文档和外部数据的关系，构建多来源元数据信息的搜集与融合机制，充分发挥外部数据对抽取结果的修正与补偿作用，实现元数据的准确、全面抽取，突破现有方法的局限性。具体地，本项目将围绕种子元数据的生成、外部元数据的搜索、多源元数据的融合等关键问题，研究基于组合优化策略的种子元数据抽取方法、具有自适应性的元数据搜索策略、基于能量最小化模型的元数据信息融合算法、基于统计反馈的数据源质量评估体系等，为元数据抽取提供一个新的手段。其研究成果将大幅度提高元数据采集技术的自动化水平。
基于深度学习的满文文档图像检索关键技术研究	卷积神经网络;文档图像检索;生成对抗网络;满文;字定位	以深度学习为主要方法,研究满文文档图像的字定位检索关键技术。1设计级联条件生成对抗网络，对满文字体风格迁移和图像质量退化原理建模；以类别标签为条件变量，人工合成数据为网络输入，生成质量退化的不同字体满文单词图像样本，满足深度学习对样本规模、数量均衡度和多样性的要求。2采用卷积神经网络学习满文查询词图像特征表示，避免浅层特征的主观性和局限性；为了解决卷积神经网络输入尺寸固定而满文单词长度变化大的矛盾，实现任意尺寸满文单词的深度特征表示，设计具有空间金字塔采样层的卷积神经网络；采用第1步级联条件生成对抗网络产生的满文单词图像作为训练数据，以检索系统性能为依据，通过实验手段优化卷积神经网络的超参数，最终确定满文查询词图像的深度学习特征表示法。3针对满文历史文档图像特点，融合连通域分析和机器学习等方法研究满文文本列和满文单词的提取方法。4采用度量学习获得相似性度量准则实现查询词图像深度特征匹配。
结合用户间相互关注的个性化APP图推荐模型研究	图推荐模型;互指导相关度计算;应用推荐列表构造;个性化应用推荐	随着智能手机的广泛普及，手机应用（APP）如雨后春笋般涌现。面对数量如此众多的手机应用，如何让用户获得满意的应用已经成为各大门户网站竞相研究的热点。然而，迄今为止，普遍采用的应用推荐方法仍是首先计算应用和用户兴趣标签的匹配度，然后将匹配度大的应用推荐给用户。此种推荐方式有三个问题：1，推荐的应用重复度很大；2，无法发现用户隐含的兴趣爱好；3，无法将具有相关性的应用一同推荐给用户。上述问题存在的核心原因是缺乏一种有效的应用间相关度计算方法，同时缺乏有效的手段能够自动获取用户的兴趣爱好。针对以上问题，本项目研究了面向手机应用的个性化图推荐模型构建问题，该模型以应用间的相关度计算结果为基础，同时通过结合用户间的相互关注能够挖掘出用户隐含的兴趣点进而向用户推荐更加适合的应用。借助腾讯公司提供的应用宝数据，本项目还能够利用用户的行为数据（包括用户的点击、下载、评价行为）进一步提升推荐模型的准确度。
面向短文本理解的带约束语义文法自动学习方法研究	短文本理解;语义解析;文法学习;文法评价;约束学习	短文本理解是口语理解、语义搜索等应用的核心技术之一。短文本通常具有不符合书面语法、语境少歧义多等特点，本课题拟在已构建的一个基于领域本体和带约束语义文法的自然语言理解系统基础上，进一步研究和实现语义文法自动学习方法，包括：拟研究一种文法规则自动扩展学习方法，首先利用核心文法对解析失败句子进行部分解析，基于部分解析树预测顶层节点及子节点，基于相似性度量等进行规则扩展并构建完整解析树，经过垂直概化和平行概化处理后得到新文法规则；针对文法歧义问题，拟研究一种文法约束自动学习方法，将其看作一个ILP学习问题，通过改进搜索策略、约束搜索停止准则、约束学习停止准则等以保证高效地学习到可以覆盖尽量多正例且覆盖尽量少反例的约束；为了保证文法学习质量，拟研究基于文法规则扩展集的冗余检测和歧义检测方法以及基于约束划分效果和约束复杂度对文法约束进行评价。
基于中文文本挖掘技术的SIPO专利知识演化分析	本体构建;机会发现;语义检索;社会关系网络;信息抽取	专利是技术知识最有效的载体，专利知识演化图谱的构建将会极大地提升专利的应用价值。项目的宗旨是：综合运用文本挖掘技术，从知识主体和知识客体两个视角，进行面向专题的专利知识演化分析。首先，对于给定的用户需求，构建相应的领域本体，用于术语识别和查询扩展，检索国家专利数据库SIPO，建立专题数据库；然后，给出专利的逻辑表示，定义专利知识的细粒度表示<Feature,Effect>、<Effect，Value>,利用命名实体识别、属性抽取、语义标注等技术，填充专利的Feature、Effect和Value值框架，将非结构化信息转化为可以量化的知识单元。在专利知识相似度和新颖度基础上进行专利的主题聚类；最后，构造基于知识主体的竞争网络和基于知识客体的共词网络，按照时间维度，研制专利知识演化图谱，进行热点专利识别、专利机会发现和专利趋势预测，建立可视化的专利挖掘平台。
多领域网络文本数据的自适应结构化分类方法研究	结构化分类;多领域数据;自适应;网络文本	网络文本数据来自多个不同的领域，形成了一个领域高度多元化的文本数据集，给自然语言处理带来新挑战。现有结构化分类技术在领域多元化的网络文本数据上缺乏跨领域的自适应学习能力。为了解决此问题，本项目拟研究多领域网络文本数据的特点，提出具有自适应能力的结构化学习方法。主要研究内容如下：（1）把每个领域作为一个和其他领域相关的任务，研究多任务学习技术用于处理多领域网络文本数据。该方法对领域关联度进行自适应学习，从领域相关性自动建模的角度处理跨领域的网络文本。（2）把领域特性作为任务的隐含信息，研究条件隐变量模型对多领域数据的自适应处理能力。该方法对领域的隐含信息进行统一建模，从而能够自动融合多领域数据，实现高效的结构化分类目标。（3）不管是多任务学习还是条件隐变量模型，处理多领域网络文本都面临复杂度高、速度慢的问题，我们研究高速的优化算法解决这个问题。
基于移进归约算法的细粒度意见挖掘	情感分析;意见挖掘;移进归约;深度学习;结构学习	细粒度意见挖掘的目的是抽取句子中的意见或者观点，并分析出其详细的意见要素信息，例如情感极性，意见持有者和意见对象等等。这些信息能够极大的方便用户决策，因此细粒度的意见挖掘对很多实际应用都有着非常重要的价值。过去的方法一般将这一任务进行分解得到若干子任务，然后采用分类或者序列标注的方法来分别进行处理，这类方法面临的主要问题是局部特征局部优化问题。本项目拟将基于移进归约的算法应用在这一任务上，不仅可以使得全局特征能够被充分的使用，而且能够将它所包含的所有子任务进行联合的分析，这样便缓解了过去方法所面临的主要问题。本项目拟从建模、特征和数据三个角度来对基于移进归约的细粒度意见挖掘算法进行展开研究，最终目的是实现一个能满足实际应用需求的高性能的意见挖掘系统，并且在移进归约算法层面上也有一定的贡献。
基于语法制导的汉语语法、语义一体化深度分析技术研究	语法制导;语法分析;深度学习;一体化;语义分析	自然语言处理极其重要，而且任重而道远。自然语言处理方法一般分为理性主义和经验主义两大流派，大部分方法尚停留在规则或数学统计浅层学习层次，虽然取得了很大的成绩，但还是远远不够的。本项目的研究目的，就是希望探索一种"深层学习"的方法，把语义知识准确抽象，构建一套语义知识库，借鉴语义学的研究成果来设计知识的结构和组织形式，使得定义的语义知识和语法规则融合在一起，模拟人类联想、推理、纠错的深层学习方法。语法知识是关于语言结构的知识，语义知识则是关于世界的知识。它们各成体系，相互依赖，不可分割。通过对汉语语法和语义的特点及其之间关系的研究，建立语法、语义一体化分析框架，解决现有语言分析中语法、语义分析分离的问题，使分析结果更准确地反应语言描述的内容。把构建的知识库与计算机高速计算耦合起来，改变语义知识零散孤立的状态，把语法、语义和语用三个方面知识融合在一起，最终归结为语法、语义的一体化研究。
面向视障用户的网络信息智能化处理关键技术研究	智能信息处理;信息检索;协作推荐系统;信息无障碍;视障用户	由于技术原因，目前视障用户无法或者不能完全利用互联网获得所需信息。本项目以研究面向视障人士的信息处理技术为基础，以他们的网络浏览认知实验为辅助，实现网页信息的智能化处理，为视障人士提供上网查询和浏览信息的快捷、准确方式。在本项目研究中，我们致力于解决面向视障人士网络信息智能化处理研究领域存在的一些难点，即通用网站的浏览导航问题和基于情景的知识呈现问题；同时我们将协作推荐系统原理和视障用户认知行为相结合，探讨面向视障用户的浏览路径的推荐问题，为进一步研究网络信息无障碍开拓新的思路。该项目的成功实施，将对面向视障用户的网络信息智能化处理研究产生积极的影响，使中文网络信息无障碍研究达到国际先进水平。在更大范畴内，该研究对现有的协作推荐系统理论进行补充和扩展；其研究成果还可以广泛运用于网络数据挖掘，提高搜索引擎性能，优化网站设计等诸多领域。
面向图像检索的互补哈希表构造方法研究	多特征;最近邻搜索;互补哈希表;图像检索;局部敏感哈希	基于局部敏感哈希的多哈希表方法能够显著提高图像检索的效率和整体性能，是海量图像检索等应用的关键技术之一，同时也是目前基于哈希的图像检索的研究热点之一。然而，目前多哈希表方法中影响其整体检索性能的因素还有待深入研究；同时，图像关联的多种视觉和语义特征也未能在其构造中有效综合利用。针对上述问题，本项目将建立互补哈希表的构造准则，结合图像检索，系统地研究集成多视角信息的互补哈希表方法。在理论层面上，分析高维数据最近邻分布特性，研究影响互补哈希表性能的主要因素，建立多哈希表的互补性准则和配置优化准则。在技术层面上，自适应融合图像多种视觉特征建立互补哈希表，提高非监督情形下多哈希表的鲁棒性和检索整体性能；基于语义标签和哈希表的稀疏关联构造语义适配的互补哈希表，提高哈希表对语义近邻的分辨能力及多哈希表自适应查询能力。本项目最终将针对图像检索建立互补哈希表的构造体系和方法，有效提高图像检索的整体性能。
面向互联网舆情分析的文档自动摘要关键技术研究	情感摘要;跨语言摘要;文档自动摘要;动态多文档摘要;多媒体摘要	文档自动摘要在互联网舆情分析系统中有着重要地位，而面向互联网舆情分析的文档摘要具有动态性、跨媒体、跨语言与情感相关性等特点，传统文档自动摘要方法无法满足这些要求。本项目以对传统文档自动摘要方法的研究成果为基础，提出并解决动态多文档摘要、多媒体摘要、跨语言摘要以及情感摘要这四种新颖的摘要问题。本项目争取有学术上的突破，同时，研究成果将应用于互联网舆情分析系统，方便用户加强对互联网舆情信息的监控和管理。
基于翻译学习和核方法的中文模糊限制信息检测研究	核方法;中文模糊限制信息检测;迁移学习;翻译学习	作为信息抽取的一个重要环节，模糊限制信息检测旨在区分不确定信息与事实信息，避免将模糊限制信息作为事实信息用于信息抽取。近年来，英文模糊限制信息的检测已取得了阶段性研究成果，中文模糊限制语广泛用于中文各个领域，开展中文模糊限制信息检测的研究对于中文事实信息抽取具有重要意义。本项目首先针对生物医学文献，基于英文标注数据，采用翻译学习方法，训练中文模糊限制性句子识别模型，实现跨语言学习；然后采用迁移学习方法，将从中文生物医学文献学习获得的模糊限制性句子识别知识迁移至向其他领域，实现跨领域模糊限制性句子识别；设计并构建中文模糊限制信息语料库；抽取平面特征和句法、语义的结构化特征，使用多项式核和卷积树核的复合核，建立模糊限制信息范围检测模型。跨语言、跨领域的模糊限制性句子识别研究，将为自然语言处理中知识的迁移、推广提供理论基础和方法支撑；研究中文模糊限制信息检测将提高中文信息抽取的真实性和准确性。
信息检索中的文本重排技术研究	半指导学习;信息检索;伪标记文本;自动聚类;文本重排	文本重排是信息检索中的一个关键阶段。它一般处于初次检索和查询扩展之间，目的是改进初次检索的质量，为后续的查询扩展提供较多的相关文本。本项目拟把文本重排形式化为一个分类问题、利用自动聚类或自动抽取关键词语产生伪标记文本、采用基于半指导学习的分类方法，以期在缺少标记文本的情况下，根据非标记文本之间的关系，获取尽多相关文本并提升其排名。本项目也拟研究如何评估文本序列的质量和如何利用篇章理论的话题和次话题等概念来认定相关文本，以期从计算理论上判断文本重排的必要性和从语言理论上检验文本重排的功效性。本项目的研究有助于提高查询扩展进而信息检索的质量，对及时获取各种信息包括安全信息、商业信息和生活信息有重要意义。
基于社会化网络的信息推荐方法研究	信息推荐;用户兴趣模型;社会化网络;标签推荐	随着互联网、电子商务和移动互联网的快速发展，能够为用户推荐有用信息，帮助他们克服信息过载的信息推荐技术变得越来越重要。传统的信息推荐技术主要通过用户对信息的评价和浏览记录来进行推荐，这种方式增加用户负担并且容易侵犯用户隐私。社会化网络应用的出现使得通过分析用户公开的社区活动进行信息推荐成为可能。本项目主要研究基于社会化网络的信息推荐技术，提出了基于标签的信息推荐方法。该方法利用标签推荐技术，用标签来统一描述用户和文档；然后以在此基础上进行的用户之间以及用户与文档间的兴趣度计算结果作为推荐依据。标签还可以使推荐依据可视化，增加用户对推荐信息的可信度。项目计划以新兴的社会化网络应用"微博"为载体来检验和评价所提出的信息推荐方法的效果。研究目标是使用户对至少80%的推荐结果感兴趣。
基于多视角特征相关性挖掘的大规模异构媒体融合标注方法研究	异构媒体;多媒体标注;多视角特征;共享子空间;相关性挖掘	本课题是研究融合图像、音频、视频、三维模型等异构媒体进行联合语义标注的新课题。语义标注是多媒体检索与挖掘的重要支撑技术，但现有成果只是标注单一类型媒体或对两类媒体进行相关性分析，无法完整、准确地给出语义描述。通过直接对内容特征和文本特征的相关性进行建模的方法，获取多视角特征的一致性描述，建立语义空间的非线性映射模型，将媒体标注问题转换为近邻搜索问题。研究保持异构媒体语义关联性及空间本征结构的异构媒体共享子空间半监督构建方法，并给出模型的更新和扩展机制，使得不同类型媒体数据能够关联和互补，提高模型准确性、健壮性和泛化能力。设计语境信息快速传播和演化机制，实现子空间中深层次语义关联信息的挖掘。并提出子空间中语义相关性和多样性保持方法，解决子空间内的弱标签和语义单一化问题。所提出模型和方法具备规模化处理能力。研究成果可大幅提升标注性能，为媒体理解与挖掘等应用提供新的解决方案，具有广阔应用前景。
网络虚拟社会中基于交互行为的重要用户发现和追踪研究	群体发现;语言风格;用户重要度;交互信息网络;兴趣话题	互联网用户是真实世界人物的映像，网络用户在虚拟社会的交互行为和发言讨论会直接或间接地反映出其内在的潜藏动机。然而，对于虚拟社会的网络用户，如何发现其密切联系群体，其行为中是否存在诸如指纹的稳定性特征，都还没有专门和深入的研究。本课题面向网络信息安全领域舆情监测的实际需求，针对论坛、博客、微博等互联网交互平台中的用户行为信息进行分析挖掘，首先建立用户之间的交互关系网络，在此基础上研究基于交互信息网络的用户群体发现和用户重要度计算方法，对于自动发现或者重点关注的重要用户从语言风格和兴趣话题两个主要方面进行分析，挖掘网络用户行为的稳定性识别特征，实现对虚拟社会重要用户的同一性识别和准确追踪，为舆情分析和反恐维稳等提供关键技术支撑。
基于信息重组的多文档自动文摘技术	层次主题结构;多知识源融合;多文档自动文摘;信息重组	本申请以多文档信息重组为基础内核，建立一个适合多任务的中文多文档自动文摘模型。在剖析多文档主题结构的基础上，深入研究了文本片段相似度计算、多文本主题结构分析、关键信息抽取、文摘句冗余消除、时序排列、文摘评测等一系列关键技术并最终建立起一个高效、准确的汉语多文档自动文摘系统。在最为关键的多文本信息重组算法中，引入了更为接近文本集合真实内容的层次主题结构的概念，以及动态变阈值文本片段聚类的层次主题结构识别算法。在多文档关键信息抽取策略上，通过文本单元信息量化模型以及多知识源的并行融合算法实现了针对不同文摘需求的关键信息抽取。最后本申请还提出了基于模糊标注的多文档文摘评测方法，实现了多文档文摘定量、客观评测。本申请的相关研究成果能够进一步促进相关汉语自然语言处理技术的发展，同时，一个可行的多文档自动文摘模型对于加快人们对网络信息的处理速度与准确率具有重要的实际应用价值。
基于机器学习的相关反馈算法中若干关键问题研究	文档质量评估;排序学习;相关反馈;机器学习	伪相关反馈是解决信息检索过程中词不匹配问题的有效手段，是提高信息检索准确率和召回率的关键技术之一。在传统基于查询扩展的伪相关反馈技术中，由于假设初次检索得到前K篇文档为相关文档，使得1）当初次检索返回文档集质量不高时，容易引入噪音；2）不同质量反馈文档无法区分对待。本课题重新审视伪相关反馈的基础假设，研究如何挖掘网络资源和使用机器学习技术来解决伪相关反馈中若干关键问题，进一步提高基于查询扩展的相关反馈技术的性能：1）引入新的基于质量偏重相关反馈假设，并提出面向相关反馈文档质量评估模型；2）引入新的基于主题相关反馈假设，并提出查询相关反馈主题提取算法；3）提出基于多种外部资源的反馈模型，解决首次查询精度较差时，反馈文档质量无法得到保证的问题。
面向英汉双向跨语言信息检索的若干自然语言处理底层关键技术研究	查询翻译;自然语言处理;底层关键技术;跨语言信息检索	随着国际互联网的快速发展，Internet上信息资源类型和数量都愈来愈丰富，所使用的语言亦愈来愈具有多样性和不平衡性。为跨越不同语言之间的障碍，使信息用户可以方便地利用日益丰富的多语种网络资源，跨语言信息检索应运而生，即以不同语言描述的用户查询与文档之间的匹配问题。跨语言信息检索研究位于查询翻译、信息检索、自然语言处理底层关键技术三者之间的交集领域，其中的主要问题涉及到两部分。第一部分是跨语言信息检索的核心算法，包括翻译与检索两大模块，目前有关研究大部分都集中于此。而第二部分是跨语言信息检索特别是查询翻译中所必需的自然语言处理底层关键技术，这些技术虽然相对独立地研究较多，但离完全解决仍然距离很远，特别是如何适用于跨语言信息检索环境中，依然是一个需要解决的难题。因此，研究这些技术并使其符合跨语言信息检索的特殊需要，是一项非常具有重要意义的任务。
泛在学习的资源组织模型及其关键技术研究	学习资源组织;泛在学习;知识关系网;学习资源生成与进化;学习元	随着普适计算与物联网技术的发展，信息空间与物理空间将无缝融合，形成虚实结合、无处不在的信息空间。这使得学习越来越泛在(Ubiquitous)化，也就是无处不在、无时不在、按需发生。当前关于泛在学习的研究，主要集中于概念模型与支持环境等方面，而如何组织学习资源，使其满足无处不在、按需提供、适应呈现等泛在学习的需求，则是一个新的研究问题。目前的学习技术关注封闭结构中学习资源的共享，忽视学习资源持续的发展和进化能力，忽视学习资源动态的、生成性的联系，忽视通过学习资源在学习者、教师之间建立动态的联系。本研究提出一种具有可进化发展、认知网络联通、基于语义聚合、自跟踪、微型化等基本特征的学习资源组织方式- - 学习元，它可以实现学习资源在使用过程中不断进化生长，能够聚合学习资源和人形成知识关系网络（KNS），共享学习者群体智慧。本研究可以为普适计算支持下泛在学习环境提供资源层面的架构理论和实践基础。
面向时空应用的大规模复杂模糊时空XML数据管理关键技术研究	XML;推理;模糊时空数据;模型;查询	时空数据库的目的是管理、分析和处理时空数据，时空应用中大规模复杂模糊时空数据的建模、推理及查询是时空数据库真正付诸实践的关键技术。然而在传统数据库中时空数据的模糊扩展以及结构的严格限制等问题尚不能满足高效处理大量复杂类型模糊时空对象的应用需求。因此，基于扩展性良好且具有树型结构等特征的XML研究能够支持复杂模糊时空数据表示和推理的数据模型，并实现大规模复杂模糊时空数据的查询成为真正实现模糊时空数据高效管理亟待解决的重要问题。本项目从支持模糊时空语义和约束的数据模型入手，深入系统的研究时空应用中模糊时空XML数据的建模、推理及查询问题，目标在于形成有关复杂模糊时空XML数据从建模到推理和查询的完整框架并突破其中的关键技术。项目的研究内容将为大规模复杂模糊时空XML数据的建模、推理及查询提供理论和技术上的解决方案，从而为时空应用中模糊时空XML数据管理的实现奠定坚实的理论基础。
面向网页检索应用的汉语语义概念图表示方法研究	信息检索;概念图表示;汉语语义计算;概念复合	面向网页新一代智能检索，致力于提高查询准确率，并为今后手机检索应用前景提供必要的基础研究。探索汉语语义概念图表示方法，将用户需求和网页摘要由语言表达式转换生成概念图，匹配，指导对现有方式的检索结果的再分类，标出准确解，排除噪声，旨在保证用户所需查询实体具有的内涵特征完整，根本改变当前因特征离散、缺损不完整造成大量噪声的弊端。研究方法上重视语言本体理论研究，充分发扬汉语所具有的概念直接耦合的独特优势。在内涵逻辑模型思想下，提出概念模型三元序偶组<E,A,V>的构想及其实现，综合了认知学与修辞学的词汇语义方法，在通常的代入替换等运算之外，创造性地将借代、比喻手段概念图化。着重研究汉语复合词，以名词为中心的概念图表示，明显不同于印欧语系以动词、谓词为中心的方法，充分表达汉语的概念认知及其对客观实体的命名/识别的特点。复合词有可能作为多语种翻译网格结构中的语言单元自动对齐。本项目系重点项目的继续。
融合文本内容与结构信息的话题分析方法研究	话题检测与跟踪;自然语言处理;语义分析	近年来社会媒体在我国取得了蓬勃发展，所发布和传播的信息提供了人们在日常生活中争相讨论的热门话题，对社会舆论产生了广泛的影响力。由于传统的话题分析研究主要以新闻报道作为处理对象，无法充分结合社会媒体所具有的信息内容、社交网络和用户行为等重要特性。因此，本项课题研究具有重要的学术和应用价值。我们拟针对社会媒体，从话题表示与建模、话题发现与跟踪、话题结构和语义分析等方面开展融合文本内容和结构的话题分析方法研究，具体内容包括：1）综合考虑社会媒体的重要特性，建立融合结构和语义的话题表示模型；2）研究基于非参数贝叶斯方法的话题检测与跟踪算法、社会媒体和新闻媒体的关联挖掘方法、话题传播分析与预测算法；3）根据所构建的话题表示模型，研究基于结构化机器学习的话题结构和语义框架分析算法，以及基于主题模型的话题关键词抽取算法。通过本项课题研究，我们拟在CCF推荐的国际学术会议或期刊发表论文15篇以上。
基于图结构的文献挖掘算法研究	语义分类;自动摘要;情感分析;文本推理;图结构	传统的文本表示方法是建立在"词袋"（Bag-Of-Words）表示方法上的，即认为文档是一个关于词或短语的离散集合。经典的信息检索模型、文本分类方法和文献挖掘算法等无一不是建立在这种表示方法之上的。然而这种表示抹杀了文档内部描述单元之间的句法、语义上联系，抹杀了自然语言固有的内在本质。实际上，单词之间有句法、语义上互相依赖，句子之间有前后、篇章的依赖，只有图或树等复杂结构才能有效地表示。本项目将围绕这一基本问题，开展二个方面的研究：一，针对实际问题，如何利用图结构有效地表示文本；二，在图结构表示的基础上，如何有效地开展相关文献挖掘算法的研究，包括基于图结构的自动摘要、文本推理、评论信息的情感分析、文本分类的研究。项目研究的领域以生物文献挖掘为主，同时也利用TAC国际评测提供的数据，以验证算法的通用性。
基于内容分析和行为分析的社区问答关键技术研究	自然语言处理;信息抽取;问答系统;文本内容分析	问答系统是自然语言理解和信息检索领域的重要研究课题，然而受限于自然语言处理和人工智能技术的水平，目前自动问答系统能够解决的问题类型非常有限，难以满足真实用户的个性化复杂信息需求。随着Web2.0的兴起，基于用户生成内容的互联网服务越来越流行，如果能对海量社区问答数据进行有效挖掘和利用，并和深层问答技术结合，将有可能有力地推动问答技术的发展。本申请以社区问答数据的有效挖掘利用为总目标，从分析社区文本内容以及用户行为两方面入手，针对社区问答系统的四项关键技术展开研究：(1)基于空间压缩和语义知识扩展的短文本问题的大类别分类；(2)基于最短路径融合的新类别标签动态生成；(3)基于高鲁棒性短语翻译模型和大规模图结构挖掘的问答对检索；(4)基于用户兴趣建模和行为弱标记学习的最佳回答者推荐。以上研究成果一方面可以直接应用于社区问答系统，提升其智能化水平；另一方面也为自动问答系统的发展产生重要影响。
面向语音环境基于情感计算的动态推荐系统模型研究	情感计算;情感补偿;语音环境;动态推荐系统;机器学习	智能语音技术的高速发展与应用，推动人类从触屏时代向智能语音交互时代发展。语音将成为信息存储与传播最重要的载体，语音信息资源的迅速增长，使得有效信息的筛选变得更为复杂。但现阶段信息筛选模型大多关注于文本内容的知识抽取，缺乏面向语音信息筛选的模型研究，同时情感倾向是影响人们形为的重要因素，研究基于情感计算的信息筛选模型具有重要的意义与价值。本课题旨在融合语音数据中的声学情感信息和内容情感信息建立情感计算模型，并提出基于情感补偿的推荐模型，根据用户情感变化的特点构建基于情感计算的动态推荐系统模型。本课题采用理论分析、算法设计与原型系统实证相结合的技术路线，最终为解决智能语音交互时代信息筛选问题探索新方法与新技术。
基于分布式语义的融合式社会化标注语义分析方法研究	社会化标注;分布式语义;本体;大众分类;语义模糊	社会化标注是近年流行的重要的社会计算应用方式。然而，语义模糊性阻碍着社会化标注成为高效且可信赖的基于内容的信息检索方式，是社会化标注研究领域的核心问题。本项目围绕社会化标注系统中的语义模糊问题开展研究，旨在形成系统化的、可有效处理语义模糊问题的社会化标注语义分析方法。具体而言，以基于二阶共现分布的分布式语义分析为核心方法，首先解决大众分类标签与本体概念的匹配问题；然后，在此基础上，研究大众分类中标签同义关系识别方法；接着，在前两项研究基础上研究多义标签语义分析方法；最后，研究面向大众分类的本体演化方法，开发融合大众分类与本体的社会化标注语义分析系统，以实证研究方式验证本项目的研究成果。本项目研究的成功实施可提升社会化标注系统在整个信息检索领域中的应用价值，对应的研究成果可为深入完善基于大众分类的信息检索及推荐方法提供直接的支持，对本体领域的研究具有参考价值。
面向查询的多文档自动文摘技术研究	自适应聚类;信息检索;语料库;多文档自动文摘	面向查询的多文档自动文摘将查询结果文档集合的内容提炼为包含与查询相关的主题、满足个性化需求的摘要，它能够显著提高信息获取和利用的效率。本项目的研究策略有以下特色：提出了文本、段落两阶段聚类发现潜在子主题的策略；设计了五种文摘模式，满足个性化的信息需求；以主题为单位构造文本集合的网络拓扑图，支持按照逻辑顺序浏览信息。在具体的技术和算法研究上，有以下创新：把复杂网络的理论与方法应用于面向查询的多文档自动文摘，它在文摘主题发现、拓扑结构显示等方面有鲜明特色；提出了利用聚类差异度－不纯度优化法自动确定聚类个数的方法；提出了利用用户自反馈信息与弱指导的机器学习策略自动判定相关与不相关文档的方法，能避免靠经验确定相关文档数的主观性；提出了基于主题词对分布的文档排序策略。同时，还将建设为多文档自动文摘服务的中文语料库，这是相关研究急需的语言资源。
汉语框架语义依存图自动抽取关键技术研究	语义标注;框架语义依存图;汉语框架网;语义分析	语义依存图是进行深层次语义分析的一种语言模型。汉语框架语义依存图是基于汉语框架网对汉语句子语义结构的一种形式化表示，提取一个句子的框架语义依存图就意味着抽取了这个句子的语义骨架。汉语框架语义依存图自动抽取技术研究在国内外尚属首次。本项目基于山西大学的汉语框架网工程，研究面向汉语句子深层语义理解的框架语义依存图自动抽取关键技术，研究内容包括（1）汉语框架语义依存图的表示，并建立汉语框架语义依存图的标注规范；（2）顶层目标词的识别及目标词所属框架的选择；（3）框架元素语义角色及语义关系的自动标注；（4）零形式核心框架元素的识别和自动填充；（5）建立面向汉语框架语义依存图提取的标注语料库，研发一个汉语框架语义依存图自动抽取工具软件。本项目的研究成果将为实现汉语句子语义的深层次理解提供新的途径，为基于汉语框架网的篇章事件推理奠定基础，对自然语言处理相关领域的研究有着重要的理论意义和应用价值。
汉字字体流形构建方法研究	形状分割;流形学习;高层语义;字体流形;汉字字体	近年来，个性化字体在社交软件、娱乐节目、平面广告等场合得到广泛应用。但是，由于汉字数量庞大、形状复杂，设计和制作高质量中文字库通常耗时费力、成本昂贵且需要高超专业技能和丰富从业经验，导致普通用户日益增长的个性化中文字体订制需求难以得到满足。本项目拟基于汉字形状特性、中文字体设计规范与字库制作要求，对汉字字体流形构建中的复杂字形轮廓精确匹配、字体风格高层语义信息提取和大规模流形学习等关键技术开展深入研究，提出大规模汉字字体流形的快速有效构建方法，并将其应用于中文字体设计与字库制作中，开发出一个基于字体流形的中文字库自动生成系统。本项目的研究一方面有望首次解决大规模汉字字体流形的构建难题，显著提高中文字体设计与字库制作的效率；另一方面将把现有中文字库的数量和种类从少量自动扩展到无穷，颠覆现有的中文字体选用模式与用户体验。应用前景广阔，经济效益显著，具有重要的理论研究和实际应用价值。
语义知识驱动的网络上下文广告投放高效方法研究	上下文广告投放;内容相关度;语义知识	随着万维网的快速普及，网络上下文广告的重要性日益显著。没有上下文广告，网络的商业价值将遭受严重损失。不同于一般性的网络文档，网络文本广告篇幅较短，包含较少的关键字，并且需要动态嵌入目标网页，因而，对精度和效率均提出了更高的要求。然而，现有的上下文广告投放方法，难以在这广告投放的准确性和高效性之间取得较好的平衡。所以，设计出一种"既准且快"的上下文广告投放方法，具有重要的科学意义和重要的应用前景。.基于语义知识库，本课题将深入研究：.1）如何利用知识库丰富的语义知识来捕获和扩充文本广告的内容特征向量，克服传统方法容易引发的语义混淆、关键词重叠率低、内容失配等问题，提高上下文广告投放的准确性。2）如何通过设计高效的语义空间映射算法，快速地获取目标网页的内容特征向量，确保上下文广告投放的高效性。.3）以及，如何将文本广告嵌入到目标网页中与广告内容最相关的位置，确保上下文广告投放的局部准确性。
基于语义依存图的汉语复杂名词短语资源建设与自动分析研究	复杂名词短语;区分性模型;语义依存;多标记;语义资源	本项目旨在研究汉语复杂名词短语的语义依存结构，提出基于多标记有向图的表示机制，建设大规模标注资源并探讨基于区分性模型的分析策略。语义依存结构跳脱句法依存的限制，允许多父节点、边多标记和交叉依存。所建资源包含源于真实语料的8万复杂名词短语，所提区分性策略基于对数线性模型，其特征设计可刻划局部和全局性的结构化信息。本项目有助于探讨和阐清适合汉语实际的语义描写机制；丰富汉语自身的语义资源和语义分析策略；对提高汉语自动分析、信息抽取和机器翻译等技术的性能有一定意义。
基于网络用户行为分析的垃圾网页识别方法研究	网络用户行为分析;垃圾网页识别;网络信息检索	互联网信息量的迅速增加，使得搜索引擎成为人们日常工作和生活中不可或缺的信息获取手段，网络垃圾页面利用各种不正当的手段获取较高的检索结果排名，对搜索引擎的运行和用户的使用产生了极大的不良影响。面对垃圾页面作弊技术的发展，传统的针对垃圾页面作弊形式而设计的垃圾识别算法面临着只能处理单一作弊形式，难以及时应对新出现垃圾类型的问题。用户行为分析方法一直是搜索引擎改进算法与系统结构设计的主要依据，垃圾网页的作弊目的必定会对用户的访问行为产生影响，而造成用户对垃圾网页和正常网页访问行为模式的差异，这种差异则可以成为识别垃圾网页的重要依据。本项目的主要目的，就是基于用户行为分析的方法，对垃圾页面的作弊目的及用户访问行为模式进行分析和挖掘，考察并提出相应的垃圾页面识别特征和定位算法；并尝试将识别算法应用于真实网络环境，以提高搜索引擎应对垃圾页面作弊的能力。
基于多种双语平行语料相互关联分析的中轴语言统计翻译知识获取研究	中轴语言组合;知识融合;统计机器翻译;最优路径;翻译知识获取	针对传统统计机器翻译模型大都是在一个的平行语料库上独立进行翻译知识获取的不足，本项目尝试利用不同双语平行语料库之间的关联，挖掘多个语料库整体组合中所蕴含的翻译知识。我们将经由中轴语言的翻译知识传递累积过程形式化为相应稀疏矩阵操作，提出了基于线性结构的多级中轴语言短语翻译知识获取模型，利用一系列双语平行语料之间所蕴含翻译知识的线性传递，使得原本不存在充足训练数据的两种语言可以通过多种中轴语言的线性组合构建翻译系统。并且，利用扩展矩阵中非0元素比例的方法，对源语言-目标语言之间存在的多条翻译路径和多种翻译资源所能提取的翻译知识进行了融合，促使统计机器翻译在解码过程中利用尽可能多的翻译资源。我们希望通过相关问题的研究和解决，即能借鉴数学和人工智能等学科的成熟知识累积来进一步夯实统计机器翻译的理论基础，又能降低其所需的翻译资源壁垒，提升统计机器翻译的翻译性能为社会大众提供更加有效的服务
篇章结构分析及基于双语投射的篇章标注方法研究	篇章标注;双语投射;篇章分析	自然语言处理经历了几十年的发展，分析的对象从字、词、短语到句子，自然而且必然地进入了篇章这一层面。在统计自然语言处理思想和语料库语言学盛行的今天，随着宾州篇章树库的发布，学者们开始尝试借助各种机器学习方法，通过对篇章关系的标注来解释篇章结构，引发了篇章结构分析的热潮。但是，由于篇章问题的复杂性，篇章关系分析的核心部分- - 隐式关系的判别，其准确率没有超过50%。这也是篇章分析处于起步阶段的最好证明。本项目首先将矛头指向这一难题。汉语方面，目前最大的问题是没有大规模的篇章语料库, 严重制约了汉语篇章的研究和应用。而篇章语料库的标注又无疑是一项难度大、费时费力的工程。在本项目中，我们希望借助汉英双语平行树库这一资源，通过对英语端的篇章分析，来得到汉语的篇章关系标记。无论将获得的汉语篇章语料作为种子语料，还是视其为一种篇章标注的框架，都将是未来构建大规模汉语(甚至其它语言)篇章语料的便捷途径。
面向专利文献的统计机器翻译语境分析	专利文献;统计机器翻译;语境分析	直至目前，面向专利文献的统计机器翻译系统尚不能满足文献翻译的实际需要，它未能提供一种切实可行的长句翻译策略，也无法利用上下文语境来实现篇章的翻译。因此它大多作为人工翻译的辅助工具或与规则系统融合使用。本研究尝试着将专利文献的长句分析和上下文语境分析有机地结合起来，提出具备自动专利语境分析功能的统计机器翻译方法。该方法针对专利文献机器翻译中的关键问题与技术难点，分别提出"高精度的专利文献的长句分析方法"用于进行专利文本的复杂长句简化、"适中语义粒度的专利文献上下文语境分析功能"用以加深机器翻译系统对句子乃至篇章的语义理解以及"基于专利语境的统计机器翻译模型"以生成目标翻译。该项研究中关键技术的攻克，将极大地提高机器翻译系统对于专利文献的语境自动分析能力，获得准确率更高的统计机器翻译系统，这不仅在机器翻译领域具有重要的理论创新意义，而且在专利文献处理中具有重要的应用价值。
机器翻译中大规模异类特征的迁移学习	迁移学习;异类语料;异类机器翻译系统/标签系统;大规模训练;异类特征	传统的机器翻译系统融合是提高级器翻译性能的一种重要手段，但是传统的融合模型并没有给出一体化模型的定义，同时也没有考虑机器翻译系统差异性给系统融合造成的影响和传统训练方法的局限性。本课题利用迁移学习的强大理论基础，从迁移学习中两个基本问题（任务和领域）出发，把造成差异性（异类特征）的原因分为异类机器翻译系统/异类标签系统（从任务角度出发）和异类语料（从领域出发），且采用了大规模特征训练算法，克服了传统训练方法对于特征数量的限制。本课题主要先进行一体化模型定义和效率的研究；对于异类机器翻译系统/标签系统，进行基于特征/参数大规模融合；对于异类语料训练通过公共特征的选择，把公共特征加入到融合前的机器翻译系统中来进行融合。而且对于异类机器翻译系统问题研究，能够更好的认识到每个类型机器翻译的优缺点；对于异类标签系统和异类语料的研究，能够更好的认识到异类标签系统和异类语料对于机器翻译系统的影响。
高精度的跨语言信息检索查询词自动翻译技术研究	查询翻译;WEB挖掘;双语资源;跨语言信息检索	互联网上有海量多语言文本资源，通过分析不同类型网页的内容、结构和链接特征，利用机器学习方法可以实现文档、句子和词汇级双语资源的自动获取。.以网络文本挖掘为手段，研究跨语言信息检索查询词翻译获取的方法，重点研究基于本地语料库和基于网络的翻译技术。.本地语料库以网络挖掘方式建设，有低成本、高效率、强时效性，广覆盖面等特色。对本地语料库词汇和语法覆盖度进行优化，实现最小时空开销下的高翻译质量。.对本地语料未覆盖的查询词，以网络挖掘的方法解决，并用以扩大本地资源库。.基于网络的翻译方法中利用共现信息查询扩展方法获取搜索引擎摘要，克服意译词的挖掘瓶颈；利用频度量度和邻接信息，在有噪声的、规模较小的双语摘要库上抽取高质量的候选单元，提高抽取效率；综合利用音译、表层模版、语义、频度-距离等特征进行译文的选择，提高翻译精确度。.研究成果可用于跨语言信息检索、机器翻译等领域。
汉越双语事件语料库构建及舆情观点挖掘方法研究	信息检索;观点挖掘;跨语言信息检索;舆情分析;话题分析	及时有效分析互联网越南新闻事件对把握越南事件舆情观点有重要的作用，本课题针对新闻事件及汉越语言特点，研究汉越双语事件本体知识库及语义语料库构建、新闻事件话题发现与追踪、事件舆情观点挖掘方法。首先，定义新闻事件分类体系，构建事件类别术语、事件关系、事件观点等义原类层次树，构建汉越双语事件本体知识库及带语义要素标记的事件语料库，为分析汉越事件提供知识与语料基础。其次，针对汉越双语事件话题产生演化特点，融合双语语言知识、事件本体知识、事件对齐等特征，研究融合双语主题分析和进化聚类的话题发现与追踪方法，解决双语混合事件话题探索与追踪问题；在此基础上，针对事件间及事件内部特征关联特性，融合事件间关联、句子间关联、实体关联及双语关联等特征，研究基于图模型的双语观点句识别、观点分析、持有人分析及倾向性分析方法，解决融合关联特征的双语事件观点挖掘问题。成果将为有效分析汉越双语舆情事件提供资源及技术支撑。
面向实例密集型应用的云工作流资源管理优化方法研究	资源配置;云工作流;实例密集型应用;资源管理优化;资源调度	实例密集型应用是互联网与云计算时代业务系统呈现的显著特征。目前，作为支持该类业务流程自动化的工作流系统很少考虑利用实例密集型应用的特点以优化云工作流的资源管理，从而降低在云端的开销或租赁成本。针对该问题，本项目尝试研究一套面向实例密集型应用的云工作流资源管理优化方法。具体包括：1）根据实例密集型应用的未来工作负载与截止时间需求，利用在线支持向量机与微粒群优化等方法，研究基于执行时间预测的云工作流资源静态配置优化方法；2）根据实例密集型应用执行时并发实例在数据等方面的关联或约束关系，通过引入实例方面处理，研究截止时间约束下可最小化服务成本的动态调度方法，以及服务成本预算约束下可最小化实例平均执行时间的动态调度方法；3）对所提出的方法进行实验测试，并实现原型系统。项目的预期研究成果将有助于改进云工作流的资源管理方式，并可为云服务提供商降低实例密集型应用在云端的服务成本提供理论基础和实践指导。
融合语义控制实体识别和结构化要素识别的生物医学事件抽取	词表示;联合模型;命名实体识别;神经网络;事件抽取	基于文献的生物医学事件抽取是生物医学自然语言处理领域的新兴研究热点，为疾病的诊断、预防、治疗和新药研发提供启发和依据。目前的方法存在如下亟待解决的问题：标注语料规模小而导致数据表示信息量不足、已有生物实体识别工具或方法泛化性较差、复杂事件抽取精度较低等。由此，本项目提出：1. 融入丰富的生物医学和语言学功能单位，并改进原有神经网络结构，建立全新的生物医学领域相关的词表示模型，改善数据表示信息不足的问题；2.研制新的嵌入类型语义控制的双向LSTM-CRF深度学习模型，提高生物实体识别的泛化性和精度；3.提出新的结构化要素识别方法，提高复杂事件抽取精度；并与先进的双分解算法相融合，避免分阶段方法中的级联错误，最终获得高性能的生物事件抽取模型。本项目与领域专家合作，以癌症相关的事件抽取为重要实例，通过构建癌症相关的生物事件数据库和交互网络，验证系统的真实有效性，同时为癌症的研究提供生物医学知识。
大规模标注RDF数据管理的关键技术研究	图数据模型;图索引;压缩;存储结构;标注RDF	随着数据规范组织与互联的需要，RDF数据量在迅速增长，与之相伴随的RDF数据元信息，即标注RDF数据规模同样在快速增加，亟待有效管理。目前标注RDF数据的管理通常基于RDF的数据模型，并沿用其存储技术，未能有效考虑标注RDF数据的特征。这导致数据模型的灵活性不好，表达能力弱。采用RDF数据的存储技术来管理标注RDF数据可扩展性差，消耗的存储空间膨胀，性能低，当存储大规模数据时问题尤为突出。针对大规模标注RDF数据管理问题，本项目首先研究基于多部图的标注RDF数据模型、其矩阵表示和变换运算。为存储大规模标注RDF数据，研究标注RDF数据的存储结构及标注RDF数据划分；研究标注RDF数据的压缩技术以提高存储效率；研究标注RDF数据的索引选取及构建技术以便于高效查询及推理。本项目研究形成的有关刻画标注RDF数据的模型、大规模标注RDF存储结构将为大规模标注RDF数据管理提供支持。
网络舆情信息中事件篇章关系检测方法的研究	事件关系;篇章关系;关系检测	事件篇章关系检测是信息抽取和舆情分析交叉领域的重要研究课题，对于以事件为主体元素的自然语言逻辑关系抽取，以及借助关联事件挖掘舆情信息的衍生线索和发展脉络，都具有很高的实用价值。目前，事件关系检测的相关研究较少，尤其借助篇章分析从语义层面深入解释和描述事件关系的研究尚属空白。本课题将重点研究刻画事件关系的语言学规律，并基于篇章分析，探索事件语义关系的机器学习和自动检测方法。主要研究内容包含如下四个方面：基于跨实体推理的事件抽取、基于动态话题模型的跨篇章关联事件识别、基于平行理论的事件篇章关系检测、事件关系层次作用域的自动构建。特别是研究借助宏观话题对事件关系的约束，识别浅层事件关系的方法；以及借助事件语义平行性识别，利用平行事件参与篇章关系形成过程的语言学共性，检测事件逻辑关系的数学建模方法。目标是实现针对舆情信息中各类事件逻辑关系的自动识别与检测，借以辅助事件衍生与发展的预测与预报。
云计算环境下支持复杂并行业务的高铁数据中心关键技术研究	动态多目标规划;高速铁路;云计算;数据中心;数据布局	云计算在大规模异构资源优化管理方面的优势使其逐渐成为新一代主流计算模式。本课题以确保高速铁路安全，提升其预防维护能力、运营效率、服务质量为目标，面向云计算环境下高铁数据中心大规模复杂并行业务处理与海量分布数据管理的需求，分析实际业务与数据的特征及关联，探讨计算和存储紧密耦合的演化机理，基于本体、核心元数据及约束理论构建高铁数据模型。以此为基础，探索数据中心层次化混合存储架构，采用虚拟化及大规模数据集并行处理技术，结合模糊理论与动态多目标多约束决策理论，综合考虑负载均衡以及自适应机制，研究数据布局策略、调度算法以及中间数据容错机制。同时，针对跨地域密集布控的高铁传感监测设备回传的海量不确定流数据，寻求复杂高效查询处理算法。最终通过理论分析与仿真实验相结合的手段验证所设计的机制和算法,为下一步高铁数据中心的设计与管理提供新的理论和技术支撑。
语义主题与社交关系融合的特定群体发现关键技术研究	群体发现;主题分析;社交网络;社会关系	以微博与微信为代表的社交网络影响力日渐增强，已成为公众信息获取与社会交往的主要媒介。特定群体指的是在社交网络中没有直接的强关系，由聚焦特定主题或兴趣偏好的个体自发形成的集合。特定群体有着主题性强、小众化、弱关联、较为隐蔽等特点，很难通过传统的社区发现方法自动发现，纯粹靠内容来过滤则无法发现较少发言的幕后大V。本项目旨在研究微博类社交网络特定群体的自动发现关键技术，构建特定群体的表示模型，研究融合语义主题与社交关系的群体发现算法，实现"转世党"与"失独家庭"等小众化特定群体的示范应用。具体技术路线为：针对给定的群体主题或种子列表，计算社交网络个体的主题语义相似性，综合利用关注、转发、点赞、提及等四类社交关系扩展群体目标，最后融合语义主题与社交关系的相似性计算实现特定群体的自动发现与精准定位。本项目拟在特定群体表示与发现方面实现理论突破，在社交网络空间上为国家安全保障与社会治理创新提供技术支撑
基于词语独异性特征的大规模词义标注语料库自动构建研究	词语独异性特征;词义消歧;主动学习;词义区分;自举方法	词义消歧是计算语言学领域的一个核心研究课题。历经半个多世纪的努力，词义消歧研究并未取得突破性进展，其中一个重要原因就是缺乏大规模高质量的词义标注语料库。本课题的研究目标就是采用机器学习方法，实现人和机器的良性互动，探讨大规模词义标注语料库自动构建的理论和方法。研究内容主要包括：1)人工构建一个小规模词义标注语料库作为初始训练集；2)基于Web采用自举方法自动扩充低频义项例句；3)语言学指导下自动学习每个多义词的词语独异性消歧特征，基于支持向量机实现高效的词义自动消歧；4)利用大规模汉语基本标注语料库，采用主动学习方法选择信息增益最大的例句，自动构建大规模词义标注语料库。本课题的研究成果将大大促进汉语词义消歧的研究与应用，所构建的词义标注语料库将力争成为汉语词义消歧研究训练和测试的基准语料，其研究方法和关键技术对其他汉语语料库建设也将具有方法论上的参考意义。
基于倾向性演化学习的新闻话题变种检测方法研究	新闻话题;变种检测;倾向性演化	新闻话题检测是舆情分析领域中的重要研究课题，对于舆情的监督、管理和调控有着很高的实用价值。特别是新闻话题的变种检测对于突发事件和敏感话题的预报尤为重要。目前，针对话题变种检测问题的探索尚未开展，借助舆情的倾向演化解释话题变种衍生规律的研究在国内外尚属空白。本课题将重点研究新闻话题和倾向性的协同演化规律以及相应的机器学习策略，并探索话题变异锚点的实时检测和话题变种的描述方法。本课题的主要研究内容包含如下四个方面：基于时序事件链的话题建模、基于"能愿"动词的倾向性识别、话题与倾向性协同演化的自适应学习、实时话题变种检测。特别是研究融入事件时序属性的结构化动态话题建模；利用"能愿"强度层次体系的倾向性演化描述；以及依赖倾向强度和事件突发性依存关系的协同演化数学建模。目标是实现针对舆情信息中倾向性和话题协同演化的自动监控，以及话题变种的有效识别与预报。
基于简标注和弱监督学习的开放的信息抽取研究	简标注;弱监督学习;命名实体识别;多知识源;开放的信息抽取	从自然语言文本中自动获取有用信息是信息抽取研究的目标。与传统的信息抽取针对某一类特定的关系信息不同，开放的信息抽取旨在利用信息抽取技术获得海量的非特定的关系信息，从而实现真正的广泛的信息抽取。目前，开放的信息抽取面临如下的挑战：一，系统性能不高；二，泛化能力弱。针对这两个挑战，本项目首先引入一个多知识源导向的开放的信息抽取框架，在其中构造一个基于简标注和弱监督学习的信息抽取器，并进行命名实体识别和开放的关系抽取的联合分析，从而提高系统的性能和泛化能力，进而实现项目的最终的目标－"面向非特定的关系，构造一个具有高准确率和召回率的信息抽取系统，并拥有很强的泛化能力"，实现真正的广义的信息抽取。
多任务一体化统计复述生成技术研究	统计复述生成;复述资源;复述应用任务;一体化统计模型	复述，即对同一语义的不同表达方式，是人类语言使用中的常见现象，亦是人工智能和自然语言处理研究领域的经典课题。复述生成是指生成给定输入句的复述句，其在自然语言处理的诸多领域皆有重要应用，但目前的研究尚存很多不足。本申请旨在基于一体化的统计模型面向多种应用任务进行复述生成，其主要特点和创新点体现在如下三方面：（1）本项目将针对复述生成的自身特点及其与其它研究方向的区别为其设计专门的统计模型；（2）本项目将综合利用、分析和比较前人在复述资源获取方面的研究工作和成果，并将获取到的复述短语、复述模板和复述搭配等细粒度的复述资源用于复述生成，以解决数据不足的问题，同时生成更丰富、更有价值的复述句；（3）本项目提出的方法和模型将面向诸如"句子压缩"、"句子浅显化"以及"句子相似度计算"等多种常见且十分重要的应用任务，为其提供一体化的解决方案。
赣方言篇章平行语料库构建及计算模型研究	计算模型;赣方言;平行语料库;篇章;语料标注	方言作为中华民族优秀的一种非物质文化遗产，其不应该随普通话的日益普及而消失。针对目前方言的标注体系有待完善、语料库构建和计算模型研究等方面的不足等问题，本项目拟在以下方面进行深入的研究和探索：（1）建立一套适用于赣方言处理的标注规范，并手工标注完成一定规模的高质量赣方言篇章平行语料库。（2）基于标注的平行语料，研究基于潜在语义对偶空间的赣方言词对齐模型，并利用自动后处理的词映射机制对抽取的词对齐加以修正。（3）通过融合抽取的词对齐、句子分布式表示等多方面的特征，研究递归神经网络下的句子级赣方言识别模型和基于强化学习机制的篇章级赣方言识别模型，并探索赣方言篇章衔接性与连贯性联合学习机制。本项目开展的研究工作对于推进教育部的语言资源保护工程建设具有重要理论意义和应用价值，同时也有利于江西省有声资源库的后续开发和利用。
汉语依存句法分析若干关键技术研究	依存句法分析;名词复合短语分析;局部动态优化;句法分析;句子片段识别	句法分析是自然语言处理的核心问题，对信息抽取、机器翻译等应用有重要的支撑作用。依存语法以其形式简洁、易于标注、便于应用等优点，逐渐受到重视。虽然目前汉语依存句法分析研究取得了一定的进展，但是其准确率和效率仍然不能满足实际应用的需要。本项目针对汉语的特点以及汉语句法分析的难点，面向实际应用，试图从三个方面对汉语依存句法分析技术加以改进：1、首先识别句子中的名词复合短语，然后将整个名词复合短语作为一个单元与句中其它部分进行句法分析，最后再分析名词复合短语内部的句法结构，这就降低了句法分析的复杂度，从而提高句法分析的准确率；2、通过识别句子片段，将长句分解为短句，然后在短句内部进行句法分析，最后将短句的句法分析结果关联起来，也可以降低句法分析的复杂度，从而提高句法分析的准确率；3、采取基于局部动态优化的确定性分析解码算法，避免了全局寻优带来的时空复杂性的激增问题，提高了句法分析的效率。
藏语命名实体识别关键技术研究	命名实体;藏文信息处理;条件随机场;人名识别;机构名识别	命名实体识别技术是信息抽取、句法分析、跨语言检索等自然语言处理领域研究的前导技术和难题。藏文在自然语言处理方面研究起步比较晚，基础研究薄弱，当前尚未完全解决藏语命名实体高精度自动识别问题。本项目以藏语命名实体为研究对象，通过分析藏语人名、地名、机构名的内部和外部特征，充分结合规则和统计方法的优点，提出一种适合藏语自身的快速、高效、精准的藏语命名实体识别框架。首先，基于机器学习算法分别从大规模藏语语料和汉藏对齐语料中构建机构名识别知识库和汉藏对应的音译对照统计库，改进藏语命名实体识别的精度；其次，研究基于层次式机器学习模型的藏语命名实体识别方法，将简单和复杂命名实体集中在统一识别框架下，研究多个子模型的参数学习方法；本项目将建立藏语机构名识别知识库、汉藏对应的音译对照统计库、藏语命名实体标注语料，为藏语自然语言处理的研究提供基础。
Web社区高质量识别算法研究	内容分析;引力模型;社区识别;页面分割;链接分析	社区是Web最有价值的结构特征之一。社区识别是Web领域的热点研究课题，在许多实际应用中起着重要的作用。现有的算法仅通过链接分析识别社区，求解质量偏低，不能满足实际应用的需求。我们通过前期大量研究和分析工作得出结论：仅通过链接分析不可能精确识别社区。本项目针对这个难题设计高质量的社区识别算法，算法以链接分析为主，辅以内容分析和页面结构分析，引入页面间引力模型、页面均匀抽样、页面语义块分割等技术，解决链接加权、准目标社区与层次聚类结果匹配、页面的多主题识别等一系列影响社区识别算法求解质量的关键问题。为了保证算法的效率，本项目将复杂的社区识别任务分解，采用逐步求精的策略分阶段地逼近目标社区。继而本项目对社区进行初步分析并设计友好的界面，以方便用户使用。本项研究将促进聚焦爬取、自动化门户、内容预取等一系列关键技术的进步，为保证我国在Web科学和信息检索等前沿领域取得优势发挥重要作用。
面向科技文献的机器翻译关键技术研究	统计机器翻译;翻译模板;科技文献翻译;领域自适应	科技文献自动翻译具有重要的研究意义和实用价值。近年来机器翻译技术取得了重大的研究进展，为科技文献自动翻译提供了新的有力的手段。本申请针对科技文献翻译的特点，以统计机器翻译翻译技术为基础，结合传统机器翻译技术的优点，研究适合科技文献翻译的机器翻译关键技术和方法。具体的研究内容包括：句子骨干翻译模板的自动获取方法；传统语言学知识和统计机器翻译模型的融合策略；以及统计机器翻译系统的领域自适应方法。本课题的研究目标是对科技文献自动翻译中的关键问题提出有效的解决方案，显著提高科技文献的自动翻译质量，增强科技文献机器翻译系统对不同领域科技文献的自适应能力，推进科技文献机器翻译系统的实用化。本课题的研究成果将应用于一个实际的科技文献机器翻译系统- - 面向专利文献的机器翻译系统中。
基于树核函数的弱指导实体间语义关系抽取研究	树核函数;动态语义关系树;弱指导学习;基于自举加权支持向量的标注传播算法;实体间语义关系抽取	实体间语义关系抽取是自然语言理解的关键和热点问题之一。本项目将在前期研究的基础上，重点解决困扰目前语义关系抽取研究的两个关键问题，一是如何获取和利用有效的结构化句法信息；二是如何减少对手工标注的大规模标注语料的依赖。主要研究内容包括：1）在语言学理论的指导下，研究语义关系抽取所需的关键结构化句法信息，探索自动获取相关结构化句法信息的动态语义关系树抽取方案，以确保抽取的语义关系树既涵盖关键的结构化句法信息，又能减少不必要的噪音；2）在研究现有的树核函数的基础上，探索既能有效集成上下文信息又允许模糊匹配的新颖卷积树核函数，以更好地体现语义关系抽取所需的各种结构化句法信息；3）在研究现有的弱指导学习方法的基础上，探索基于自举加权支持向量的标注传播算法，以捕获标注语料和未标注语料中的自然簇结构，同时有效避免数据不平衡问题，减少内存需求和计算成本。
面向事件时间感知的微博检索研究	事件;检索模型;相关性反馈;微博;检索排序	以微博为代表的社交网络已经成为工业界和学术界关注的焦点，从大规模微博流中检索出满足用户需求的信息即微博检索是有效利用微博数据的关键技术。然而，和传统检索对象相比，微博具有内容短、传播快、有特定结构、时间关联强等特性，因此传统检索技术难以直接用于微博检索。现有微博检索研究主要集中于对微博查询、微博记录进行扩充、对传统检索模型进行改进，以适应微博检索的需求。但是现有工作一方面忽视了微博的事件传播属性，另一方面现有利用时间信息的微博检索所基于的假设也过于简单与实际不符。此外，大多数研究没有考虑微博查询自身的特点，查询相关的微博检索研究有所不足。本课题主要从微博的事件属性出发，研究面向事件时间感知的微博检索技术。目标是提出一套面向事件的微博查询分类体系，研究高精度的微博查询自动分类方法，研究面向事件时间感知的统一微博检索模型，在模型框架下研究时间感知的检索方法，研究自适应的微博检索和相关反馈方法。
基于图的统计机器翻译方法研究	语料库选择;统计机器翻译;语料库优化;图;解码	在统计机器翻译中，除了语料库的规模之外，如何充分利用语料库至关重要。典型的机器翻译方法，其基本假设是：语料库中的句对都是高质量的翻译对，且句对之间互相独立，该假设过于严格。因此，本课题将针对此问题进行深入研究，试图放松该假设的强约束，基本思路是：基于图构造语料库中句对或者句子之间的内部联系，利用形成的拓扑结构，研究如何提高翻译模型的质量和解码的质量。具体包括：1、基于图的语料库质量评价模型和优化方法研究，力求使得高质量的句对在训练翻译模型时获得更大的比重，以提高翻译模型的质量；2、基于图的语料库选择方法研究，确保获得语料库的完备集合，保证翻译质量的同时，耗费最少的计算或人工翻译等资源；3、基于图的解码方法研究，利用语料库的内部结构来指导解码的完成，提高翻译的质量。本课题将阐明语料库的拓扑结构对机器翻译的影响机制，给出基于图的语料库优化和选择算法以及解码算法，形成基于图的统计机器翻译框架。
面向开放领域的自动关系抽取技术研究	图模型;关系抽取;非监督学习;信息抽取;面向开放领域	为了应对信息爆炸带来的挑战，迫切需要一些自动化的技术帮助人们在海量数据中迅速找到自己真正需要的信息。信息抽取技术在自然语言处理领域正越发地体现出它的重要性。本课题将对信息抽取的关键支撑技术，即关系抽取任务，进行深入研究，指导计算机从自由文本中自动识别出实体之间的关系。当前国际上更多的是针对有监督学习的关系抽取技术的研究，这种技术通过训练样本的学习获得抽取模式，实现特定领域的关系抽取功能，因而需要对该知识领域较熟悉的人根据事先约定的规则来标记训练样本，同时需要足够数量的训练数据才能保证系统的抽取质量。为此，本课题积极探索面向开放领域的自动关系抽取技术，提出用多知识融合的手段来构建关系候选，建立基于图的关系抽取模型，并充分利用很容易获得的未标签样本的信息，在该图模型上进行非监督的学习，解决手工标注样本的困难，使其在各应用领域中都可扮演重要的角色，也为下一代基于自动问答的搜索引擎的发展奠定基础。
结合深度学习与非参数先验的自动新闻事件提取与新闻主题建模技术研究	跨媒体;知识库;概率主题建模;贝叶斯非参数;深度学习	互联网改变了人们接受与传播信息的方式，极大地促进了新闻的快速传播与扩散，并为了解、分析与预测新闻事件要素（时间、地点、人物、事情等）对事件发展演变的作用提供了大量素材。本项目面向具有跨媒体特性的网络热点新闻报道，采用以概率建模为主，结合知识标引、深度学习、非参数先验、多模态数据建模、主题演化等机器学习与数据挖掘领域的最新技术，最终实现自动新闻要素抽取与热点新闻事件、主题建模。
自然语言处理中基于矩阵的结构化学习研究	自然语言处理;信息抽取;结构化学习;中文分词;序列标注	随着互联网的发展, 自然语言处理成为整理和分析大规模文本数据的核心和基础. 结构化学习作为一种高效, 实用的机器学习方法, 在自然语言处理中具有广泛的应用, 也是近年来的研究热点之一. 但在目前的结构化学习中, 通常将模型的特征表示成为向量. 这样的表示方式存在着信息丢失, 不能有效利用先验知识和实际问题的特性等问题. .    在本项课题研究中, 我们将关注自然语言处理中的特征表示方法, 并在其基础上建立新的结构化学习模型, 研究相应的参数学习和解码算法, 并力争提高自然语言处理任务的性能和效率. 其研究目标包括: 1) 自然语言处理中基于矩阵的特征表示和模型建立; 2)基于矩阵的结构化学习算法; 3) 基于矩阵的结构化学习在词法分析, 句法分析等实际系统中的应用..    预期的研究成果包括: 发表国内外学术期刊或会议论文6-8篇, 申请专利1-2项.
基于内容的图像检索中语义特征表示及语义融合	语义融合;语义特征表示;基于内容的图像检索;语义信息检索	基于内容的图像检索研究在过去的十几年里受到了广泛关注，取得了极大的发展。但是语义鸿沟问题的存在造成图像检索技术的应用效果距离用户的期望还有一定的差距。本项目将对图像检索中的语义特征表示及语义融合展开研究，以达到减小语义鸿沟的研究目的。本项目将对经典的词袋模型加以改进并提出一个语义图像检索架构。该架构利用视觉显著性模型及排序学习分别解决图像的语义特征表示及前景目标与背景区域的语义融合，以达到优化检索结果，满足用户高层语义检索需求的目标。本项目将提出基于色彩、纹理及形状等底层特征的语义特征表示方法及基于排序学习的语义融合方法。预计本项目的研究成果能广泛应用于网络搜索、智能交通、犯罪预防等领域。
文本观点倾向性分析和挖掘关键技术研究	极性分析;文本分析;综述摘要;观点挖掘;观点分析	大规模文本智能处理技术是目前自然语言处理领域的重要应用研究内容。传统文本智能处理技术如信息检索主要针对文本中包含的事实性知识，如何分析处理主观性文本中包含的非事实性知识，具有重要的应用研究意义。本课题主要研究从海量主观性文本数据中分析和挖掘用户观点的倾向性评价，实现文本观点倾向性分析和挖掘关键技术研究。其中主要涉及到观点相关词的获取和语义倾向性分析、观点倾向性分析（侧重于极性分析）、观点持有者识别、观点焦点对象分析、观点倾向性理由分析、观点的地域来源分析和面向观点倾向性评价的综述摘要等关键技术研究，最后构造一套中文文本内容观点倾向性的分析和挖掘平台系统。本课题研究的关键技术可以很容易地被扩展应用于英文文本的观点倾向性分析。从应用角度来看，本课题的研究可以促进NLP应用技术的研发，开发出具有潜力的商业应用系统，如公共舆情分析系统、公司产品市场评价分析系统等。
多所有者RFID标签所有权可验证动态安全转换机制研究	多所有者;射频识别;标签;所有权转换;秘密共享	电子标签所有权安全转换是RFID技术在物流过程中推广应用的关键问题之一，满足多所有者安全需求的所有权转换机制是当前研究热点。目前的研究主要集中在单所有者标签的所有权转换，而多所有者标签还面临隐私保护及秘密分割等问题。本课题拟构建多所有者RFID标签所有权可验证动态安全转换机制。首先研究利用轻量级函数构建秘密分割及恢复算法，为多所有者标签的所有权转换机制奠定理论基础；然后基于双变量单向函数和中国剩余定理，提出轻量级可验证的秘密共享方案，在此基础上设计面向多所有者标签的可验证所有权转换机制；确定密钥阵列和所有权安全转换子系统之间的映射关系，提出多所有者标签动态所有权转换机制。对所构建的所有权转换机制进行分析，这两种机制能满足所有者的安全需求，抵御多种攻击，且效率更高。本项目成果为多所有者标签所有权安全转换提供理论基础，可以为RFID技术在制造、零售、物流和医疗等领域广泛应用提供安全保障。
面向科技文献的引用摘要生成关键技术研究	自动文摘;篇章分析;深度学习;信息抽取;引用摘要	科技文献的爆炸式增长使得自动摘要成为减轻科研人员负担的一项关键技术，而论文引用能从多个角度去帮助理解论文的方法、应用、贡献和局限性。因此，本申请的目标是探究引用的真正动机和生成式摘要技术。在此基础上定义了不同于过去的引用摘要任务，不限于论文本身内容，而进一步依据引用的各个维度对论文的影响进行总结。研究内容主要包括：(1)研究面向科技文献的信息抽取技术，克服了传统信息抽取技术高度依赖人工的局限性，对特定领域的实体、事件、关系等进行自动提取；（2）提出一套科技文献的篇章标注规范，引入依存结构对论文段落进行篇章表示，并结合深度学习方法探索有效的篇章分析算法；(3）围绕引用摘要任务进行引用的多维度分析，其中包括引用重要性、引用内容、引用倾向性等方面；（4）研究基于模板的引用摘要生成框架，研究以概念为骨架的模板生成技术、基于篇章分析的文本连贯性计算模型、基于模板和引用维度分析的引用摘要生成技术。
面向互联网+智能电视平台的推荐系统研究	智能电视节目推荐;社会媒体;互联网+智能电视平台;推荐系统;个性化推荐	互联网+智能电视平台是融入互联网环境的电视系统，其节目包括了有线电视的上百频道和与TV厂家有共享协议的上百亿网络视频。但用户想找到喜欢的节目则变得十分困难。该平台上的推荐系统是根据每个ID用户的特点，为其进行个性化推荐。但目前已知的推荐系统理论模型均不能直接应用到这类平台上的推荐系统设计。原因是：1）同一个ID可能对应多个不同类型的用户；2）没有用户-节目评分矩阵；3）用户对节目的喜好不仅仅取决于过去看过的节目类别，而且还与获奖、导演、演员和流行度等节目属性有关；4）对新闻和直播节目的推荐是上下文受限。本申请课题将根据该平台上的用户和节目具有更丰富的语义描述和可以利用共享视频网站上用户之间、用户-节目评分等特点，给出能部分解决上述问题的推荐模型和实现技术。其研究成果可直接应用到互联网+智能电视的推荐系统设计，并且在推荐模型、系统框架、实现技术和在线推荐评估方法等方面给出创新成果。
英汉动词次范畴化对应关系自动获取研究	次范畴化对应关系;动词;英语;自动获取;汉语	本课题研究英语和汉语动词次范畴化现象所表现出的语言共性和语言个性，完善英汉单语动词次范畴化框架(SCF)的形式化定义，探索英汉双语动词SCF对应关系的自动获取算法和实现方式，以及双语SCF词汇知识库在具体NLP领域内的应用技术。总体目标是对相应理论问题做出符合真实语言现象的回答，开发基本实用的英汉SCF对应关系的自动获取工具，并建立符合一般NLP研究需要的英汉双语的动词SCF词汇知识库。英语和汉语都属于世界上最具影响力的语种，英汉相关的信息处理量极大；二者在单语动词次范畴化自动获取方面又都有着相对较好的研究成果。因此，英汉动词次范畴化对应关系自动获取研究既有立项的必要性，又有具体实行的研究基础。该项研究有着重要的学术价值，其进展和成功必将带来可观的经济和社会效益。
汉字书写规范性表征与评判	评判;端正性;手写汉字;正确性	书写正确和端正汉字是中小学生写字规范的基本要求，本课题针对联机采集的汉字骨架结构，通过对小学生汉字写字语料库调查分析，研究如何表征汉字的拓扑结构，进而评判汉字书写是否正确；研究如何用可计算指标表征汉字书写的端正性，在此基础上，研究汉字书写规范性评定算法。.利用汉字结构层次性特点，汉字拓扑结构和书写端正性可以用笔画、部件和字三级表征，表征方法采用汉字形描述语言，在表征的基础上，研究以下两种形式的汉字书写规范性评判：.１）汉字书写过程动态反馈。发现书写过程中出现的笔势、笔顺、笔画规范性、笔画间搭接的规范性等涉及到书写正确性、端正性问题。.２）书写水平评定。根据书写测试集汉字，给出汉字的总体书写水平，同时根据端正性要素，进行分项评定，反馈书写汉字存在的问题。
基于格依存树到串模型的日汉机器翻译研究	格依存文法;格依存句法分析;日汉机器翻译;自然语言理解;格依存树到串模型	日汉机器翻译方法研究对我国国防、国家安全和经济建设具有重要意义。 .本项目提出了融合依存树到串模型和格语法的日汉机器翻译方法，创新性主要体现在：充分利用日语格语法特点，提出一种新的格依存句法结构描述形式和一种基于格依存树到串模型的机器翻译方法；主要研究内容包括：1）日语格依存结构描述及其形式化定义；2）日语格依存句法分析算法设计实现、规则或参数学习等；3）基于格依存结构的树到串翻译方法，包括翻译数学模型，训练和解码。 我们将深入探索基于格依存结构的树到串模型的形式化描述、面向大规模真实文本的翻译规则抽取和概率估计以及高效解码算法等问题。本研究拟采用统计为主规则为辅的研究策略，通过实现高质量的日汉翻译系统，为黏着语系与孤立语系间的基于句法的统计机器翻译实现提供借鉴经验和方法理论依据。
面向问答社区的中文描述性答案融合框架及融合方法研究	答案融合;短文本处理;问答社区;分布式表示;语义信息要素	网络问答社区的出现和兴起体现了人们对知识获取和知识分享的客观需求。随着问答社区的不断发展，答案信息的规模飞速增长，用户已经不再满足于对问题的单一答案的获取，而希望从更高质量的答案中得到全面的知识，因此有必要对同一问题的多个正确答案进行合理的融合。本项目提出了一种面向问答社区的描述性（复杂）答案的融合框架，针对答案信息的短文本语言特点，通过引入语义信息要素和分布式表示，为不同类型答案的融合任务给出了统一的解决策略。同时提出了基于深度学习的答案内容分析和语义相关性量化方法，以及基于语义信息要素关系的融合结果生成方法。本项研究是对短文本语义分析和融合的一次深入探索，研究内容涵盖短文本内容理解、抽象、重构等多个关键问题，其研究成果可以直接服务于多种新型网络信息平台的信息挖掘和融合应用。
大规模图像近似拷贝快速检测方法研究	视觉词汇;图像近似拷贝检测;图像检索;上下文建模	图像近似拷贝检测是图像检索领域一个新的研究方向。在大规模图像库中实现快速鲁棒的图像近似拷贝检测，尚需解决图像的紧致描述与高效检索等关键问题。当前基于视觉词汇的方法对视觉词汇的多义性和同义性问题缺少针对性的关注。本项目拟以视觉词汇的多义性和同义性问题为出发点，研究面向大规模图像库的有效利用视觉词汇上下文信息和视觉词汇扩展的图像近似拷贝快速检测方法。研究内容包括：(1)局部特征视觉词汇化方法，使视觉词汇具有紧致性、快速映射、强区分能力、数量有限性；(2)视觉词汇上下文建模方法；(3)大规模高维视觉词汇的快速近邻检索；(4)高效的图像近似拷贝验证方法。通过本项目的研究，有效弥补当前在大规模图像库中视觉词汇表示和检索方面的不足，推动近似拷贝图像检测技术的进一步发展，相关研究成果有助于促进基于视觉词汇的图像分类和检索研究。
基于异构信息融合的实时竞价广告响应预测方法研究	实时竞价广告;数据稀疏;张量分解;异构信息融合;广告响应预测	为了有效地挖掘用户、上下文和广告之间的三维交互关系，张量分解模型开始被用于解决实时竞价广告响应预测问题。然而实时竞价广告响应预测面临严峻的数据稀疏问题，尤其是广告转化率预测，单纯地只依靠融合某类或某些信息不能有效地解决严峻的数据稀疏问题，只有同时综合利用各种各样的异质、异构信息共同应对。本项目重点研究如何将各种各样的异构信息融合集成到张量分解模型中缓解数据稀疏问题，提升模型预测的准确性和可靠性。首先，我们根据可以获得并利用的信息的类型、性质、结构、表示方式及其在解决数据稀疏问题中所起的作用等将所有信息分成五个类别，普通对象特征、层次和聚类信息、时间序列信息、点击与转化反馈信息及全局特征。然后，我们针对不同类型信息的性质和特点，基于张量分解模型，研究不同的融合方案和方法。最后，我们研究同时能够融合五类不同信息的综合框架和解决方案，并通过排序和回归组合优化同时提升基于排序和回归的性能指标。
汉语框架语义角色自动标注技术研究	语义角色;框架语义;统计机器学习;自动标注	近年来，自然语言语义处理从句法学方面转移到语义学，词一级语言单位的语义研究是重点。山西大学从2004年开始，采用框架语义学（Frame Semantics）理论构建汉语的FrameNet(CFN)。构建大规模的框架语义知识库，以及为自然语言应用系统提供一个语义层面的分析工具，都离不开自动标注器。本项目基于山西大学的汉语框架语义知识库，利用统计机器学习的条件随机场(CRF)、极大熵马尔可夫(MEMM) 模型等，研究汉语语义角色自动标注技术.即给定句子中要标注的目标词，自动判定该目标词所属的框架，自动标注该词所直接支配的各个短语（或词语）的语义角色（即框架元素）及其短语类型和句法功能。力争准确率和召回率分别达到80%和75%以上。开发一个汉语框架语义自动标注软件（试验版），为构建大规模汉语框架语义知识库（CFN）提供一个实用工具，为现代汉语语料库深加工提供语义层面的分析工具。
基于深度神经网络的个性化推荐系统	深度神经网络;用户行为序列分析;推荐系统;隐式反馈学习;个性化推荐	推荐系统是数据挖掘领域中十分重要研究领域，对于互联网上日益严重的"信息过载"问题提供了有价值的解决方案，吸引了大量研究工作。然而，现阶段的推荐系统还存在着一些局限性，包括多种异构信息的建模、序列化行为建模、冷启动问题等多个方面。另一方面，深度神经网络在图像、语音等领域得到了迅速的发展，其模型优越性被多次得到证明。深度神经网络对于大规模数据的建模能力以及对高阶关系的挖掘能力在推荐系统中也将带来巨大的优势，提供了推荐系统算法中潜在的一大突破口。但由于现阶段深度神经网络在多种数据类型下的局限性，在输入数据较为复杂的推荐系统中还存在着许多待解决的科学问题。本课题中，我们将针对深度神经网络在此类问题中的局限性进行研究，探索如何将深度神经网络应用至推荐系统的场景中，基于此提出新型推荐系统深度学习模型框架。本研究有助于拓展深度学习的应用范围，推动深度学习在信息检索领域中的应用，并进一步改进推荐系统算法。
网络信息的话题挖掘和分析关键技术研究	信息过滤;社会网络分析;话题发现和跟踪;自然语言处理;信息抽取	对网络信息的话题内容进行智能处理，不仅具有重要的应用价值，而且在科学研究上也极具挑战性，是目前学术界研究的热点。针对网络信息在话题内容上的演变性、在传播方式上的流动性和社会性等特点，本项目把网络信息的话题挖掘和分析问题放在社会网络这一背景下进行，通过有机结合话题分析和社会网络分析这两方面的研究，以自然语言处理技术和机器学技术为基本手段，达到提高网络信息内容分析准确性的目标。本项目主要研究内容包括：以事件为核心的话题描述框架，以及基于事件模型的话题发现和信息抽取技术；多层次多特征话题信息自适应过滤技术；面向网络文本信息的社会关系挖掘和社会网络分析技术；在此基础上，以社会网络挖掘为基础，有机融合网页的结构特征、文本内容的语义特征、信息传播的空间特征和社会关系网络特征等，实现多特征融合的特定话题信息流的跟踪，以揭示重要话题的传播和演化规律，提高互联网信息的话题挖掘和分析的准确性。
串到树统计机器翻译的若干关键技术研究	篇章级翻译;句法分析;串到树统计机器翻译	统计机器翻译核心思想是给每个潜在的翻译结果都赋予一定的概率，并选择概率最大的翻译作为最终的翻译结果。统计机器翻译的研究和系统开发已经成为自然语言处理乃至整个人工智能领域的核心问题之一，已经被广泛地应用在在线翻译和受限领域的机器辅助翻译中。串到树统计机器翻译是基于句法的统计机器翻译研究的主流框架之一。本申请课题在深入分析目前基于句法统计机器翻译模型研究工作存在的一些问题的基础上，重点研究串到树统计机器翻译的一些关键问题和改进技术。主要研究内容包括：改善现有语言分析平台、弱指导的迭代式词对齐、基于多句法分析器的翻译规则抽取和融合、目标语树结构评价、基于实例约束的解码、篇章级翻译一致性检测等技术。最终集成这些关键技术，构建串到树统计机器翻译开放共享支撑平台。
汉语普通话语音生理模型研究	汉语语音合成;语言生理与声学的关系;动态声门;动态声道;语音生理模型	在言语链中，语言信息传递中最重要的一个环节是人大脑控制下的言语生理机制到言语物理层面的信息转换。这个转换的科学基础涉及神经科学、言语生理学、生理语音学、言语声学、语音学和音位学。研究语言信息从生理层面到声学层面的转换对于认识人类语言信息的产生和传递有重要的理论意义。本项研究从言语生理的角度入手，利用高速数字成像设备、X光设备和核磁共振(MRI)等生理仪器和设备，采集包括汉语普通话语音、动态声门录像、声门阻抗信号、动态二维X光声道录像、二维核磁共振静态声道图像、三维核磁共振声道静态图像、二维核磁共振动态声道录像、二点五维核磁共振动态声道录像和三维核磁共振动态声道录像等一系列生理信号，利用语音和图像处理技术，研究汉语普通话动态声门和声道基本机制，对其生理机制和声学的关系进行深入的分析汉研究，并在此基础上构建基于生理几何模型和声学语音模型的汉语普通话语音生理基础模型。
基于信息抽取技术的蛋白质相互作用网络构建及蛋白质复合物识别研究	生物信息学;关系抽取;文本挖掘;自然语言处理;实体识别	随着基因组学研究和高通量技术的飞速进步，蛋白质之间的相互作用数据迅速积累，从蛋白质相互作用网络中识别出蛋白质复合物，是生物体行为理解、蛋白质功能预测和药物设计的基础。本项目综合利用各种生物医学知识源，使用特征耦合泛化策略构建蛋白质的实体识别模型；使用基于语义的相似度计算解决蛋白质名标准化中的歧义问题；使用平面特征核、卷积树核以及特征耦合泛化核的复合核模型进行蛋白质相互作用关系抽取，从而构建高准确的蛋白质相互作用网络。在抽取蛋白质复合物的过程中，综合考虑图的拓扑结构、蛋白质复合物的生物结构和蛋白质的功能标注信息，并引入基于监督的分类算法，从已知蛋白质复合物提取包括结合图的拓扑结构信息、关系的可信度和络合物内蛋白质相似程度在内的特征，结合机器学习模型抽取蛋白质复合物。本项目将相关技术应用于肺癌的蛋白质相互作用网络构建和蛋白质复合物提取，发现肺癌肿瘤标志物，用于肺癌早期诊断。
无监督分词及词性归纳联合方法研究	词性归纳;分词;自然语言理解;联合方法;无监督	无监督分词和词性归纳作为相继任务，是计算语言学中重要的研究课题，具有较高的理论研究价值和广阔的应用前景。本研究拟提出无监督分词及词性归纳相结合的联合方法，使分词和词性归纳两个不同层次的统计信息相互补充，以期同时提高两种不同处理在自然语言理解中的性能。本联合方法基于申请者先前提出的无监督分词方法和环境内聚思想，一方面通过获得基于语素及其类别的不针对特定语言的形态信息，以进一步提高处理精度，另一方面通过获得一词多类的归纳结果，以及利用全局统计特征分辨封闭词类与开放词类，以产生接近人工标准和便于人类理解的处理结果，通过提高评估成绩达到提升性能的目的。本研究成果将为构建包含语法归纳在内的更大规模的无监督联合方法奠定基础。
基于组合范畴语法的汉语深层句法分析	组合范畴语法;精粒度词法范畴标注;深层句法分析;句法分析	深层句法分析旨在获取比传统的短语结构分析和依存分析更为深层的语法信息，并提供通向组合语义分析的透明接口，是近些年兴起的一个重要研究课题。本项目提出基于组合范畴语法来研究汉语深层句法分析，力图在范畴语法和汉语句法分析两方面取得创新性成果和研究性进展，为汉语的语义理解等深层文本分析任务提供支撑。为实现这一目标，我们将着重研究基于深层词汇计算的词法消歧和语义驱动的句法消歧等两项深层句法分析的核心技术，构建汉语深层句法分析器。在此基础上，将进一步研究辨别式与隐变量生成模型的集成学习，异质数据融合以及无指导词汇归纳等三个统计机器学习问题，藉此从学习算法和拓展数据源两个方面来改进深层句法分析。本项目的最终目标是探索汉语深层句法分析问题、研究相关核心技术并构建高质量的语言理解系统，从而为文本数据挖掘、问答系统、机器翻译等研究领域提供有益参考。
意见挖掘中隐式情感的资源建设和自动分析研究	资源建设;情感分析;深度学习;隐式情感;文本分类	情感分析是近年来自然语言处理和社会计算的热门研究话题。隐式情感分析作为情感分析的重要组成部分，相关研究非常缺乏，暂无相关大规模标注资源和分析模型。本项目拟研究汉语隐式情感的资源建设和自动分析技术。为此，本项目将探讨汉语隐式情感表达现象，建立一个汉语隐式情感标注资源，提出基于上下文的神经网络模型和基于知识图谱的深度文本推理模型来自动分析汉语隐式情感。本项目有助于构建面向汉语的隐式情感标注资源，探讨面向汉语隐式情感分析的语义理解关键技术，推动知识图谱、深度学习和文本推理技术在情感分析中的应用，进一步完善汉语情感分析研究。
面向部分标注多模态数据的大规模跨媒体检索技术研究	标签补全;多模态数据;跨媒体信息检索;部分标注	大规模的异构多模态媒体数据的爆发式增长，对更高效的跨媒体检索技术提出了迫切的需求。在针对大规模"图像-文本"多模态数据的跨媒体检索问题中，现有的方法通常试图利用已有的类别标签信息提高跨媒体检索模型的性能，却忽视了这些标签信息本身的质量对检索模型性能的影响。.    在此背景下，本课题针对现有的大规模图像文本数据集只包含部分类别标签的局限，探索如何学习出高效的跨媒体检索模型。本项目将从三个方面展开研究：（1）部分标记的多模态数据的标签补全研究；（2）利用标签信息的跨媒体检索模型设计；（3）挖掘各模态数据内部隐含非线性结构。以上三个研究点互为耦合且逐渐增强，为实现高效的跨媒体检索系统提供理论基础支持和实际应用验证。
基于部分指导的词义学习和词义排岐综合研究	部分指导;词义学习;词义排岐;层级聚类;未标数据	本项目旨在将词义学习和词义排岐问题一般化为一个基于部分指导的词义学习问题，并提出了一个基于Random Walk、主动学习和层级聚类的综合策略。该策略能够同时实现词义排岐和词义学习功能、无需遍历可能的义项数而自动推导出义项类及其个数、具有自我修正学习错误的功能、同时又充分发挥未标记数据的作用。本项目在同一个框架内同时考察词义排岐和词义学习问题，有助于提高实际应用中词义处理的鲁棒性；有助于在义项级别上丰富现有词汇语义资源；对于模拟词义知识获取的认知过程也有一定意义。
网络社交媒体中特定社会安全事件的侦测分析与态势评估研究	属性知识库;侦测分析;特定社会安全事件;态势评估;社交媒体	特定社会安全事件是指网络社交媒体中发布传播的危害国家安全､社会稳定、民族团结等突发性安全事件。该类事件不同于网络攻击类事件,其以传播危害国家安全和社会稳定的不良信息为目的,具有强度小､信息繁杂､隐蔽性高的特点,且不会导致设备故障或网络瘫痪，也不存在任何告警信息，其侦测和态势评估的难度较大，研究较少｡本项目的目标是建立一套适用于社交媒体中特定社会安全事件的侦测分析与态势评估的理论体系，探索该类事件信息在社交媒体中的传播机理及关注群体的互动规律。研究思路：构建基于多源社交媒体的社会安全事件基础数据库->设计社会安全事件的特征属性体系及其相应的特征提取算法->提取特定社会安全事件的特征属性并构建面向该类事件的属性知识库->基于该属性知识库，研究社会安全事件信息的传播机理模型与算法、子事件的侦测识别与跟踪算法、事件关注群体的识别分析与互动规律、事件的态势评估及预测模型->构建相应的实验系统。
基于部件的联机手写藏文音节识别方法研究	部件;音节切分;字丁-部件生成模型;联机手写藏文音节识别;集成识别框架	针对藏族地区信息处理技术的重要性，以及当前联机手写藏文识别技术尚不能完全解决支持连续书写的藏文手写输入的问题，本项目以联机手写藏文音节识别为研究对象，通过分析藏文音节的结构特点，以部件为识别基元，结合部件统计识别方法和基于部件的结构识别方法的优点，提出一种基于部件的联机手写藏文音节识别框架。首先，研究基于部件的藏文音节的切分算法，以解决字丁/部件之间粘连和重叠的问题；其次，研究音节识别框架中需要集成的四个子模型（部件分类模型、基于字丁的语言模型、字丁-部件生成模型和几何模型）的构建；最后，基于音节过切分的结果，利用集成切分与识别的思想，将这四个子模型集成到统一的识别框架下，研究多个子模型的信息融合和参数学习方法，根据最大后验准则对切分和识别进行评价，最终得到音节的切分和识别结果。该研究成果中的关键技术可以应用到基于笔式交互的移动设备中，并为联机手写藏文文档的分析与识别奠定研究基础。
Web信息检索中搜索结果个性化和多样化算法的融合技术研究	检索模型;查询意图分析;搜索结果多样化;个性化搜索	搜索引擎中的查询词往往具有歧义性和模糊性。不同用户即使使用了相同的查询词，也往往具有不同搜索意图。个性化搜索和搜索结果多样化技术是解决这种问题、提高用户满意度的两种有效方法。个性化搜索基于用户的知识背景和兴趣爱好返回给用户个性化的结果，而搜索结果多样化的目标是提高结果列表尤其是顶部的多样性，以保证不同用户都能在搜索结果的靠前位置查找到所需要的信息。目前已经有一系列单独的个性化或多样化算法被提出，但对二者之间的关联关系研究仍然较少。个性化和多样化能否结合，是否可以结合是重要但尚未被深入研究的问题。针对这一问题，本项目以查询意图的理解和分析为基础，充分研究个性化和多样化算法的作用机理及性能预测方法，以此为基础分别研究基于决策树的弱耦合个性化和多样化融合方法及直接对个性化和多样化联合建模的深度融合方法，为搜索引擎进一步提高用户满意度奠定技术基础。
基于复杂网络的信息推荐技术研究	信息推荐;二部分网络;相似性指标;协同过滤;复杂网络	大部分推荐系统本质上可用用户-对象二部分图进行刻画，复杂网络的发展提供了精细刻画二部分图结构特征和演化行为的有力工具，从而有望揭示推荐系统结构演化的特征，为提高推荐质量提供借鉴。项目将系统研究真实推荐系统的用户-对象二部分图的静态结构和动态演化行为，总结大量系统结构上的共性和个性，最终建立简单可控且能较好再现这些统计共性的网络演化模型；在此基础上，拟系统地研究用户-对象二部分图的结构特征与推荐效果之间的关联关系；最后，在协同过滤的算法框架下，系统地研究基于局部信息和全局信息的各种用户相似性指标，得到如何通过分析数据集特性选择合理相似性指标的办法，提出一些整体性能优异的新的相似性指标。该研究有望揭示推荐系统自身的统计特征和演化规律，提供根据推荐系统数据集特征选择推荐算法的一般化指南，推动并最终解决个性化推荐领域具有相当挑战性的一个问题：如何为具有不同特征的数据集选择适当的算法。
基于含隐结构变量的结构化预测模型的中文语义解析研究	结构化预测模型;自然语言交互;语义解析;地理信息系统	语义解析（semantic parsing）任务的目标是将自然语言形式的句子转换成一种完全形式化的意义表示，从而使得自然语言形式的句子能够被计算机自动理解和执行。本课题针对中文的特点，研究与设计一种基于统计学习模型的鲁棒的中文语义解析实现方法。课题结合中文GIS自然语言交互这个实际应用领域，首先定义与设计有效的形式化意义表示语言，并构建相应的中文语义解析标注训练语料；通过将中文语义解析任务看成是一种结构化预测任务，提出一种基于含隐结构变量的结构化SVMs模型的中文统计语义解析算法，引入同步上下文无关文法SCFG等隐结构对输入与输出之间的对应关系进行建模，并设计相应的学习算法；进一步通过将直推式SVMs的思想扩展到含隐结构变量的结构化SVMs模型中，研究与设计一个半监督的中文语义解析算法，以利用大量未标注的查询语句实例提高和改进中文语义解析的性能。
基于领域本体的Petri网自动集成机理与应用模式研究	PNML;领域本体;OWL;Petri网;动态行为	本课题面向Petri网在语义Web上的应用方法，具体研究基于领域本体的Petri网自动集成技术与应用方法，主要从以下4个方面进行: 1) 基于领域本体的Petri网的语义化描述方法，2) 基于领域本体推理的Petri网自动共享合成操作的实现，3) 语义Web动态行为系统Petri网模型的自动生成技术，4) 语义Web动态行为系统执行的动态监控和实时控制的Petri网方法。并开发语义Web上动态行为系统的Petri网分析平台原型系统，对课题提出的相关理论和方法进行分析与验证。.本课题的研究将为实现Petri网在语义Web 上的实际应用提供切实可行的技术路线和应用方法，同时，充分发挥Petri网在系统建模和系统结构、动态性质分析方面的优势，为语义Web动态行为系统的有效运行提供技术支持。
个性化Web信息检索中排序算法及其优化技术	个性化Web信息检索;排序算法;用户兴趣模型;隐私保护	信息检索已经成为互联网用户查询和获取信息的重要手段。个性化Web信息检索根据用户的偏好将用户最感兴趣的内容置于检索结果列表的第一位，从而能有效地提高传统检索的准确度，更好地满足用户的信息需求。因此一直以来个性化Web信息检索都将提高排序算法的准确度作为其研究的核心问题之一。随着Web上信息资源多样化和快速膨胀，用户不仅要求检索结果更为准确，而且希望检索速度快、个人信息得到安全使用。本项目研究针对用户对个性化检索提出的新要求，探讨解决提高其排序算法准确度、效率和安全性的优化技术。主要包括基于查询词和用户兴趣获取时间的排序算法、排序算法效率和用户模型的更新机制、基于隐私保护的用户兴趣模型构建、具有隐私保护的排序算法等，并设计和实现算法，在真实数据之上评价相关算法的各项性能指标及相互关系。本项目争取在信息检索理论和技术上取得一定的突破，为今后的实际应用推广奠定坚实的基础。
基于汉藏语言有序对应数据库的亲缘关系计量研究	语言亲缘关系;计量研究;汉藏语言数据库;有序对应;算法	本研究力图编制判定对应规则和判定时间层次的对应算法程序，配合人工择词与比较分析，建立起严格的汉藏语诸支系有序语素对应数据库。在此基础上，评估已有的谱系分类算法，在已有程序的基础上开发适合语言亲缘关系的新算法和软件。运用程序完成汉藏语系下各分支之间的比较及数据库的对接，并探讨分析其中反应出的语言之间的语源关系，实现自动根据同源数据库中核心同源语素的比率生成有亲缘关系的语言的谱系树，并对语言数据与树图之间的关系给出数量评估。整个研究不仅涉及语言学、计算机科学和计算数学共同感兴趣的画树方法、数据库构造技术和算法设计等，还将为汉藏语系语言之间纷繁复杂的谱系关系等提供一个客观的说法。
社会网络的主题演化分析与传播趋势预测研究	主题演化分析;传播趋势预测;主题抽取;社会网络;压缩感知	在线社会网络的主题演化分析有着重要的研究意义和应用价值，而其中主要的技术瓶颈是对海量低质数据的抽取与分析。基于压缩感知的数据采样与压缩理论，在信号处理领域已获得了广泛应用，但并不直接适用于社会网络。本项目中，首先通过特征指标打分、特征稀疏转化等，实现社会网络特征张量空间到压缩感知时频空间的映射，为压缩感知理论在主题分析中的运用提供依据。在此基础上，设计整合先验知识的主题信息重构算法K-OMP，在样本数据远少于原始样本集的情况下，重构逼近完整的主题信息，实现高质量主题抽取。进而，提出基于动态冗余字典的主题演化分析算法DRD-EA，分析主题流的内容和生命周期演化规律。最后，基于主题演化状态、传播强度和节点影响力等，改进无标度网络BA模型，对主题传播趋势进行预测。研究成果将是对传统的社会网络主题抽取与演化分析方法的全新突破，有利于更高效地挖掘社会网络数据的潜在价值，促进社会网络的健康发展。
基于大规模无标注语料的跨领域跨语言汉语依存句法分析	依存句法分析;汉语依存分析;依存结构;句法分析;领域自适应	依存句法分析是自然语言处理的一个核心问题。与英语依存分析相比，汉语依存分析在性能上还存在较大差距，成为制约中文信息处理的一个瓶颈。本项目针对汉语依存分析中存在的人工标注训练语料不足和领域自适应能力差等关键问题，重点探索如何利用大规模多领域跨语言无标注语料来改进汉语依存分析性能，特别是在处理互联网文本时的依存分析性能，大力提高汉语依存分析的研究水平。为此，本项目拟从四个方面开展创新性研究：1）研究基于大规模无标注语料的依存特征表示体系；2）研究基于大规模多领域语料的面向互联网文本分析的跨领域迁移学习；3）研究基于大规模跨语言语料的面向汉语依存分析的跨语言迁移学习；4）研究基于多信息源的汉语依存句法分析模型和解码算法。最后，集成上述研究成果，构建一个领域自适应能力强的高性能汉语依存分析平台。本项目的开展将为汉语依存句法分析研究作出重要贡献，并为后续应用研究提供有力支持。
内容语义感知的Web文本可信鉴别与求证方法	信息文本;内容信任;鉴别求证;信任特征	互联网已经成为人们获取信息的重要途径，然而海量Web信息来源广泛，良莠不齐，有益危害信息混杂一起，阻碍了网络的健康发展。因此，如何诊断信息内容是否可信，即解决Web"内容信任"问题是一项迫切而挑战的工作。本项目以信息的本质单位"信息文本"为对象，开展基于内容语义感知的Web信息文本可信鉴别与求证方法研究。从内容语义的角度提炼蕴含在文本中的信任事实、信任证据、信任模式等高级信任特征；利用有限自动机、时序描述逻辑等形式化工具研究信任事实的智能鉴别，信任证据的多源求证，信任模式的逻辑验证以及信任语义关系网的联合推导，进而评估判定出文本内容的可信性；最后，通过一个Web新闻报道的可信评定应用示范，检验所提出方法的有效性。可见，该方法直接对信息文本内容进行信任鉴别与求证，无需特殊数据和用户参与，是一种普适的内容信任判断方法，为安全有效使用互联网信息资源提供理论方法及指导意义。
汉语关联结构的资源建设和自动分析模型研究	文本蕴含;关联结构;区分性模型;语义依存;语义资源	汉语的关联结构（由连词构成的复句）包含着丰富而复杂的语义信息。长期以来中文信息处理比较专注于单句的表示和分析，复句的建模和分析处于较忽略的地位。本项目旨在建立一个完整的汉语关联词语本体，研究关联结构的语义依存结构，提出基于语义依存图（有向图）的表示机制，建设大规模标注资源并探讨基于判别性模型的分析策略。语义依存结构跳脱句法依存的限制，允许多父节点和交叉依存。所建资源包含一个汉语关联词语本体和2万个从真实语料中选取的例句，基于对数线性的二阶段区分性分析模型用以分析关联结构的语义依存，其特征设计可刻划局部和全局性的结构化信息。本项目有助于探讨适合汉语实际特点的语义描写机制，丰富汉语语义资源和语义分析策略，对提高汉语自动分析、文本蕴含、信息抽取和篇章理解等技术的性能有一定意义。
Web搜索引擎的多层次缓存数据布局方法及实时检索缓存失效内容更新策略研究	检索效率;实时搜索;搜索引擎;web搜索;缓存	缓存是有效提升大规模Web搜索引擎性能的重要组件，搜索引擎多层次缓存与面向实时检索的缓存查询结果实时性问题是当前领域面临的重要挑战。.    本项目研究在多层次缓存场景下的搜索引擎缓存数据布局方法，突破现有研究仅适用单一层次缓存技术局限，通过分析查询结果、倒排表、倒排表交集因素间的影响关系，将该难题转化为多背包问题进行求解；研究工作负载感知的缓存失效内容更新策略，填补面向实时检索缓存失效内容更新策略研究的空白，对搜索引擎工作负载进行自相似性特征分析，提出搜索引擎工作负载感知的缓存失效内容更新策略，包括基于查询频率、查询时间开销、缓存内容生命周期的更新策略。.    最后，实现一套面向实时检索的高性能搜索引擎多层次缓存系统，采用大规模真实商业搜索引擎查询日志作为工作负载，在该系统上开展实验，验证研究成果的有效性。
基于记忆、推理和注意力机制的端到端神经对话系统研究	推理和注意力;神经网络;对话系统;记忆;语义哈希	端到端神经对话系统是在不需要人工参与特征和规则设计情况下，对外部结构化知识库和当前对话历史信息进行向量化编码记忆，通过对话用户当前时刻的输入文本自动激活神经记忆单元中的相关语义信息进行融合，并基于此融合向量进行动态序列化解码生成系统的响应文本。本项目拟对神经对话系统中对话历史的短时记忆编码、结构化知识的长时记忆编码和信息提取与融合等关键问题进行深入研究，以达到改进已有方法、推动实际应用的目的。主要研究内容包括：（1）利用循环神经网络模型将对话历史进行层次化编码，得到句粒度和词粒度记忆编码，前者便于进行语义定位，而后者便于挖掘对话历史中的细节；（2）采用融入语义哈希学习的双通道模式对结构化知识进行编码，得到二值化和实值化记忆编码，前者极大地提高了大规模知识库上的检索效率，而后者保存了更精确的语义信息；（3）基于K最大采样推理和注意力机制，为短时记忆和长时记忆设计了不同结构的特征提取方法。
基于互动的用户社会行为挖掘	兴趣预测;用户兴趣建模;浏览行为;用户行为分析;用户兴趣	日益增长的个性化网络应用促使各种个性化技术应运而生，这些个性化技术需要分析用户网络数据，以发现其兴趣和行为规律，即用户行为分析。当前的用户行为分析主要基于用户自身历史行为数据，未考虑社会因素对用户行为的影响，比如朋友互动等社会因素对用户行为的影响。为此，本项目将针对朋友互动影响用户行为这一问题，从用户行为互动的基础、用户行为互动短期效果、用户行为互动长期效果这三个方面出发，研究基于互动的用户社会行为。具体开展以下研究内容：1）互动基础，研究融合消息内容和已有链接结构的社会链接预测方法；2）互动短期效果，研究基于链接关系的用户兴趣挖掘模型；3）互动长期效果，研究社会互动和用户自身因素对用户行为和兴趣演变。本项目的研究成果对社交网络商业广告推荐、社交网络舆情分析等领域具有重要的理论价值和应用前景。
基于文本表示学习的金融市场行情预测方法研究	文本表示学习;预测模型;文本挖掘;金融市场;大数据	大数据技术已广泛应用于商业决策系统中，并有效驱动企业产能、效率等方面的提升。然而对于大数据驱动的金融市场行情预测任务，现有研究一方面难以全面深入理解文本内容，另一方面抽取的特征维度较高且十分稀疏。本课题旨在通过对大规模文本进行语义表示学习，进而推动大数据驱动的金融市场行情预测研究工作，其主要创新点体现在如下四方面：1）提出一套面向预测的事件表示学习方法，将同类事件映射到向量空间相邻位置，提高事件归一化准确率，为大数据驱动的预测技术奠定基础；2）提出面向预测对象的句子表示学习方法，针对同一句子该方法为不同的预测对象学习出不同的句子表示，进而得到不同的预测结果；3）提出基于层次化LSTM模型学习篇章级文本语义表示，进而克服了事件信息量小、缺乏背景知识等不足，为大数据驱动的预测技术提供全新的解决思路；4）提出一种基于卷积神经网络的预测模型，量化学习不同层级金融文本特征给市场行情带来的影响。
基于特征融合的图像近似最近邻搜索哈希方法研究	最近邻搜索;哈希选择;图像检索;特征融合;位置敏感哈希	基于哈希的图像近似最近邻搜索方法，能够显著提高高维数据的存储和索引效率，成为当前的一个新研究热点。在这种方法中，目前由于缺乏高性能的哈希函数，使检索的准确率还不能满足要求。本项目结合图像多种视觉与语义特征在反映图像特性上具有互补性的特点，以特征的多层次融合为着眼点，对高性能哈希函数的构造方法展开系统研究。在理论层面上，通过研究高维空间数据的分布特性，利用最大熵原理和特征子空间方法，研究哈希最近邻搜索机理与哈希性能评价指标体系及提升方法。在技术层面上，研究基于多核学习的多视觉特征融合的哈希方法，研究基于语义特征选择的哈希监督学习方法，以及基于多语义共享的哈希迁移与查询自适应机制。在应用层面上，通过构建哈希函数图，研究普适的哈希选择及多表构建方法。本项目最终将建立一种高性能哈希函数构建理论体系，有效提高基于哈希的图像近似最近邻搜索的准确率。
非均衡概念漂移网络舆情大数据流挖掘模型、算法与评价机制研究	智能优化;数据挖掘;非平衡概念漂移;大数据;网络	网络舆情挖掘日渐成为研究热点。但先前研究基于静态、均衡分布、规模适量情境，面对非均衡分布、突变、主题演化的大数据流，传统理论和方法遇到了一定困难和挑战。本研究旨在将传统挖掘技术从理想态向现实态的泛化更新，故必导致向非均衡概念漂移大数据流路线的拓展延伸。研究主要问题有：1）构建非均衡概念漂移大数据流集成分类器挖掘模型；2）研究基于时间戳的基分类器动态权重集成方法；3）构建非均衡概念漂移大数据流向适度规模数据流的平滑转化算法；4）构建该模型内涵的采样方法；5）研究概念漂移与动态主题演化时序耦合规律；6） 构建挖掘评价机制及验证方法。本项目旨在探索非均衡概念漂移情境下"分类器集成（模型）—大数据流精简及采样（样本）—动态主题演化（语义）—多测度衡量（评价）"具有系统逻辑的知识表征与系统建模新路径，揭示非平衡概念漂移大数据流与动态主题演化的融合挖掘机理，对舆情数据流挖掘具有一定理论意义与实践价值。
大数据下多源数据记录连接的文本处理方法研究	多元信息融合;数据源;数据质量	将来自不同数据源的记录连接来提高数据质量在医疗保健，政府服务以及商业应用中起到越来越重要的作用。目前的解决方案仍然存在有效性不足和对大数据集的执行效率不高的问题。我们针对大数据环境下数据来源复杂，数据规模巨大以及更新速度快的特点，提出有效的方法来提高记录连接的质量，设计高效的算法来提高大数据集的执行效率，研究复杂的自适应索引技术使得数据到达组织时，能够近实时地连接数据。.我们提出了大数据环境下提高记录连接的质量的有效方法，包括对不同来源和准确度的数据进行相似性比较的近似匹配方法研究，利用逻辑回归的分类器的设计方法，提出编码领域知识和置信度的概率变换规则；我们提出了提高记录连接的效率的方法的研究，包括原始数据的分层聚类方法，记录相似性度量的快速计算方法；我们还对大数据的更新数据提出了快速处理方法，并研究在Hadoop系统上开发并行算法的可能性，旨在根据处理器数量成比例地改进执行时间。
基于层次马尔科夫随机场的自适应查询扩展技术研究	层次马尔科夫随机场;词语失配;查询扩展;伪相关反馈	信息检索中的一个非常严重的问题是"词语失配"，即用户查询表达和文档表达中所用的词语并不一致。查询扩展特别是基于伪相关反馈的查询扩展是解决这个问题的目前研究最广泛、应用也最成功的技术。然而，目前的基于伪相关反馈的查询扩展技术存在着缺乏理论框架、不支持多种特征融合、不支持自适应扩展等诸多缺陷，从而大大限制了它们的使用效果和应用范围。本项目力图提出一个能够融合各种特征的查询扩展的理论框架，并利用层次马尔科夫随机场图模型，提出一个能够融合内容和结构特征的具体的查询扩展技术，在此基础上研究自适应的扩展方法。本项目的研究成果不仅具有很强的理论价值，也有重要的实用意义。
跨语言信息检索中的机器翻译研究	功能短语;机器翻译;可嵌套模板函数;跨语言检索	互联网信息在全球范围共享的主要障碍是多语言问题，跨语言信息检索（CLIR）是解决该问题的有效方法之一。但是，现有的跨语言信息检索的精确率过低，没有达到实用的水平，提高跨语言信息检索系统性能的关键是提高检索语句的翻译精度。本项目从中英文两种语言的信息检索入手，研究跨语言信息检索中机器翻译的若干关键技术。针对跨语言信息检索及机器翻译的特点，从三个方面提高机器翻译的精确率：一是考虑从单语检索结果中提取出检索语句本身的多种词法信息，为检索语句的翻译提供细粒度词法信息，从而提高检索语句的翻译精度；二是提出一种融合短语结构和句法功能的功能短语，把对翻译要素的考虑提前到句法分析阶段，提高句法结构歧义的消歧率和机器翻译的精确率；三是提出可嵌套模板函数和统计方法等多模型结合的机器翻译方法，提高含复杂结构的句子或短语的翻译精度。其中，后两种方法对一般机器翻译的研究也具有重要意义和应用价值。
基于查询语义分析与推理的隐式相关反馈检索模型研究	中文语义分析;相关反馈模型;查询语义推理;隐式反馈模型;交互式信息检索	用户查询语义理解是智能信息检索的关键技术之一。在信息检索领域，有关在检索模型中引入（查询语义所代表的）用户需求以及用户与系统间交互信息的理论和方法都还很不成熟。在移动互联网时代，探讨为用户提供智能、高效、精准的交互式搜索服务具有重要的应用价值。本课题以基于查询语义驱动的下一代交互式检索系统为应用牵引，以面向查询语义分析的知识获取、集成和组织为手段，从查询语义表示模型、查询语义分析与推理方法及查询语义驱动的隐式相关反馈模型等方面展开研究。研究融合用户知识和情景知识的查询语义表示模型。研究面向查询语义分析的知识获取、集成与组织方法。按照"实体-查询子话题-查询主题（意图）"的意义传递和结构组织实现查询语义的逐层分析，最后通过隐式一体化相关反馈模型为用户提供精准的智能检索服务。课题研究成果将促进中文查询语义分析、查询知识库构建、隐式相关反馈模型等方面的研究，推动下一代交互式检索系统原型的研发。
汉语全文词义标注关键技术研究	多词表达;词义预测;成语知识库;全文词义标注;词义动态发现	文本的全文词义标注是文本内容理解的前期重要的基础性工作。目前汉语的全文词义标注多关注多义词的消歧任务，仍然无法解决未登录词的词义预测、词典中缺失义项词语的义项标注、成语及惯用语、多词表达的义项标注及语义知识库的完备性等问题。本申请拟从以下几个方面进行研究：（1）将现有词义资源整合，形成完善的词义标注体系，并制定标注规范；（2）针对现有语义词典义项划分的不完善，文本中出现的义项可能在语义词典中缺失的问题，建立词义动态发现模型，自动发现文本中词语的确切词义；（3）构建成语及惯用语知识库和多词表达知识库，扩充词义词典的规模；（4）建立规则与统计相结合的未登录词语词义预测模型，解决未登录词义项标注的难题；（5）综合利用上述研究成果，建立高质量的汉语全文词义标注平台；（6）利用全文词义标注平台，对大规模语料进行词义标注，并利用语料校对技术进行后处理，形成高质量的词义标注语料。
基于规则学习汉语语义构词研究	语义构词;数据挖掘;机器学习;规则集;未登录词	在自然语言理解和机器翻译系统中，未登录词的识别和理解一直是难以突破的"瓶颈"问题，尽管学者们经过半个多世纪的努力在语义构词方面取得了一定的成果，但对于该问题的解决并没有取得突破性的进展，其中一个重要原因就是缺乏详尽可靠的语义构词规则。本课题的研究目标就是采用数据挖掘和机器学习技术，通过人机互动，总结语义构词规则并将它运用到未登录词的语义理解中。研究内容主要包括：（1）校对并扩充已建成的《汉语语义构词数据库》，并抽取一定的训练集；（2）利用数据挖掘技术提取语义构词规则，采用人工干预确保规则的准确性；（3）将这些规则运用到验证集中，通过反复调试得到最终的语义构词规则集；（4）将规则应用到未登录词的预测和理解。本课题的研究成果从理论上说可以推动汉语词汇语义学的发展，丰富和完善汉语词汇语义学理论；从实践上来看有利于推动计算语言学尤其是自然语言理解和机器翻译的进程，也有助于对外汉语教学实践。
基于进化模糊机制的Web新闻挖掘关键技术	进化模糊系统;社会计算;web新闻挖掘;Web信息抽取;大数据	Web新闻挖掘技术应用的主要障碍是挖掘效率低，已有web新闻挖掘方法在web新闻识别提取、web新闻内容分类、web新闻内容摘要等关键应用挖掘技术方面存在准确度低的问题。项目围绕上述问题，为构建高性能的web新闻挖掘模型，在分析、借鉴和发掘传统技术和方法的基础上，系统地探索web新闻的模糊性和动态演变性特点及挖掘模型优化的方法。首先，将进化模糊机制引入网页分类模型，根据新闻所处网页的类型，分别选择采用相应的新闻识别提取方法，提高识别提取的准确度。其次，将进化模糊机制引入新闻分类模型，解决传统方法存在的按照预先定义的类别分类而不能动态地增加新类别的问题，提高新闻分类的准确度。然后，又将进化模糊机制引入新闻摘要模型，解决传统方法在一个确定的模型中摘要短文的候选关键句选择规则不能根据新闻的动态演变情况而改变的问题，提高新闻摘要的准确度。最后，利用仿真试验平台对模型和方法进行验证。
基于模糊本体和情境感知技术的用户行为偏好分析及个性化推荐研究	用户兴趣建模;不确定性推理;情境感知;模糊本体;个性化推荐	准确且动态更新的用户偏好库及个性化推荐算法在个性化信息检索中作用重大。利用模糊本体和情境感知技术对用户的行为、偏好、环境状况和共同知识等情境信息进行分析是构建用户偏好库的重要依据。前期研究工作显示，基于模糊逻辑和信任模型的通用分层情境本体有利于本体概念的重用和降低本体规模，而基于情境条件熵构建的情境本体有利于准确高效的用户偏好库的构建。但前期研究对不确定上下文的处理能力及上下文信息的互操作和推理等方面尚显不足。本项目拟通过建立通用的支持上下文质量的多角度分层情境本体模型和基于可信度和依赖度的移动用户动态行为分析策略实现知识共享和不确定性推理，并在基于情境条件熵的个性化推荐算法的调控下阐明本体模型与用户偏好库进行二次匹配和个性化扩展的方法。本研究以模糊本体和不确定性上下文处理的关系为切入点，为情境识别和基于语义网络的二次扩展奠定基础，为普适计算和跨媒体信息检索领域中用户偏好的挖掘提供新思路。
基于浅层文本理解的社会关系网络构建研究	浅层文本理解;社会关系网络;复述;多名聚合;社会关系抽取	目前的社会关系网络构建通常基于大规模文本中的人物共现关系来实现，这就导致了两个主要问题：一是社会关系网络不够完整，缺乏丰富的关系类型，忽略了人物社会关系的多重性；二是没有考虑自动抽取出的社会关系的可信度，限制了社会关系网络的表现力和推理能力。为了提高社会关系网络的完整性和可靠性，本项目的研究内容包括：1）提出基于分层采样的种子选取策略和基于复述技术的种子集扩展方法，并把它应用于弱指导社会关系抽取；2）基于马尔可夫网络模型，研究多名聚合和多重关系抽取的联合学习策略；3）深入探索社会关系网络的可信度表示和计算方法。通过本项目的研究，可以从自然语言文本中自动构建更完整、更丰富和更可靠的社会关系网络，为下一步的实际应用提供良好的理论依据和实践基础。
命名实体消歧与多源实体知识获取方法研究	知识融合;多源数据;命名实体消歧;共指消解;知识获取	歧义消解与知识获取是自然语言处理研究中最基础的问题；而命名实体则是语言信息处理中广受关注的对象。本项目以汉语的命名实体为对象，研究实体歧义消解与知识获取的方法，为命名实体的理解探索一条有效的途径。主要研究内容包括：(1)构建实体知识表示的框架。研究从多源网络百科中自动归纳实体的基本知识结构和扩展知识结构，并通过扩展知识结构适应对不同实体类的描述；(2)提出实体知识获取与融合的方法。通过挖掘网络百科中的文本知识表示模式以及同义变换规律，从多源数据中获取实体知识；通过文本内和文本间实体共指关系，实现知识融合；(3)提出基于实体知识库的命名实体消歧方法。通过深层学习模型构建文本中的命名实体与实体知识库中对应实体的语义关联，实现对命名实体的理解；(4)探索基于多数据源的命名实体消歧方法。在实体知识不完整情况下，通过从多源数据中获取实体信息实现歧义消解，并提炼信息完善对实体知识的描述。
基于多源语义表示学习的社交媒体文本属性情感分类研究	社交媒体文本挖掘;情感分析;观点挖掘;自然语言处理;情感分类	属性情感分类是社交媒体文本情感分析与挖掘领域的重要研究问题。现有方法主要利用文本内部特征构建分类模型，由于文本包含的语义信息有限，导致分类性能受限。考虑到社交媒体中的用户交互信息以及开放知识库的属性知识可以提供更多语义知识来源，本项目拟开展基于多源语义表示学习的社交媒体文本属性情感分类研究。具体包括：利用文本结构与情感信息进行注意力机制下的表示学习，研究基于上下文语境的文本情感语义表示方法；通过异质网络节点嵌入模拟面向用户、内容和属性，研究融合用户交互信息的文本情感语义表示方法；通过多源约束下的知识表示对属性进行情感推理与消歧，研究融合开放知识库的文本情感语义表示方法；应用端到端的学习机制，实现文本、用户与属性知识的统一语义表示，研究基于多源语义表示的属性情感分类方法。在此基础上，构建面向证券领域的情感分类示范应用。本研究将推动社交媒体文本情感分析的基础研究，也为社交媒体相关应用提供借鉴。
面向领域本体的深度学习方法研究	领域本体学习;本体关系抽取;深度学习;深度网络;特征表示	深度学习是受认知科学理论启发而产生的新兴机器学习方法，有望解决自然语言处理中的传统难题，如本体学习。本申请拟研究面向领域本体的深度学习方法，在分析深度学习和本体学习所存在问题的基础上，深入研究深度网络的有效表示、高效学习、结构优化、输入特征选择等一系列关键技术。通过结合有监督机器学习方法，引入主动式样本标注机制，使得在有限人工标注基础上，产生符合特定任务的深度特征表示；通过对深度网络的分块训练机制，有效融合多源异类特征，提高学习效率与性能；通过网络剪枝策略，在训练过程中自动调整网络结构，消除噪声，提高网络泛化能力；通过构建全面的深度网络输入特征，并最终建立高效的深度网络模型，为本体学习提供高质量的输出特征表示，进而提高本体学习的准确率。本课题相关研究成果将对深度学习的理论研究和本体学习的应用研究产生深远影响，具有重要的理论意义和应用价值。
信息物理融合系统的网络控制抽象与算法研究	信息物理融合系统;网络化控制	控制是信息物理融合系统（Cyber-Physical Systems,CPS）的核心概念之一。传统控制系统设计忽略了计算与通信，不满足CPS海量物理实体的控制需求。本项目拟提出基于数据中间件的CPS网络化控制方法，将已有的、处理离散事件的、不关心时间和空间参数的计算技术、网络通信技术，与现有的、处理连续过程的、注重时间和空间参数的控制技术整合起来。首先基于数据中间件研究CPS网络化系统应用抽象，将控制算法与网络化控制系统实现进行分离；通过控制获取机制实现控制理论开发与应用时的松散耦合，设计本地控制实施机制降低应用时通信与计算对控制的消极影响，研究适用于CPS网络化控制实现技术的控制算法，最后拟搭架移动小车实验仿真平台，将所提出的理论方法与算法在实验中进行验证。力图找到适合CPS自然特性的网络化控制方法，实现控制与计算、通信的深度集成，为我国CPS产业化实现提供技术支撑。
日志模式提炼与跨类型日志分析方法研究	高性能计算环境;日志处理;大数据分析;模式提取	日志是计算机系统运行维护工作中重要的信息来源，但其具有的数量大、格式各异、类型复杂等特征给日志分析工作造成许多困难。国家高性能计算环境作为国家科研领域的战略性服务工具，对环境的运行维护则决定着环境的工作效率，但环境中产生的大量各类日志目前尚未存在一个良好的处理和分析方法。本项目将着眼于环境日志分析中的几个关键技术，通过进行关于日志模式的定义和应用扩展、以及对于日志模式提炼算法的优化对日志进行整理，并对环境中的多种类型的日志展开跨类型综合分析，探索其中的关联性和用户行为分析方法。研究成果预期将应用于国家高性能计算环境，同时进行抽象使之适用于高性能计算环境以外的其他计算机系统。
基于Valence-Arousal空间的维度型中文文本情感分析研究	情感计算;维度型方法;Valence-Arousal空间;中文文本情感分析;语义嵌入	区别于现有类别型方法，维度型文本情感分析方法可以提供更为准确细致的情感信息。目前针对中文文本的维度型研究仍面临词典和语料资源覆盖性差，现有分析方法效率及准确度低等问题。项目基于Valence-Arousal(VA)空间，研究从词汇、短语、句子和文本等多个层次进行中文维度型文本情感分析，具体包括三个方面的内容：1) 通过将情感信息引入词嵌入的学习过程，形成基于情感信息的词向量修正模型，解决现有词向量无情感信息的问题；2) 在短语层次，实现基于自动权重学习的修饰词短语情感强度预测模型，整合实词的情感强度以及修饰词的修饰权重，解决现有基于规则方法中准确率低的问题；3) 在文本层次，利用基于残差堆叠的长短期记忆模型，构建一个六层神经网络实现文本层次的VA值预测，解决深层模型的退化问题。项目希望形成一套系统性的维度型中文文本情感分析方法，构建中文VA情感词典，实现中文文本情感分析的原型系统。
基于特征联想的中文短文本分类方法研究	词语对之间关系;短信息过滤;多信息融合;中文短文本自动分类	短文本分类就是对长度短的文本（通常文本长度小于160字符）进行自动分类。短文本分类技术在手机短信息过滤和客户评论自动分类等方面具有重要的应用前景。本项目将进行以下几个方面研究：（1）以半自动方式，建立由15个不同领域的50万篇中文短文本构成的150个文本集（训练集和测试集）。(2)研究利用"知网"等专家构造资源中的可用信息来扩展短文本所描述概念，建立词语对之间关系的技术和方法。(3)研究词语对之间关系的选择方法。(4) 研究有效利用概念扩展后的短文本所包含的有效信息进行分类的分类模型和分类方法。（5）设计并实现一个中文短文本分类原型系统，其性能基本达到实用水平。本项目的完成也对其它自然语言处理问题（例如二次信息检索等）具有推动作用。
面向查询的XML文本自动文摘研究	自动文摘;XML元素;查询;群落结构	XML已成为网上信息描述和交换的事实标准，XML文本检索是当前国际上的研究热点，根据查询需求将XML文本检索结果的摘要返回给用户能有效提高信息获取效率。本项目以XML信息检索引擎返回的XML元素(以文本为中心)为对象，以生成满足用户特定查询需求的、简洁且可读性良好的摘要为目标，研究面向查询的XML文本自动文摘关键技术，包括特征选择、XML元素摘要内容抽取模型、摘要内容排序模型和话题群落结构分析方法。考虑XML元素自身的结构性和检索引擎返回结果的层次性，本项目选择支持向量回归模型集成查询、内容和结构三类特征，并采用高效且具有并行化特点的瀑布型摘要内容抽取框架。对得到的摘要内容片段，利用随机冲浪模型从全局的角度考察句子的顺序关系，改善摘要的可读性。为使用户把握XML检索引擎返回结果中各子话题之间的联系，还采用基于电路图的群落结构分析法构建各子话题之间的群落结构拓扑图。
典型事件过程建模的研究	文景转换;典型事件过程;常识获取;事件图	典型事件过程是指符合常识的，此事件从开始到结束中涉及的一系列子事件及它们之间的过程关系。目前和事件相关的研究主要集中于事件识别、事件时序等一些关系抽取，还没有在文献中发现对典型事件过程建模的研究。而这类知识可以用于NLP领域和文景转换中与事件推理有关的各种应用中。本课题提出了基于常识语料库的典型事件过程建模方法，也就是形式化为有向事件图的方法。课题以英语为研究对象，从普遍意义角度，设计表示典型事件过程的事件图；提出用相对熵表示事件之间有向的关联强度，从而确定子事件；研究基于数据挖掘、信息抽取方法的事件图生成技术；以wiki网站内容和儿童故事文本为资源，构建常识丰富的语料库。由于传统金标准（golden-standard）评价的昂贵代价，提出基于实验和应用的的双层评价体系。前者负责评测各种特征对该方法性能的影响；后者在动画自动生成任务上检查典型事件过程模型的有效性。
基于Web及知识获取的无指导汉语词义消歧技术研究	数据稀疏;知识获取;统计学习;无指导词义消歧;基于Web	词义消歧是很多相关研究领域的一项困难而又重要的基础课题。由于有指导方法所能处理的词汇有限，无指导词义消歧近年来得到了普遍关注，而知识的自动获取是无指导消歧方法的关键。同时，Web资源在计算语言学领域的应用已经越来越受到重视并取得了很好的效果。本课题提出了基于Web及知识获取的无指导汉语词义消歧技术研究方法：1）将汉语词汇基于所需不同消歧知识进行一定粒度的分类；2）利用搜索引擎在Web及现有各类语义资源上进行词汇、句法及语义等不同层次消歧知识的自动获取；3）探求面向知识的特征选择，针对不同词汇类建立多知识源混合的消歧模型及消歧算法；4)在分治与自举的框架下，进行模型与算法优化及Web噪音过滤。目的在于寻求用最小资源与代价自动获取汉语词义消歧所必须的各类有效信息，排除知识获取过程中出现的Web噪音干扰，建立适合该无指导体系的词义消歧模型，缓解数据稀疏，最终给出实用的汉语词义消歧无指导解决方案。
查询语义分析驱动的多层次交互式查询意图识别技术研究	交互式信息检索;查询歧义分析;相关反馈;查询意图识别;查询语义归纳	查询意图是指用户在构建查询时希望搜索系统能够返回的信息。准确识别查询意图是搜索引擎克服信息过载问题的关键。由于数据稀疏和用户隐私等问题，试图完全自动地预测查询意图面临着较大困难与风险。本课题尝试采用人机协同方式，研究查询语义分析驱动的多层次、交互式查询意图识别技术。具体研究内容包括：1）利用语义组合构建查询全局语义表示，克服由于数据稀疏和搜索结果质量不高导致的难查询语义表达问题，支持查询语义分析。2）基于查询歧义分析，自动判断查询意图层次，从语义层次到属性层次逐层确定查询意图，与用户搜索过程自然结合。3）基于查询语义意图归纳，挖掘并清晰表达潜在的查询意图，减轻用户认知负担，促进交互。4）以查询意图识别结果为基础，提出了基于语义意图的相关反馈模型改善文档相关性排序，以及基于属性意图的多维度信息摘要直接满足用户信息需求。课题目标是实现高性能的交互式搜索系统，解决因查询意图模糊导致的检索难题。
基于归纳逻辑程序设计的本体学习方法	归纳逻辑程序设计;语义Web;本体学习	本体学习是语义Web能否成功的关键之一。已有的本体学习工作集中在术语、同义词、概念、分类体系和关系层，而公理层的研究很少。已有的学习描述逻辑工作主要研究概念的定义公理，而没有研究角色的定义公理、以及概念和角色的约束公理。到目前为止，还没有见到学习OWL DLP本体中所有公理的报道。OWL DLP是可转换为一阶Horn子句逻辑的OWL Lite子集和RDFS超集,Horrocks等人的研究表明，它覆盖了大部分语义Web本体。虽然可以采用归纳逻辑程序设计（ILP）方法学习一阶规则集，再将其转换为OWL DLP公理，但是传统的ILP方法存在次优解问题，并不适于学习OWL DLP公理。本项目提出一种适于学习OWL DLP公理的ILP方法；研究将一阶Horn规则集转换为OWL DLP公理的方法；提出一种获取最大一致学习本体的OWL DLP不一致推理方法；基于以上方法和技术，构造本体学习工具和应用。
面向短文本数据流的信息检索与信息过滤协同学习研究	在线排序算法;信息检索与信息过滤协同学习;参考文档模型;短文本流	随着移动互联网的迅速发展，互联网上短信息的发布更加普遍，以微博为代表的短文本流的处理的重要性逐渐彰显。课题首先针对微博的短文本特性，提出了补偿文档模型，通过引入含有更丰富信息的补偿文档作为反馈源，利用反馈技术准确地估计出查询模型和微博模型，是短文本检索建模的一个新的尝试。从另一方面来说，微博不断更新，特别是在用户查询期间不断有新微博到来，需要根据用户的反馈及时更新模型，对此课题进一步尝试从信息过滤的角度对微博建模，提出了在线排序逻辑回归模型解决该问题，探索在线学习和排序学习结合的新机制。最后，课题选择能够在在线学习环境工作的协同学习算法，利用其协调来源不同、异构、具有互补性的在线排序逻辑回归模型和补偿文档模型，并采用主动学习策略，缓解单边反馈问题，达到大幅提高系统性能的目的。
面向PDF文档的数学公式搜索技术研究	信息检索;语义检索;网络信息检索;信息检索模型;搜索引擎	数学公式凝聚着人类知识的精华，当前Web上公式资源日益丰富，加之公式自身结构复杂，公式搜索成为搜索引擎、知识管理等领域的一个研究热点；另一方面现有公式搜索技术主要面向Web资源（如MathML、LaTeX等），对于包含大量公式的主流文献格式-PDF文档，尚难以处理。为此本课题拟研究面向PDF文档的公式搜索技术，围绕公式的识别抽取、查询输入、分词索引、匹配排序等关键问题，研究公式定位与结构分析、基于层次泛化的分词索引、基于多级匹配的相似度评价、上下文匹配、排序学习与重排序等算法。本课题将实现一个完整的公式搜索流程，包括PDF文档中公式的自动发现与结构化、一种新颖便捷的公式输入(即从PDF文档中直接"拷贝")等方法，解决现有公式搜索系统难以处理PDF文档公式的难题；所提出的半语义结构树构建、相似度计算等方法将有效提高公式搜索的查全率与查准率，推动公式搜索的技术进步，促进公式资源的挖掘利用。
基于映射关系理解的实体翻译方法及应用研究	映射关系;实体翻译;机器翻译;机器学习;实体识别	实体翻译在机器翻译、跨语言信息检索等领域都有非常重要的用途。目前实体翻译面临以下几个挑战：实体作为多信息成分的组合体，在翻译中呈现不同的映射方式，目前翻译模型难以表示和容纳这些丰富的映射知识；传统的双语实体抽取方法难以从模式、内容多样性的网络资源中获取双语词典；实体识别错误是实体翻译应用于机器翻译系统的最大障碍。因此，本项目拟在以下几个方面进行深入研究和探索：（1）在对实体映射关系进行分析、定义的基础上，结合实体识别任务，提出实体映射关系的理解方法；（2）在此基础上，研究提出基于映射关系理解的实体翻译一体化模型；（3）利用图模型对混合网页中翻译对的抽取问题进行建模，并建立主动学习引导下的双语词典生成的新方法；（4）最终面向机器翻译的应用，提出基于多核学习的扩展实体翻译模型，实现实体识别和实体翻译的交互，并辅助机器翻译系统性能的提高。本项目开展的研究工作具有重要的理论意义和应用价值。
考虑用户浏览行为的网络短文本推荐的研究	浏览行为;推荐系统;短文本	在社会化网络时代，承载着丰富信息的短文本数据被大量地产生出来，并在互联网络上迅速传播。根据用户浏览行为产生的数据，推荐用户感兴趣的短文本信息及其链接，成为帮助用户及时发现和有效地获取各种网络媒体信息的重要手段。这种以网络短文本数据为主要内容的推荐，给传统的推荐技术及其所依赖的基本假设都带来了新的挑战，并逐渐引起工业界和学术界的广泛关注。本课题的研究针对短文本篇幅短包含的内容极少、流式和时效性短、以及特征的非独立性等挑战，以微博话题的动态推荐和基于用户浏览历史的网页浏览推荐为基本应用场景，将内容特征极稀疏的高维数据建模、流式短文本数据的在线话题聚类、非独立多特征数据的推荐模型等作为课题主要的研究内容，来解决上述问题。本课题的研究旨在帮助解决，利用用户浏览行为的数据进行网络短文本推荐所面临的基本问题，进一步完善推荐技术，推动推荐系统在社会化互联网中更广泛和有效的应用。
基于双语文档反馈的跨语言信息检索研究	平行语料;跨语言信息检索;伪反馈	跨语言信息检索目前主要采用基于查询翻译的方法，性能受到现有翻译质量的制约。同时，当前跨语言信息检索系统在建模时没有考虑在跨语言条件下获取用户检索意图，是导致检索性能不足的另一个重要原因。本课题以汉英跨语言信息检索为对象，探索将双语文档引入跨语言信息检索建模过程，通过选择双语文档来反映用户的检索偏好；进而将源语查询和目标语文档分别通过双语文档进行伪反馈，据此建立查询模型和文档模型；并研究查询模型和文档模型在不同的语言表达空间上的相关度计算方法，从而获得源语言查询和目标语文档的相关度排序，最终实现"不用翻译"的跨语言信息检索。与传统的基于语料库方法不同之处在于，本课题不再单独使用双语语料训练翻译模型，而是将双语文档作为检索模型的参数,参与构建一体化的跨语言检索框架。
自适应的中文网络意见挖掘关键技术研究	情感分析;意见挖掘;机器学习;主观性识别	从网络评论中挖掘意见信息是当前网络信息处理研究领域的热点问题之一。领域适应性和性能稳定性是目前意见挖掘系统在处理大规模开放网络文本时所面临的两个主要问题。针对这些问题，结合中文网络评论的特点，本项目拟以自然语言处理技术为基础，融合多种语言学知识，在机器学习框架下研究自适应的中文网络意见挖掘关键技术。主要研究内容包括：研究面向网络评论文本的中文处理技术，重点解决网络文本存在的次生成问题；研究中文情感知识获取和意见语料构造方法，重点研究领域和上下文相关的动态情感知识自动获取方法，以提高系统的自适应能力；研究模式匹配和情感密度相结合的主观性识别算法；在机器学习框架下研究融合多个特征和情感知识的意见抽取和极性分类方法，重点研究特征选择和优化算法，以提高系统的性能稳定性。本项目的实施对自然语言处理、信息检索、文本挖掘、自动文摘、问答系统和智能信息服务等研究领域具有重要的科学意义和应用前景。
乌金体藏文古籍文档分析与识别研究	藏文古籍;版面分析;文本识别;乌金体	藏族有悠久的历史和灿烂的文化，藏文古籍浩如烟海仅次于汉文，是中华文化重要的组成部分，也是珍贵的人类文化遗产。但是，由于年代久远，大部分古籍存在模糊、纸张疏松、断裂和破损，有些甚至不能翻阅，亟待抢救和整理。本项目的目标就是为藏文古籍的数字化保护提供技术支持。在对古籍样本图像深入分析和处理从而提高图像质量的基础上，本研究提出将古籍页面图像分割为文本、图像、图形或表格等不同属性区域的版面分析方法；根据古籍手写和木刻的复杂文本特征，构建具有较高准确率的文本区域行、字切分算法模型；通过乌金体古籍文本字符图像的部件采样，创建基于部件图像的乌金体藏文、梵音藏文大字符集样本库合成方法，解决字符样本的多样性和对藏文古籍文字识别的适应性；研究多特征融合的大字符集藏文特征表示方法，训练具有较强鉴别能力和鲁棒性的分类模型；设计和实现一个藏文古籍识别系统，将藏文古籍自动转换为相应的电子格式并进行有效的检索。
基于枢轴语言和图映射的历史典籍术语对齐研究	图映射;枢轴语言;术语对齐;可比语料	针对历史典籍术语翻译中缺乏古汉语分词算法和大规模双语平行语料的问题，本项目结合历史典籍的特点，使用白话文解释以词对齐和枢轴语言的方式，帮助历史典籍进行分词和术语对齐。在分词上，将现代汉语的字词组合信息通过词对齐的方式映射到历史典籍中进行分词。在术语对齐上，使用白话文解释作为枢轴语言建立间接对齐模型，对直接对齐模型得到的候选术语进行修正、补充和删除。并利用对齐结果进行句子对齐，使用自举的方法获取更多的平行语料。为了摆脱双语平行语料的限制，本项目在可比语料上结合其他中英文语料资源建立中英文关系图，对两图节点使用包含拓扑结构、上下文等多种信息的相似度进行映射获取术语翻译对。本项目利用现代汉语分词语料和平行语料的丰富，解决典籍术语翻译中存在的基础问题，研究基于枢轴语言和图映射的对齐方法，获取术语翻译对。期望本项目的研究能有助于历史典籍的翻译工作，促进中国文化的海外传播。
基于词义的文档表示模型及多语亚文档主题分析研究	词义;主题分析;多语;文档表示模型;亚文档	互联网加速发展，给以主题分析为核心的舆情监测带来了机遇和挑战。主题分析研究目前主要面临三个难题：（1）基于词汇或词簇的文档表示模型不能有效处理一词多义和多词同义等语义现象，因而不能精确表示文档。（2）面向整篇文档的主题分析方法无法应对文档多主题现象。（3）多语言/跨语言瓶颈问题日益突出。针对上述问题，本项目提出基于词义的文档表示模型（SCM），具有如下优越性：第一，一词多义和多词同义现象在文档表示阶段就能准确体现，文档表示更加精确。第二，基于词义的模型对文档长度具有鲁棒性，数据稀疏问题大大减弱。第三，以词义表示文档，多/跨语言处理潜力较强。本项目进而提出主题分析的两项创新性工作：一是面向亚文档的细粒度主题分析，使主题分析更加准确。二是多语言/跨语言主题分析，提高主题分析的国际化能力。本项目的顺利完成，将进一步推进主题分析研究，提高我国舆情监测的水平，从而促进互联网健康发展。
面向云平台数据与隐私安全的分布式信息流控制技术研究	数据安全标记;云安全;分布式细粒度信息流控制;细粒度能力传播	数据所有权与数据控制权本质上的分离，导致云的数据安全成为阻碍云计算技术进一步发展应用的瓶颈问题之一。目前已有的研究主要是利用加密和认证技术对云数据进行存取保护。然而，一旦木马等恶意程序窃取或修改了云平台中用户的数据，在现有技术下，数据拥有者将永远失去对这部分数据的控制；其主要原因是加密和认证算法无法对云平台中的数据进行从产生到销毁整个过程的安全保护和控制。本项目的总体研究目标是：针对云平台的特点，建立细粒度的分布式信息流控制模型和技术，保障云平台的数据与隐私安全。拟重点研究如下内容：(1)研究云计算平台的数据文件安全标记方法；(2)研究云平台的细粒度分布式信息流控制模型和技术；(3)研究细粒度的标签能力传播方法，实现虚拟机内和虚拟机间的进程一对一访问控制能力的授予和撤销。项目的主要创新在于所提出的方法实现了对云平台中的数据文件从产生至销毁全过程的细粒度访问安全。
基于矩阵—张量协同分解的大规模知识推理方法研究	语义网;知识库;知识推理;关系数据;矩阵/张量分解	知识库的构建和应用是近来学术界和工业界关注的焦点。其中，一个很重要的研究议题就是知识的自动推理，即运用知识库中已有的知识推理出新的、未知的知识。它能显著提高知识的完备性、扩大知识的覆盖面，具有广阔的应用前景。利用张量分解技术实现知识推理具备灵活无依赖和高度可扩展的优势，因此发展成为当下研究的热点。然而，现有基于张量分解的知识推理方法都只用到了实体和实体间的关系这一种信息，存在着因数据稀疏所带来的推理准确度不高、容易发生过拟合等缺陷。本课题在此基础上，创新性地引入实体类别以及关系定义域和值域这两种信息，提出了一套融合多元信息的知识推理通用框架。一方面，通过引入额外信息，它能有效解决现有方法中的数据稀疏问题，提高知识推理准确度，降低过拟合风险。另一方面，它能成功继承现有方法易于分布式处理的优良特性，计算效率高，可扩展性强。本课题的研究面对的是知识库中的核心问题，具有重要的理论意义和实践价值。
面向临床医疗文本的实体时序化问题研究	时序化;时间关系抽取;临床医学自然语言处理;临床医疗实体抽取	近年来，自然语言处理技术在临床医学领域受到了广泛关注，成为这一领域的一个重要分支。我国正在推进以电子病历为核心的医院信息化建设工作，临床医学NLP技术的发展将有利于医院信息化的建设和升级。课题将研究临床医疗文本中实体时序化的关键问题，目的在于把一个病人的所有临床医疗实体准确定位到统一的时间轴上，形成按时间顺序排列的医疗实体序列，为其他医疗信息处理系统提供支持。与临床医疗实体时间关系抽取相比，临床医疗实体时序化从更深层次挖掘蕴含在临床医疗文本中的时间信息，包括以下三个方面的内容：1）临床医疗实体抽取；2）临床医疗文本中的时间表达式抽取；3）临床医疗实体时序化。课题将分别对中文和英文临床医疗文本进行研究。研究成果具有重要的理论价值和实际意义。一方面进一步补充和完善临床医疗实体时序化理论体系；另一方面填补了面向中文临床医疗文本的临床医疗实体时序化技术空白。
基于复杂查询类型的多媒体检索	视频;多媒体;复杂查询;检索;图像	近年来，如何有效地进行复杂查询的多媒体检索面临重大的挑战。复杂查询是指包含至少两个语义概念且概念之间存在复杂关系的查询输入，比如"两个男人马路上打架"，"摩托车夜间赛车"等。目前传统的"基于文本的检索"由于文本信息的不完整导致复杂查询的搜索性能不佳。为解决这个问题，本项目从"基于内容的检索"和"基于概念的检索"方式上提高复杂查询的检索性能。在基于内容的检索中，我们针对复杂查询用相关反馈技术缓减"语义鸿沟"。与传统方法相比，我们的方法用相关样本克服正样本不足的问题。另外，我们还使用增量学习算法结合图像分割技术实现有效的交互式的多媒体检索。在基于概念的检索中，我们构建大规模的复合概念集合，这比使用简单概念更加有效。我们还使用多任务和多实例学习来有效地学习概念分类器，并提出了一个新颖的概念选择方法来精确地解释用户查询。最终，我们的目标是设计一个基于友好用户界面的多媒体搜索系统来集成我们的成果。
基于认知语境的文本情感计算及其应用	情感图式;情感迁移;情感语料库;意见挖掘;情感词汇本体	情感计算旨在赋予计算机观察、理解和生成各种情感的能力，情感表达方式主要是文字、语音以及多模态数据。目前文本情感计算局限于褒贬二义的倾向性分析，方法以统计学习为主，缺乏情感语义资源的支撑和认知语言学的指导。本课题的研究目的旨在以多情感的语义资源为基础，以认知语言学为指导，进行文本的情感识别和情感迁移的研究。研究内容是以情感词汇本体、情感语料库以及情感常识库为基础，以情感主体为主线，建立不同粒度的情感识别模型。在词汇层，从情感分类、强度和极性三个维度描述词汇的情感信息；在语句层，着重完成情感词汇的语义消歧、情感搭配的识别以及情感主体的识别，确定语句情感类别，构建相应的情感链；在篇章层，结合认知－评价理论，建立基于情感图式的篇章情感分析模型，构造一个可视化的文本情感计算平台，并将其应用在意见挖掘、产品评论和舆情监控等方面。
基于半监督结构化学习的跨语言映射研究	半监督学习;跨语言映射;自然语言处理;结构化学习	语料资源缺乏的小语种语言的自然语言处理技术受到语料资源的限制而难以发展高精度的统计方法。当前的跨语言映射方法局限于双语对齐句对的词对齐结果，双语间标注的映射方法难以处理复杂对应关系、准确率低。为此，本课题提出了通过统计方法从语料中学习映射模型，并允许映射模型与目标模型彼此互相改进的跨语言映射框架。为了完成这一任务，本课题将结构化数据的自然语言处理任务的跨语言映射形式化为半监督结构化学习问题，利用半监督结构化学习方法，结合自然语言处理问题的任务特性，为跨语言映射问题提供新的解决方案。同时，本课题希望将语言的更抽象的属性引入到跨语言映射的半监督学习框架中，而不仅限于词对齐结果。这些抽象属性既包括语言学符号及其关系，也包括通过双语上下文统计得出的相似关系。这些属性使得双语语料中的更多信息可以得到利用，帮助提高跨语言映射方法的精度。
基于图像的植物识别和检索研究	植物概念网络;植物识别;基于内容的图像检索;分层学习;多任务学习	随着信息技术的快速发展，人们可以很便捷地获取喜爱植物的照片，并期望能在互联网上查找到该未知植物的相关信息。虽然基于关键词的文本搜索技术已相对成熟，但人们在多数情况下并不知道所感兴趣植物的名称，因此找不到合适的查询词。为满足人们日益增长的鉴赏和了解各类植物的需求，本课题将研究一种新的基于图像匹配和统计学习算法的大规模植物图像的自动识别和检索框架：1）基于大量植物类网站来全自动地构建大规模植物图像库；2）结合相机的元数据和植物图像的视觉特征来更准确地检测图像感兴趣区域；3）基于植物分类学和植物特征建立大规模植物概念网络；4）基于植物概念网络的多任务学习和多层次学习算法，利用植物概念之间的语义和视觉关联性来指导训练大规模植物概念分类器；5）基于自适应的图像摘要和交互式可视化的植物概念分类器评估方法。针对植物识别与检索这一特殊研究主题的深入探索，其成果也将推动图像处理与检索等相关领域的研究和发展。
基于语言特征的网络用户身份属性识别方法研究	网络用户身份属性;语言特征;区分方法	网络用户的注册资料经常含有大量残缺或虚假信息，给网络犯罪预防、舆论监管及商业推广等关键应用带来极大障碍。现有研究大多限于年龄和著作者身份识别，且主要集中在英文领域。本项目将研究网络用户身份属性的识别方法，从用户发表的文档中，通过分析其语言（特别是中文的）特征，区分出性别、年龄段、籍贯、职业和著作者身份等多重属性。首先，拟研究数据优化措施，以消除用户发表文档中以大众话题形式存在的噪声及类别倾斜问题的不良影响。其次，拟研究高效的特征选择算法和基于少量种子的标注特征扩展方法，以解决网络环境下语言特征的数目庞大及标注困难问题。最后，拟研究用户身份属性的区分方法，以获得语言特征-分类任务-分类算法-评价标准的系统认识，并为作者众多、测试域开放的网络著作者身份区分问题建立全新的算法框架。.本项目的研究有望揭示个人语言特征和身份属性之间的内在联系，并为网络用户身份区分这一重要应用提供理论和技术基础。
文本自动分类中样本重要性模型及应用研究	对偶关系;类边界;文本自动分类;特征选择;样本重要性	文本自动分类在有效分析和利用因特网数据方面有着重要作用，但这些数据的海量性和高维性是自动分类面临的主要难题。一种直接有效的解决途径是在保证学习算法分类性能的前提下，通过样本集约简或维数约简降低计算复杂性，并提高分类器的泛化能力。现有样本选择方法多基于统计抽样技术，需独立同分布假设；Boosting和最大间隔方法虽隐含样本选择思想，但依赖于具体的分类算法。本项目受认知科学中的样例理论启发，不对训练样本的分布做任何统计假设，从样本角度出发，根据样本对分类的贡献程度，提出样本重要性原理；拟应用随机过程和高维数据统计分析理论，给出训练集中类边界样本的自动判别方法，建立不依赖于具体分类器的样本重要性模型，研究样本重要性计算算法，并给出理论证明；结合已有分类算法，研究融合样本权重的分类算法；构建样本重要性与特征重要性的对偶关系，研究相应的特征选择和样本选择的新方法，为文本分类及一般分类问题提供新的思路
汉语解释性意见挖掘关键技术研究	解释性意见聚集;深度学习;解释性意见挖掘;解释性意见抽取;解释性意见摘要	意见挖掘研究近年来取得很大进展，但现有意见挖掘系统大多只关注褒贬意见而忽视其背后的事实、原因、条件或建议等意见解释信息,而这些信息对基于意见挖掘的决策和信息服务极为重要。为此，本项目拟对汉语解释性意见挖掘展开研究，即研究产生褒贬意见的原因、条件等意见解释信息，主要研究内容包括：(1)研究意见解释表达的的基本理论及其语言学表示特点,建立意见解释语义与关系分类体系，制定标注规范，构建相应语料；(2)以上述理论分析及所构建的语料为基础，研究解释性意见关系识别、意见解释复述识别和意见解释句子摘要生成等关键问题及相应的意见解释抽取、聚集与融合方法；(3)基于上述方法构建解释性意见摘要框架，实现一个多文档汉语解释性意见摘要系统，并验证所提出方法的有效性。本项目的实施不仅可以拓展意见挖掘的研究领域，而且可以为用户的精准决策提供意见解释信息支持，在意见问答、智能客服和推荐对话等领域具有广阔的应用前景。
股票投资组合选择模型和实证研究	投资组合选择;股票;量化投资;投资组合管理	投资组合理论可以应用到多种资产的组合，跨国界的资产组合，我们把这一理论应用到股票这种证券上。鉴于金融市场的复杂性，我们希望运用统计学的方法，综合利用定量分析、定性分析和技术分析三种不同的投资哲学，给出优化的股票投资组合选择模型，并进行实证研究。我们的研究内容包括：1）量化分析股票价格。利用搜集到的在中国、美国和其他国家上市的股票历史价格数据，用数据挖掘技术和金融模型，对单只股票和多只股票组合的风险与收益进行定量分析。2）量化分析股票相关文本。利用股票相关新闻、研报、人民日报重要版块，用自然语言处理和机器学习方法，量化驱动股票市场收益的定性分析和技术分析的文本内容，修正前一步基于股票价格量化的风险与收益。3）投资组合管理器。训练并检验决策模型，确定股票投资组合权重策略集及策略选择。
纳西图形文识别研究	图元;形状匹配;链码;压缩	纳西族东巴古籍文献被联合国教科文组织列为世界记忆遗产，是我国少数民族文字方面仅有的一项世界遗产，为了解决纳西历史文献的数字化（保护）问题，本项目要对纳西图形文字的识别进行研究。主要的研究内容有：纳西文粗分类问题、基于图元的象形文文识别、基于链码的图形文字识别三个主要问题。重点研究在于图元的提取和图元的编码以及构建适合于纳西图形文识别的链码。纳西图形文字的识别研究目前还处于萌芽状态。本项目组是最早从事该研究的课题组之一并有很好的工作积累。目前已完成了纳西图形文字的轮廓字库的建立，实现了纳西图形文字的按音输入法并已经申请国家发明专利，为纳西文字的识别研究奠定了坚实的基础。
基于公式的数学搜索引擎的研究与开发	PageRank算法。;相关度;数学搜索引擎;数学公式索引;数学公式查询语言	本项目主要研究以数学公式为基础的信息检索方法，构建一个数学搜索引擎系统MathSearch，实现在WWW上对含有数学公式、数学符号及数学相关内容的网页、文档、资料的搜索。本项目具体包含：1. 数学搜索数据源的界定及表达方式之间的转换研究; 2. 公式输入方法和用户界面的建立与研究; 3. 数学公式查询语言规范的建立与研究; 4. 数学公式索引的建立与研究; 5. 数学搜索系统性能与质量的研究; 6.搜索结果排序及显示研究。总体而言，数学搜索引擎MathSearch拟对数学公式进行细粒度搜索，该方法比通用文本搜索引擎系统在数学内容搜索上具有更强的功能和更高的效率。本项目还拟将细粒度的数学搜索与计算机代数系统（ CAS）相结合，并建立高效的数学公式查询语言，对数学公式建立更为行之有效的索引，来实现基于公式的数学搜索。
面向社区的协同检索方法研究	信息检索;联合聚类;协同检索;社区	随着社会化网络的飞速发展，协同检索成为信息检索领域的研究热点，它对于提高社区内用户检索的准确率和效率具有重要的实际意义。社区不断变化，因此需要对社区信息持续更新，但检索过程的特点为此造成了很大困难，包括：①数据稀疏；②特征空间维度高；③数据更新频繁。本课题围绕以上三个特点展开研究，内容包括：⑴三维空间相关性模型：建立由用户、查询和文档构成的三维空间，并采用概率方法量化三个维度间的相关性；⑵基于联合聚类的社区动态确定方法：针对检索过程的特点①和②，将原本仅用于分析二维列联表的信息论联合聚类方法进行扩展，使之适用于分析三维问题，进而动态确定用户社区；⑶增量学习机制：针对检索过程的特点③，从数据所在维入手，增量更新三维概率关系及联合聚类结果。本课题基于三维空间的概率关系，重点围绕社区的动态更新问题，兼顾理论分析和实践验证，为协同检索方法的进一步研究与应用提供新的思路。
面向在线检索的医学影像多特征降维方法研究	基于内容的医学影像检索;多特征互补;增量更新;数据降维;跨库检索	基于内容的医学影像检索一直是近年来学术界的研究热点。使用数据降维方法对从医学影像提取的多种高维特征向量进行降维、消除其中的冗余信息，是实现高效医学影像检索的关键之一。在大数据环境下，医学影像检索呈现在线检索的新应用形态，医学影像多特征降维因而面临三个亟待解决的关键问题：特征互补问题、增量更新问题和跨库检索问题。项目针对这三个关键问题、围绕面向在线检索的医学影像多特征降维一个主题展开研究。提出多特征空间组合模型，在此基础上：1）提出基于子空间互补的医学影像多特征组合降维方法，以解决特征互补问题；2）提出基于局部近邻结构更新对齐的医学影像低维特征表达更新方法，以解决增量更新问题；3）提出基于子空间数据分布差异最小化的医学影像低维特征表达迁移方法，以解决跨库检索问题。项目将在多个医学影像数据集上，设计基于内容的医学影像检索实验，验证上述研究内容的有效性。
基于非独立同分布学习理论的图模型词义消歧及领域适应方法研究	词义消歧;领域适应;非独立同分布学习理论;词义相似度	词义消歧是自然语言处理研究的关键基础问题。图模型因其可有效表达词义概念之间的语义关联关系，可将消歧问题转化为词义结点的重要度评价问题，具有良好的消歧性能，近年来倍受关注。但是，图模型词义消歧方法在关联边权重设定、结点重要度评价和领域适应机制等方面依然面临困难和挑战。本项目将针对这些难点，研究图模型词义消歧及领域适应方法；重点研究基于非独立同分布学习理论的词义相似度计算方法，摒弃传统方法对语义属性的独立性假设，分析语义属性的耦合关系，以准确地评估图模型关联边的权重；同时，对比研究各种图模型评价策略，提出优化的结点重要度评价机制，突破图模型对PageRank算法的过度依赖；研究图模型领域适应机制，挖掘文档、篇章、词义领域知识构建并调整图模型，提高其领域消歧能力。本项目将形成一套完善的图模型词义消歧及领域适应方法，对机器翻译、信息检索等相关研究工作将起到有力的推动作用。
深度挖掘人工译文信息的机器翻译自动评价方法研究	机器翻译自动评价;深度学习;概率依存模型;篇章结构	机器翻译自动评价是影响机器翻译发展的一个关键因素。它不仅可以评价翻译系统的性能，还可以指导翻译系统性能的提高。目前的自动评价方法主要是计算人工译文和机器译文的相似度，人工译文信息的挖掘程度对评价方法的性能起到了举足轻重的作用，然而现有的自动评价方法对人工译文信息的利用并不充分。本项目在以下几个方面对人工译文信息进行深入分析和挖掘：（1）针对基于句法的评价方法受限于子结构长度的问题，研究基于概率依存的自动评价方法，通过人工译文的依存信息拼接出机器译文的依存树，覆盖全部句法信息。（2）针对人工译文数目过少的问题，研究基于人工译文自动扩展的评价方法，通过深度学习对人工译文进行自动扩展，在扩展后的人工译文上进行评价。（3）针对基于句法的评价方法在计算系统级分数时只使用句子内部信息的问题，研究基于篇章依存的自动评价方法，通过篇章依存结构挖掘句子间的联系，提高评价方法在系统级的评价性能。
基于内容的大规模近似图像检索及挖掘技术研究	Web图像检索;大规模;图像超链接	随着Web 2.0的引入以及各种便携式移动多媒体设备，如智能手机，数码照相机等的普及，互联网上有着数以千亿的多媒体资源。项目以互联网用户对基于内容的图像及视频检索需求为背景，探索具有高可伸缩性的、可高度并行的网络图像检索及超链接生成算法。研究内容包括提出新的图像特征表示方法，改进高维数据检索结构以及探索在大规模图像集合上建立超链接的高效算法。研究涉及计算机视觉，大规模信息检索领域中的基础性问题，属于相关领域的关键技术。.项目提出了新的图像特征表示方法，既增强了特征的区分度，又以新颖的方式实现高维特征的维度分解，从而降低最近邻检索的难度。另外，对现有的最近邻检索算法提出改进方案，新方案避免潜在最近邻丢失的情况，同时加快检索过程。此外，项目提出可高度并行的图像链接生成算法，并且引入海明嵌入验证。同时，项目提出新颖的几何嵌入验证方法。基于这两种验证方法，算法有效降低链接生成的时间和空间复杂度。
海量文本信息集合可视化呈现及可视化文本检索方法研究	文本信息可视化;文本处理;文本信息图形化检索	近年来，网络技术的普及化进程为信息处理领域带来了新的课题。当信息的来源是否充足已经不再是主要矛盾之后，人们对于搜集到的海量信息进行必要的处理提出了更高的要求。通过互联网搜索引擎进行对于若干关键词的搜索，得到的往往仍然是海量的结果；因而人们需要更为精准的把握这些结果与自己所期望的结果之间的紧密程度，做到有效地信息挖掘和取舍。本课题的目标是研究文本信息集合的可视化方法，探索在可视化界面上实现文本的图形化检索。为此，课题提出在文本集合中抽取可视化特征，使用二维和三维图形等高友好度用户界面进行呈现，对相关可视化技术以及可视化的信息检索技术进行深入的研究。文本信息集合的可视化技术以及图形化检索技术，是用户从宏观到微观各个层面上有效获取信息的新型工具，为解决文本检索界面友好度低的问题开辟了一条新的研究思路，可以帮助用户走出现有信息检索对用户检索能力要求较高的困境，从而改善用户对获得需求信息的满意度。
面向维基百科的多粒度一体化信息抽取方法研究	一体化抽取;维基百科;本体知识库;多粒度知识	维基百科拥有庞大高质量语料资源，抽取维基百科并形成结构化知识具有重要意义。本项目系统研究面向维基百科的信息抽取问题，提出多粒度一体化信息抽取方法，思路是把维基页面按页面结构分割成多个信息单元，并以信息单元为横坐标，抽取的粒度知识为纵坐标，纵向进行多粒度抽取，横向进行一体化抽取。具体从多粒度、一体化和信息组织三方面展开，研究内容包括：（1）多粒度信息抽取。针对每个信息单元，从粗粒度到细粒度进行分层抽取，重点解决细粒度知识抽取问题。（2）一体化信息抽取。针对每种类型的粒度知识，选取所有抽取该粒度知识的信息单元，充分考虑不同信息单元之间知识与结构等方面的参照作用，进行一体化研究，提高信息抽取效果。（3）抽取结果的信息组织。运用本体方法组织抽取结果，建立维基概念的层次网络，形成一套完整的知识体系。研究成果作为基础资源进行信息服务，对自然语言处理相关领域的研究具有重要应用价值。
具有商品组合效应的集合推荐问题及关键技术研究	投资组合理论;集合推荐;组合效应	随着互联网技术和电子商务的发展，推荐系统在其中变得越来重要。目前推荐系统的研究都集中在如何向单个用户推荐单个他最喜欢或最可能购买的商品。然而，在现实中单个用户在购买或消费商品的时候往往会有购买一组商品（一个商品集合）的需求，我们把向一个用户推荐一组相关商品的这类推荐称为商品集合推荐。集合推荐和目前推荐系统领域主要研究的单个商品推荐很不同，多个商品的组合含有商品组合效益。即若干个用户都喜欢的单个商品，组合一起成为商品集合打包向用户推荐的时候，用户未必会喜欢，甚至会厌恶。在本研究项目中，我们拟对商品集合推荐问题进行建模和形式化定义；基于经济学中著名的投资组合理论来设计一个候选推荐集合筛选算法，来从所有商品中挖掘和选择出合适的待推荐商品集合；此外，拟研究商品组合效益问题及其计算方法，量化其对集合推荐的影响；提出一个创新的、基于投资组合理论和商品组合效应的推荐算法来给用户进行集合推荐。
知识问答中自然答案生成关键技术研究	知识库;答案生成;知识问答;自然语言生成;对话系统	当前知识问答是针对用户的问题提供精确的答案实体。但是，仅仅提供这种孤零零的答案实体并不是非常友好的交互方式，用户更希望接受到以自然语言句子表示的完整答案。实际上，包括SIRI在内的知识服务类应用都是返回完整句子形式的答案，人工客服等知识服务也会返回用户自然语言形式的回复。本课题的目标就是融合问答和对话，在知识问答服务中对用户提出的问题，提供包含正确内容的自然答案。具体研究内容包括：1) 使用基于全局知识和前后向生产模型回答简单问题，得到一致、流利的自然答案； 2) 融合拷贝、检索和预测三种词语获得模式，用统一的模型对其建模，最终对复杂问题生成一个合适的自然答案； 3) 研究融合长距离事实和隐含知识的自然答案生成模型； 4) 研制开放域知识问答系统，对于用户提出的问题返回自然答案，提高系统实用化程度。本课题研究成果具有非常明确的现实意义和强烈的应用背景，
面向口语对话系统的用户情感识别研究	情感计算;用户情感识别;口语对话系统	自然和谐的人机对话是高速信息时代人机交互的主要发展趋势和迫切需求。传统的口语对话系统主要侧重于面向特定任务的对话，很少涉及对用户的情感状态进行分析，这使得系统无法实时掌握用户遇到挫折或感到沮丧的状态，也无法根据用户的情感状态进行适当的应对。本课题致力于研究面向口语对话系统的用户情感识别问题，它是实现智能情感会话的基础。具体内容包括：会话用户情感的分析与表示，提出通过对用户的多维情感进行编码建立基本情感之间的联系；会话情感特征分析，构建具有多源特征，并包含用户真实情感的会话情感库；用户情感对象特征融合与识别建模，设计针对多源特征的特征选择和特征降维方法；提出基于多源时序特征的用户情感序列识别模型，采用不同的用户情感影响因子，以实现个性化的用户情感识别，并能反映会话过程中用户情感叠加与衰减。对这些问题的研究将为口语对话系统中用户情感识别提供新的思路和解决方法，为促进人机交互打下理论和技术基础。
基于深度学习的面向海量科技文献的大规模高性能本体构建技术研究	本体构建;本体关系抽取;本体概念抽取;深度学习	本体是一种重要的知识库，其所包含的丰富的概念以及概念间的各种关系可以为问答系统、信息检索、语义Web、信息抽取等领域的研究提供重要的支持。本申请项目将以海量科技文献为数据源，研究构建大规模高性能领域本体所需的各项关键技术，并通过具体应用对这些技术的可靠性进行验证。具体而言，本申请项目将对以下本体挖掘中的关键技术展开研究：本体表示方法、基于深度学习的考虑时间特性的本体概念及相应关系抽取方法、本体元素变化识别方法、本体更新方法、基于本体的文本分析技术以及基于本体的科研热点识别技术。本项目的相应研究成果不仅可以完善本体构建的相应理论，并且还可以为与本体相关的各项相关研究提供一定的技术支持，具有重要的科学意义和应用价值。
NT小句复合体模型的理论和应用研究	NT小句;机器翻译;话题结构理论;语言认知;语义约束	现有的语言学的小句理论是以动词为中心的，不适合描写汉语，并且对小句层面以上缺少形式化的研究。自然语言处理偏重于统计机器学习，缺少语言理论和语言知识的指导，使得篇章处理、长句翻译的效果不佳。.本项研究在国家自然科学基金资助的前期工作的基础上，建立起以指称语为中心的NT小句复合体模型的科学理论体系，包括形式结构、语义约束和认知解释。这一理论体系超越特定语言的句法细节,既适合于汉语，又适合于英语，从而可以用作跨语言的语法平台，支持长句机器翻译。
利用机器学习改进统计机器翻译的研究	图模型;近似推断;统计机器翻译;结构化半监督学习;机器学习	目前，主流的统计机器翻译方法面临以下挑战：翻译模型难以表示和容纳更丰富的与翻译过程密切相关的知识，训练算法从真实文本中获取的翻译规则数量巨大且质量良莠不齐，以及解码算法难以在庞大的搜索空间中高效准确地定位最优候选译文。作为一个新兴研究领域，统计机器翻译边缘性和交叉性的特点决定了它需要从其它学科借鉴新的成功理论来获得进一步的发展空间。我们认为机器学习能够为统计机器翻译提供帮助，因为两者之间存在紧密的联系。从机器学习的角度来看，统计机器翻译是一个结构化预测的问题。本项目希望在统计机器翻译和机器学习之间找到恰当的结合点，利用机器学习最新的研究成果（图模型、结构化半监督学习和近似推断）来为统计机器翻译当前所面临的挑战提供解决方案，从而进一步推动统计机器翻译的研究发展。开展此项目的研究，不仅可以让统计机器翻译和机器学习获得共同发展，同时能够帮助提高机器翻译系统的性能来为社会大众提供更好的服务。
面向设施农业的信息物理融合系统关键技术研究	信息物理融合系统;路由协议;设施农业信息系统;数据融合	设施环境智能感知和调控对设施农业现代化有重要意义。本项目旨在研究设施环境调控系统感知、传输和调控三者失谐问题，确定设施环境信息物理融合系统快速部署、互联互通、数据融合和故障管理为本课题的研究内容，提出：（1）基于感知特性的规则多面体空间覆盖算法，通过传感器节点关联特性和空间填充算法揭示设施环境内外环境因子垂直分布规律，实现对设施环境的感知覆盖和快速部署，解决系统感知受限和部署困难；（2）基于分簇的快速路由算法与协议，通过分簇路由交换实现网络快速互通，解决系统传感失谐和联通不畅；（3）基于分布式压缩感知理论的数据融合算法，通过提取数据的空间和时间相关性提高数据的准确性和系统决策支持能力，解决系统感控失谐问题；（4）基于关联感知的故障检测算法，通过研究感知数据与故障的关联机制实现网络快速管理，解决系统可靠性问题。本课题为阐明设施环境调控系统传输、感知和调控协作机制提供新思路和理论。
文本情绪计算框架、模型和方法研究	情绪场模型;情绪分析;情绪归因;情绪个性化建模;文本情绪计算	结合心理学、认知科学和计算科学的文本情绪计算正成为自然语言处理研究的热点。在对个体情绪产生、迁移及表达机制进行深入分析基础上，本项目提出基于"刺激认知-反射输出"机制的文本情绪计算框架和情绪场计算模型。在统一的框架和模型下，对文本情绪计算四个关键问题进行深入和相互促进的研究：1.情绪分析研究利用情绪文本表达常识、情绪转移历史相关性和期望相关性，识别个体情绪描述并分析其情绪状态的方法；2.情绪归因研究利用情绪认知常识和个体情绪迁移发现，从文本中识别个体情绪迁移原因的方法；3.情绪预测研究利用情绪认知知识，预测个体在接收到文本刺激后情绪状态迁移的方法；4.情绪个性化建模研究利用社会化媒体文本对用户个体的情绪特质进行建模的方法。最终实现结合预测的情绪分析、结合分析的情绪归因、结合归因结果的情绪预测以及结合情绪常识和个性化模型的情绪计算。本项目将推动文本情绪计算研究的深入，为相关应用研究奠定基础。
向量组合学习框架下基于依存混合树的中文语义解析研究	依存混合树;深度学习;自然语言接口;语义解析;递归神经网络	语义解析的目标是将自然语言形式的句子转换成一种完全形式化的意义表示，从而使得自然语言句子能被计算机自动理解和执行。本项目面向实现中文GIS自然语言接口的实际应用需求，针对现有的判别式语义解析模型中特征工程方法的不足，探索在深度学习的向量组合学习框架下基于特征向量的自动学习实现语义解析的新途径。为此,首先需要设计一种新的树型构造机制，使之既能灵活地桥接自然语言句子与形式化语义表示之间的对应性，又能反映句子的句法结构；然后视之为隐变量，使用一种基于向量组合计算和结构化预测的联合学习方法，通过综合利用隐变量中的句法结构信息和分布式的词、短语向量中语义信息，实现更有效的语义解析方法。主要研究内容包括：大规模中文语义解析语料库建设、作为隐变量的树型构造机制的设计、中文词向量学习模型的选择与设计、向量组合学习框架下多层神经网络的建模、相应的推导和学习算法的设计，以及在中文GIS系统中的实际测试与应用。
面向微博平台的短文本话题检测与跟踪研究	话题检测与跟踪;微博;短文本	微博(Microblog)已成为信息发布、交流的热门平台，其信息的实时性与内容的丰富性均是传统平台所不具备的。基于微博这样一个汇集海量信息的平台开展话题检测与跟踪(Topic Detection and Tracking,TDT)工作，将会帮助人们及时掌握重要信息。然而其消息的短文本属性以及平台中话题相关信息的小样本特性，使得在其中开展TDT 工作较为困难。目前国内外在TDT 方面的研究大都限于长文本范围，较少涉及短文本环境。本课题针对微博这种新兴并飞速发展的社交网络平台上的海量信息，提出一种新的结合了短文本分析和用户特征分析的文本融合技术框架，采用文本相似度计算、LDA 话题挖掘和基于拟合的句子排序等具体技术，对微博话题进行动态的检测、跟踪和分析，并以图示和列表等用户易于理解的方式，返回话题关键信息。帮助用户把握全局性的事件背景，并提出趋势发展的预测结果，为决策者提供高质量的决策支持。
基于推理现象的中文文本推理资源建设和自动分析研究	文本蕴涵识别;资源建设;文本推理;推理现象	影响文本推理系统性能的一个重要因素是推理系统能否识别多样化的推理类型。推理现象的研究有助于识别各种推理类型，然而目前相关研究非常缺乏，也没有建立相关的大规模标注资源和分析模型。本项目拟研究汉语推理现象的自动识别，并基于推理现象进行推理判断。为此，本项目将深入考察汉语结构特点，研究汉语推理现象的表现形式，据此建立一个汉语推理现象标注资源。在此基础上，本项目将研究推理现象的自动识别，包括语义单元的自动识别和推理现象的自动识别，提出并研究基于推理现象的贝叶斯信念网络推理模型，并利用该模型进行文本自动推理。本项目有助于研究汉语文本推理的特点及相关推理现象，探讨面向汉语文本推理的深层理解方法，推动中文文本推理的平台建设，并评估现有文本推理系统的性能。
基于生成树库分析与生成一体化机器翻译模型研究	生成树库;搜索算法;译文调序;统计机器翻译	面向英汉机器翻译的生成树库是北京语言大学研发的语料库，树库中的生成树中包含了机器翻译所需要的深层次、细粒度的翻译知识：英语的句法结构、汉语译文生成模式和词汇短语的习惯翻译等，本研究以该树库作为主要训练语料，结合现有的大规模双语和单语语料，研究建立面向英汉机器翻译分析和生成一体化统计模型：将规则化知识和统计方法有机结合在一起，避免规则方法层次化翻译过程所造成的错误累计，和规则不易把控的问题；同时，该模型统计对象为带有句法信息的英文短语和对应译文生成模式，解决了现有机器统计翻译以词或者短语为统计对象所造成的模型泛化能力差的问题。另外，现有的短语翻译模型短语限定为连续词串，译文生成时，全局调序能力差，生成树库具有大量短语调序知识，依托本树库，译文生成时短语预调序也是本研究另外主要内容。
潜在语义分析中特征传递优化技术的研究	潜在语义分析;特征传递;奇异值分解	潜在语义分析是一种无指导的特征抽取方法，该方法通过文档间词语共现的传递关系，改善了自然语言理解中对同义和多义等问题的处理能力，从语义层次上推动了信息检索、文本分析等多个研究领域的发展。但目前的潜在语义分析研究中，对特征传递关系的质量评价、空间选择等关键问题缺乏深入的研究和探讨。因此，本课题从改进特征传递质量的角度出发，提出了潜在语义分析优化的研究思路，重点研究改善特征传递质量的优化方法，探讨利用分析过程中的中间矩阵进行多重潜在语义分析的优化技术。同时，考虑到与先验知识和现有文本分析技术的结合，提出了基于伪文档的潜在语义分析方法，满足了潜在语义分析在人工指导和时效性方面的实际需求；采用文本分割、聚类等技术细化了特征间共现粒度，为构建更为良好的特征传递关系提供了更有效的融合策略。本课题的研究将为潜在语义分析的研究提供新的研究思路，其研究成果也将为语义层次的信息处理技术提供新的技术基础。
基于反馈式排序框架F-Rank的查询导向的更新式多文档自动摘要研究	更新式;多文档自动摘要;排序;相似度;查询导向	自动摘要技术广泛应用于信息的检索、定制、分析与追踪，当前的研究热点包括查询导向、更新式、主题聚焦等多文档摘要任务及其相互融合技术。传统的多任务融合方法通过权值控制每种任务在排序中的重要度，难于全面反映任务的全部信息，且忽略了融合前任务间的交互作用。本课题提出一个通用的反馈式排序框架F-Rank，通过灵活的反馈学习方式和排序改进策略，为不同类型和不同数量的自动摘要提供一种能够综合反映摘要任务目标的交互式排序结果融合方法；提出并研究基于正负增强句子关联关系的更新式摘要模型R-PNR及其句子打分和排序方法；基于文档、句子和词三个文本粒度的相互增强关系，提出结合用户查询需求影响的相互增强链模型Q-MRC，实现查询导向的多文本粒度间的相似度测度和句子排序方法；在此基础上，基于F-Rank框架对以上两个摘要任务的基本排序结果进行交互式反馈学习和融合排序，从而生成查询导向的更新式摘要的综合排序结果。
基于情感知识库构建、领域适应和终身学习的社交媒体情感分析方法	情感分析;文本挖掘;自然语言处理;社交媒体分析;机器学习	社交媒体情感分析是自然语言处理和文本挖掘领域的前沿问题和研究热点，也是社交网络和大数据时代情感分析技术面向应用辄需解决的重要问题。尽管传统的情感分析已经得到广泛关注和深入研究，然而社交媒体文本的"特征稀疏、话题动态、数据海量"等特点，给情感分析研究带来了新的挑战。本项目针对上述问题，从情感知识库构建、文本表示、数据采样和终身学习的角度，提出一种社交媒体文本情感分析统计机器学习模型新框架。首先提出融合统计信息和语言知识的社交媒体领域情感知识库自动构建方法，在此基础上，提出基于同义扩展和反义置换的文本表示特征迁移方法、基于权重抑制正则化的领域适应权重采样算法和基于堆栈式增量学习的海量动态数据终身学习模型，最终建立一个高效鲁棒的、领域自适应的、适合大规模数据场景的、不断学习和更新的社交媒体情感分析系统。
隐喻识别与理解的理论与方法研究	隐喻计算;知识获取;特征选择;隐喻推理;隐喻知识库	在长期进行歧义消解研究之后，自然语言处理要向自然语言理解方向前进，必须攻克隐喻这个堡垒。隐喻的识别与理解是计算语言学更上一层楼的新的开拓性研究课题，关系到机器翻译、信息检索、问答系统等诸多应用系统的质量和成败。本项目以高质量机器翻译和自然语言理解为目标，探索汉语隐喻识别与理解的理论、方法及实现技术。主要内容有：⑴在对汉语隐喻类型全面考察和计量分析的基础上，总结和发现隐喻的映射规律，建立以源域为核心的隐喻知识架构体系。⑵利用已有的《现代汉语语法信息词典》和《中文概念词典》等基础资源，采用主动学习方法从大规模语料中获取隐喻资源，建造面向机器理解和对外汉语教学的汉语隐喻知识库和标注语料库。⑶优化基于机器学习方法的隐喻识别模型，提高识别效率。(4)开展相似度推理的隐喻理解研究，实现大规模文本的源域、目标域、喻底的自动获取。本项研究将有助于解决隐喻对中文信息处理诸多环节的困扰，为相关应用提供支持。
社交化搜索技术研究	位置敏感;社交化搜索;个性化服务;文档检索;搜索引擎	社交化搜索技术是在线社交网络上信息获取的重要手段，本项目在深入分析了相关工作的基础上，在基础理论、关键技术和应用系统三个层次，对社交网络上的搜索技术展开研究。在基础理论方面，针对搜索模型的准确性问题，研究社交网络上搜索意图的建模理论、社交化搜索结果的表示模型，在此基础上，研究社交化搜索模型的评价方法。在关键技术方面，针对关联模型的可计算问题，研究用户搜索意图和查询候选之间的关联度度量方法、结合用户影响力的度量方法，在此基础上，研究基于用户间相似度和影响力的个性化搜索方法。在应用系统方面，针对搜索模型更新的时效性问题，基于并行化技术、流处理技术等关键技术，针对社交网络大数据的规模大、实时到达、用户敏感、地理位置敏感、复杂关联分析等特性，实现灵活可配置的可计算平台，并基于海量真实数据对基础理论和关键技术进行验证。通过研究社交化搜索技术，为社交网络舆情分析和预警提供关键技术支撑。
面向在线新闻评论的跨领域情绪分析关键技术研究	情感分析;情绪分类;跨领域;迁移学习;情绪标注	越来越多的民众通过在线新闻了解时事动态，以新闻评论的形式抒发情感。掌握用户情感，可帮助在线新闻服务商理解用户偏好，为用户提供更好的个性化服务；也有助于政府进行民意问询，有效实现舆情分析和监控。情绪分类方法性能很大程度依赖于足够的训练数据，不同异构数据集合和不同领域的在线新闻情绪分析需要不同的分类器和各自充分的训练数据，但人工标注工作耗时耗力且代价高昂。针对上述问题，本项目将围绕在线新闻评论的多类情绪预测问题，研究1)融合多种异构信息源的用户个性化和评论个性化情绪分析技术；2)利用含有已标注数据文档集的分类知识帮助没有标注数据文档集的情绪分析任务，实现跨异构数据集的在线新闻评论情绪预测；3)在源领域和目标领域情感类别集合相同和不同两种情境下，实现跨领域跨类别在线新闻评论情绪分析等，以期取得情绪预测性能的提升和情绪分析服务的个性化、领域广泛化，尽量减少耗时耗力的人工标注工作。
模糊多属性决策安全计算和隐私保护关键技术研究	密码协议;模糊多属性决策;多方安全计算;优势排序;隐私保护	安全计算和隐私保护是信息安全研究的热点之一。多属性决策模型研究已经取得了一些成果，但是目前研究主要集中在多属性决策算法问题上，很少有文献涉及多属性决策的安全计算和隐私保护问题。近年来，虽然已有文献对多属性决策模型中赢家决定等问题进行了一些研究，但是从信息安全角度在多属性决策方面的研究才刚刚开始。本项目拟从模糊多属性决策模型入手，探讨基于效用方程和基于优势排序的模糊多属性决策模型所需安全计算和隐私保护方式。从"模糊多属性决策模型所需安全计算和隐私保护关键技术"这个新视角，探讨基于优势排序方式的模糊多属性决策模型决定方式与基于效用方程的多属性决策模型决定方式所需安全计算和隐私保护技术的差异，并对基于效用方程和优势排序的模糊多属性决策模型中所需要的安全关键技术进行深入讨论，为模糊多属性决策模型研究提供新的理论和视角，给多属性决策模型中的安全计算和隐私保护技术的研究开拓新的思路和方法。
约束驱动集合相似大数据高效能连接关键技术研究	相似连接;空间索引;流水线;MapReduce;前缀过滤	作为互联网时代极具潜力的数据处理手段，相似连接在数据清洗、分析、挖掘和集成等方向具有广阔的应用和研究价值，已成为数据库和知识工程的交叉研究热点。本项目以数据及查询的关联约束为驱动，将交换高通量和计算高效能作为目标，对典型集合数据展开适用于大规模并行的优化布局方法研究，并力图为相似连接提供高效的查询剪枝执行手段。项目面向层次约束构建研究体系，首先基于关系约束在MapReduce下进行数据级联存储，借助流水线和多路连接深入探索相似连接的任务分割与负载均衡策略；研究论证频繁更新下数据为中心的公制距离连接技术，以格网分区与优化映射为基本途径，展开GPU下空间约束剪枝和跨Block同步策略研究；最后以最优符号组合剪枝为目标，对资源平衡视角下符号组合选择策略、分组与前缀压缩交换技术及其过滤方法进行重点研究。借助项目研究的实施，初步构建出一套健壮、高效和可扩展的面向大数据不同约束层次的关联优化核心技术。
汉语抽象意义表示关键技术研究	抽象语义表示;AMR解析;联合模型;语料库标注;语义理解	抽象语义表示（Abstract Meaning Representation, AMR）是一种抽象的句子级语义表示方法。它将一个句子的语义抽象为一个单根有向无环图，把句子中的实词抽象为概念节点，实词之间的关系抽象为带有语义关系标签的有向弧，忽略虚词和由形态变化体现的较虚的语义，同时允许补充句子中省略或缺失的概念，能够更加全面地描写语义，有利于语义的自动生成。目前针对汉语抽象语义表示的研究刚刚起步，本申请拟从以下方面进行研究：1. 根据汉语特点，设计一个合理有效的汉语AMR标注规范；2.开发和构建一个大规模、高质量的汉语AMR标注语料库；3. 研究AMR解析模型与算法，包括基于概念嵌入和全局归一化转移神经网的AMR解析算法和在深度多任务学习框架下探索中文依存句法与AMR联合分析模型；4. 在高性能AMR解析器的支持下，选择信息抽取等实际应用领域，探索AMR语义表示结构的应用价值。
面向搜索引擎的用户个性化查询意图分析	查询分类;查询意图分析;检索结果聚类;用户个性化建模	查询意图分析是信息检索研究中一个非常重要的课题，对于改善搜索引擎性能以及用户搜索体验有着十分重要的作用。然而在当前的查询意图分析研究中，用户个性化信息并没有得到充分利用。为此本项目提出了一种融合用户个性化信息的查询意图分析方法。具体地，本方法包含以下几个主要方面：（1）提出了在查询意图分析模型中使用用户个性化信息作为特征，旨在使查询意图分析的结果体现出不同用户的差异性；（2） 提出了基于用户自然标注资源的共性查询意图识别与挖掘方法，即能识别宏观的用户查询意图，又可自动挖掘细粒度的查询意图；（3）提出了基于话题模型的个性化用户检索兴趣建模方法，可以更好的学习用户模型，改善查询意图分析的效果；（4）将查询类别信息作为查询意图识别的重要特征加以利用，并提出了基于URL的查询分类算法，可以极大提高查询分类的效率；（5）将本项目提出的查询意图分析方法应用于检索结果聚类，即围绕多种不同的查询意图对搜索
高效业务过程模型检索技术与评估体系	业务过程管理;业务过程数据库;过程检索;评估体系;过程模型索引	目前，业务过程管理已经成为企业提高自身管理效率的核心技术，大部分企业都逐步将其内部以及与合作方交互的业务过程绘制成过程模型。这使得一个企业甚至是一个部门就需要管理成百上千的业务过程模型，例如中国移动通信仅其管理信息部门的办公自动化系统中就有8000多业务过程。如此大量模型需要业务过程模型数据库来管理，而业务过程模型检索是数据库的一个核心功能，也是目前学术界和工业界的研究热点。然而还没有一种高效数据库检索技术能支持四种不同的检索方式(结构相似性搜索、行为相似性搜索、结构精确查询和行为精确查询)，也没有对检索技术优劣的评估标准。为了解决这些问题，本项目贡献分为以下三方面：1)提出第一个可以同时支持四种不同的业务过程模型检索的业务过程模型索引结构; 2)为每一种检索提出一个能够结合索引的高效确认技术来进一步提高效率; 3)建立一个业务过程模型检索的评估体系，包含理论评估标准和实验评估标准两部分。
汉语词汇关联知识的计算融合和分析应用研究	可信句法分析;词汇概念网;语义关联度;语言资源融合;词汇知识获取	本项目以词汇概念网的知识融合和自学习能力发展为主线，将基于词汇概念网的语义关联度计算知识与句法分析模型训练方法相结合，达到词汇知识获取和句法分析技术互动提高的处理效果。设计统一的词汇关联对描述格式，融合现有各种语言资源，打通不同语言知识的描述界限，构建句法语义知识高度整合的词汇概念网，计算形成反映客观分布的语义关联度计算模型；将词汇概念网、语义关联度计算模型与句法标注语料库组合形成开放式的学习环境，进行规则进化学习和统计模型训练，构建规则与统计相结合的可信的句法分析器；利用置信度较高的句法分析结果，构建词汇关联知识自动获取工具，形成具有正反馈效果的词汇关联知识自动进化处理机制。其预期研究成果，将形成一个融合现有各种句法语义描述资源的大规模的词汇关联知识计算平台，初步实现汉语词汇关联知识的计算融合、分析应用和自动获取的完整解决方案，为进一步进行汉语真实文本内容的深入理解研究打下基础。
融入概念的高效主题分析框架与关键技术研究	主题分析;在线学习;主题解释;主题建模	以主题建模和主题解释为一体两面的主题分析技术，已经被广泛应用于自然语言处理、信息检索和信息抽取等领域。现有主题建模方法大都基于"文档-主题-词"三层贝叶斯假设，该假设缺乏对"概念"等语义因素的刻画；而目前主题解释算法复杂度过高，难以适应大数据场景。为此，本课题拟从效果和效率两个角度深入探索高效主题分析的理论和方法。首先，考虑主题与概念的关系，探索基于"文档-主题-概念-词"四层贝叶斯的主题建模新假设；其次，分别探索新的无监督和有监督主题模型，以验证所提假设的有效性，并基于粒子滤波理论和减小梯度方差思想提出相应的在线学习算法解决主题建模效率问题；再次，基于申请人在COLING2016和AAAI2017上提出的主题解释新框架，在数据独立和数据依赖两个维度上分别探索新方法，解决主题解释算法复杂度过高的问题。通过上述工作，形成体系化的高效主题分析框架，有效提升大数据主题分析的准确性和效率。
基于NLP的高精度文本检索模型研究	自然语言处理;高精度文本检索;语言模型	文本检索系统的查询条件和文档集都是由自然语言构成的。由于传统文本检索系统本质上只是将文本看作一组无序词串，利用简单的词频统计来模糊计算相关性，因此，传统检索系统面临许多无法解决的问题。同时，一些研究表明将相对复杂和精确的自然语言处理（NLP）技术直接（浅层）应用于传统检索系统并不能带来性能的明显的改善。.本申请书提出的基于NLP的高精度文本检索模型研究，是以NLP技术与信息检索中的语言模型方法的深层次融合为出发点，主要探讨不同于传统IR模型的能够融入NLP技术的新的语言模型检索方法，研究这些不同层次的NLP技术对IR性能的影响，并期望在比较后获得相对最佳的融合模型。.本项目试图建立NLP与IR之间的紧密的联系，来系统地揭示一些客观现象，而这在国内尚属空白。
特定域个性化交互式问答技术研究	个性化交互式问答评测;用户模型;交互式问答;相似用户群	问答技术旨在令计算机能够回答用户用自然语言提问的问题。然而，在当前的研究中，没有很好地融入人机交互及个性化分析技术，因此难以准确理解用户意图和个性化需求，从而无法为用户提供更加精准的答案。本项目针对特定域开展个性化交互式问答技术研究，其主要特点和创新点体现在如下方面：（1）系统能够根据人机交互的上下文对用户当前问题进行分析；（2）系统对于有歧义或模糊的用户问题，可自动生成澄清请求问题，通过与用户的交互进一步明确其信息需求；（3）深入挖掘用户兴趣和偏好，构建用户模型，从而为用户提供个性化答案；（4）对相似用户加以聚类，通过协同式问题推荐的方式向用户提供其感兴趣的信息；（5）建立以系统为中心和以用户为中心的评测方案，对个性化交互式问答系统的性能评测进行研究。我们力争通过本项目的研究推动问答及个性化信息服务技术的发展。
跨语言敏感事件抽取关键技术研究	事件抽取;敏感度度量;双语语料库;敏感事件抽取;以图搜图	敏感事件的自动抽取是舆情分析领域一项重要的研究任务。跨语言敏感事件抽取是事件抽取、舆情分析和双语知识学习与应用的交叉学科。传统方法由于受封闭域有限事件类型与样本的限制，无法实现类型多样粒度不一的多语种敏感事件的抽取任务，对新型的事件属性也缺少有效的判别手段。为了有效解决上述问题，本课题集中研究开放域敏感事件抽取技术，包括开放类型、属性和语言环境条件下的抽取任务。重点研究事件类型的自动发现与扩展技术、面向敏感度、外延关系和真伪等新型属性的抽取技术，以及针对稀疏语种中敏感事件缺少先验翻译知识这一问题的双语资源挖掘技术。此外，本课题提出了面向事件关系检测的场景还原与分析、以图搜图为桥梁的平行和可比较语料发现、不确定性覆盖域为线索的真伪判别等新技术。目标是实现多任务和多语种条件下稳定的敏感事件发现与属性抽取系统，辅助舆情分析与监控。
半监督文本情感分类方法研究	半监督学习;特征提取;主动学习;文本情感分类	文本情感分类是自然语言理解的一个研究热点，具有着广泛的研究价值和应用前景。本项目将在前期研究的基础上，重点研究困扰目前文本情感分类研究的两个关键问题：一是如何减少对大规模人工标注语料的依赖；二是如何解决文本情感分类中特征空间的高维度问题。主要研究内容包括：1）在语言学理论的指导下，研究文本的多视图表示，进而实现基于多视图的半监督文本情感分类方法，在少量人工标注语料的基础上，利用大规模非标注语料提高系统性能；2）探索基于多视图的主动学习文本情感分类方法，在不影响性能的情况下，显著降低人工标注语料的规模。同时，将该主动学习方法与基于多视图半监督学习方法结合，在尽可能使用少的标注语料的情况下，利用大规模非标语料进一步提高系统性能；3）研究文本情感分类的特征提取方法，重点研究在半监督学习机制下的特征提取方法，在不影响系统性能的情况下，大幅度降低文本特征空间的维度。
面向话题演化的时序多文档文摘内容选择技术研究	特征向量选择;谱聚类;文摘内容选择;时序多文档文摘;进化流形排序	时序多文档文摘为自动文摘领域的新方向，可应用于舆情监控，应急决策支持等领域。本课题研究面向话题演化的时序多文档文摘中抽取式内容选择方法。如何在网络信息不断更新的时序演化背景下去判定文摘内容的动态话题相关性（重要性），新颖性和覆盖性，是时序文摘内容选择面临的主要挑战。为此，对话题演化按一种新的观点建模，即动态增强代表用户需求的话题描述，形成动态的虚拟查询，充分提高查询的表达能力；同时借鉴动力系统中相关工作的研究成果，分析跨时段文档集随着时间的演化模型。依据对动态演化信息的建模，主要提出：（1）基于进化流形排序的动态话题相关内容选择算法；（2）时序谱聚类增强的动态话题相关内容选择优化；（3）发展特征向量优化选择的时序谱聚类算法来改进内容选择。由此发展在时序信息演化背景下新的流形排序和谱聚类学习算法，形成一种新的机器学习框架来解决面向话题演化的时序文摘内容选择问题，有着重要的研究价值和应用价值。
中文句法分析与语义角色标注的联合学习机制研究	层次句法分析模型;语义角色标注;联合学习机制;句法分析;树核函数	语义角色标注(SRL)是自然语言处理的一个关键问题，也是目前的一个研究热点。研究发现，SRL严重受制于自动句法分析的性能，中文语义角色标注更是如此。因此，本课题提出中文句法分析和语义角色标注的联合学习机制研究，目的是使句法分析更加适合于语义角色标注，以缩短SRL在自动句法分析和手工句法分析上的性能差异。研究内容主要包括：一是句法分析模型和联合学习机制研究，重点探索可扩充的层次句法分析模型，在此基础上，实现句法分析和语义角色标注的联合学习，使得句法分析和语义角色标注能同时有效进行，减少自动句法分析对语义角色标注系统性能的负面影响；二是基于树核函数的语义角色标注研究，研究和改进现有的树核函数，探索新颖的树核函数，同时探索语义角色关系实例的结构化信息的最佳表达形式，以更好地体现所需的各种结构化句法信息。
跨语言文本复制检测研究	文本复制检测;双语文本;文本挖掘;半结构化文本	在网络环境下保护电子文本知识产权，打击非法复制、剽窃论文等不端学术行为，是当前亟待解决的一个热点问题。现有文本复制检测方法不能有效检测从英文翻译到中文这种翻译型的文本剽窃。项目将要研究在网络条件下多语言文本混杂、无结构文本和半结构文本混杂的情况下，如何高效、快速检测各种类型雷同文本。包括：基于双语本体的翻译型无结构自然语言文本复制检测方法，基于小波变换提取结构特征的半结构文本复制检测，面向网络服务的主动式文本复制检测体系模型。研究方案的特色在于：（1）不需要对文本进行机器翻译，而是根据双语本体把中英文字词转变为概念，然后依据概念集序列检测文本复制。（2）提出比较全面、主动、快速的文本复制检测策略和体系模型。本项目的研究对于文本挖掘、文本相似性度量和自然语言处理具有很大理论意义，对于保护电子文本知识产权，打击论文造假，端正学术风气具有重要的应用价值和社会意义。
中文专利检索中关键技术研究	专利趋势分析;专利无效性检索;专利相关性检索;专利分类	专利检索是信息检索领域中的一个重要研究方向，如何在充分考虑专利文本自身特点的基础上进行有效地专利检索，是一项非常值得研究的课题。本申请项目的研究目标是在充分考虑专利文本自身特点、并对专利文本进行深入分析的基础上系统地研究中文专利检索任务中的各项关键技术。我们的目标是建立一套面向中文的有效的专利检索方法。在具体研究中，涉及的研究内容包括专利相关性检索、专利分类、专利无效性检索、专利趋势分析等任务。本申请项目的研究成果不仅可以完善信息检索的相关理论与方法，还可以通过内容分析技术提高中文专利检索各项任务的性能。而且，本申请项目的研究成果可以促进开发有潜力的专利检索系统，具有广阔的市场应用前景。
面向搜索排序的主动学习理论	信息检索;主动学习;搜索排序;机器学习	搜索排序将搜索结果以相关性排序。它是信息检索的核心组成部分，直接关系到搜索结果的质量和信息利用的效率。近年来基于机器学习的排序有效提高针对大量复杂数据类型的检索质量。排序学习需要大量高质量训练数据，但获得这些训练数据非常昂贵和费时。本项目通过主动学习理论的研究，探索如何选择性标注最具信息量的训练数据，从而提高排序模型精准度和稳健性，同时有效减少学习成本。本项目在贝叶斯理论框架下，重点研究基于预期损失优化的主动学习理论。同时针对排序学习问题的特性，系统研究面向搜索排序的主动学习算法，具体包括主动学习采样算法、批处理采样策略、以及主动学习终止条件。最后结合文本检索、互联网搜索等应用，验证算法的先进性和实用性。本项目的研究成果有望提高我国主动学习理论的基础研究水平，为有效提高信息检索质量提供新的理论依据和关键技术。其研究成果也可在商务智能、国防安全、生物信息学等领域获得广泛应用。
基于学术文献引文的自动摘要关键技术研究	自动摘要;引文倾向性分析;摘要评测;引文识别	学术文献中的引文对于帮助学者了解某篇文献的学术价值及对后续研究的影响具有重要的价值。然而随着学术文献数量的日益庞大，使得学者们快速获取引文信息变得越来越困难。基于此，本项目针对学术文献中的引文进行自动摘要关键技术研究，主要包括：（1）分析学术文献中显示引文和隐式引文的特征，提出基于SVM的引文识别算法，提高引文识别率；（2）探索与引文倾向性相关的各种特征，提出基于随机森林的倾向性分类方法；（3）研究基于学术文献引文的自动摘要方法，提出将引文句聚类和排序过程相互作用的排序策略，用以提升摘要生成质量；（4）研究基于语义的文摘评测方法，引入LDA主题模型衡量机器摘要与人工摘要的语义相似度。本项目的研究将为学术文献引文检索系统的实际应用提供理论和技术上的支持，具有重要的科学意义和研究价值。
融合语义相似性和关联性的深层主题模型研究	语义表示;文本挖掘;大数据;机器学习	在当今信息过剩的时代，传统基于浅层语义分析手段所得到的信息检索系统已逐渐难以满足人们获取精准信息的强烈需求，这就要求机器做能到深度准确地理解语义信息。主题模型的研究近年受到广泛的关注，在大数据环境下它能体现强大的语义类别属性，且系统扩展性很强，已成功运用于数据挖掘、机器学习和自然语言处理等领域。但其模型初始化假设为每个单词是独立分布存在的，这与实际情况不符，它忽略了词语之间的相似性和关联性。基于神经网路语言模型学习而成的词汇向量化表示可以将语义相似度简化为简单的加减运算，但是它在多义表达和全局分析能力较弱。此外，通过关联模式挖掘技术可以提取出语义的关联性，产生不同形式的模式集合可以形成语义层级结构。因此，本课题将综合考虑语义的主题类别性、相似性、关联性，创新性地定义基于主题的深层语义模型，最终将其应用于自然语言处理领域的自动问答系统和文摘系统，验证其有效性和普遍适用性。
基于云计算的海量多源智慧交通数据流的实时查询与可视化研究	智慧交通;云计算;实时查询;海量数据管理;并行计算	大数据时代，城市交通信息爆炸式增长。云计算环境下大都市交通体系中高并发交通数据流的管理与利用变得越来越重要。本研究针对城区密集布控的各类可感知设备回传的海量、多源、实时、动态不确定数据流，运用理论分析与仿真实验相结合的方法展开研究。.首先，分析城市交通状况与数据流的特征，探讨不确定交通流演化机理，基于核心元数据及约束理论构建智慧交通流数据模型。.其次，采用虚拟化大规模数据集并行计算技术，综合考虑负载均衡以及自适应机制，寻求解决动态、持续、高并发交通数据流的查询算法。.进而，分析海量多维持续查询结果集的整体结构、各维的分布特征及聚类情况，建立基于增量滑动窗口技术的多维信息可视化实时分析机制。.最终，通过仿真实验可视化方式展示选定区域的交通状态，评价、验证所设计的机制和算法，设计并实现智慧交通信息实时分析与展示验证系统。为北京等大都市智慧交通数据流管理与应用提供新的理论和方法。
结合社会网络的网络信息传播分析研究	社会网络;表示模型;信息传播;社交媒体;话题发现与跟踪	Web2.0时代，新型社会媒体不断涌现，深刻地改变了人们信息交流的方式。社会媒体中的信息传播主要由用户的社会交往行为驱动，呈现出文本质量参差不齐、数据规模迅速增长、热点信息快速扩散、信息内容动态演化等新特征，为科学研究和实际应用带来了新的挑战。本项目将通过有机结合社会网络分析和信息传播分析，从面向用户生成内容的语义表示和相似度计算方法、面向社会媒体的热点信息挖掘方法、基于社会网络的信息传播分析方法等三个方面开展研究，拟提出结合外部语义资源的文本表示模型、融合语义相关性和社会特征的热点话题发现方法、结合社会网络分析的信息传播跟踪与分析方法，力求在网络文本语义特征建模、大规模社会媒体数据中的热点信息发现、社会网络与信息传播的相互作用等关键科学问题的研究中获得进展和突破。本项目将形成面向社会媒体进行信息传播挖掘与分析的一系列方法和关键技术，为深化互联网信息的挖掘与分析提供支持。
三维模型在异构空间中的语义迁移方法研究	异构子空间;多核学习;三维模型检索;异构网络;迁移学习	三维模型检索是多媒体信息检索的重要组成部分。由于模型的低层特征不能很好表达高层语义，使得现有的检索技术很难取得令人满意的结果。我们认为，克服语义与特征之间"语义鸿沟"的关键在于三维模型内容特征与表达语义的有效结合。因此，课题以语义与特征异构空间为切入点，探索三维模型高层语义和底层特征的有效结合方式，进而揭示两者的相互作用和内在联系。首先，分别对特征空间和语义空间展开研究。一方面，研究特征空间中异构关键特征的选择性融合方法；另一方面，以三维模型有效且可量化的语义表达方式为目标，构建描述模型语义关系的异构语义网络。其次，结合语义空间和特征空间，研究语义与特征异构子空间的构建方法及异构空间中的语义迁移方法。最后，在此基础上提出三维模型语义与特征异构距离度量方法。课题的研究能对大幅度提高三维模型检索的有效性提供有力的支持。课题建构在通用的模型描述之上，对其它多媒体信息检索领域也有一定借鉴作用。
移动云环境下基于上下文信息的个性化推荐模型研究	上下文感知;个性化推荐;移动云环境	近年来随着移动云计算模式的蓬勃发展，网络中数据资源规模愈发庞大，且呈现出多源、异构的特征。针对如何有效利用这些数据资源及与用户相关的上下文信息，在移动云环境下为用户提供实时个性化推荐的问题，本项目致力于开展移动云环境下基于上下文信息的个性化推荐模型研究。本课题首先拟通过分析用户历史行为信息，设计基于信誉模型的反馈激励机制，并融合上下文信息研究样本数据选择策略，解决推荐系统中样本数据的稀疏性问题；然后通过研究基于上下文信息和模型预测的样本质量优化方法，解决样本数据中数据缺失问题，进一步提升样本质量；最后通过研究上下文感知的用户动态偏好获取方法、多模型融合推荐方法以及并行协同推荐框架的设计，提高移动云环境下个性化推荐系统的准确性、实时性及可扩展性。本项目的研究将丰富和完善推荐系统的学科内涵，并对移动云环境下的个性化推荐系统的基础理论和技术的研究起重要推动作用。
汉语语篇连贯的事件链模型研究	模型融合;统计模型;事件链;标注资源;语篇连贯	语篇连贯是篇章信息处理的一个重要问题，在篇章话题分析、篇章结构组织、自动文摘和自然语言生成等方面均有重要作用。目前篇章连贯的研究主要包括中心理论和词汇链技术，但这些都是实体层面的形式模型。本研究拟从实体层面深入到事件层面，提出事件链的概念和连贯的语篇一定存在一个事件链这一假设。基于此，我们拟建立一个大规模的中文事件链标注资源，其中包含3000语篇实例，并在此基础上建立事件链的分析模型，确立事件链和语篇连贯的评估机制，最后探讨该模型在作文评判、自动文摘和生物事件分析中的应用。针对事件链，我们拟采用一种融合分析策略，将生成模型、判别模型和半指导学习有机结合起来，以避免学习过程中的过度拟合及发挥大量非标注数据的作用。本项目的研究有助于建立汉语篇章语义的形式表示机制、丰富汉语篇章级的标注资源和深化篇章级的语义分析，对文本规划、自动文摘和互联网信息处理也有重要意义。
基于社会媒体的产品销量预测技术	社会计算;文本挖掘;自然语言处理;人工智能;信息抽取	社会媒体已经迅速发展成为具有重大影响力的新媒体，并在很多领域表现出了惊人的预测能力。基于社会媒体的产品销量预测，通过对社会媒体数据的挖掘与分析，聚集大众的群体智慧，运用科学的知识、方法和手段，对产品销量未来发展趋势和状态做出科学的估计和评价。本项目旨在构建基于社会媒体的统一通用的产品销量预测模型，其主要特点和创新点体现在如下三方面：1）本项目面向产品销量预测问题提出消费意图挖掘任务，相对于广泛应用于产品销量预测中的用户口碑分析，消费意图能够更加直接地反映出产品销量的未来走势；2）本项目基于深度神经网络建模学习现实世界中的事件与产品销量之间隐含关系，将当前发生的事件对产品销量可能产生的影响直观地呈现出来；3）本项目提出基于社会媒体的预测模型将基于消费意图与基于事件的产品销量预测相结合，进而将相关关系与因果关系、线性模型与非线性模型整合到统一的预测模型当中，为产品销量预测提供一体化的解决思路。
基于藏文网络动态流通语料的语义文本分类技术研究	藏文信息处理;数据挖掘;语义文本分类;藏文网页文本分类	语义本体是共享概念模型明确的形式化规范说明。英汉语义知识库资源丰富，应用广阔。藏文语义资源短缺，加快建设步伐势在必行。藏文网络资源增长迅速，基于藏文网络动态流通语料的语义文本分类技术可以实时采集网络数据，并进行实时数据分析和处理，提供精准的分类结果；同时可以使相关部门快速地掌握网页动态，并做出正确的舆论引导。本项目对藏语分类本体创建技术开展研究，首先采用信息论方法对藏语分类语料进行类别主题词抽取，基于主题词、Hownet语义知识结构、藏汉电子辞典释义创建分类本体的概念层次，准确描述概念间的关系；对藏文网络流通语料的实时预处理技术进行研究，自动地抽取重要信息；对基于本体的语义空间映射、概念相似度及加权语义网文本相似度计算、语义分类算法进行研究，提高文本分类精度。本课题有助于解决藏语本体分类体系创建、Web语义文本分类等关键技术问题，同时对开展藏语信息检索、机器翻译等语义层面研究提供有效支持。
藏语词法句法联合分析理论与方法研究	命名实体;联合分析;短语结构;词法分析;句法分析	藏语词法分析、句法分析是藏文信息处理的重要任务，前期研究成果表明，两个任务都是彼此相对独立的，而且在藏文句法分析方面主要以依存结构为主，短语结构相对较少。本研究首次以藏语短语句法为基础，构建藏语短语句法树库，在藏语短语句法树库的基础上，采用融合藏语音节、层次级命名实体等语言学线索特征对藏语词法句法一体化分析进行研究，将两个相对独立的任务联合起来进行分析，探索藏语词法分析和句法分析的新方法，对藏语分词、命名实体识别，句法分析准确率的提升提供一种新的思路。
《蒙古语语义信息词典》的设计与实现	语义信息;蒙古语;语义属性;信息词典;描述体系	研制《蒙古语语义信息词典》是蒙古文信息处理的重要组成部分。具有很大的理论意义和应用价值。蒙古文信息处理工作20年的经验告诉我们，无论是基础研究还是应用开发，没有一个基于词汇的语法、语义属性描述体系，就无法满足更深层次的语言信息处理需求。在目前的技术、资源条件下，蒙古文自然语言处理系统必然要求大规模语言知识库的支撑。经过十年我们在词语的语法属性描述方面，已打下一定的基础（已研制"蒙古语语法信息词典"），但在词语的语义属性描述方面还显滞后。我们在开发机器翻译系统过程中感觉到，计算机要得到正确的蒙古语句法结构,以及在多义词辨义时能够选择准确的译词,仅有语法信息是远远不够的，需要补充更多的语义信息。因此，建立蒙古语语义信息词典是蒙古文信息处理的燃眉之急。本课题旨在建立一套蒙古语语义描述体系，并在实用化系统中加以实现。
基于Web知识挖掘与融合的命名实体消歧技术研究	信息提取;实体排歧;自然语言处理	网络知识源数量丰富，如何在信息处理具体任务中，将多源异构知识动态挖掘并有机融合起来为当前目标服务，是一个重要科学问题。本课题以实体排歧为具体任务，研究结构化知识源中的知识挖掘与融合方法、非结构化知识源中的知识挖掘与融合方法，探索多源异构知识在实体排歧中的应用，为网络时代基于知识的信息处理方法寻求有效途径。研究内容包括：（1）提出基于语义图的结构化语义关联方法，对多源异构结构化知识统一建模，并有效挖掘和集成显式和隐藏的结构化知识；（2）建立知识驱动的语言模型，并通过基于相关文档扩展训练集和基于层级结构平滑参数两种手段，解决数据稀疏问题，实现非结构化知识源中知识的有效挖掘与集成；（3）提出基于结构化知识的实体聚类排歧方法，用知识关联替代简单词匹配，提高实体排歧系统的性能；（4）提出基于多源异构知识的实体链接方法，利用实体概念在知识空间中的关联信息辅助概率化语言模型进行实体链接排歧，提高其性能。
开放链接数据（LOD）"使用质量"评估理论与方法研究	开放链接数据;度量;质量评估;使用质量;本体对齐与实例匹配	虽然数据质量被定义为"适合使用"，但现有质量研究未曾体现不同应用需求对评估的影响，且评估过程围绕度量计算展开，评估目标模糊并缺乏精确的质量模型。因此，无法应对开放链接数据（LOD）应用中，使用场景变化大、评估目标数据集合范围广、数据量大导致人工评估成本高等挑战。本项目重点研究"使用质量"驱动的多数据集合的质量评估理论与方法。特别地，项目形式化地定义了应用上下文，明确了应用需求与数据集合、质量维度之间的量化关系；并利用等价类采样、正交采样与一致性评估等方法来降低评估的主观性与评估成本；精确定义了LOD数据集合的质量评估排序模型与不同数据集合的最佳集成建议。本项目理论与方法的提出，为LOD数据集合的评估实践奠定了良好的基础。
基于用户搜索意图理解的在线社交网络跨媒体精准搜索与挖掘研究	信息感知;精准搜索;用户搜索意图;数据挖掘;语义学习	随着在线社交网络信息的剧烈膨胀，传统的搜索技术难以满足用户日益增长的个性化和精准化搜索需求，深层次挖掘用户搜索意图是提高搜索质量的关键。本项目在以往科学研究基础上，建立基于知识图谱的在线社交网络多模态信息感知模型，实现虚拟空间内跨媒体大数据的背景特征信息获取与表达；提出支持多属性多模态的社交网络跨媒体大数据深度语义学习方法，实现用户搜索意图与跨媒体大数据的语义关联；提出基于用户搜索意图理解的在线社交网络精准搜索与挖掘算法，实现对主题敏感性的社交网络对象搜索，建立支持用户搜索意图理解的在线社交网络舆情信息搜索与突发事件监测系统以及在线社交网络谣言来源搜索与追踪系统，为实现更高层次的基于用户搜索意图理解的在线社交网络跨媒体大数据的自动感知与主动获取、精准搜索与挖掘、突发事件监测与舆情跟踪提供科学准确的决策依据，力争在基于用户搜索意图理解的在线社交网络搜索与挖掘领域取得突破性进展。
渐进式中文句法分析的关键技术研究	异构数据;移进-归约;中文句法分析;领域适应性	短语结构句法分析的核心思想是识别句子中的短语以及短语之间的句法关系。短语结构句法分析一直以来都是自然语言处理领域的核心问题之一。近年来，随着大规模人工标注树库的出现，数据驱动的句法分析器在实际应用中起到重要作用。本申请课题在深入分析短语结构句法分析研究中存在的一些问题的基础上，重点研究移进-归约句法分析的一些关键问题和改进技术。主要研究内容包括：在移进-归约算法框架下引入短语信息、子树级移进-归约算法、挖掘深层次的句法信息、利用预测信息指导移进-归约方法的解码技术、利用异构树库和不带标数据、句法分析的领域适应性。最终集成这些关键技术，构建基于移进-归约的中文句法分析共享支撑平台。
汉语隐喻理解关键技术研究	隐喻识别;词语搭配;计算词汇学;隐喻推理;统计机器学习	隐喻的作用在于将人类现有的对熟悉、具体事物的丰富经验，移植到陌生、抽象事物或概念上，以加速人们的认知。隐喻在自然语言中广泛存在，因而日益受到研究者的关注，但在中文信息处理领域则刚刚起步。本课题拟从以下方面对隐喻问题进行研究：（1）在大规模标注语料的支撑下，半自动地建立隐喻标注语料库；（2）建立高效隐喻识别模型和方法，利用隐喻标注语料训练模型参数，以始源域词语为单位，分别对文本中隐喻句进行识别；（3）利用词语搭配相关技术，对识别出的隐喻句子中的目标域自动抽取，构建隐喻知识库，在此基础上归纳出较完整的分领域概念隐喻体系；（4）目前《现代汉语语义词典》尚未对词语的隐喻义项以及隐喻知识进行描述，本课题在上面研究成果的基础上，扩充并完善其隐喻知识描述功能，形成隐喻知识分库；（5）文本隐喻分析原型系统研究：将上述研究成果应用到文本隐喻分析中，对文本中的隐喻现象进行识别，然后对隐喻句给出全面的内容分析。
汉语篇章框架语义关系网自动抽取及其语义推理	篇章语义分析;篇章语义标注;汉语框架网;篇章语义推理	人类对自然语言的理解是复杂的思维过程，它依赖语言学、常识性知识以及思维规律等，篇章语义分析是自然语言处理中最重要也是最困难的问题。汉语篇章框架语义关系网是篇章的语义结构形式化描述，抽取篇章的框架语义关系网意味着抽取了这个篇章的语义骨架，建立框架语义推理机制意味着能够实现篇章语义的深层次挖掘。本项目基于汉语框架网语义资源，研究面向篇章深层语义分析的篇章框架语义关系网自动抽取及其语义推理技术，研究内容包括：（1）针对篇章汉语框架语义关系网自动抽取技术，建立所需的支撑资源；（2）研究篇章上下文语义关系自动标注技术；（3）研究篇章零形式框架元素自动识别与填充技术；（4）建立基于框架关系的篇章语义推理机制，研发汉语篇章框架语义关系网自动抽取及语义推理工具软件。项目的研究成果将为汉语篇章深层次语义分析方法提供新的思路，形成基于框架语义知识库的篇章语义分析理论体系，创新篇章语义分析的理论与方法。
基于引用极性和评论挖掘的论文综合评价模型研究	情感分析;观点挖掘;论文评价;倾向性分析;影响力分析	学术论文评价是提升科研管理的重要手段，目前论文评价依赖于引用次数而忽视了负面引用问题，偏重于作者和期刊影响力等平均性指标而掩盖了具体论文的差异。正在兴起的补充计量学认为社交媒体阅读行为的度量有助于全面评价学术论文的影响力，即不仅考虑到学术影响力也考虑到其社会影响力。项目的目标是建立单篇论文的综合评价模型，主要思想是既看重引用次数也重视负面引用和社交媒体评论的情感倾向性。首先，利用基于改进的PageRank的方法，融合作者和期刊影响力、引用次数、引用极性、引用网络等构建学术影响力的评价模型。然后，利用基于引用语义表示的LSTM方法，融合社交媒体的粉丝数、转发数、评论倾向性等构建社会影响力的评价模型。最后，利用排序学习融合这些影响力，得到单篇论文的综合评价。同时，生成论文标签和主题，构建论文画像，将各种评价信息以全方位多视角的形式展示，满足多元化评价的需要。使之提高论文利用率和科研管理的水平。
汉语言语听障评估关键技术的研究	知觉结构;声调感知;汉语言语测听;听障评估;言语清晰度指数	本项目将言语工程、语音学、听觉心理学与言语测听相结合，重点研究汉语言语听障评估的新方法及其关键技术。利用计算机辅助言语测听研究平台，考察言语声学特征对听觉感知的影响，分析汉语元辅音听感属性的关键参数，构建汉语多维知觉结构；考察声调模式对听觉感知的影响，抽取描述声调感知模式差异的区分性特征，建立测听语料的声调感知校准因子计算方法；在此基础上，研制汉语的言语清晰度指数计算方法，并进一步利用统计分类和机器学习的方法，归纳不同特征的参数取值与听障具体缺陷、残障程度之间的关联性，优化汉语言语听障评估。通过相关研究成果，推进语音感知、声学参数、语言理解相结合的研究，提高言语测听的信度（可靠性），改善言语测听的效度（残障程度的评价、听觉言语功能缺陷的具体鉴别）；也有助于规范言语测听语料，为听障言语测听、为人机交互中语音信息的感知和理解，提供必要的理论基础和关键技术，具有广泛的应用前景。
基于形态和多词的有限语料蒙汉互译调序优化方法	形态;蒙古语;有限语料;多词表达式;调序	蒙汉双语存在形态和语序两方面的显著差异，译文语序混乱是蒙汉互译系统的主要错误之一。基于大规模语料进行统计训练的调序方法在目前蒙汉语言资源有限的条件下所取得的效果有限。.针对上述问题，本项目结合语言学知识和统计方法，将在不同语言单位粒度上挖掘有限蒙汉语料所蕴含的双语知识，对蒙汉互译系统的调序进行优化，拟重点开展：1）研究基于小规模人工切分语料，以增强特征模版整合有监督和无监督的方法，实现半监督的切分以获取蒙古语细粒度的形态信息；2）研究基于形态句法结构模式与多重过滤的多词表达式抽取方法，实现在有限蒙汉语料中挖掘粗粒度的双语信息；3）研究分别利用形态信息和多词表达式对蒙汉互译系统的调序进行优化，指导调序方向，增强长距离调序能力，最终提高译文质量。通过以上研究，探索在有限语料条件下结合语言学知识和统计方法高效挖掘双语知识以优化系统调序能力的技术，为我国语言资源有限的民汉机器翻译研究提供技术参考。
细颗粒度汉语文本意见挖掘方法的研究	情感分析;主题抽取;细颗粒度意见挖掘;汉语意见型主观性文本;主题和情感关系识别	对描述非事实的主观性文本进行意见挖掘是一个新颖而且十分重要的研究方向。本申请项目所要研究的内容是：（1）汉语意见型主观性文本的标注；（2）汉语意见型主观性文本的分类；（3）汉语意见型语句主题的识别；（4）汉语意见型语句情感的分析；（5）汉语意见型语句主题和情感关系的识别。这项研究从解决汉语意见型主观性文本中句子主题、情感以及它们之间关系识别问题入手，以计算语言学和人工智能理论为基础，提出并实现适合于汉语意见型主观性文本的细颗粒度意见挖掘方法。所采用的方法发挥了统计和自然语言处理方法的综合优势，以达到最大程度地挖掘可用的细颗粒度信息和知识的目的。此项语言技术不仅可以提供给其它自然语言处理系统使用，如文本分类、文本过滤、自动摘要、自然语言生成、问答系统、对话系统、机器翻译等方面；还可应用于许多日常生活方面，如电子商务、电子学习、商业智能、报刊编辑、企业管理、信息监控、民意调查等。
基于多源特征学习的中文查询纠错方法研究	信息检索;语言资源;信息抽取;特征选择;语义分析	查询纠错旨在帮助搜索引擎自动发现用户输入的错误查询串并转换或提示合理的查询串，保证搜索引擎的检索质量，更好地满足用户信息需求。查询纠错的核心任务是纠错串优化，本项目以多源纠错特征学习为切入点，通过多源特征的挖掘、融合与演化方法来解决纠错串优化问题，并构建以多源特征学习为核心的中文查询纠错模型。具体包括：⑴在多源特征挖掘中提出从用户行为、语言学、数学模型等多角度来深度挖掘纠错特征，并依据每种特征的信息结构探索多源特征挖掘算法；⑵在多源特征融合中提出多核学习方法，考察每种特征的分布情况、特征之间权值分配，探索一种适于多源特征融合的核函数方法，实现高效整合异构的纠错特征；⑶在多源特征演化中提出从训练资源演化与特征类型演化两方面实现特征演化。⑷在此基础上，开展查询纠错算法体系与模型研究，并组织适合这些算法训练和测试的资源，最终构建具有动态演化机制的中文查询纠错模型。
基于云计算的文本复制检测研究	文本重用;云计算;拷贝检测;MapReduce;复制检测	随着互联网的发展，网页的数量呈现爆炸式的增长。在如此规模的海量数据中，存在大量内容重复、接近重复或者非常相似的网页。重复文本的自动检测，不仅可以提高搜索引擎、观点挖掘等Web应用的准确率和效率，改进用户体验，还可应用于知识产权保护、抄袭行为检测等任务，具有广泛的应用前景。.   本项课题针对海量文本数据，在云计算环境下，研究精度高、速度快、鲁棒性强且具有可扩展性的文本复制检测和区域定位算法，并在此基础上研究信息流的传播模式。具体内容包括：文本表示和特征提取方式；基于云计算框架的相似度计算、检测和定位算法；构建多种颗粒度的中英文文本复制检测标准评测库；结合文本复制检测和定位结果，研究信息流的表示模型和传播趋势。预期研究成果是在国内外权威期刊或主流学术会议发表论文8~12篇，专利申请1-2项。
基于树的句法翻译模型关键技术研究	规则抽取;统计机器翻译;句法模型;解码搜索;句法分析	统计机器翻译核心思想是给每个潜在的翻译结果都赋予一定的概率，并选择概率最大的翻译作为最终的翻译结果。统计机器翻译的研究和系统开发已经成为自然语言处理乃至整个人工智能领域的核心问题之一，已经被广泛地应用在在线翻译和受限领域的机器辅助翻译中。本申请课题重点研究基于树的句法翻译模型（包括树到串和树到树模型）的一些关键问题，目的更好利用源语句法结构来改善句法翻译规则抽取和解码搜索技术，最终改善翻译性能。主要研究内容涉及到句法翻译规则抽取、模型训练、特征权重优化、解码搜索和目标语句法结构评价等关键技术，最后计划将集成相关研究成果到实验室研制的开源统计机器翻译系统NiuTrans中，与国内外同行们共享相关研究成果。
大规模知识图谱的分布式表示学习、知识获取与推理应用	知识图谱;知识获取;表示学习	知识图谱以结构化的形式描述现实世界中实体间的复杂关系，是推动人工智能学科与智能信息服务产业发展的重要基础，也是实现信息检索从字符串匹配到智能理解飞跃的重要驱动。知识图谱的主要研究目标是，从无（半）结构的互联网信息中获取有结构知识，自动融合构建知识图谱，服务知识推理等相关应用。知识表示是知识获取与应用的基础。针对现有研究缺乏对知识图谱进行有效表示与管理手段的问题，本项目以分布式表示为理论基础，研究大规模知识图谱中不同类型知识的表示框架与学习机制，实现对实体与关系的语义信息的统一精确的表示。以此为基础进一步开展以下研究：探索多源异构信息的知识获取与融合表示，建立大规模知识图谱；以社会媒体为典型场景，研究知识表示驱动的文档理解与用户建模；以智能个性化推荐为典型应用，研究知识表示驱动的推理技术与个性化推荐，验证本项目研究成果。本项目预期成果将深化知识图谱研究，对人工智能与智能信息服务均深具意义。
面向语义检索的汉语名名组合自动释义研究	语义模板;名名组合;自动释义;语义检索	名名组合是最简洁的结构表达式，在英语和汉语中产量极高，具有衍生能力强、组成方式简单但是歧义性高的特点。名名组合内部隐含着复杂的意义构建过程，存在语义压缩，常常隐含了谓词。对名名组合进行释义的主要目的是发现两个名词之间隐含的谓词，进而揭示这两个名词之间的语义关系。其研究成果不但能够服务于信息检索、问答系统等自然语言处理系统的需求，而且可以为研究心理语言学关于概念组合的认知机制，提供语义解释的依据。本课题的重要创新是采用动态策略，用基于动词的方法研究汉语名名组合的语义解释，探索名名组合隐含谓词的获取方法，并对其语义组合模式进行逻辑建模，建立在计算机上操作的理解模型。本课题将分析结果应用于网络搜索词中的名名组合，实现语义计算在搜索引擎中的初步应用。
基于用户建模的个性化微博排序研究	用户建模;排序学习;个性化;微博客	作为新型的社交媒体，微博已经成为目前流行的互联网服务，为用户提供大量的实时信息。用户在享受微博方便、快捷服务的同时，经常遇到信息稀缺和信息过载问题。针对这些问题，本项目研究基于用户建模的个性化微博排序。用户建模包括个体用户建模和群体用户建模。针对信息稀缺问题，基于微博属性的群体用户建模方法能理解大众化的趋势信息，满足用户一般性的信息需求。针对信息过载问题，基于微博属性的个体用户建模能获取用户的兴趣爱好，满足用户个性化的信息需求。然后，探索融合多特征和多交互的隐因子模型，使微博排序模型不但可以利用个体用户建模和群体用户建模的显式信息，还可以挖掘用户和微博、用户与用户之间交互的隐式信息。最后，在个性化微博排序评价体系方面，研究基于用户行为的自动化微博排序评价方法。
社交媒体信息可信度分析与评估机制的研究	文本不确定性;情感分析;信息可信度;用户可信度;信息传播	随着社交媒体的迅猛发展，人人都有了网络话语权，可以便捷的发布和接收各种信息，然而这些信息真假难辨，鱼龙混杂，信息的可信度问题国家安全、社会和谐带来了隐患。因此，迫切需要进行面向社交媒体的信息可信度分析和评估机制的研究。然而，社交媒体中信息可信度的评估非常复杂，信息可信度本质特征和传播的基本规律的研究仍然处于初阶段，缺少相关的理论支撑。本项目将以"网络用户—信息内容—传播过程"为核心来研究社交媒体的信息可信度，围绕用户可信度、信息内容确定性以及传播过程可靠性，深入研究社交媒体中用户行为建模与用户可信度的计算方法，社交媒体信息内容表示与信息确定性计算方法，社交媒体中信息的传播过程及信息可信度演化规律，分析信息可信度与网络用户、信息内容以及传播过程的关联关系，建立一套面向社交媒体的信息可信度分析与评估机制。在该评估机制基础上，项目将研制谣言检测原型系统，并通过真实数据进行实验测试。
面向句法分析的动词次范畴化应用技术研究	应用技术;句法分析;动词次范畴化	本课题研究动词次范畴化同句法结构之间的内在联系，验证并完善动词次范畴化框架的形式化定义，探索基于次范畴化改善现有句法分析技术的方法和全新的基于次范畴化的句法分析算法和具体实现方式。总体目标是对相应理论问题做出符合真实语言现象的回答，开发更加实用、高效的汉语句法分析程序，并为其它自然语言处理任务应用次范畴化信息提供经验和技术。句法分析同动词次范畴化之间有着密切的关系，句法分析是动词次范畴化自动获取的重要前提条件之一，也是检验次范畴化词汇知识库的主要应用性任务。次范畴化信息作为句法语义连接的系统描写和抽象分类，必然会揭示出许多隐藏在词汇序列中的结构和分布，并最终提高句法分析算法的整体性能。因此，面向句法分析的动词次范畴化应用技术的研究既有立项的必要性，又有具体实行的可能性。该项研究有着重要的学术价值，其进展和成功必将带来可观的经济和社会效益。
面向手持终端定位服务的时空数据模型研究	事务回溯机制;位置服务;时空数据模型;手持终端	项目拟针对手持智能终端移动GIS 相关定位服务的应用需求，深入分析面向手持智能终端设备的GIS 定位应用服务特点，探索适用于手持智能终端大规模定位服务用户下的低能耗动态GIS 数据交互更新方法；建立面向LBS 多用户异步交互的时空数据模型；提出面向LBS 的增量式时空数据更新机制；充分利用手持智能终端多核CPU 计算能力引入异步多通道数据传输以提高传输效率，降低终端能耗；研究面向手持智能终端定位应用的精简可靠的高维移动对象轨迹与空间地物索引方法。主要研究内容包括：（1）面向LBS 的多用户同步/异步时空数据模型；（2）大规模用户下LBS 时空数据交互更新方法；（3）高维移动对象轨迹与空间地物场景索引方法等。项目研究可为手持智能终端上的移动GIS 软件应用与推广提供理论基础和核心技术，具有重要的理论价值和广阔的应用前景。
基于语义分析的中文微博信息挖掘方法研究	话题发现;情感分析;信息挖掘;微博;语义分析	微博作为一种新型的社交媒体和信息交流平台，越来越受到人们的热捧。微博文本与普通文本有很多不同，因此，研究面向微博文本的语言分析技术和信息挖掘方法十分必要。本项目以语义分析理论为指导，探索面向中文微博特点的语言分析及信息挖掘方法。内容包括：微博语料采集及加工处理方法与规范；中文微博可信度的评价方法、情感倾向性分析方法、话题检测与追踪方法以及个性化信息搜索方法。采用的技术路线为：首先，对用户关系语料进行分析和挖掘，发现用户之间的关系网络；然后，对微博文本语料进行分词、标注以及特征提取等加工处理，并建立相应的语言知识资源库；最后，利用已获取的语言知识资源以及微博文本的各种特征构建中文微博可信度检测、情感倾向性分析、话题检测与追踪、个性化信息检索的模型与算法，并建立相应的实用系统。本项目对政府舆情监控、谣言控制、市场营销等具有实用价值，并对面向微博的信息处理技术与方法的研究具有十分重要的理论意义。
在线诊断：针对临床征兆的诊断搜索模型研究	查询重写;知识关联;信息检索模型;用户行为分析;信息抽取	全民关注健康的时代，在线医疗的发展促进了互联网医疗数据的迅速增长，人们往往选择在线搜索的方式对其出现的临床征兆进行诊断／预诊断，称为在线诊断。和传统医疗诊断不同，在线诊断缺乏"医生"角色的智能支持，因此通过搜索模型来模仿"医生"职能。和一般搜索引擎不同，在线诊断强调医疗领域搜索，输出为诊断结果，而非一般信息普及。和专业数据库搜索不同，在线诊断主要针对无医疗知识用户，数据来源多样化以及要进行知识转换和诊断决策。..本申请课题关注临床征兆的在线诊断搜索模型，侧重征兆查询语句重写、"征兆－术语"知识关联和诊断结果输出。首先，针对无背景用户的无序征兆查询，课题将用户行为分析和主题模型相结合，设计一种基于用户行为的半监督主题模型。其次，对应"医生"角色的知识转换职能，提出一种基于贝叶斯学习的"知识－术语"关系挖掘算法。第三，对应"医生"角色的诊断决策职能，提出一种基于诊断概念特征学习的分类算法。
Web图像的语义表示及在聚类与排序中的应用	信息检索;数据挖掘;聚类;图像检索;检索排序	虽然目前Web上的图像资源急速膨胀，但对Web图像检索的研究还处在相当不成熟的阶段。本课题的研究目标是提出一种新颖的Web图像语义表示方法，并在此基础上研究更加有效的Web图像聚类和排序算法。具体研究：1）根据Web多媒体网页内容，建立Web图像的文本和视觉特征的标注、类别和类型标注和发表时间等元数据描述，并把实体和突发词作为重要的标注词源。根据上述描述，利用领域本体和图算法对语义描述进行进一步的精化；2）研究新型的Web图像表示下的图像平面和层次聚类算法，以及通过聚类进行面向主题的图像聚类和对事件与热点的发现算法；3）研究根据Web多媒体网页自身的特点和分类信息，利用基于内容的图像检索中的反馈技术，结合用户查询日志，研究更有效的Web图像检索排序算法。上述研究问题是Web图像搜索引擎设计中最迫切需要解决的关键问题，并有着广泛的市场前景。
基于数据重构的社会突发事件文摘研究	社会媒体;文本挖掘;信息抽取;微博文摘	社会媒体作为主导的通讯手段，非常规突发事件频发使得研究社会媒体下的高效信息获取刻不容缓。本课题正是以危机事件应急响应与应急决策为应用前景，以社会媒体产生的特定危机事件话题相关的微博集作为研究对象。探索基于数据重构的社会突发事件文摘加速算法新思路，以满足文摘内容选择的重要性、可信度、新颖性以及覆盖性。抓住社会媒体的新挑战：1.简短、口语化、无结构性；2.社交、信任性；3.时序冗余性。由于传统文摘方法无法适应这些新挑战，为此探索从压缩感知、数据重构角度，借助稀疏学习及社会学相关研究成果，将新挑战建模到稀疏优化模型中，提出：1.基于小波分析时间窗自适应的重要时间点选择；2.基于组结构化稀疏学习联合的内容选择；3.融合可信度建模的优化内容选择；4.时序演化性导向的Sparse Fused Group Lasso内容选择。由此发展社会突发事件文摘内容选择的加速机器学习框架，有着重要的研究和应用价值。
面向自然语言文本生成的事件语义计算研究	事件语义模式;事件关系图;事件语义计算;文本生成;事件语义关系	要解决自然语言文本生成中语义信息覆盖、冗余控制以及语义连贯等关键问题，首先要理解文本语料的意义。近年来，事件语义研究成为了自然语言处理领域的热点，但理论语言学仅通过特殊句式来分析事件语义，没有考虑事件语义的计算特性。本项目以小句原子事件为基本信息单位，基于篇章宏观结构和事件语义学的意义组合性原则，自下而上研究句子、段落以及篇章的事件语义计算理论与方法，通过事件语义计算达到对文本语料意义理解的目的，进而基于事件语义计算结果生成表达原文本语料意义的新文本。在基于文本语料实例进行半监督增量学习获得事件语义模式的基础上，本项目研究事件语义结构和事件语义关系识别技术，并使用事件图和事件关系图对事件和事件语义关系进行形式化描述；面向自然语言文本生成，采用优化后的图算法对事件关系图中的事件语义进行计算,进而探讨在自动文摘、问答系统、信息检索等领域有重大应用价值的基于事件语义计算的自然语言文本生成技术。
互联网环境下中文实体知识挖掘关键技术研究	开放域信息抽取;实体关系;实体	从复杂多变的网络数据中挖掘实体、实体类别以及实体关系等知识并进行组织，建立知识间的语义关联，对于文本内容理解、信息检索和问答系统等都具有重要的支撑作用。本申请针对互联网数据"海量不确定"、"多源异构"、"动态变化"、"含噪"等特点，研究互联网环境下的中文实体知识挖掘技术，具体研究内容包括：（1）面向 "关系多样化、可计算、概率化描述"的知识表示需求，研究基于多层语义图的实体知识表示及其知识体系自动构建方法；（2）充分利用网络信息间的差异性、互补性和相关性，研究基于网络信息关联的中文实体知识协同挖掘和验证方法；（3）研究大规模概率化逻辑推理方法，从知识推理的角度探索网络新知识的获取方法；（4）构建实验性实体知识库，并在课题组已有的百科知识问答系统平台上，对以上关键技术进行验证与测试。本申请课题的研究成果将为自然语言理解、互联网信息深度计算等提供参考。
基于大规模主题建模和用户行为分析的微博检索方法研究	信息检索;文档语言模型;微博检索	随着微博平台上信息量呈指数级的增长，微博搜索引擎已成为一种重要的信息获取平台。在微博信息检索中，查询和文档更加简短，因此数据稀疏性问题将更加严重。另外，不同微博用户的权威性有较大差异。微博信息的这些特点严重制约了微博检索系统的服务质量。本课题组拟提出一套基于语言模型框架的微博信息检索方法，利用大规模主题建模技术和用户行为分析提高微博信息检索的效果。首先，通过大规模主题建模技术挖掘微博文本中丰富的语义信息，并结合主题信息构建文档语言模型；其次，利用微博内容和用户行为信息对用户兴趣偏好建模，并构建个性化查询模型；然后，通过微博用户行为分析生成面向查询的局部用户-微博贴关系图并计算微博贴权威性。最后，整合文档模型、查询模型和微博贴权威性信息构建面向微博的信息检索模型。本课题研究对完善微博信息检索方法的研究体系，对提高微博搜索引擎的智能化水平都将具有重要意义。
文本情绪分类的资源建设及关键技术研究	情感分析;情绪分析;文本表示;线性规划	情绪分类是情感分析的一个核心任务，旨在对文本中所表达的情绪信息进行自动分类。该任务是自然语言理解方法研究的一个重要组成部分，同时，该任务在舆情监控、信息安全等领域具有广泛的应用需求。针对目前情绪分类研究中存在的标注资源匮乏、文本表示信息不足、情感分类方法有缺陷等问题，本项目拟开展以下研究工作：1）研究带有基本情绪和复合情绪的情绪分类体系，并在该分类体系下，构建覆盖多个文本类型的高质量情感分类语料库；2）研究基于多信息的文本分布式表示方法，以充分利用多元信息来源中包含的情绪信息；3）研究基于多通道卷积神经网络的情绪分类方法，用于充分利用已学到的多信息文本表示。4）研究基于线性规划模型的情绪分类方法，有效解决情绪分类中普遍存在的样本"多标签"问题。
基于大数据的复杂交通网络节点动态关联性研究	动态关联分析;信息管理系统;大数据;复杂交通网络;机器学习	随着城市交通拥堵问题的日趋突出，实现交通信号的动态控制是未来的发展方向。而交通信号动态控制小区的识别与划分是其中非常重要的环节。本项目研究基于大数据的复杂交通网络节点动态关联模型及基础理论，正是为解决这一问题。首先，针对海量多源异构交通数据的复杂特征，研究数据处理的有效方法，构建复杂交通网络统一数据单元模型，解决交通信息孤岛与处理缓慢的问题。然后，面向高速数据流量快速响应的需求，研究多样本的演化机理，提出基于机器学习的交通状态模式聚类与识别算法。接着，采用大数据技术构建完成复杂交通网络节点之间关联度模型，实现交通控制子区实时动态划分和在线学习优化方案，构建出交通控制子区实时动态划分理论和交通控制子区之间关联度分析方法，形成独立创新的基于大数据的复杂交通网络节点动态关联性研究理论与方法，为动态、实时控制交通信号、分配交通流量和诱导交通路径奠定理论和技术基础。
结构化情感倾向表示与分析方法研究	语义倾向;态度分类;情感倾向;建模表示;观点检索	随着互联网以及用户参与程度的不断提高，情感倾向性分析已经成为商业智能决策、舆情分析等系统中必不可少的组成部分，同时也成为近年来自然语言处理领域的热门研究方向之一。但是目前的以模板和槽填充的表示方式，以及实体和关系抽取为主要方法的研究面临一些新的问题。.    在本项课题中，我们将研究结构化的中英文情感倾向的描述方法，并在新的描述方法基础上研究分析技术，将书面语以及口语话文本转化为该种描述方式，从而提高应用系统的准确性和可用性。其研究目标包括：1）研究新的基于图的结构化情感倾向描述方法；2）构建符合该描述方法的情感倾向分析标准语料库；3）研究基于结构化机器学习方法的情感倾向分析挖掘算法；4）将情感倾向分析发掘结果集成到观点检索、舆情分析等系统。.    预期的研究成果包括：国内外权威期刊和主流学术会议论文8～12篇，专利1～2项。
基于生物医学文献和领域本体的蛋白质复合物预测方法研究	生物信息学;关系抽取;文本挖掘;自然语言处理;领域本体	预测蛋白质网络中的蛋白质复合物是探索各种生命活动机理的重要基础，对于人们深入了解生命系统意义重大。当前公开的蛋白质网络数据仅能表示蛋白质间的拓扑结构信息，这使得复合物预测研究中无法利用复合物重要的功能特性。本项目针对这一核心问题，利用自然语言处理方法，抽取生物医学文献中蕴含的蛋白质相互作用类别信息，整合基因本体资源，构建蛋白质生物属性网络；基于属性图聚类理论，建立生物属性网络的距离模型，融合生物属性网络中的网络拓扑和生物属性两种异构信息；并结合Core-Attachment结构理论，建立高效的蛋白质复合物预测模型。本项目从挖掘并整合生物医学文献和基因本体领域知识入手，不仅为复合物预测研究提供了重要的生物属性信息，而且提出了一种整合多元领域知识进行复合物预测的理论框架，使蛋白质复合物预测研究能将复合物的结构特征和功能特性有机地结合，为建立高效的复合物预测方法提供了新的思路和理论依据。
基于语义科学引文索引的学术推荐与检索	进化引用网络;学术推荐;多网络协同流形排序;社会化张量分解;语义科学引文索引	为克服科技文献数量爆炸式增长带来的严重"信息过载"，智能学术搜索引擎已上升为促进人类科学发展的必然需要。针对"语义缺失"的现状，本课题旨在建立一种基于语义科学引文索引的学术推荐和检索的新范式，研究在学术推荐和检索中融合科学人际交流语义的关键技术。本项目的主要创新如下：针对异质语义学术网络中的多元社会关系，提出了以语义学术超网络为基本模型的多元学术关系和异质学术对象的协同排序算法，实现学术推荐；针对科学人际交流过程中形成的隐含结构，提出了基于异质语义学术网络社区结构的带约束的多网络协同流形排序算法和基于扩展的协同过滤问题框架的社会化非负张量/矩阵分解算法，实现学术推荐；针对自动学术推荐的可用性，提出了进化引用网络和语义引用族谱反映科学领域知识结构和发展脉络，实现探索式学术检索。本项目站在学科新兴的结合点上，提出了面向未来智能学术搜索引擎的新思路和关键技术，在理论和实践两方面都有重要意义。
统计机器翻译领域自适应关键技术研究	统计机器翻译;机器翻译;领域自适应	如何提高统计机器翻译系统的领域自适应能力，是一个具有重大实用价值的科学研究问题。本项目针对人类语言的领域多样性和动态变化等特点，将从三个主要方面对机器翻译领域自适应问题展开深入研究。第一，从机器翻译的角度来研究句子聚类方法，把具有相同或相似翻译规律的句子聚合在一起，把领域混杂的平行语料库划分为不同的领域，从而为领域自适应技术的实施提供便利条件。第二，研究一种基于短语网格的主题模型构建方法，能够在文本的表示方法和粒度上都更适应于机器翻译任务，使得翻译系统具有更好的领域区分能力。第三，研究基于单语语料的词语新译法自动发现及译文挖掘方法，能够从实时更新的单语语料中源源不断地获取新的翻译知识，使得翻译系统具有应对语言动态变化的能力。综上，本申请的研究目标是提高机器翻译系统的领域自适应能力，更好推动机器翻译走向实用化。
图文混合跨媒体知识单元的模糊分类方法研究	模糊分类;知识单元;跨媒体数据;一致性表示	图文混合跨媒体知识单元的主题模糊不确定性对知识的快速有效获取提出了挑战。本项目针对图文混合跨媒体知识单元特征稀疏、模态异构及主题模糊不确定等问题，研究开放知识资源中图像文本两种模态数据共存的复杂多媒体知识单元模糊分类问题。拟解决的关键问题包括：一、针对图文混合跨媒体知识单元特征稀疏性，分别研究图像、文本知识单元的抽取和特征构建问题。二、挖掘图文混合跨媒体知识单元之间学习依赖关系及语义相关图像-文本知识单元之间认知辅助关系，为图文混合跨媒体知识单元一致性表示和分类提供支持。三、提出基于学习依赖关系的图文混合跨媒体知识单元一致性表达模型；并在此基础上，研究图文混合跨媒体知识单元多主题模糊分类问题。本项目一方面有助于丰富和完善图文混合跨媒体知识单元研究的理论与方法，另一方面有助于克服现有知识单元模态单一问题，为构建新型跨媒体知识管理和服务平台提供理论和技术支持。
面向社交媒体的群体性事件态势感知与演化机理研究	群体性事件;情感分析;态势演化;社交媒体	网络群体性事件本质上是网民群体围绕某事件或主题，通过网络聚集方式制造社会舆论，引发社会行动的具有重要影响力的事件。从宏观层面上，随着关注事件的网络用户群体的情绪波动，群体性事件的生命周期通常会经历预警、爆发、缓解和善后等阶段性状态，称之为群体性事件态势。在社交媒体上，群体性事件的主题更新快、情感波动频繁、覆盖人群广，这使得信息可以迅速汇聚形成舆论，从而加剧了网络群体性事件的滋生和传播，给国家安定、社会和谐带来了隐患。本课题面向社交媒体从态势感知与演化分析的角度对群体性事件进行细粒度刻画和探究，具体研究内容包括：1）实时检测网络群体性事件，并利用统一的语义表示对群体性事件进行跨媒体跟踪；2）研究由个体到群体的情感聚集原理，以及群体情感随主题、事件、时间等因素的演化机理；3）研究群体性事件态势表征，以及群体情感与事件的互动规律，实现面向社交媒体的群体性事件态势感知与演化分析。
海量数据信息下一致性协作推荐机理研究	正向相似性;反向相似性;因果相似性;一致相似性;协同过滤推荐	推荐系统的出现打破了用户在海量数据中难以获得个性化信息的僵局。在众多推荐算法中，基于二部图网络的协同过滤算法由于适应性强，准确性、多样性和个性化方面推荐性能优异，得到了广泛关注。但是，以往在二部图网络上，协同过滤算法主要是基于时间顺序上物品间的因果关系来研究物品相似性的，但当物品间没有因果关系，并且物品的选择是基于用户一致性偏好时，采用因果性推荐将导致相似性估计偏差，造成了推荐性能的局限。针对因果性推荐机理的不足，本项目在对比因果性推荐机理和用户选择物品的一致性偏好基础上，从基于一致性机理的物品相似性指标和推荐模型入手，对协作推荐机理及算法展开研究。首先，研究二部图网络属性对因果相似性估计的影响，以及因果相似性与一致相似性的关系。其次，研究如何基于因果相似性指标构建正向相似性和反向相似性指标。最后，研究基于正向和反向相似性指标构建非平衡一致性协同过滤推荐机理和算法模型。
基于迁移学习的自适应信息抽取技术研究	术语抽取;关系抽取;共指消解;信息抽取;迁移学习	本项目尝试基于迁移学习方法，解决传统的信息抽取过程需要较多人工参与且依赖于大规模训练语料和缺乏领域自适应性的问题,研究从现有的数据中迁移知识，用来帮助将来的学习或者其它领域的学习。通过探索相应的信息抽取方法，弥补领域资源匮乏和领域资源变迁的问题；系统地研究信息抽取的领域自适应方法，从而提高信息抽取的自动化程度；致力于研究信息抽取中的术语抽取、关系抽取、术语的共指消解等关键技术。本项目提出基于指示词和链接分析的方法实现术语抽取；采用自底向上的规约和聚类方法得到关系类型并抽取关系实例；基于多特征抽取与优化的共指消解策略；同时探索上述方法在自然语言处理具体应用中的实施策略，并通过相关任务检验和评价信息抽取方法。为信息检索、自动文摘、文本分类、本体自动构建等各种智能信息处理任务提供重要的支持和借鉴。
融合网络特征的文本观点挖掘	社会网络分析;自然语言分析;观点挖掘;社会化媒体;文本质量分析	互联网信息的内容分析具有重要的理论意义和应用价值，观点挖掘是将网络信息内容分析引向深入的重要途径。本项目根据当前网络信息发展的趋势，把观点挖掘问题放在社会化媒体背景下进行研究。针对Web发展中观点挖掘出现的新特点，即观点表达上的特点、文本质量上的特点、文本观点与社会网络相互作用的特点等，通过有机结合观点挖掘和社会化媒体分析，从观点相关特征分析、观点文本质量分析、结合社会网络特点的观点分析等三个方面开展研究，拟提出网络文本的观点表达的语言特征和环境特征发现方法、融合话题相关性和社会化特征的观点文本的质量度量方法、以及结合社会网络特点的观点分析方法，力求在观点的语言表达分析、高质量信息获取、以及观点挖掘和社会网络相互作用等关键科学问题的研究中获得进展和突破。本项目将形成面向社会化媒体、结合网络特征进行观点挖掘的理论、方法和关键技术，为深化互联网信息的内容分析提供支持。
海量社会媒体数据中不实信息的分析与检测	社会媒体;用户分类;传播模型;不实信息检测;大规模数据提炼	微博等社会媒体的蓬勃发展，帮助人们更快捷地获取信息。但是，由于任何人都可能成为信息发布者，使得许多不实信息混杂其中，而且传播更加迅速、蛊惑性强且不易甄别。因此，迫切需要一套自动、高效、准确地衡量信息真实度的模型与算法，以检测不实信息。.    本课题拟采用基于多元采样、事件聚类和半监督标注的分层提炼方法构建面向海量社会媒体的大规模、高质量不实信息数据集；基于上述数据集，从内容、用户和传播等三个方面，以主题模型、机器学习技术、回归分析方法和社会学传播理论为工具全面理解不实信息，获取分析不实信息的基本特征。基于上述特征分析，建立综合"内容－用户－传播"特征的支持向量机回归SVR模型以判断博文信息真实度，建立图模型来共同检测用户和信息真实度度量，最终形成科学的不实信息自动检测方法。在上述理论方法和技术的研究基础之上，本课题还将开发不实信息的在线预警与检测系统，服务于社会媒体的和谐稳定与健康发展
基于网络社交媒体的层次化用户兴趣建模	社会关系网络;数据挖掘;中国互联网;社交媒体;用户兴趣	近年来,随着网络社交媒体的兴起与不断发展,社交媒体在网络用户的生活中的影响越来越大,大规模的网络用户积极参与到社交媒体中来,形成了十分活跃的虚拟社会，引起了政府、业界和学界多层次的关注。从学界来看，可分为两个主要方面，一是考察以往在社会网络分析中得到的经典结论在网络社交媒体上体现的形式和程度，二是考察在网络社交媒体上是否存在新的基础性原理。而其中用户行为模式的分析、理解、与挖掘成为一个非常关键的研究问题。本课题定位在社交媒体中的用户兴趣建模,进而来更好地理解社会媒体,以及其内 部信息传播的一些基本模式和规律。本课题提出的假说是：尽管用户兴趣纷繁复杂且动态变化，但层次式结构能对它们进行有效地表达。我们希望通过探索相关理论并建立一套具有层次性的动态用户兴趣模型来支持这个假说，并希望所建立的用户兴趣模型能改进一系列针对社交媒体的分析和挖掘工作。研究中，我们将特别考虑结合我国的社交媒体的特点。
基于轨迹数据的用户意图挖掘关键技术研究	主题模型;深度学习;基于位置的社交网络;轨迹挖掘;兴趣点预测	随着信息通讯技术的高速发展和位置感知设备的普及应用，近年来出现了越来越多的时空轨迹数据，对这些数据进行挖掘从而理解用户的行为模式，是智能交通、城市规划、基于位置的服务等领域的重要需求，而分析轨迹数据背后的用户隐含意图，是理解用户行为的重要途径，但现有工作还鲜有显式涉及。为此，本项目将围绕用户意图理解这一核心问题，展开三方面的研究：1）研究构建基于深度学习的用户意图模型；2）研究基于意图理解的用户推荐，主要包含兴趣点推荐，下一位置预测等；3）为解决在意图建模及应用中遇到的数据稀疏、缺失问题，研究轨迹数据与文本等社交网络数据的多源数据融合与相互增强；为支持轨迹数据的大规模处理，研究流数据处理技术，主要包括分布式索引结构和查询算法等。本项目的研究将为用户行为的深入分析和理解提供新的方法和技术，为轨迹数据挖掘提供新的支点，满足来自智慧城市、移动社交网络等领域的应用需求。
基于社会化标签的个性化推荐技术研究	社会化标签;个性化推荐;协同过滤推荐	本项目拟围绕基于社会化标签的个性化推荐技术展开研究，具有重要的理论意义和实际价值。项目主要研究内容包括：①基于社会化标签的混合个性化推荐策略研究：使用基于内容的推荐算法对社会化标签数据进行处理，然后结合协同过滤推荐技术进行推荐；②基于模型矩阵分析的协同过滤推荐策略研究：将社会化标签三维模型分解为三个二维模型，简化模型系统，并使用协同过滤方法进行个性化推荐；③使用张量因式分解的个性化推荐策略研究：拟在现有的张量因式分解技术上，使用损失函数缩小预测值和实际值的距离，然后再进行偏差移除以进行结果优化；④基于训练集优化的推荐模型动态生成方法研究：个性化推荐模型的建立和误差数据的筛选迭代进行，直至推荐模型收敛为止，动态生成精确度更高的推荐模型。拟在国内外SCI、EI收录刊物以及计算机学会推荐高水平学术会议上发表论文6～8篇、申请国家发明专利3～4项；培养博士毕业生1～2人、硕士毕业生3～5人。
基于马尔科夫树与DRT的汉语句群自动划分算法研究	汉语篇章分析;篇章表述理论;句群划分;马尔科夫树模型	句群自动划分是自然语言处理中的重要课题，在机器翻译、篇章理解、信息检索等领域有广泛应用前景。针对现有汉语句群划分方法未充分利用句子上下文信息及句间关联信息的不足，本项目利用篇章表述理论（DRT）能动态地描述自然语言意义的特性，提出一种基于马尔科夫树和DRT理论的汉语句群自动划分方法。主要研究内容包括：（1）汉语句群构成特点分析；（2）汉语段落的马尔科夫树表示和句群自动划分算法；（3）DRT理论中篇章表述结构（DRS）构造算法；（4）DRT理论的语义解释模型。本项目研究的难点和核心问题在于构建马尔科夫树对汉语段落进行层次表示并利用动态规划算法实现句群自动划分，以及提出改进的DRS和语义解释模型对句群划分结果进行修正。本项目研究对于丰富汉语句群划分理论与方法，具有重要的建设性意义，同时为自然语言处理中从句法结构表示向语义形式表示转化提供了一种普适的方法，弥补了目前在语篇语义表征方法方面的不足。
推荐系统的信息核挖掘及其应用研究	协同过滤;推荐系统;复杂网络;网络演化	推荐系统已经在理论和应用中取得很大进展，但其所需处理的数据往往规模巨大，从而导致推荐算法的效率不能满足应用需求。本项目拟基于复杂网络理论，研究基于二部图网络表示的推荐系统，挖掘推荐系统的信息核，在满足算法准确性要求的前提下，大大提升推荐算法的效率。首先，从推荐网络拓扑结构的统计特征入手，挖掘推荐网络的信息核，设计信息核提取算法，确保信息核在满足推荐算法功能需求的前提下极大化压缩数据量；其次，通过信息核的演化分析，建立模型刻画其网络结构的动态演化机制，力求通过信息核网络的演化特征揭示原始推荐网络的演化特征，进而实现推荐网络建模；最后，设计基于信息核的静态和动态算法，利用推荐网络信息核保功能而规模极小的优势，设计高效的推荐算法。本项目在保证推荐功能的前提下对推荐网络进行结构压缩，为推荐算法处理大规模数据集提供新思路，其结果不仅有利于在应用实践中取得效益，而且丰富了复杂网络理论研究。
面向Web环境下藏语社会网络分析的关键技术研究	图模型;社会网络分析;WEB环境;数据挖掘;藏语网络实体	本项目通过藏语网络实体关联分析，为国家安全提供分析数据。以此为背景，研究WEB环境下藏语社会网络分析关键技术。研究内容：藏语Web社会网络分析数据获取和表示；藏语Web数据实体识别和检索；以图模型为指导的藏语社会网络多关系挖掘；对藏语社会网络时空图模型发展变化进行预测。拟解决的关键问题：建立藏语Web数据统一表示模型；藏语实体识别和检索算法；高效的藏语网络实体语义关系抽取和建模方案；藏语Web时空动态变化和藏语实体间依赖关系，建立概率图模型，求解动态变化的藏语社会网络模式；社会网络分析中藏文本体技术，包括藏文编码统一、变形显现、版式规范、藏文分词、语料库及其标注体系、藏汉辅助翻译系统等。创新点：藏文实体搜索引擎的研发；Web环境下藏语实体属性模型和实体关联计算体系结构；动态网络环境下藏语网络群体的挖掘及演化分析算法；藏语社会网络全局信息发展态势分析及舆情预测的集成展示环境。
互译语言形态非对称的统计机器翻译模型构造方法研究	统计机器翻译;形态分析;模型融合	在统计机器翻译过程中，由于互译语言（源语言与目标语言）形态结构不对称，极易造成译文错误。2005年以来，将语言学形态知识应用于统计机器翻译的方法引起了国内外学者的广泛关注，并围绕英语/捷克语、英语/土耳其语等形态非对称语言的机器翻译开展了研究。我国少数民族语言大多属于形态丰富语言（屈折语、黏着语），而汉语属非形态语言（孤立语）。在汉/民机器翻译中，由于语言形态结构不对称，经常导致译文在语法、语义、语用等层面出现错误。本项目针对上述问题，拟开展以下研究：1、多层级的形态分析方法；2、形态信息与统计模型融合策略；3、融合形态信息机器翻译解码算法；并以语言形态差异较大的汉/蒙统计机器翻译为例，开展相关实验。.通过上述研究，探索应用形态学知识构建统计模型的机制；为形态丰富的屈折语和黏着语的形态处理提出有效的解决方案；为互译语言形态非对称的统计机器翻译模型构造理论方法提供新思路和依据。
面向产品评论的评价对象层次结构分析与极性识别	隐式评价;评价对象;层次结构;情感倾向性分析;极性识别	评价对象的抽取与极性识别研究是面向产品评论的情感倾向性分析领域的重要研究任务。然而对于评价对象的抽取任务，现有研究忽视了评价对象的层次性和完整性，为精准的情感倾向性分析应用带来了很大的困扰；对于评价对象的极性识别任务，现有研究仅关注含有评价词语等明显极性特征的显式评价，忽略了极性特征不明显的隐式评价，造成部分评价对象的极性丢失。基于此，本项目提出评价对象层次结构分析的研究任务，表现为产品品牌、属性和子属性三个层次组成的层次结构，挖掘评价对象内部完整的层次关系。同时，将评价对象对应的评价文本分为显式评价和隐式评价，分别进行极性算法研究。具体内容有：评价对象层次结构的无指导识别算法；面向显式评价的基于句子压缩的评价搭配抽取算法；面向隐式评价的基于图的篇章内外特征相融合的极性识别算法。本项目旨在深入研究相关算法，更精确、有深度且全面的挖掘评论中的情感信息，为情感文摘、电子商务等应用提供技术支持。
基于生物医学文献的隐含知识发现方法研究	生物信息学;文本挖掘;信息抽取;隐含知识发现;实体识别	以MEDLINE为代表的海量生物医学文献资源中，存在大量的蕴含于公开发表的文献，而尚未被人们认知的隐含知识。采用文本挖掘技术从这座宝库有效的提取隐含生物医学知识的需求变得非常迫切。本项目以MEDLINE的生物医学文献为主要数据源，在生物实体识别和名称标准化的基础上，利用UMLS、MeSH、GO、UniProt、DrugBank、KEGG Database等生物医学资源，建立基于生物医学概念的概念空间和基于概率潜在语义索引的潜在语义空间表示；利用信息抽取和段落检索技术进行医学概念共现识别；引入监督学习方法，选取包含潜在语义空间相似度、医学语义关联度和全局语料库统计量以及信息抽取的统计特征等多种特征来综合评定概念间的相关度量，最终获得生物医学文献中的隐含知识。此外，本项目将实现挖掘知识的可视化，建立具有实用价值的生物医学文献隐含知识发现平台。
在线社会网络中的强关系和弱关系的研究	人物推荐;社会网络;用户属性信息推断;弱关系;强关系	在线社会网络（online social networks, OSNs）有着各种各样的人际关系。网络中的强关系和弱关系具有特殊意义，这些有意义的人际关系不仅为个体提供了支持边，而且组成一种特殊的网络：社会支持网络。但是OSNs有着严重的信息缺失现象，网络的边权值被视为均等的，没有反映出人们之间的关系强度。网络中的强关系和弱关系是隐藏的，没有被标识出来。这些缺失的信息给社会网络分析带来困难。本申请主要研究OSNs中的强关系和弱关系，研究内容有：1）研究OSNs的关系强度的计算方法、强关系和弱关系的识别方法，将OSNs转换成标记了强关系和弱关系的加权社会网络；2）在该网络上利用网络中的强关系和弱关系，考察各种人物推荐算法对强关系和弱关系的推荐能力，研究面向异质性信息获取的人物推荐算法；3）利用网络中的强关系和弱关系，改进现有的用户属性信息的推断方法，对OSNs缺失的用户属性信息进行增补与还原。
高性能低比特视觉搜索及芯片结构研究	特征提取;硬件加速;预处理;特征选择;视觉搜索	直接利用数字图像这种更加直观的信息载体，通过智能终端进行视觉搜索将成为互联网信息检索的重要手段。然而实际应用中往往带宽和存储资源受限，所以研究高性能的低比特视觉搜索具有很重要的意义。围绕低比特视觉搜索这个问题，本课题从以下四个方面展开深入研究：（1）基于图像预处理的高鲁棒性特征提取（2）自适应局部特征选择（3）高性能视觉搜索算法（4）紧凑视觉特征提取硬件加速。通过自适应图像预处理算法，去除不同光照的差异，进而提取出对光线更加鲁棒的局部特征；通过融合局部特征自身的显著度以及先验概率信息，自适应选择更加具有辨别力的局部特征；通过多种查询扩展策略，提升视觉搜索的准确率和召回率；通过合理的软硬件分区和多层次混合流水线设计，对紧凑视觉特征进行高能效加速。本课题预期通过上述四方面的研究，从视觉搜索准确率和实时响应两方面改善低比特视觉搜索体验。
基于依存图的汉语依存分析技术研究	组块分析;浅层分析;长距离搭配;依存分析;依存图	依存文法对于语序灵活的汉语来说具有良好的描写能力，然而"投影性原则"使得依存树基本等价于短语结构树，没有充分体现出表示方法和分析精度的优势。为了摆脱这一限制，满足后续语义分析等应用的需要，本课题提出了基于"依存图"的汉语依存分析方法，重点研究两大问题：一是建立基于依存图的句法标注体系，给出基于原有树库的自动调整和转换方法，并研究与之相应的图搜索算法。另一方面，为了提高长句的分析精度和效率，引入浅层分析技术，使用组块分析捆绑短语使得句子扁平化，使用骨架分析识别长距离搭配以廓清句子结构；尝试用基于图的算法，将浅层分析和依存分析融合起来，最终给出实用的汉语依存图分析算法。
开放域语义关系抽取、表示和计算关键技术研究	关系抽取;开放域信息抽取;语义计算;表示学习;语义分析	语义关系是人类知识的核心组成部分，其抽取、表示和计算是智能信息服务的关键支撑。本课题面向智能信息服务，以现有的大规模语义知识为驱动，针对开放领域，在语义关系的抽取、表示和计算三个层面展开研究：（1） 在抽取层面，本课题利用知识约束、语法结构约束、统计分布规律性和大数据冗余性，研究远距离监督关系抽取技术和开放式关系抽取技术，实现开放域文本的高覆盖语义关系抽取。（2）在表示层面，本课题以大规模语义知识为核心，研究语义关系的表示学习技术，挖掘语义关系所承载的信息，并将其表示为适合计算的形式；研究结构推导算法，发现语义关系之间的联系，按层次分类体系有效组织语义关系，为语义计算提供基础。（3）在计算层面，本课题面向真实自然语言理解场景，研究基于深度神经网络的组合语义算法和结构化深度语义核，实现以语义知识为核心的文本语义计算。最后，本课题以智能问答为平台进行验证。
基于自然语言处理技术的生物实体语义网络研究和应用	抽取;本体;语义;生物实体;机器学习	本项目研究并抽取生物文献中命名实体（蛋白质、基因和疾病）之间的语义关系，并建立面向疾病的语义关系网络，将网络以可视化的形式展示。我们需要做的工作有：标注相关的实体关系资源；研究和建立实体关系抽取模型；抽取关系并建立实体语义关系网络；研究发现新的实体关系的方法；研究关系网络随语料时段变化的演化趋势，发现生物研究热点；将实体关系网络应用于乳腺肿瘤的诊断和研究。根据研究领域和研究对象的特点，为了实现以上目标，我们采用基于自然语言处理的方法结合多核学习的机器学习技术研究本项目。具体是以开放的生物文献为研究对象，首先采用自然语言处理技术对文本进行处理，获得句法解析树和依存图，然后利用解析结果得到合适的句法和语义特征，采用基于Simth-Waterman算法的复合核函数抽取实体之间的语义关系，构建语义网络，我们将对抽取的语义网络应用到乳腺肿瘤的早期辅助诊断。我们还将对结果利用公开数据进行评估。
无线数据广播环境下位置相关Skyline查询问题研究	位置相关查询;Skyline计算;动态偏好;数据广播	无线数据广播环境下位置相关Skyline查询综合了Skyline计算、位置相关查询与数据广播三方面的特性，能很好地满足数量众多、资源受限且运动模式多变的移动客户端对广播数据的复杂查询需求，因而可广泛地应用于智能交通、物流管理、数字战场等涉及到位置相关服务的移动计算领域。与传统的Skyline查询相比，由于受应用环境(无线数据广播)和应用特征(位置相关、移动查询点)的影响，无线数据广播环境下位置相关Skyline查询面临诸多新的问题。本项目在深入分析无线数据广播环境下位置相关Skyline查询问题的特征、约束、需求与性能评价标准的基础上，以低能耗为优化目标，研究支持动态偏好、增量计算、网络距离度量的有效的广播数据组织模式、索引结构与高效的位置相关Skyline查询处理算法。本项目的研究有助于丰富和完善Skyline查询理论成果，拓广其应用范围，从而为相关产业的发展提供理论与技术支持。
面向学术文献的知识提取与总结关键技术研究	关系抽取;文档摘要;学术知识点提取;学术文献挖掘;知识结构图	随着互联网上学术文献资源的逐渐增多，用户需要借助学术搜索引擎查找相关文献。而目前的学术搜索引擎只能返回列表式检索结果，同时高质量的综述论文稀缺，用户只有通过浏览大量相关文献才能了解相关研究进展。本项目基于自然语言处理与文本挖掘技术，对学术文献内容进行深度语义挖掘和总结，通过学术知识点抽取与关系识别，构建以学术知识为核心的知识结构图，并生成高质量的综述，力图在面向学术文献领域的信息抽取与文档摘要技术上取得创新性进展，并为构建下一代基于知识搜索的学术搜索引擎提供关键技术支撑。本项目的最终目标是为了方便研究人员快速准确了解相关研究成果和研究进展，进而提高研究效率。
汉语篇章连贯性分析：话题结构、逻辑语义结构及其联合学习研究	篇章分析;联合学习;话题结构;篇章连贯性;逻辑语义结构	与词法、句法分析相比，篇章分析研究相对滞后，特别是，汉语篇章分析的研究处于起步阶段，由于尚未形成成熟的理论体系，资源极为匮乏，因此相关计算模型的研究受到了严重的制约。篇章逻辑语义结构和话题结构从不同视角描述了篇章的连贯性，本项目将从汉语篇章逻辑语义结构和话题结构出发，基于已有的篇章分析和话题结构理论，重点研究汉语篇章的连贯性。主要的研究内容包括：1）提出并实现融合多种信息的隐式篇章逻辑关系识别方法，构建高性能的端到端的篇章逻辑语义分析平台，并基于该平台进行基于ILP和结构化感知器的全局优化研究；2）提出并实现基于话题-评述关系理论的微观话题结构分析方法，并在此基础上进行基于话题链的宏观话题识别研究；3）从连贯性视角分析汉语篇章逻辑语义结构和话题结构的关联性，并基于此提出并实现基于句法和谓词论元结构的汉语篇章逻辑语义结构和话题结果的联合学习方法。
网购产品评论可信计算模型、方法及评价研究	可信计算;评价偏离;虚假评论;大数据分析	随着产品评论大数据在推荐、决策等活动中起到的作用日益突出，虚假评论等现象也相应增多，其有效识别问题逐渐引起重视。项目围绕产品评论可信计算涉及的理论模型、方法及评价等展开，并从行为分析及内容表达两个角度进行评论异常发现。首先在借鉴国内外研究成果的基础上，建立网购产品评论可信计算的多维度指标评估体系及评价偏离模型并重点从用户可信度计算角度进行综合、突破。其次从文本内容角度研究基于细颗粒度情感计算的异常评论偏离发现、可信度主题判别及基于迭代的评论可信度等相关计算模型及方法。然后构建面向多模态数据的深度信任网络以形成产品评论可信度融合计算框架，评价不同机器学习方法和特征的实际作用。最后从不同角度构建产品评论可信度计算的评价方法及进行相应平台建设，为研究展开和效果提升打下基础。研究成果有助于丰富现有虚假评论识别理论与方法，提高评论数据驱动决策、评论攻击预测预警等相关研究的数据源可信甄别能力。
可比语料库质量量化与提升方法研究	语料库质量;跨语言信息检索;可比语料库;双语词典抽取	鉴于平行语料库在某些领域和语言对上的稀缺性，可比语料库近年来受到了研究者的重视并已被成功应用于多种应用任务中。已有的基于可比语料的知识挖掘工作大多关注挖掘算法的优化，它们的发展已经遇到瓶颈难以提升。以提升可比语料质量来间接提升挖掘算法的性能是一种符合直观经验的思路，但现有工作大多忽视了可比语料的质量差异及其对应用性能的影响。鉴于此，本项目将系统研究可比语料质量的量化、评测、提升方法以及对实际应用的影响。在质量量化上，可比度指标综合考虑了外在词汇特征和内在主题相关性特征；在可比度性能评测上，我们设计了与真实语料相似且可量化的基准测试语料和性能评测指标；针对可比语料质量提升，项目采用了高效的层次聚类策略和子聚类选择方法；最后，应用部分通过双语词典抽取和跨语言信息检索任务来检验项目整体策略的有效性。本项目对揭示可比语料质量的重要性，对可比度指标的设计、评测以及相关应用性能的提升都有重要价值。
基于多传播信息流博弈的微博谣言自动检测方法研究	深度神经网络自学习;多传播信息流;社交智能博弈;谣言检测	微博谣言是当前社会关注的热点，面向微博的自动谣言检测也是舆情分析技术研究的前沿。本课题从虚假性和负面性两个方面来研究微博谣言，构建微博谣言自动检测系统。首先，本课题通过深度神经网络自学习机制从微博大数据中学习言论虚假性和负面性的语义特征；接着，根据学习到的语义特征，结合社会网络结构、用户模型构建微博言论传播的链接、观点和情感三个层次的多传播信息流模型，预测言论的传播路径，分析言论传播者的传播收益；最后，引入社交智能博弈的方法来模拟多传播信息流模型中社交个体对言论虚假性和负面性的智能判别与传播过程，实现对谣言的自动检测。本课题的研究意义在于从多传播信息流的角度，通过社交博弈来构造微博谣言自动检测系统，这为网络谣言研究开拓了一条可行的途径，对丰富网络舆情分析方法、促进自然语言处理技术和倾向性分析技术的研究都有着重要的学术意义，也对当前网络环境的净化，社会舆情的分析疏导具有非常现实的应用价值。
基于排序学习和深度学习的专利检索研究	检索模型;结果排序;排序算法;相关性反馈;检索排序	专利是世界上最大的技术信息源，专利检索是当今从海量专利文献中获取知识，了解技术动态的重要手段，能够极大地提升专利的利用价值。项目的宗旨是：综合运用信息检索、文本挖掘和机器学习方法，从查询扩展、检索模型、方法融合等多个角度，进行专利检索模型的构建。重点研究基于不同信息源的查询扩展方法；针对专利文本域的内容差异性，对于不同的文本域采用不同检索方法；针对专利中的摘要等文本域构建基于深度学习的检索模型，对多个文本域的检索结果进行融合；采用排序学习方法对于提出的多种方法进行融合，在模型训练过程中加入专利的质量因素，提高专利检索准确率以及用户对于返回结果的满意度。本研究为以语义检索技术为目标，以文本表示、查询理解、查询重构、文本相似度计算等为基础，构建基于排序学习和深度学习的专利检索方法，为专利检索提供一个可靠的研究思路。
面向标注社会网络的极性相关影响力最大化问题研究	传播动力学;极性;标注社会网络;信息传播模型;影响力最大化	影响力最大化是社会计算研究领域的重要科学问题，是解决政府和企业推广信息需求的关键技术。现有研究大都基于仅包含正向关系的无标注社会网络开展，忽视了网络中负向社会关系的存在。本课题拟面向同时包含正向关系和负向关系的标注社会网络，开展极性相关影响力最大化问题研究：（1）基于情感倾向分析技术，挖掘网络中用户关系间隐含的正负极性，并建立反映关系极性的社会网络模型；（2）融合计算机科学、社会科学和物理科学等多学科知识，基于线性迭代思想和热量传递理论，构建标注社会网络中极性相关的扩散动力学模型，揭示标注社会网络中的信息或者影响力的传播机理；（3）结合贪心策略和模拟退火思想，提出可以准确挑选出固定规模的拥有最大正影响力或者最大负影响力的用户集合的方法。本课题将影响力最大化问题向真实社会做了进一步拓进，旨在推动影响力最大化研究成果在实际场景的应用。
企业全生命周期知识管理系统客户化定制与进化方法	进化;知识管理;客户化定制;本体工程	知识和持续的学习能力是企业创新和发展的源泉。然而目前企业知识管理系统的建设仍存在种种困难。企业需求的差异和易变性，与现有软件工具缺乏客户化定制与进化能力之间存在着根本性矛盾。这种情况造成现有商用工具很难满足企业的特殊需求，同时在特定时期研制的系统，又往往不能适应未来新的需求。本项目针对知识管理系统构建中的困难，提出基于本体的知识管理系统的客户化定制框架；通过对本体协作建模、协作知识获取与重用过程的建模、多类型知识集成融合、面向全生命周期的进化方法等问题的研究，建立一个集成多种知识类型，具有对知识结构、知识处理过程等要素进行客户化定制能力，支持协作过程知识流管理，支持不同应用需求，支持企业全生命周期进化管理的KMS原型系统。在典型科研院所以及较大规模企业的知识管理过程中进行应用验证。
基于句法结构和篇章结构的统计机器翻译关键技术研究	双语句法推导;句法结构;篇章结构;统计句法机器翻译	语言的结构性，包括句法和篇章等结构信息，是语言的基本特征之一。统计句法机器翻译把翻译看作是一个从源语言到目标语言的句法结构转换过程，而这种转换过程目前是以单一句子为基本单位进行的。因此，跨语言句法结构差异性和跨句子篇章结构信息的缺失是目前统计句法机器翻译面临的两个核心问题。本项目拟围绕这两个问题展开以下创新性研究：1）从双语映射角度出发，研究弱指导和无指导的双语句法推导算法，自动构建适合机器翻译的双语句法规则体系和映射机制，进而解决跨语言句法结构差异性；2）建立篇章级翻译模型，使得源语言篇章结构信息和篇章基本特征在目标语言中得到体现，使生成的目标语言具有良好的篇章一致性，进而填补机器翻译中篇章信息缺失这一研究空白。本项目预期成果不仅可以为下一代统计句法机器翻译奠定理论和技术基础，同时也可以为未来基于深层语义结构信息的统计机器翻译提供借鉴。
基于深度学习的句子相似度计算研究	句法语义分析;句法分析	现有的基于深度学习的句子建模方法，主要侧重构建和改进深度网络框架，过于强调自动学习特征表达和抽象的过程，没有将体系完善的语言知识充分融合到学习框架中。本项目从汉语和日语两种语言入手，研究基于深度学习的句子相似度计算的关键技术并将其应用到机器翻译等领域。针对深度网络模型及人类对句子认知过程的特点，从三个方面提高句子相似度计算的性能：一是提出一种基于语义计算的单词概念泛化方法，研究语义单元的泛化粒度、泛化标准及泛化算法，将语言知识融合到泛化规则中，提高学习句子模式的能力和嵌入表示句子性能；二是提出一种基于深度学习的句子表示模型，将句子视为"词－短语－句子"的层级结构，综合考虑LSTM和Attention改进机制构建深度学习网络模型；三是设计一个合理、高效的算法来计算句子之间的相似性，主要考虑将相似度计算算法加入到句子建模过程中，达到句子建模过程和相似度计算过程的参数可全局调优的效果。
多模态医学成像引导精准放疗中的快速知识协同与跨域知识借鉴学习方法研究及验证	医学成像云;快速知识协同学习;多模态医学成像;快速跨域知识借鉴;精准放疗	多模态医学成像引导精准放疗旨在结合各模态成像信息使医生较准确地评估患者肿瘤病灶及周边组织/器官真实状况，从而制订合理放疗方案、实施精确放疗过程。然而现行精准放疗部分环节要么较依赖医生临床经验要么主要面向单一模态成像进行。针对此现状，本课题拟开展快速知识协同与跨域知识借鉴学习方法的相关研究与验证，着重面向精确诊断和精确定位环节，研发关注区内(ROI)基于多模态快速知识协同和跨域知识借鉴的目标区域划分、基于多模态知识协同和跨域特征增强的组织/器官/肿瘤类型识别、基于生成模拟CT的多模态成像间配准与PET衰减校正、目标成像的历史关联成像检索等关键方法以及作为支撑的多核融合与知识借鉴协同谱聚类、多核融合有监督/半监督快速协同分类等算法，并基于这些内容构建面向精准放疗的多模态医学成像云。本课题工作既服务于多模态成像引导精准放疗的直接技术需求，也为其它精准医学相关课题的研究或临床应用提供通用技术支撑。
通用Web结构化信息检索引擎的关键技术研究	结构化信息检索;Web结构化数据;深层Web;分面搜索;语言模型	Web上存在大量的结构化数据，大多处于深层Web数据库中，很难被一般的搜索引擎所检索。如何利用这些数据来满足用户的信息需求是长期以来的一个研究问题。早期的数据集成法更适合特定领域的垂直搜索引擎。近年来通用搜索引擎中使用的数据抓取法是预计算出尽可能多的相关页面，但由于这些页面被作为普通HTML页面一样被索引和检索，因而无法利用数据中原有的结构信息来改善检索效果。针对两者的主要缺陷，本项目的研究目标是研制一个跨领域的通用Web结构化信息检索引擎，既能在检索中充分利用结构信息，又是跨领域和通用的。具体地，我们将数据集成法和数据抓取法两者的优势结合在一起，并使用新的基于语言模型的结构化信息检索模型，充分利用数据和查询中的结构信息改善检索效果，并能将结构化数据和非结构化数据的检索统一在一个系统中，从而使得通用搜索引擎即时搜索Web上的各种结构的和非结构的数据成为可能。
针对微博客的公共突发事件演进趋势关键技术研究	突发事件;自动检测;网络舆情;微博客	经过微博客平台传播的社会事件，能够在短时间内积聚公众的关注，形成突发事件的信息网络舆情。从海量微博客数据中自动检测社会突发事件并科学预测其演进态势，具有重要的现实意义和理论价值。本课题的研究将从计算机科学与传播学相结合的角度为我国针对社会化媒体的网络舆情预测提供一系列的基础理论和核心算法。课题从数据采集的完整性、突发事件识别的针对性、演进趋势预测的有效性方面入手，面向微博客网络的突发事件演进趋势预测系统定义并解决其中的关键技术问题。课题首先构建面向微博客的分布式数据采集系统，获得与原生微博客平台中完整网络具有最大拟合效果的数据集合，在此基础上综合考虑微博客独特的媒体特性与传播特性提出适合于微博客的突发事件检测方法，进而建立突发事件生命力短期预测模型，并根据事件的生命力指数的变化规律及短期预测值分析突发事件在"产生、发展、消亡"生命周期中所处的演进阶段。
短文本情感分析关键技术研究	情感分析;观点挖掘;情感词;情感分类	情感分析具有广阔的应用前景，可以带来巨大的经济和社会效益。随着社交网络的蓬勃发展，短文本具有数据量大、内容简略、特征稀疏、信息混杂等特点，这使得以往的情感分析方法在处理短文本时,难以保证其分析效果。针对上述挑战，本课题按照短文本情感要素抽取、短文本情感分类、短文本情感归纳三层不同的研究任务，构造一系列情感分析模型，分别解决隐式属性词及基于属性词的情感知识获取问题、情感词典抽取过于依赖外部资源的问题、短文本情感分类的数据稀疏问题、短文本情感归纳的表征与建模问题。本项目所研究的这一系列模型能够自底向上满足不同层次情感分析的实际需求。
网络下的西夏文及西夏文献处理研究	西夏文;网络化;信息处理;数字化;西夏文献	当前随着西夏学研究的不断深入，将西夏文及西夏文献计算机网络数字化和文本化，并对数字化、文本化的文献进行查询与检索是目前迫切需要研究与解决的问题。本研究项目将利用计算机在网络环境下对西夏文及西夏文献的处理进行研究，是建立在已有的"夏汉字处理及电子字典"的研究基础之上，通过对已有的西夏字库、夏汉电子字典的修正和补充，进而建立新的西夏文网络字库、西夏文献网络数据库和在线夏汉电子字典等数字化资源，研究西夏文献的数字化、网络化整理的解决方法和实现技术，最终将西夏网络数字化资源集成并整合为国内乃至国际上较全面的西夏学数字化网络资源平台。该平台将实现西夏文的网页显示和西夏文献的文本化及西夏文关键字在西夏文献数字化资源中的精确定位与检索和字库、文献资源的快速更新与发布。通过平台的建立进而探索少数民族古籍文献的计算机研究方法和计算机科学技术与人文社会科学相互交叉、相互结合的研究方法。
基于大规模知识库的问答系统关键技术研究	知识库;基于知识库的推理;人工智能;问答系统;语义分析	随着大规模结构化知识库的兴起,基于大规模开放域知识库的问答系统已成为学术界和工业界的关注热点。本项目以基于结构化知识库的问答系统为主要研究对象,分别从问题意图解析、结构化查询的构造、推理问题解答等角度研究以开放域结构化知识库为基础的自然语言问答技术。不同于以往以信息检索为基础的问答系统,大规模开放域结构化知识库能提供具准确的语义信息,同时其天然的图结构属性又为问题语义建模、高效的结构化查询及推理问题的解答提供了便利条件,从而更好地满足用户的知识检索需求。本项目围绕大规模开放域结构化知识库,集中研究以下四个方面:基于结构化知识库的查询意图分析方法,基于结构化知识库回答事实性问题的方法,基于结构化知识库推理的方法以及如何利用结构化知识库提升现有基于文本的问答系统。
基于语义资源和深度学习的情感隐喻识别方法研究	情感分析;情感隐喻;深度学习;自然语言处理;语义资源	情感隐喻普遍存在于人类语言中，是对复杂、抽象的情感进行概念化的重要手段，也是情感分析深入发展面临的重大挑战之一。目前情感隐喻识别方法缺乏语义资源支撑和认知语言学指导，并且偏重隐喻识别而忽视了隐喻传递的情感信息。因此，本项目以认知语言学为指导，以语义资源建设为基础，以深度学习等相关技术为主要支撑，展开情感隐喻识别研究，并以此为基础提出跨语言情感隐喻的识别方法。首先构建面向情感隐喻识别的语义资源，主要包括采集语料、制定标注规范和质量监控体系；然后进行情感隐喻识别，利用命名实体识别等方法识别出本体、喻体以及所属领域，通过领域冲突检测判断是否存在隐喻，再采用深度学习的卷积神经网络模型挖掘出隐喻传达的情感；最后利用非监督自编码神经网络模型，采用非监督的特征学习训练方式，进行跨语言隐喻识别。本项目将建立起较为完善的情感隐喻识别机制，从而提升情感分析精度，有助于情感分析和自然语言理解的深入发展。
面向Web图像检索的在线多模态哈希技术研究	多模态学习;Web图像检索;在线哈希	Web图像有着多模态性、海量性与动态性等主要特性。虽然现有的多模态检索以及哈希技术能够有效解决海量Web图像的检索。但依然有两个难点无法得到解决。第一点是当前的多模态检索技术缺乏在线学习的功能以应对动态性，而在线哈希方法也无法处理多模态的Web图像。另外随着Web图像的变化其哈希码也应改变，现有的在线哈希方法仅动态更新哈希函数，而无法动态更新Web图像旧有的哈希码。针对Web图像的特性以及现有哈希方法的不足，本项目研究一种在线多模态哈希方法。首先提出一个统一框架，将多模态关联、多图学习以及哈希码更新三个模块有机整合在一起，从而能够支持多模态Web图像的哈希检索。其次研究哈希函数与哈希码的在线学习。由于哈希码的计算效率受数据库大小影响，因此将哈希码转化为一个较小的动态矩阵进行优化。最后在公开的Web图像数据集和本项目收集建立的数据集中验证项目方案的有效性，并与国际上最先进的哈希算法进行对比。
用户自适应的社会标签生成和优化模型研究	计算广告学;社会标签;生成模型;多目标优化;话题分析	标签是Web 2.0下用户标注网络信息资源的重要手段，应准确地体现用户对资源的高度理解。本项目旨在研究用户自适应的社会标签生成和优化模型，以便能够对特定网页生成最合适当前用户背景的标签。为此，拟从以下几个方面展开研究：首先，建立一定规模的用户标注语料库，并设计和训练概率生成模型来模拟用户对特定文档的标注过程，以此推导出用户对标签的偏好程度，该模型还将考虑时态因素，以反映用户的实时兴趣；然后，对新网页标注时，借助维基百科和训练集进行对网页扩展，生成标签树，再利用训练好的生成模型获取用户对标签的偏好程度，并综合考虑用户的偏好度、标签之间的冗余度以及主题的覆盖度，采用多目标优化技术产生一组理想的标签；最后，考虑到标签的自适应性，反馈机制也纳入模型研究之中。本项目的研究对于提高Web信息检索质量，捕获Web信息中的热点话题以及应用到计算广告学中提高网页、用户和广告三者的精确匹配都有着重要意义。
基于互联网与本地数据融合的"互联网+医疗健康"信息检索研究	信息检索;多样化算法;医疗健康;演化建模;数据融合	当前通用搜索引擎在医疗健康信息检索方面的效果有限，随着智慧医疗、健康中国的提出，医疗健康信息的检索面临新的机遇与挑战。互联网上(线上)的医疗数据数量巨大，但质量良莠不齐；医院本地(线下)的数据质量较高，公众却无法访问；两者都在时间上碎片化、类不平衡、非常稀疏。因此，本项目从满足不同用户群体的医疗健康信息需求的角度出发，拟研究基于线上、线下数据融合的"互联网+大数据+医疗健康"信息检索中的基础理论及关键技术，包括：研究基于深度学习的线上、线下多源异构数据的融合及知识表示；研究医疗健康问题的演化过程建模、个体与时空差异分析、复杂关联关系挖掘；最后研究融合以上成果实现新型的面向多目标的多样化信息检索算法。本项目的目标是通过线上、线下数据的融合，优势互补，挖掘问题的演化规律及隐含的知识，使信息的表示适合不同群体的理解能力，提高人们获取信息的质量和效率，为人类保健及疾病的预防、治疗提供新的技术支撑。
结合分布相似和汉语构词特征的词义相似度计算	分布相似度;自然语言处理;词义相似度;金标准数据	词义相似度计算旨在自动获取与任一给定词广义相似（包括语义相似或语义相关）的相似词序列。活用所得到的相似词序列可以有效缓解数据稀疏，如平滑统计语言模型，提高自然语言处理的基本问题- - 词义消歧的准确率。本课题的重要创新是结合汉语特点，提出基于大规模语料库的新的词义相似度计算方法。研究内容包括：1）博采多种基于上下文分布特征获取相似词的算法之长，并利用汉语特有的诸如名量搭配之类的可以表征词义的句法关系，提炼新的算法，得到给定词的初步的相似词序列；2）利用汉语的"部首偏旁表字义、字义表词义"的构词知识，增加与给定词具有相同表义字或相同表义偏旁部首的那些相似词的权重，调整相似词序列；3）提出词义相似度计算的评测方法，制备高质量的标准数据；将词义相似度计算作为构件嵌入到其他自然语言处理实用系统，检验效果。申请人在本领域完成了博士论文，组织过多次国际评测，基础扎实，积累丰富。
现代藏文自动校对研究	现代藏文;自动校对;纠错;侦错	现代藏文自动校对技术研究是藏文信息处理技术中一项具有广阔前景和极具挑战性的研究课题。随着藏文信息处理技术的发展促使现代藏文出版业电子化，藏文网页、藏文电子书、电子报纸、电子邮件及其办公文件等不断涌现，电子文本呈海量增长。使得在使用这些电子文本时，其中的校对环节的工作量大大增加，人工校对的方式已经无法适应电子文本校对，有了自动校对系统就可以通过快捷、简便、准确的对现代藏文文本进行字、词和句法的自动校对，将改变原始、落后、繁重、劳苦的人力校对方式。本项目在借鉴现有中文和英文文本校对技术的基础上，对现代藏文文本自动校对领域中的音节字、词和格助词进行深入研究和分析。充分利用传统藏语语法的理论成果，研究现代藏文文本中音节字、词和格助词的构成方式和搭配规则，结合文本校对的方法和理论分析音节字、词和格助词的错误类型，针对性的提出用于校对现代藏文文本的侦错与纠错方法及算法。
中文情感资源自动构建的关键技术研究	极性偏移;情感分析;汉字情感;资源自动构建;极性非对称性	情感分析是目前计算语言学领域的研究热点，而情感资源是支撑情感分析的基础。目前，中文情感资源相对匮乏，质量也不高；此外，当领域变化后，已有的资源往往不够充分甚至不适用。本项目旨在从大规模无标注语料中快速自动构建质量高、覆盖度广的情感资源，将从如下四个方面展开研究：(1)提出适合文本自动处理的情感模型，能覆盖各种情感粒度、情感特性；采用判断题形式（从语料中自动挖掘）设计情感标注规范，使得标注过程清晰、可操作，标注结果一致性强。(2)提出基于非对称性的极性判断方法，能使用无标注语料自动判别观点的极性。该方法还能考虑上下文信息，从而更加准确地判断极性。(3)构建汉字情感资源。此外，结合构词法的研究，提供汉字和单词之间的情感传播方案，应用于统计信息较少时的单词情感推断。(4)采用序列挖掘算法抽取出典型的极性偏移模式（否定、转折等）。
汉英篇章衔接对齐资源构建与分析研究	机器翻译;篇章衔接性;对齐分析;省略;语料库标注	篇章衔接性分析是理解篇章的基础，英语和汉语在指代、省略和连接等主要衔接方式上存在差异。现有汉英平行语料主要进行了句子对齐，缺乏衔接信息的对齐，导致国内外对于汉英篇章衔接对齐分析研究很少，从而影响了融合衔接信息的机器翻译等相关应用。本项目旨在创建汉英篇章衔接对齐资源，研究衔接自动对齐分析技术，并将此应用于融合衔接信息的机器翻译。首先，研究汉英篇章衔接对齐标注策略，建立包含指代、省略和连接对齐信息的汉英篇章衔接对齐资源；其次，基于所建资源，结合汉英衔接特点，采取不同的分析策略和处理方法，实现汉英衔接对齐分析平台；最后，将衔接信息融入机器翻译系统中，从提高机器翻译性能和改善评测两方面考察衔接信息的作用。本项目开展的研究工作对于推进汉英篇章语义分析研究具有重要的意义。
业务过程模型的重构技术研究	业务过程管理;复杂性;重构;业务过程模型;并发	如何提高业务过程模型的质量，是过程感知信息系统迫切需要解决的问题。现有业务过程模型重构研究，主要关注从活动标签质量、可理解性和可维护性方面提高模型质量，较少关注效率和复杂性。本项目从效率和复杂性视角，研究提高模型质量的业务过程模型重构技术，解决以下问题：（1）提出一种挖掘并发性的重构技术，自动识别业务过程模型中紧邻任务间的假顺序关系和非紧邻任务间的假传递顺序关系，并把这两种关系重构为并发关系，以提高模型的效率。该重构过程从数据视角把不改变模型的数据处理结果规约为建立重构前后模型间的相关性同构。（2）提出一种消除结构冗余的重构技术，使用基于结构的分析方法，高效地自动识别业务过程模型中的隐式库所，并设计重构操作消除隐式库所，以减少模型的复杂性。该重构过程从控制流视角把不改变模型的行为规约为建立重构前后模型间的基本关系同构。为企业实施过程感知信息系统面临的模型质量问题提供新的思路和技术支持。
基于回答集语义的观点挖掘方法研究	规则质量评估;回答集语义;观点挖掘;规则学习;不一致性处理	基于规则的观点挖掘方法已被广泛应用。规则具有简单、可解释、高效等优势。当前基于规则的观点挖掘方法研究不足主要有三点：1）现有方法大多基于单调的一阶逻辑规则抽取观点，在复杂的非单调任务上具有局限性；2）现有方法使用的观点挖掘规则多是领域专家手工设计和筛选的，难以保证规则质量；3）探索观点挖掘规则不一致问题的研究较少。本项目研究基于回答集语义的观点挖掘方法。一方面，基于回答集语义的观点挖掘规则可以突破一阶逻辑规则不能进行非单调推理的局限，更加适合处理复杂的观点挖掘问题。另一方面，在回答集语义下可以高效地进行规则学习和推理，也可以方便地处理规则集中的不一致问题。本项目将着重探索以下两个问题：1）基于回答集语义的规则学习方法；2）基于回答集语义的规则不一致问题处理方法。本课题的研究不仅对观点挖掘、规则学习的理论创新具有重要意义，也为其它应用领域的知识发现提供理论支撑和技术储备。
基于主体个性化的微博情感分析关键技术研究	情感分析;观点挖掘;情感综合;微博计算;主体个性化	随着新型互联网应用的迅猛发展，微博快速崛起，用户数达到2.5亿，使用率达到48.7%，每天数以千万人通过微博分享自己对各类话题的观点与情感，如何自动感知微博主体的情感，并从宏观上科学研判微博社区对特定话题的观点倾向性，已经成为微博计算与舆情分析亟待解决的基本科学问题。微博内容的碎片化与主体化特征日益凸显，传统的情感分析算法存在本质缺陷，效率低下且效果很难满足实际需求。本课题旨在研究基于主体个性化的微博情感分析算法，主要包括：结合微博主体个性化特征，研究单条微博内容的情感分析算法；根据微博的情感波动变化，研究微博博主的情绪感知方法；针对特定话题，研究大众的情感综合研判技术；在理论研究的基础上进行算法的实践验证。本课题的主要创新体现在对短小而不规范的微博内容进行情感分析过程中，引入微博主体的个性化特征，参考博主对特定主题的历史态度，从而提高对微博内容情感分析的客观性与针对性。
基于深度神经网络的自动作文评分算法研究	自动作文评分;深度学习;自然语言处理	在自动作文评分系统中, 对能够衡量作文水平与质量的特征的提取是保证评分准确性的关键技术手段。当前的自动作文评分算法普遍采用文章长度、语法错误等浅层特征，然而受限于目前自然语言处理技术水平，这些特征仅能在词法句法层面有效反应作文写作质量，而对于语义内容层面则仅能定制出较为浅层的特征，无法正确表示作文的上下文语义内容。申请人在前期工作探索了多种自动作文评分方法和评分模型常用特征与写作质量的相关性和泛化能力，归纳出当前自动作文评分技术因受限于所用特征的浅层性问题，导致该技术的鲁棒性和有效性受到严重制约。在此基础上，本研究拟基于深度学习技术构建新的自动作文评分算法，通过挖掘深层次的、能够有效反应文章写作质量的语义特征, 进而训练基于深度神经网络的自动作文评分模型，并在ASAP与HSK等公开中英文作文数据集上通过多重交叉检验进行性能验证评价，以期能显著提升现有评分系统的人机一致率和鲁棒性。
面向话题的事件关系抽取与网络构建研究	事件关系网络;全局优化;事件关系抽取;时空义三维表示体系;可信度计算	随着移动互联网的发展，热点话题层出不穷。作为联系话题内相关事件的纽带，自动识别事件关系并围绕某个话题构建事件关系网络，对理解并获取话题核心内容至关重要。本项目将在话题结构和语义一致性等理论的指导下，研究面向话题的事件关系抽取与网络构建方法，重点解决事件关系多样性和信息缺失问题。主要研究内容如下：⑴针对事件关系多样性问题，提出了面向话题的事件关系时空义三维表示体系，并基于此开展基于主动学习和标签传播的事件关系语料库构建方法研究；⑵提出了基于语义一致性理论的文档级单维事件关系全局优化方法和多维事件关系联合学习方法；⑶针对信息缺失问题，提出了基于Tree-LSTM和平行推理的跨文档事件关系抽取方法；⑷提出了基于最优网络的事件关系网络构建方法，并基于此提出了基于多源融合的事件关系网络可信度计算模型。本项目的研究对于推动信息抽取技术的发展和探索人类语言理解的认知机理，具有重要科学意义。
基于数据耕种的对抗决策支持系统	数据耕种;数据挖掘;决策支持;云计算;博弈论	本课题从数据耕种技术入手，对基于数据耕种的对抗决策支持技术进行深入探索。通过将数据耕种模型包括已经开发的Agent模型用一定接口加入到仿真环境中，解决数据耕种模型统一问题，以基本对象模型的方法来实现模型动态重构。采用以数据耕种和数据挖掘相结合的方式对决策问题需要的知识进行深度挖掘，构建基于数据耕种的知识库。建立以云计算服务为数据耕种生长机制，通过对负载平衡算法等研究解决数据耕种需要超大计算量的问题。同时用改进的模糊层次分析法对耕种结果进行有效评估。构建的对抗决策支持系统以数据仓库为平台；数据耕种用来搜寻未知信息和没有预料到的知识；数据挖掘从海量数据中提取出可信、新颖、有价值的知识，从而对模型进行改进；并针对不同态势建立相应博弈模型。通过将数据耕种、数据挖掘、数据仓库和博弈论等方法的有机结合，解决现有决策系统存在的面向模型、封闭的、禁止不确定性和风险等弊端，为决策支持技术的研究开辟新途径。
融合事件关系推理和情感博弈的网络不实信息演化机理研究	角色转移;兴趣度分析;情感博弈;团体划分;事件关系推理	自媒体环境下，由于信息呈碎片化传播导致网民难以认清事件发生的前因后果，为网络不实信息的滋生和传播提供可乘之机。研究网络不实信息演化机理对探测民意、净化网络空间、维护社会稳定等方面具有积极的现实意义。.      本课题从事件关系推理和情感博弈的角度分析网络不实信息的演化机理，首先针对由信息碎片化传播带来的事实真相获取困难的问题，研究同一事件关联检测机制，提出一种基于实体依赖的层次关联检测模型，并结合情感一致性来推理事件之间的关系；其次针对不实信息事件关系不唯一问题，研究网民历史信息和历史行为，挖掘网民间的强弱关系作为初始博弈角色定义的依据；进一步研究网民个体情感和群体情感，在定义评价对象潜在情感的基础上推理网民隐性情感，构建基于情感博弈的角色转换模型，用于划分博弈角色团体作为事件关系消歧的依据；最后，构建信息信任评估模型，用于预判网络不实信息，还原事实真相。
从海量文本中获取概念的多重属性、多重关系以及它们的元性质	多重属性获取;知识获取;概念和属性的元性质;增量式获取;多重关系获取	文本挖掘、术语抽取、本体学习等研究问题受到学术界的普遍关注。但是，目前研究人员主要集中在特殊形式和要求的概念（如命名实体等）和关系(如上下位关系等)的获取上。同时文献调研表明，人们对概念不同种类的属性获取以及对概念和属性的多种元性质(meta-properties)的获取缺乏足够重视。.针对这些问题，在我们已有工作的基础上，本课题将研究一套方法和技术：（1）获取概念间不同种类的语义关系，包括可显式定义的上下位、部分整体、同义、位置等关系，以及不能显式定义的关系，并且获取不同种类关系的关联性以及关系属性；（2）获取概念不同种类的属性，包括数值型、性质型、角色型等属性；（3）获取概念c和属性a的元性质，包括c是否为类型概念？c的基数是有限的还是无限的？a的值域是否可变？a的值域是否有序？a的取值是否具有继承性？等等。
高动态SINS/GPS超紧耦合组合导航系统的反馈式多目标信息融合理论研究	超紧耦合;多目标信息融合;反馈;组合导航系统;卫星导航	在军事航空航天领域和车辆等民用领域，高动态的SINS/GPS超紧耦合组合导航系统是组合导航领域的研究热点，有重要的研究意义和高端研究价值。本项目主要研究高动态条件下SINS/GPS超紧耦合组合导航系统的多源信息融合问题，包括：以信噪比和延时误差为目标,积分及清零时间为优化变量的双目标动态优化策略，结合小波变换实现高动态环境GPS信号的可靠获取；结合固有的融合信息反馈和交叉性，提出一种基于粒子滤波的高动态SINS/GPS超紧耦合组合导航系统反馈式多目标信息融合策略；研究基于FPGA平台的高动态SINS/GPS超紧耦合组合导航系统高可信并行计算实现，并进行试验验证。本研究对增强组合导航系统对GPS信号的跟踪锁定能力, 提高组合导航的鲁棒性、跟踪能力和导航精度，对高动态GPS / SINS超紧耦合组合导航的工程实现提供理论指导。
多视角自适应哈希学习及其应用	可变比特分配;多视角互补哈希表;哈希最近邻搜索;自适应量化编码;多视角流形嵌入	随着网络技术的快速发展，图像数据规模急剧增加。建立高效的索引机制并实现快速查询已经成为海量图像数据存储和管理的核心问题。基于哈希的最近邻搜索方法是实现海量图像数据高效索引的关键技术。然而，海量图像数据的多视角、多语义、非结构等特性使得现有的哈希搜索方法难以获得理想的检索性能。本项目以多视角自适应哈希学习为研究对象，通过分析多视角数据的拓扑结构和信息差异，构建哈希函数信息度量模型并设计可变哈希比特分配策略，进而提出自适应哈希量化编码方法，以更好地保持编码相似性；通过挖掘多视角数据之间的关联性和互补性，利用流形嵌入的局部重构一致性，建立联合相似性测度学习模型，进而提出多视角流形哈希学习框架，以提高检索精度；通过对多哈希表样本近邻空间结构进行协同建模，建立可解释的多哈希表互补准则，进而提出多视角互补哈希表构造框架。本项目的研究成果将推进哈希学习技术的理论发展，促进其在海量图像检索中的推广应用。
基于主干成分的句法统计机器翻译模型研究	基于句法的模型;统计机器翻译;主干成分翻译;解码;模型训练	统计机器翻译是当今自然语言处理领域的重要研究课题之一。虽然近些年来已经有一些成功的统计机器翻译模型被提出，如何更加充分的利用（源语言）句子的结构信息及句子主干信息来进一步提高翻译性能仍是十分重要且有待研究的科学问题。本课题研究基于主干成分的句法统计机器翻译及相关科学问题，内容涉及中文句子主干成分自动识别、基于主干成分的句法统计机器翻译建模、基于主干成分的句法统计机器翻译模型训练和解码等内容。本课题将以数据驱动的方法为指导，结合人们在翻译过程中形成的先验知识构建整个机器翻译框架。课题的选题及实施依托于申请人所在团队（东北大学自然语言处理实验室）在机器翻译方面研究的多年积累，课题的研究成果将全部集成到开源统计机器翻译系统NiuTrans中，无偿为学术界共享使用。
复杂网络在词语语义相关性度量中的应用	语义相关度;信息检索;多文档;短文本;复杂网络	语义相关性度量是自然语言处理（NLP）中的基础问题。目前相关性的研究主要限于"词对相关性"，且计算方法与评测手段均独立于待分析文本，而相关度与文本的语义是密切相关的。复杂网络在语言学及NLP中已有初步应用，能发掘出传统方法难以探测到的文本内深层信息。根据NLP任务的普遍需要，本项目提出包括"词与短文本之间的语义相关性计算"等5项相关性计算任务，且要求相关度计算结果符合文本的语义。采用复杂网络作为背景知识表示，完成这5项相关性计算。采用两类方法评测：1）设计心理学试验，获取针对文本语义的人类直觉数据，采用合适的参数，产生评测平台，对比计算获得的各项相关度与人类直觉相符程度；2）在关键词抽取和信息检索两个任务中评价计算获得的相关度的应用效度。本研究有望克服传统方法依赖人工资源，对数据稀疏敏感，难以处理未登陆词和变体词等局限性，推进语义相关性的研究，对从语义上突破NLP的众多任务有着重要意义。
基于中心扩展对齐的汉-英统计机器翻译研究	统计机器翻译;调序模型;译文路径;中心扩展;评价特征	本课题研究统计机器翻译的知识获取与解码技术。提出了中心扩展的短语对齐方法，摆脱了汉、英之间语法异构性的制约。同时考虑源语言满足句法约束和不满足句法约束的短语翻译对，以覆盖更多的语言现象。提高词汇覆盖度，细化语义分类体系，利用语义知识、句法和统计信息来增加译文中心的识别率。深度挖掘汉、英语言学之间的对等关系，使用句法、词性、词形、语义和长度等属性来定义双语评价特征，揭示评价特征与短语翻译对自身特性之间的关系。在输入句子的句法树上，以调序概率和插入概率为基础来构建译文调序模型，使调序过程可以充分地利用句法边界信息。结合双语评价特征，使用最大熵算法来选择译文路径，以综合考虑多种上下文相关信息。力求降低搜索解码空间，提高机器译文输出质量，为基于句法的统计机器翻译提供一个新的解决思路。
基于社交网络的多样性小众推荐技术研究	多样性推荐;社会化推荐;社交网络;推荐系统	传统的推荐技术以提高推荐精度为主要目的，推荐列表往往聚焦于少量的流行商品。为了提高用户-系统粘度，针对老顾客在流行性推荐失效后必须考虑推荐列表的多样性，才能满足顾客的个性化需求。因此，如何在兼顾精确性的同时保证推荐列表多样性，成为当前推荐系统的面临的一个重要问题。同时，随着facebook，世纪佳缘，新浪微博等社交网络的兴起，基于社交网络的社会化推荐越来越流行，如何有效利用各种社交网络信息进行商业推荐也越来越受到人们的关注。由此，本项目基于复杂网络分析技术并结合网络社区结构及其演化特性提出一种同时满足精确性和多样性的推荐方法，并利用超图聚类方法融合信任网络、标签网络等各种社交网络信息，实现具有多样性的社会化推荐服务。最后，研究大规模复杂网络的近似计算方法，将各项技术推广到应用领域。本研究成果不仅能应用于基于社交网络的社会化推荐，在传统基于长尾的推荐任务中，也能起到很好的胖尾提升效果。
互联网藏文文本资源挖掘及语料抽取关键技术研究	藏文;藏文分词;信息检索;语料库;信息抽取	藏文信息处理目前面临着基础语料匮乏的困境，互联网为我们提供了大量的藏文文本资源，是藏文语料的一个重要来源。本项目将利用网络爬虫与藏文自动编码识别技术，自动从海量的互联网资源中挖掘藏文资源，并配合人工分析，考察藏文文本资源的分布情况和存在形式，发现有利用价值的藏文文本资源；我们将建立藏文搜索引擎原型系统，对互联网藏文资源进行有效索引，以便于挖掘包含预设模式的网络资源；将研究藏文网页的全自动篇章抽取技术和汉藏双语平行语料的自动发现技术，并自动采集藏文篇章语料和汉藏双语平行语料；本项目将建立藏文文本资源URL库、藏文篇章语料库、互联网藏文词（短语）库、汉藏双语平行语料库，并基于大规模藏文语料进行词频统计、训练藏文语言模型，为藏文信息处理的研究提供基础资源。
基于单语语料的无监督统计机器翻译模型研究	单语语料;基于短语的统计机器翻译;无监督学习	目前，几乎所有的统计机器翻译模型都建立在双语平行语料上。给定某一领域足够的双语平行语料，现有的统计机器翻译模型能够获得较为满意的翻译结果。然而，由于现实中双语平行语料很难收集，当面对一个缺乏双语平行语料的语言对或领域时，统计机器翻译质量就会急剧下降。相反地，绝大多数语言的各领域单语语料大量存在于网络之中，且易于获取。因此，本项目旨在充分利用网络中的大规模单语语料，研究并构造面向单语语料的基于短语的统计机器翻译模型。在自动获取源语言和目标语言同一领域的大规模单语语料后，本项目着重研究基于单语语料的概率化双语词典的无监督构建方法、双语短语翻译规则的学习方法以及翻译模型与调序模型的概率估计方法。本项目通过创造性地重新设计翻译模型的构造过程，力图突破双语平行语料对统计机器翻译的限制，使统计翻译得到更加广泛深远的发展。
海量、动态、嘈杂语义数据集上的递增随时推理方法研究	嘈杂语义数据;海量语义数据;消解相关;递增随时推理;动态语义数据	本项目提出海量、动态和嘈杂语义数据集上的递增随时推理方法。立项依据是：1、传统推理方法追求完整解，并假设数据的稳定性和一致性，无法处理具有上述特征的语义数据集；2、在前期研究中，1）我们已经初步建立了嘈杂语义数据的处理方法，且实验表明推理结果的质量提高了约一倍（该工作为欧盟最大的语义网项目LarKC中城市计算子项目，结果发表在语义网领域顶级国际会议ISWC2011）。2）提出了消解相关性函数优化推理性能的方法（工作已申请三项PCT国际专利，发表一篇国际杂志文章）。3）提出了使用搜索结果计算一般语义距离的方法（工作已申请一项国内专利，发表一篇国际会议文章）。这些研究结果初步验证了递增随时推理方法的可行性。本项目计划进一步扩展研究工作，完成三个核心任务：1、设计消解相关函数来递增选择最重要的数据进行推理；2、使用消解相关树动态更新解的有效性；3、使用一般语义距离保证嘈杂语义数据推理中解的合理性
面向移动应用的个性化排序学习研究	动态用户偏好;移动应用表示学习;语义匹配;排序学习;个性化排序	随着移动应用数量的迅猛增长，用户要从浩瀚的应用海洋中发现感兴趣的移动应用越来越困难。作为帮助用户发现信息的一种重要手段，信息检索在工业界和学术界已经得到广泛的关注与研究。然而面对移动应用这一新兴媒体，主流的检索模型排序学习也面临着很大的挑战，包括信息异质化、展示受限、情境化排序等问题。针对上述挑战，本课题拟以用户查询日志以及移动应用使用日志为基本资源，研究基于矩阵分解的多元异质信息的表示学习，基于展示优化与排序优化的排序学习算法，基于动态偏好与深度学习的个性化语义匹配等问题。从工业界来看，本课题的研究能够惠及移动应用分发平台，用户以及开发商。从学术界来看，本课题的研究，能够帮助解决大规模异质信息的发现与获取中面临的基本问题。
社区问答系统关键技术研究	社区问答;答案筛选;标签推荐;问题匹配	社区问答系统是一种建立在问答社区之上的新型问答系统，并已成为新一代搜索引擎的重要发展方向，具有重大的理论意义和巨大的商业价值。本项目拟充分利用大规模社区问答网站中所蕴含的海量知识，并针对社区问答中文本所具有的显著特点（短文本、不规范性、开放性等），综合运用自然语言处理、文本挖掘与信息检索等技术，提取和融合问答社区产生的文本数据和用户交互数据的多源特征，准确度量社区问答中各类短文本之间的相关性，力争在面向社区问答的社会化标签推荐技术、相似问题匹配技术、以及高质量答案筛选技术方面有所突破，取得原始性的创新研究成果。在此基础上，设计并实现更为高效、准确的社区问答原型系统，改善系统生成答案的质量。本项目的研究成果可为建立社区问答系统提供理论基础与技术支撑，有助于提高信息检索的服务质量。
跨语言文本自动分类关键技术研究	信息检索;文本挖掘;跨语言;文本分类	文本分类是文本挖掘的关键性和基础性问题之一。日益加快的全球一体化进程对跨语言的文本分类技术提出了迫切的需求。虽然目前研究者们已经进行了大量的文本分类相关研究工作，但是针对的跨语言文本分类问题的研究比较匮乏，限制了跨文本挖掘的发展和应用。本项目将针对多语言环境下跨语言文本分类的关键问题进行深入研究。具体研究内容包括：（1）基于特征概念的文本表示方法和特征概念的提取方法；（2）跨语言的文本相似度计算方法和类别判定方法；（3）中英跨语言分类测试语料集合的建立，实现原型系统，对算法进行评价和改进。通过本项目的研究，不仅能突破跨语言文本分类的难题，还可为跨语言的信息检索和文本挖掘提供有效的基础算法，使更大范围和更深层次的跨语言应用成为可能。
基于结构化学习的有监督词对齐方法研究	统计机器翻译;词对齐;有监督;结构化预测	机器翻译是自然语言处理和人工智能领域的重要问题之一，在文本信息处理的各个方面都得到了广泛的应用。词语对齐是统计机器翻译的必需步骤，对机器翻译的结果有决定性的影响。传统的词对齐采用无监督的方法，近年来，人们开始利用有标记的信息进行有监督的基于结构化预测的方法来提高词对齐的效果。 针对现有的基于结构化预测的词对齐研究中存在的难以融入全局特征、数据稀疏、领域不一致等问题，本项目拟结合国内外现有的研究成果，在结构化预测的框架下，采用基于压缩森林的重排序方法、协同训练、子样本加权等策略，探索更为有效的利用标记数据的词对齐学习方法，从而提高机器翻译系统的效果。
基于图结构的迁移学习在文本倾向性分析中的应用研究	直推式迁移学习;归纳式迁移学习;图结构;迁移学习;文本倾向性	由于文本倾向性分析中数据同分布假设不成立会造成机器学习泛化能力降低，本项目拟利用基于图结构的迁移学习方法对此类问题进行研究。具体的研究工作包括：首先分析具有倾向性文本中特征的特点，利用图模型有效地表示出已标注文本、特征和未标注文本之间的关系，建立基本的用于迁移学习的图结构模型；在此基础上，融合基于特征和基于实例的迁移学习方法，提出基于图结构的知识传播迁移学习算法；结合半监督学习方法，提出基于图结构的协同迁移算法；最后，针对目标领域中的标注样本的不同情况，进行直推式迁移学习、归纳式迁移学习和无监督迁移学习模型的对比研究，以相关语料为应用背景验证模型的有效性。课题旨在以图结构为文本及其语义的基本表示模型，从迁移学习模型的建立入手，以文本倾向性分析为应用领域，提出有效的迁移学习方法，为迁移学习技术的进一步研究与应用提供新思路和理论依据。
面向日地空间安全的大规模极光图像检索研究	卷积神经网络;日地空间安全;图像检索;大规模极光数据	极光是唯一能够用肉眼观测到的反映日地空间作用过程的地球物理现象，对极光有效数据的筛选和关键数据的分析可以帮助人类在有限时间内获取太阳风与地球磁场活动的大量信息，为日地空间安全提供可靠的技术保障。由于极光成像原理和图像内容不同于自然图像，现有检索系统的特征提取方式难以满足大规模极光图像检索的需求。为了解决这个问题，本项目拟从基于内容的图像检索技术出发，结合极光成像特点和深度学习模型，针对查询图像全面统计、重点图像精确分析和特殊图像实时预测的任务需求，分别设计基于多级卷积神经网络、分层卷积神经网络和显著域卷积神经网络的图像检索算法，以提高大规模极光图像检索系统的查全率、查准率和速度性能。本项目具有极化深度特征的有效提取、上下文语义信息的合理融合和多学科交叉合作的协同开展三个创新点，能够辅助物理学者完成日地空间的建模和预测工作。
基于知识库和深度学习的生物医学实体关系抽取研究	关系抽取;深度学习;表示学习;知识表示;实体识别	生物医学实体关系抽取研究是精准医疗时代的主要任务，对临床疾病的诊断、治疗和药物的研制具有重要意义。大规模的生物医学知识库和海量生物医学文本为生物医学实体关系抽取提供了有力的支持。融合生物医学词典、知识库和文本中有关于实体和关系的信息，开展知识表示学习研究，对于实体关系抽取具有重要的理论意义和实际应用价值。本项目首先利用生物医学词典，基于自动编码机，学习准确、完备的生物医学实体表示；然后利用生物医学知识库和海量文本，基于翻译模型和远程监督学习，实现实体融合和关系融合的知识表示，提高知识表示的区分能力；最后基于深度学习，综合利用知识表示和语言学特征，识别生物医学实体并抽取实体关系，提升实体关系抽取准确性和覆盖面。基于词典、知识库和文本等多源异质信息的知识表示学习研究，将为生物信息抽取中知识的获取、融合提供理论基础和方法支撑；研究生物实体关系抽取将有助于更深层次认识生命活动，促进生命科学的发展。
基于Wiki的垂直搜索语义技术研究	维基百科;垂直搜索;信息检索;语义Web	目前的Web搜索技术只是部分地解决海量信息资源的发现问题，信息的查全率和精确度仍然不能满足用户的需求。本项目针对当前的万维网环境下垂直搜索引擎的特点，利用维基百科丰富的语义资源，将传统信息检索技术与语义Web技术相结合，优化信息检索过程。具体内容包括：提出知识单元的语义表示方法，挖掘Wiki丰富的结构化语义关系，构建概念间的语义关联矩阵；给出主题爬虫的网页主题相关性度量方法，构建动态主题语义词典，提出垂直搜索引擎的查询自动分类算法；针对具有语义数据格式的文档索引，对语义信息进行不同粒度的解析，建立语义三层索引模型；提出语义搜索模型及其结构框架，对描述逻辑进行模糊扩展，以增加本体描述语言的模糊概念表达能力，探讨基于模糊Tableaux的可满足性推理算法。本项目的研究对探索实现智能搜索引擎具有重要的实际应用价值。
基于认知特征的新闻事件在线评论观点自动摘要方法与社会情绪测量模型	情感分析;观点挖掘;网络舆情;网络文本;短文本	利用网络在线评论数据获取重大新闻事件中公众的主要看法、社会情绪等民意信息不仅是重大突发事件应急管理的迫切需要，也是计算社会学研究的重要基础。本项目借鉴"阅读网络在线评论——感知内在社会情绪"这一人们的认知过程，研究从新闻事件网络在线评论中自动归纳公众对事件的主要看法，进而识别看法中隐含的深层次社会情绪的方法和模型。首先，基于社会心理学理论与历史数据挖掘结果，析取出社会情绪的结构特征，并以此为基础设计标准的心理学认知实验；然后从语义计算的角度，从原始评论中对情感单元进行准确的抽取和识别，并基于观点内在的社会情绪相似性对评论集进行科学划分和摘要生成；最后基于认知实验数据，建模实现从观点评价对象的社会角色特征到整个评论集蕴含的社会情绪强度的映射。本项目的研究将推进文本情感分析研究，为网络社会情绪的量化评测奠定理论和方法基础，并对重大事件应急管理决策系统开发、计算社会学问题研究提供技术支撑。
基于仿生模式识别理论的网站分类导航技术研究	网站主题结构;网站主题概念;网站分类;仿生模式识别	本申请研究一种应用仿生模式识别理论，在剖析网站的主题结构、提炼网站的主题概念基础上，实现网站按主题类别划分、按权威性排序的技术。网站分类导航技术的研究，在分类信息网站建设、专业化信息服务和领域知识库获取等方面具有非常广阔的应用前景。本申请采用关键资源生成的网站主题向量作为站点描述模型。在最为关键的网站分类算法中，引入了仿生模式识别的思想，它的基于"认识"而非"划分"的分类知识学习策略，更接近于人的学习过程，具有分类准确度高，学习性能好的特点。在获取网站关键资源的策略上，采用启发式信息结合相对熵的策略对网站拓扑结构进行剪枝，以提取网站的主题结构，并对其链出的网页运用页面结构与内容分析技术，消除文本噪声，以提高网站分类精度。本申请的相关研究成果，不但可以为网络信息分类导航系统提供解决策略和支撑技术，而且也将为仿生模式识别理论研究提供重要参考。
面向网络异构信息源的问答资源挖掘	语义相关性;问题生成;异构信息源;答案融合;问答对挖掘	当前影响广泛的在线互动问答社区系统(CQA)存在答案延迟或缺失、答案不完整、噪声严重等突出问题，对存在于互联网的海量问答资源进行挖掘和整合，形成一个全面准确的问答知识库，是解决上述问题的关键。从具有不同结构和文本特点的信息源中提取问答对知识涉及自然语言处理、机器学习、文本挖掘等领域的诸多方法和技术。本项目面向互联网中异构的问答信息源，以受限领域的在线互动问答社区系统、在线论坛和普通网页等典型场景为主要对象，研究如何智能化地挖掘和整理在互联网中广泛存在的包括用户在网络交流过程中自然产生的问答资源。涉及的关键问题包括：问答对语义相关性计算、答案融合、文本特征与非文本特征的优化与融合方法、逆向问题生成、增量式在线学习以及问答挖掘的评价标准等。在此基础上，探索互联网异构信息资源挖掘的普遍规律和通用方法。本项目的实施对问答系统和自然语言处理研究以及相关互联网应用的发展有重要推动作用。
数据紧致性在图像挖掘中的应用	界紧致性;图像挖掘;流形学习;数据紧致性;类紧致性	目前国内外对于图像挖掘的研究还不是十分成熟，很多理论上的问题还有待进一步发展。其中一个重要问题就是如何对图像数据进行紧致性分析并将之应用在图像聚类和图像分析中。我们观察这个世界，将各种场景进行归类、分析，在这个过程中数据紧致性起着非常重要的作用。世上的物体千变万化，但它们的外貌都有相对稳定、相对紧凑的模式，这其中就包含了数据紧致性。本项目将面向图像挖掘的应用问题，针对图像数据所具有的高维、大量、非线性问题，对图像数据的类紧致性和界紧致性进行理论探讨，并研究在具体的图像挖掘应用中所需的特定技术。
基于语言特性分析的互联网伪信息的自动识别与评估研究	伪信息;语言特性分析;机器学习	本项目研究探讨使用语言特性分析来自动评估互联网文本信息的可靠性问题。为此，定义可靠性和真实性不足的信息为伪信息。包含伪信息的网络文本和主要企图欺骗搜索引擎的传统网页垃圾不同，其主要针对对象是互联网用户本身，即，试图欺骗或者误导它的阅读者。当今互联网上的伪信息分布泛滥及其严重的危害性迫切要求适当的技术手段加以应对。本项目通过明确定义可计算的伪信息（在此主要指文本伪信息），以及应用和发展基于语言特性分析的方法,使用两种新型的机器学习模型集成多重知识源来有效地自动鉴别这类信息。其中，多种基础性的自然语言处理技术，包括相似文本检索、语言风格识别、连贯性检测、命名实体分布统计、表达强度词典构建等针对性地用于实现伪信息特征表示。本项目有望最终发展出一整套系统化的技术框架来有效应对已日益严重的伪信息现象并针对性发展出一系列相关的基础自然语言处理技术。
大规模汉语历时语料库建设及词汇语义变迁研究	中文信息处理;语言变迁;历时语料库;词义消岐;本体挖掘	语言变迁研究作为社会语言学的一个重要课题，在过去半个世纪中取得了显著成就，然而借助自然语言处理和语义挖掘技术对此进行的研究却比较少。一方面是因为，计算方法给出的是统计结果，无法达到社会语言学家的精确性要求；另一方面是因为，目前尚缺乏切分和词性标注并经人工校对的大规模历时语料库。本课题拟以申请者现有工作基础出发，从三方面开展研究工作：（1）汉语历时语料库建设：拟建以现代汉语为主体的，包含部分古代汉语语料的大规模历时语料库；同步建设网上语料库检索与数据可视化应用平台。(2)历时本体挖掘算法研究以及汉语历时词汇本体知识库建设。(3)基于历时词汇本体的现代汉语词汇语义变迁研究与词汇义项标注知识库建设。综合上述三方面的工作，该研究旨在构建大规模历时语料库（包括历时词汇本体知识）的同时，呈现一个完整的采用计算方法实现语言变迁研究的应用示范。
基于自消歧模式的语法知识自动获取技术研究	实例化;自消歧模式;语法属性;自动获取;概率化	前人在语法知识自动获取方面基于统计方法进行了许多探索和实验，已取得较大进展，但与语言学知识的融合相对较少；现有语法知识库多是语言学专家人工构建的，精度比自动获取的结果高，但是在覆盖度、扩展性、定量化等方面不如自动方法。本研究尝试将语言学知识与统计方法结合起来，基于自消歧结构从大规模语料库中自动获取语法知识。所谓自消歧结构指的是具有消解自身歧义能力的结构，比如含有"了"的结构可以确定出现在"了"前面的那个动词是谓语，而不会是定语。基于自消歧结构既可以实现词语小类（如名量词、动量词）的标注，也可以实现词语搭配的语法结构关系（如动宾、定中、主谓等）的自动标注。本研究将充分利用分层次、超大规模语料库以及人工构建的自消歧结构集合，获取词语搭配的实例以及频次信息，实现语法知识库的概率化和实例化；结合未登录词词类和语义类标注，实现语法知识库的辅助修正和编纂。
面向互动语言场景的类量子语言模型关键理论和技术研究	信息检索;自动问答;搜索意图;自然语言处理;语言模型	语言模型是自然语言处理相关研究的重要基础，并始终是研究热点之一。近年来，人们基于量子理论提出了量子语言模型，但是该模型本质上仍然停留在建模文本的似然性层面，尚未充分建模互动语言的不确定性，也未能融合量子理论中不确定性的核心元素。因此，为了深入发展量子语言模型的理论和应用，本项目将结合量子认知相关研究，关注于互动语言场景（涉及用户与系统的语言互动、用户与用户的语言互动）下，语言含义、语义关联、用户认知等语言和认知层面的不确定性问题，并着重研究其中诸如类量子纠缠和干涉等宏观类量子语言现象，从而建立类量子语言模型框架。进一步地，利用该框架建模用户意图即信息需求的不确定性，如潜在性、动态性和干涉性，发展新颖的用户意图表示和匹配算法。为了提升类量子语言模型的应用效果，拟结合神经网络的训练算法，优化类量子语言模型的参数，从而将其有效应用于互动语言场景的典型任务即交互式信息检索以及自动问答与对话中。
过程挖掘算法评估框架研究	框架;评估;过程挖掘;事件日志;工作流网	过程挖掘旨在从业务过程执行产生的事件日志中挖掘有价值的客观信息，这些信息对部署新的业务系统（过程建模），或者分析、审计、改进已实施的业务系统（变化分析）具有重要的参考价值与现实意义。近年来各种过程挖掘算法发展非常迅速，但缺乏通用的方法来评估由这些算法发现的过程模型的质量，进而很难对算法的优劣进行客观评价。本项目尝试建立一个包含三部分内容的过程挖掘算法评估框架：(1)提供具有各类典型特征的多组事件日志以及对应参考模型作为公共测试集（含过程模型及日志自动生成工具）；(2)提供一组常见过程建模语言到Petri网的转换工具；(3)提供一整套针对Petri网的综合度量工具。本项目的研究将有助于形成过程挖掘算法的基准测试平台，从而推动过程挖掘技术的成熟和完善；同时将有助于推广过程挖掘技术在企业中的实际应用，降低业务过程建模、审计和优化的难度，提高业务过程管理的效率和效益，进而提高企业的核心竞争力。
短文本的精确语义感知与多分类研究	多分类;精确语义;知识库;推理;短文本	对文本的语义研究是自然语言处理以及人工智能的难点与热点问题。本项目首次将"精确语义推理"作为研究重点，从语义、精确推理以及多分类三个方面对短文本感知展开全面的研究。主要研究内容包括：①语义研究，即从词汇语义学、认知语言学、认知学等语言学领域以及计算机领域的知识工程，本体知识库等入手，研究探索从哪个方面或者用哪种方法可以更好地将词义（即词汇所蕴含的知识）用一种形式化或计算机化的方法表示出来；②精确推理研究，即研究在什么条件下、应该用或者不应该知识库中的哪些知识，以及研究如何使用语义知识、各种语义知识在使用时是否有共性、有哪些共性等；③多分类研究：即在语义以及精确推理机制的支持下，研究如何将文本按照不同的维度，即文本的社会属性，如：主题类别、传播等级、情感极性以及政治敏感性等，和不同的层次，如篇张、段落和句子，进行分类。
基于关键词的大规模链接数据搜索技术研究	语义网;链接数据;语义搜索	链接开放数据项目已经汇集了超过50 billions的RDF三元组，主题覆盖出版物、地理、多媒体、生命科学等众多领域。如何帮助用户获取感兴趣的数据和信息是当前语义Web研究领域最关心的问题之一。相比SPARQL查询必须掌握查询语言语法和待查询数据模式，普通用户更适合关键词查询方式。现有语义Web搜索引擎往往仅提供RDF文档或实体的搜索，不支持更复杂的查询需求（如查询多个实体及实体间的关系）。本课题研究基于关键词的大规模链接数据搜索问题：研究多粒度链接数据摘要模型和索引方法；研究关键词查询理解方法；研究高效地将关键词查询转换为结构化查询（用查询图表示）的方法；研究查询图相关性评价问题。最终帮助用户在大规模、异构、互链数据中跨数据源地进行高效和有效的关键词搜索。
面向大规模XML文档集的关键词检索系统关键技术研究	大规模XML文档集;交互检索模型;结果评分方法;关键词检索;Top-k查询	随着大量数据以XML文档的形式存储和发布，人们亟需从这些数据中获取有价值信息，而现有XML关键词检索方法和技术不适用于处理大规模XML文档集。针对这种现状，我们提出面向大规模XML文档集的实用性强、交互性好的关键词检索系统的关键技术的研究课题。本课题拟引入机器学习的方法，解决内容和结构在结果评分中的融合问题，建立有效的结果评分方法，提高XML关键词检索效果；研究支持非单调评分方法、增量以及近似查询的Top-k查询理论方法，设计支持多种查询语义模型的Top-k查询算法，快速响应用户；研究关键词查询自动转换成树结构查询的技术，建立基于树结构查询推荐的用户交互检索模型，提高用户准确表达信息需求的能力、改善用户体验。以上述研究成果为基础，研制原型系统，形成一系列符合面向大规模XML文档集关键词检索特点的关键技术。我们的研究工作将丰富和发展XML关键词检索的理论和方法，具有重要的理论意义和实用价值。
基于深度句法的统计机器翻译方法研究	翻译优化;统计机器翻译;解码算法;句法分析;训练算法	统计机器翻译已经从基于词的模型发展到基于短语和基于传统句法的模型。虽然基于传统句法表示的机器翻译已经受到很多研究者的关注，但是直接沿用单语句法分析中的句法表示形式，并进行相应的建模已经进入了平台期。如何在机器翻译中使用深度句法信息并构建基于多层次句法的机器翻译框架已经成为了当前机器翻译中的主要问题之一。本项目拟围绕此问题展开研究工作，主要研究内容包括：1）研究面向机器翻译的深度句法表示形式；2）研究翻译推导模型，并探索基于多层次句法的统计机器翻译框架。最终，本项目的研究成果会被集成到NiuTrans开源平台中，为学术界共享使用。
蒙汉双语网络挖掘层次关联分析方法研究	互译词汇;蒙汉双语;平行句对;层次关联挖掘;可比篇章	互联网挖掘蒙汉双语文本资源的研究，对蒙汉双语资源建设具有重要的意义。目前网络中的蒙汉网页，对同一事件的描述文档多为非互译文本；同时蒙汉网页中文本的描述语言，在语言形态方面也存在着较大差异，容易出现匹配漂移的现象。上述问题，增加了蒙汉双语文本资源挖掘的困难。本项目拟采用层次关联挖掘的策略，依据蒙汉双语可比篇章、平行句对和互译词汇各层次（粒度）之间的关系，提高不同语言匹配的相关性，克服上述困难。主要工作：1、研究蒙汉双语知识融入跨语言主题模型表征方法，提高可比篇章中主题匹配的一致性；2、研究篇章、主题和上下文距离等参数对词汇匹配的影响，提升互译词汇抽取对多层次特征的敏感性；3、研究主题聚集、句法对齐和词汇消歧增强方法，提高词对齐性能较低的意译句对与可比句对的区分性。本研究将为可比语料挖掘蒙汉双语资源提供新思路与方法；为同属于形态差异较大的汉/维/日/韩等各语种可比语料文本挖掘提供有益参考。
汉语词法与句法结构的统一分析	词法结构体系;词法分析;句法分析;统一分析模型	汉语中词法与句法的界限比较模糊，导致在分词、词性标注及句法分析等汉语处理的基础环节中均遇到性能瓶颈。本项目围绕汉语这一特点，实现词法与句法结构的统一分析，打破词法与句法在汉语自动分析技术中的人为分界。为此，本项目将深入考察汉语构词特点，研究词的内部结构体系以及词内部结构与短语结构的关系，制定完善的词语结构标注规范，并据此在已有树库上标注规模为6至8万词的结构，得到词法与句法结构一体化标注的树库。在此基础上，从成分分析与依存分析角度设计词法和句法结构的统一分析模型及相应分析算法，使得对于给定未分词的汉语句子，系统输出结果同时包含词法与句法结构。本项目所研究的词法与句法统一分析，不仅可以为中文信息处理系统提供便于使用、涵盖各种语言粒度、高效准确的词法和句法分析结果，而且还可以通过计算、建模手段，加深我们对汉语的理性认识，因此，实施本项目将具有工程实践和科学探索两方面的意义。
面向小气候观测的气象传感网布局优化与数据融合算法研究	小气候观测;气象传感网;布局优化;数据融合	小气候传感网的观测数据是从事专业小气候预报研究与应用的基础，气象传感网的布局是否合理直接影响这些观测资料的代表性和准确性。观测数据的融合质量直接影响数据收集效率和网络寿命。由于现有气象传感网的布局优化和数据融合研究存在着气象要素场各向同性和均匀的假设条件，并且没有考虑传感器服务对象等问题。本项目：（1）提出基于径向基函数神经网络的插值模型来确定气象观测传感器的类型与最佳位置，此模型引入气象要素的多个环境影响因子和多种观测资料，提高气象传感网观测资料的代表性与准确性。（2）提出插值误差均衡的分簇式优化方法来确定站网的最佳密度，此方法根据研究区域子区域特点和气象传感网服务对象来权衡各子区域的插值误差。（3）提出基于感知数据时空相关性的低时延压缩感知数据融合模型，减少传输数据的冗余性，提高网络生命周期。本项目旨在利用气象基础、网络优化和数据融合等理论为气象传感网的应用研究提供新思路和理论参考。
基于社会化媒体的网络信息无障碍关键技术研究	信息推荐;视障人士;信息检索;信息无障碍;社会化媒体	目前信息无障碍领域的研究主要致力于帮助视障人士访问传统网络媒体，至今还没有一套较为完整的技术方案可以帮助视障人士顺利地访问新兴的社会化媒体。在本申报研究项目中，我们将在国内外率先开展方便视障人士获取社会化媒体信息的访问机制研究。通过结合社会化媒体的特性，以及视障人士的认知特点，研究先进的智能信息处理技术，对社会化媒体网络信息进行不同层次的重构，降低其信息访问复杂度。我们将致力于研究交互式用户界面技术；结合文本语义和页面结构布局的网页切割和重组技术；面向社会化媒体的自适应自动文摘技术；基于情景的社会化媒体信息推荐技术；基于概念语义网的社会化媒体信息推荐及解释技术。该项目的成功实施，必将对面向视障人士的网络信息智能化处理研究产生积极影响，使我国在基于社会化媒体的网络无障碍领域的研究处于国际先进水平。其研究成果还可以广泛运用于社会化媒体的热点问题跟踪、舆情分析以及精准营销等诸多领域。
物联网流数据信息处理技术研究	智能处理;流数据;物联网;数据挖掘;信息系统	传统的数据处理方式不再适用于物联网应用中的实时流数据处理，但尚未产生新的方法来解决这个挑战，这将阻碍物联网的大规模应用。本项目针对物联网实时应用环境中机器可理解的异构流数据处理方法进行理论探讨与算法研究，并将成果应用于物联网智能前端中。研究内容包括：设计异构物联网流数据的统一语义描述框架，设计具有集成能力的异构流数据接入方法；构造基于滑动窗口模型方法的物联网异构流数据概要数据结构，研究基于流密度估计的计算负载自适应算法和实时性评价方法；研究支持多用户并发查询请求的分层概要结构和规则匹配引擎，设计用于机器-机器交互的基于规则的消息推送服务，利用智能前端组建试验网络应用验证。项目研究目标为提供一个适用于物联网应用的异构流数据处理环境，解决人-机器、机器-机器之间协同感知的语义一致性、实时性与并发性挑战。
伪事件关系检测基础理论与关键技术研究	伪逻辑事件关系;混淆事件关系;篇章关系理解;歧义事件关系	伪事件关系是一种偏离或违背客观规律的事件关系，衍生于主观思维触发的知识体系，繁殖于以语言为载体的信息表述与传播过程，具有关联混淆、关系歧义与逻辑混乱三种特性。伪事件关系检测是自然语言理解与舆情信息分析交叉领域的重要课题，对于解析自然语言描述事件关系时的语义和语用规律，以及辨识舆情信息中事件关联逻辑的真伪，都具有重要的研究价值。目前，针对伪事件关系的理论研究尚未开展，相应的检测技术也属空白。针对这一现象，本课题以篇章关系理解为理论基础，以伪事件关系的语言特性为重点分析对象，形成伪事件关系检测的任务体系，并相应地对如下关键问题予以研究：关联事件识别、关系线索挖掘、混淆事件关系、歧义事件关系和伪逻辑事件关系检测。特别是研究利用多线索融合的事件混淆关系检测；利用同指焦点的事件歧义关系检测和基于全局关联脉络约束的事件伪逻辑关系检测三项关键技术。目标是实现针对舆情的伪事件关系自动识别与检测。
面向辅助翻译的多模型融合方法研究	基于实例的机器翻译;计算机辅助翻译;统计机器翻译;自然语言处理;译文置信度估计	目前统计机器翻译系统的翻译质量还无法真正满足实际翻译要求，基于翻译记忆的计算机辅助翻译软件仍然是专业翻译领域的主流工具，但是它的结果仍然需要大量的人工后编辑才能满足实际应用需求。由于翻译记忆、基于实例的机器翻译方法以及统计机器翻译在不同方面优势互补，如果能够在辅助翻译系统中引入自动机器翻译，替代一部分人工后编辑的工作，将会极大地提高翻译效率。因此，本项目面向辅助翻译应用需求，研究融合翻译记忆、基于实例的机器翻译方法和统计机器翻译模型的多模型融合新方法，主要开展以下研究：1、针对各模型的优缺点，提出在解码过程中协同考虑三种模型的融合辅助翻译方法；2、针对提出的融合模型，研究并验证其领域适应性问题；3、研究适用于该融合模型的译文置信度评估方法。该项目中的关键技术一旦得到攻克，将为翻译人员提供更好的参考译文，从而极大地提高人工翻译效率。该研究不仅具有重要的理论研究意义，而且具有广阔的应用前景。
统计机器翻译中的参数学习问题研究	非线性模型;参数学习;参数估计;翻译评价;结构化学习	统计机器翻译的学习过程实际是遵照机器翻译问题的特点和规律对参数进行定义，并根据一定的翻译质量评价标准，采用一定的机器学习方法从训练数据中对参数进行估计的过程。本项目从参数学习的角度看待这个过程，将整个过程称为参数学习过程。参数学习过程对提高机器翻译的翻译质量有着直接而重要的影响，是探索高质量机器翻译的必须解决的重要问题。同时，因为机器翻译是一类特殊的结构化学习问题，这类问题的参数学习研究也为机器学习和数据挖掘领域的研究提出了新的挑战。本项目的研究试图从参数建模、翻译评价、学习方法三个方面重新思考统计机器翻译问题，研究可扩展的非线性参数建模方法，适合参数学习的翻译评价标准以及与之相适应的结构化学习策略，从而形成一套可扩展、结构化的机器翻译参数学习框架。
基于深度神经网络的实体关系抽取关键技术研究	深度神经网络;非结构化文本;实体关系抽取	作为自动构建大规模知识库的一项核心技术，实体关系抽取对人工智能的发展有着重要的意义。深度神经网络的快速发展为实体关系抽取带来了新的思路，本申请课题针对传统实体关系抽取方法存在的缺点，以构建大规模的、快速更新的知识库为目标，以非结构化文本为抽取对象，研究基于深度神经网络的实体关系抽取中的关键技术，具体研究内容包括：1）针对传统特征鲁棒性较差，研究使用深度神经网络进行实体关系抽取方法，通过深度神经网络自动学习更具鲁棒性的特征，尽可能少地依赖现有的自然语言处理工具；2）针对弱监督实体关系抽取方法存在数据回标噪声，研究怎样在基于深度神经网络的实体关系抽取框架下解决此问题；3）针对深度神经网络对于专家知识的自动学习能力有限，研究怎样进行多源信息融合以提升实体关系抽取的效果。本申请课题的研究成果将为自然语言理解、互联网信息深度计算等提供参考。
中文自动口语摘要技术研究	语音识别;多信息融合;口语自动摘要	面对信息时代海量的多媒体数据，以智能处理手段实现高效的信息检索和数据管理的需求已极为迫切。自动摘要技术能够实现对文档内容的压缩和精炼，是信息快速获取和数据有效管理的关键技术。面向文本的自动摘要在国内外得到广泛关注，而口语文档自动摘要技术的研究则刚刚起步。最直接的口语自动摘要实现方案是先对口语文档进行语音识别，再利用文本摘要技术自动提取口语文档摘要，但这个方案既不利于处理语音识别引入的错误，也不利于挖掘口语文档所携带的大量信息。本课题将超越上述串行框架，充分挖掘口语文档中语音信号和识别得到的文本中所蕴含的各种信息，针对自动提取高性能口语文档摘要的目标进行整体设计和优化。研究内容包括：面向口语自动摘要任务的特征选择，面向不同特征的多分类器设计和参数学习算法，多知识源融合的测度统一的整体模型，从最优化角度研究高效覆盖口语文档内容的摘要提取方法等。本课题的研究对口语文档的理解和使用具有重要价值。